{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778d26e2",
   "metadata": {},
   "source": [
    "# Image Hybrid Neuroevolution Notebook\n",
    "\n",
    "This notebook implements a hybrid neuroevolution process for image classification (Parkinson detection from spectrograms). The system combines genetic algorithms with 2D convolutional neural networks to evolve optimal architectures for image processing.\n",
    "\n",
    "## Main Features:\n",
    "- **Hybrid genetic algorithm**: Combines architecture and weight evolution\n",
    "- **2D Convolutional Networks**: Optimized for spectrogram image processing\n",
    "- **5-Fold Cross-Validation**: Each individual is evaluated on all 5 folds sequentially (fitness = average accuracy)\n",
    "- **CUDA-safe training**: Sequential fold training to avoid GPU memory conflicts\n",
    "- **Adaptive mutation**: Dynamic mutation rate based on population diversity\n",
    "- **Image dataset support**: Loads spectrogram images from PNG files\n",
    "- **Intelligent stopping criteria**: By target fitness or maximum generations\n",
    "- **Complete visualization**: Shows progress and final best architecture\n",
    "\n",
    "## Objectives:\n",
    "1. Create initial population of 2D CNN architectures\n",
    "2. Evaluate fitness of each individual using **5-fold CV** (robust evaluation)\n",
    "3. Select best architectures (elitism)\n",
    "4. Apply crossover and mutation to create new generation\n",
    "5. Repeat process until convergence\n",
    "6. Display the best architecture found for Parkinson classification\n",
    "\n",
    "**âœ… Performance**: Sequential 5-fold CV provides robustness against overfitting and is CUDA-safe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f1170",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ¨ CONFIGURACIÃ“N ACTUAL DEL DATASET âœ¨\n",
    "\n",
    "**Dataset configurado**: `images_all_real_syn_n` (Espectrogramas como ImÃ¡genes PNG)\n",
    "\n",
    "Este notebook estÃ¡ configurado para usar el **nuevo dataset de imÃ¡genes** generado con `npy_to_spectrograms.py`:\n",
    "- ðŸŽµ **Espectrogramas como ImÃ¡genes**: Archivos PNG generados desde datos .npy  \n",
    "- ðŸ–¼ï¸ **Formato**: ImÃ¡genes RGB de espectrogramas de audios\n",
    "- ðŸ“Š **5-Fold Cross-Validation**: Organizado en carpetas train/val/test por fold\n",
    "\n",
    "**Ventajas de este dataset**:\n",
    "- Mayor diversidad de datos para entrenamiento\n",
    "- Procesamiento mediante Conv2D (Ã³ptimo para imÃ¡genes)\n",
    "- VisualizaciÃ³n directa de los espectrogramas\n",
    "- EstratificaciÃ³n balanceada entre clases (control/patolÃ³gico)\n",
    "\n",
    "**ðŸš€ 5-Fold Cross-Validation durante la EvoluciÃ³n**: \n",
    "- **CADA** individuo se evalÃºa en **TODOS** los 5 folds **SECUENCIALMENTE**\n",
    "- Los folds se entrenan uno tras otro para evitar conflictos de CUDA\n",
    "- El fitness es el **promedio** de accuracy de los 5 folds\n",
    "- âœ… **CUDA-safe** - evita errores de memoria de GPU\n",
    "- âœ… **MÃ¡s robusto** - evita sobreajuste a un fold especÃ­fico\n",
    "\n",
    "**ðŸ“Š EvaluaciÃ³n Final**: \n",
    "- Al terminar la evoluciÃ³n, la mejor arquitectura se vuelve a evaluar con 5-fold CV\n",
    "- Se reportan mÃ©tricas completas (accuracy, sensitivity, specificity, F1, AUC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfc737",
   "metadata": {},
   "source": [
    "## 1. Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c37071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dependency installation for Image Hybrid Neuroevolution...\n",
      "============================================================\n",
      "Installing torch>=2.0.0...\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torch>=2.0.0 installed correctly\n",
      "Installing torchvision>=0.15.0...\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (1.24.4)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torchvision>=0.15.0) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (10.0.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->torchvision>=0.15.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision>=0.15.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.8.0->torchvision>=0.15.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torchvision>=0.15.0 installed correctly\n",
      "Installing numpy>=1.21.0...\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK numpy>=1.21.0 installed correctly\n",
      "Installing matplotlib>=3.5.0...\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK matplotlib>=3.5.0 installed correctly\n",
      "Installing seaborn>=0.11.0...\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK seaborn>=0.11.0 installed correctly\n",
      "Installing tqdm>=4.64.0...\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (4.65.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK tqdm>=4.64.0 installed correctly\n",
      "Installing jupyter>=1.0.0...\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.5.4)\n",
      "Requirement already satisfied: jupyter-console in /home/jovyan/.local/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (8.0.6)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (4.0.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (3.0.7)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.0.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (3.1.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.7.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (3.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter>=1.0.0) (4.14.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (0.5.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0) (3.8.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.7.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (7.3.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.6.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0) (2.17.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->notebook->jupyter>=1.0.0) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0) (2.3.2.post1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.19.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (2.21)\n",
      "Requirement already satisfied: fqdn in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0)\n",
      "Requirement already satisfied: uri-template in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/jovyan/.local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.9.0.20250809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK jupyter>=1.0.0 installed correctly\n",
      "Installing ipywidgets>=8.0.0...\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in /opt/conda/lib/python3.11/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (6.3.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ipywidgets>=8.0.0 installed correctly\n",
      "Installing Pillow>=9.0.0...\n",
      "Requirement already satisfied: Pillow>=9.0.0 in /opt/conda/lib/python3.11/site-packages (10.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK Pillow>=9.0.0 installed correctly\n",
      "Installing scikit-learn>=1.0.0...\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.0) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.0) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.0) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK scikit-learn>=1.0.0 installed correctly\n",
      "\n",
      "All dependencies have been verified/installed\n",
      "Restart the kernel if this is the first time installing torch\n",
      "============================================================\n",
      "\n",
      "PyTorch 2.8.0+cu128 installed correctly\n",
      "CUDA available: No\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if not available.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"OK {package.split('==')[0]} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"OK {package} installed correctly\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\",\n",
    "    \"Pillow>=9.0.0\",  # For image loading\n",
    "    \"scikit-learn>=1.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Starting dependency installation for Image Hybrid Neuroevolution...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nAll dependencies have been verified/installed\")\n",
    "print(\"Restart the kernel if this is the first time installing torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch {torch.__version__} installed correctly\")\n",
    "    print(f\"CUDA available: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: PyTorch could not be installed correctly\")\n",
    "    print(\"Try installing manually with: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6033c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configured: cpu\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import glob\n",
    "\n",
    "# Threading for parallel fold training\n",
    "import threading\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device configured: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fbba9",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e444347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded (adaptive mutation enabled, 2D Conv for images):\n",
      "   Dataset: Images (Spectrogram - Parkinson Classification)\n",
      "   population_size: 20\n",
      "   max_generations: 100\n",
      "   fitness_threshold: 80.0\n",
      "   base_mutation_rate: 0.25\n",
      "   mutation_rate_min: 0.1\n",
      "   mutation_rate_max: 0.8\n",
      "   current_mutation_rate: 0.25\n",
      "   crossover_rate: 0.99\n",
      "   elite_percentage: 0.2\n",
      "   dataset: IMAGE\n",
      "   num_channels: 3\n",
      "   image_height: 32\n",
      "   image_width: 64\n",
      "   num_classes: 2\n",
      "   batch_size: 64\n",
      "   num_epochs: 10\n",
      "   learning_rate: 0.0001\n",
      "   early_stopping_patience: 40\n",
      "   epoch_patience: 2\n",
      "   improvement_threshold: 0.01\n",
      "   early_stopping_generations: 20\n",
      "   min_improvement_threshold: 0.01\n",
      "   min_conv_layers: 1\n",
      "   max_conv_layers: 8\n",
      "   min_fc_layers: 1\n",
      "   max_fc_layers: 8\n",
      "   min_filters: 8\n",
      "   max_filters: 128\n",
      "   min_fc_nodes: 64\n",
      "   max_fc_nodes: 1024\n",
      "   kernel_size_options: [1, 3, 5, 7]\n",
      "   min_dropout: 0.2\n",
      "   max_dropout: 0.5\n",
      "   learning_rate_options: [0.001, 0.0005, 0.0001, 5e-05, 1e-05]\n",
      "   normalization_batch_weight: 0.9\n",
      "   normalization_layer_weight: 0.1\n",
      "   dataset_id: all_real_syn_n\n",
      "   fold_id: all_real_syn_n\n",
      "   num_folds: 5\n",
      "   data_path: data/sets/folds_5/images_all_real_syn_n\n",
      "\n",
      "Available activation functions: ['relu', 'leaky_relu', 'tanh', 'sigmoid', 'selu']\n",
      "Available optimizers: ['adam', 'adamw', 'sgd', 'rmsprop']\n",
      "\n",
      "Data path configured: data/sets/folds_5/images_all_real_syn_n\n"
     ]
    }
   ],
   "source": [
    "# Main genetic algorithm configuration\n",
    "CONFIG = {\n",
    "    # Genetic algorithm parameters\n",
    "    'population_size': 20,\n",
    "    'max_generations': 100,\n",
    "    'fitness_threshold': 80.0,\n",
    "\n",
    "    # Adaptive mutation parameters\n",
    "    'base_mutation_rate': 0.25,\n",
    "    'mutation_rate_min': 0.10,\n",
    "    'mutation_rate_max': 0.80,\n",
    "    'current_mutation_rate': 0.25,\n",
    "\n",
    "    'crossover_rate': 0.99,\n",
    "    'elite_percentage': 0.2,\n",
    "\n",
    "    # Dataset selection (IMAGE)\n",
    "    'dataset': 'IMAGE',\n",
    "\n",
    "    # Dataset parameters for images (spectrograms)\n",
    "    'num_channels': 3,              # RGB images\n",
    "    'image_height': 32,             # Fixed size for spectrograms\n",
    "    'image_width': 64,              # Fixed size for spectrograms\n",
    "    'num_classes': 2,               # Control vs Pathological\n",
    "    'batch_size': 64,               # Smaller batch for images\n",
    "\n",
    "    # Training parameters\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 0.0001,\n",
    "    'early_stopping_patience': 40, #256+50 8k images (all dataset)\n",
    "\n",
    "    # Epoch-level early stopping\n",
    "    'epoch_patience': 2,\n",
    "    'improvement_threshold': 0.01,\n",
    "\n",
    "    # Generation-level early stopping\n",
    "    'early_stopping_generations': 20,\n",
    "    'min_improvement_threshold': 0.01,\n",
    "\n",
    "    # Allowed architecture range for 2D Conv\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 8,           # Fewer layers for images\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 8,\n",
    "    'min_filters': 8,\n",
    "    'max_filters': 128,\n",
    "    'min_fc_nodes': 64,\n",
    "    'max_fc_nodes': 1024,\n",
    "\n",
    "    # Mutation parameters - Kernel sizes for 2D Conv\n",
    "    'kernel_size_options': [1, 3, 5, 7],  # Common for 2D convolutions\n",
    "    \n",
    "    # Mutation parameters - Dropout range\n",
    "    'min_dropout': 0.2,\n",
    "    'max_dropout': 0.5,\n",
    "    \n",
    "    # Mutation parameters - Learning rate options\n",
    "    'learning_rate_options': [0.001, 0.0005, 0.0001, 0.00005, 0.00001],\n",
    "    \n",
    "    # Mutation parameters - Normalization type weights\n",
    "    'normalization_batch_weight': 0.9,\n",
    "    'normalization_layer_weight': 0.1,\n",
    "\n",
    "    # Image dataset configuration\n",
    "    'dataset_id': 'all_real_syn_n',\n",
    "    'fold_id': 'all_real_syn_n',\n",
    "    'num_folds': 5,\n",
    "    'data_path': os.path.join('data', 'sets', 'folds_5', 'images_all_real_syn_n'),\n",
    "    \n",
    "    # Image normalization (ImageNet stats)\n",
    "    'normalization': {\n",
    "        'mean': [0.485, 0.456, 0.406],\n",
    "        'std': [0.229, 0.224, 0.225]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Activation function mapping\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Optimizer mapping\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded (adaptive mutation enabled, 2D Conv for images):\")\n",
    "print(f\"   Dataset: Images (Spectrogram - Parkinson Classification)\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key not in ['normalization']:\n",
    "        print(f\"   {key}: {value}\")\n",
    "print(f\"\\nAvailable activation functions: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"Available optimizers: {list(OPTIMIZERS.keys())}\")\n",
    "print(f\"\\nData path configured: {CONFIG['data_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721d1b5",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fe83cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICANDO DISPONIBILIDAD DE IMÃGENES\n",
      "============================================================\n",
      "Dataset: all_real_syn_n, Verificando los 5 folds...\n",
      "   Looking for: /home/jovyan/audio_test/data/sets/folds_5/images_all_real_syn_n\n",
      "   âœ“ Directory found: /home/jovyan/audio_test/data/sets/folds_5/images_all_real_syn_n\n",
      "\n",
      "Checking for all 5 folds...\n",
      "   âœ“ Fold 1: 12220 images\n",
      "   âœ“ Fold 2: 12180 images\n",
      "   âœ“ Fold 3: 12200 images\n",
      "   âœ“ Fold 4: 12220 images\n",
      "   âœ“ Fold 5: 12240 images\n",
      "\n",
      "âœ“ All 5 folds verified successfully!\n",
      "   Total images: 61060\n",
      "\n",
      "Detecting original image dimensions...\n",
      "   Original image dimensions: 1681 x 1181\n",
      "   Target resize dimensions: 64 x 32\n",
      "   Channels: 3 (RGB)\n",
      "\n",
      "âœ“ Dataset verification complete!\n",
      "   During evolution, each individual will train on all 5 folds.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET READY FOR 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "   Image dimensions: 64 x 32\n",
      "   Input channels: 3\n",
      "   Number of classes: 2\n",
      "   Batch size: 64\n",
      "   Task: Spectrogram classification - Control (0) vs Pathological (1)\n",
      "\n",
      "   âš ï¸ Each individual will be evaluated on ALL 5 folds SEQUENTIALLY\n",
      "   âš ï¸ This is slower but CUDA-safe (avoids GPU memory conflicts)\n"
     ]
    }
   ],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    \"\"\"Dataset class for loading spectrogram images.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths: List[str], labels: List[int], transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_paths: List of paths to image files\n",
    "            labels: List of labels (0=control, 1=pathological)\n",
    "            transform: Optional transform to apply to images\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def load_fold_images(data_path: str, fold_num: int, subset: str) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Load image paths and labels for a specific fold and subset.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Base path to image directory\n",
    "        fold_num: Fold number (1-5)\n",
    "        subset: 'train', 'val', or 'test'\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (image_paths, labels)\n",
    "    \"\"\"\n",
    "    subset_folder = os.path.join(data_path, f\"{subset}_fold_{fold_num}\")\n",
    "    \n",
    "    if not os.path.exists(subset_folder):\n",
    "        raise FileNotFoundError(f\"Folder not found: {subset_folder}\")\n",
    "    \n",
    "    # Get all image files\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Scan for all .png files\n",
    "    for img_file in sorted(glob.glob(os.path.join(subset_folder, \"*.png\"))):\n",
    "        filename = os.path.basename(img_file)\n",
    "        \n",
    "        # Extract label from filename (control=0, pathological=1)\n",
    "        if 'control' in filename.lower():\n",
    "            label = 0\n",
    "        elif 'pathological' in filename.lower():\n",
    "            label = 1\n",
    "        else:\n",
    "            logger.warning(f\"Unknown label for file: {filename}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        image_paths.append(img_file)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "def verify_dataset(config: dict):\n",
    "    \"\"\"\n",
    "    Verifies that image data exists and loads first image to detect dimensions.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VERIFICANDO DISPONIBILIDAD DE IMÃGENES\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dataset: {config['dataset_id']}, Verificando los 5 folds...\")\n",
    "    \n",
    "    data_path = config['data_path']\n",
    "    print(f\"   Looking for: {os.path.abspath(data_path)}\")\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\nâŒ Data directory not found!\\n\"\n",
    "            f\"   Expected: {os.path.abspath(data_path)}\\n\"\n",
    "            f\"   Please run npy_to_spectrograms.py first to generate images.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"   âœ“ Directory found: {os.path.abspath(data_path)}\")\n",
    "    \n",
    "    # Check that all 5 folds exist\n",
    "    print(f\"\\nChecking for all 5 folds...\")\n",
    "    all_folds_ok = True\n",
    "    total_images = 0\n",
    "    \n",
    "    for fold_num in range(1, 6):\n",
    "        fold_ok = True\n",
    "        fold_images = 0\n",
    "        \n",
    "        for subset in ['train', 'val', 'test']:\n",
    "            subset_folder = os.path.join(data_path, f\"{subset}_fold_{fold_num}\")\n",
    "            \n",
    "            if not os.path.exists(subset_folder):\n",
    "                fold_ok = False\n",
    "                all_folds_ok = False\n",
    "                print(f\"   âœ— Fold {fold_num}: Missing {subset} folder\")\n",
    "                break\n",
    "            \n",
    "            # Count images\n",
    "            num_images = len(glob.glob(os.path.join(subset_folder, \"*.png\")))\n",
    "            fold_images += num_images\n",
    "        \n",
    "        if fold_ok:\n",
    "            print(f\"   âœ“ Fold {fold_num}: {fold_images} images\")\n",
    "            total_images += fold_images\n",
    "    \n",
    "    if not all_folds_ok:\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\nâŒ Some fold folders are missing!\\n\"\n",
    "            f\"   Please run npy_to_spectrograms.py to generate all fold images.\\n\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nâœ“ All 5 folds verified successfully!\")\n",
    "    print(f\"   Total images: {total_images}\")\n",
    "    \n",
    "    # Load first image to detect dimensions\n",
    "    print(f\"\\nDetecting original image dimensions...\")\n",
    "    image_paths, _ = load_fold_images(data_path, 1, 'train')\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        raise FileNotFoundError(\"No images found in train_fold_1!\")\n",
    "    \n",
    "    first_image = Image.open(image_paths[0]).convert('RGB')\n",
    "    original_width, original_height = first_image.size\n",
    "    \n",
    "    # DO NOT overwrite config - keep the target resize dimensions\n",
    "    target_width = config['image_width']\n",
    "    target_height = config['image_height']\n",
    "    \n",
    "    print(f\"   Original image dimensions: {original_width} x {original_height}\")\n",
    "    print(f\"   Target resize dimensions: {target_width} x {target_height}\")\n",
    "    print(f\"   Channels: {config['num_channels']} (RGB)\")\n",
    "    print(f\"\\nâœ“ Dataset verification complete!\")\n",
    "    print(f\"   During evolution, each individual will train on all 5 folds.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Verify dataset availability\n",
    "verify_dataset(CONFIG)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET READY FOR 5-FOLD CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Image dimensions: {CONFIG['image_width']} x {CONFIG['image_height']}\")\n",
    "print(f\"   Input channels: {CONFIG['num_channels']}\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Task: Spectrogram classification - Control (0) vs Pathological (1)\")\n",
    "print(f\"\\n   âš ï¸ Each individual will be evaluated on ALL 5 folds SEQUENTIALLY\")\n",
    "print(f\"   âš ï¸ This is slower but CUDA-safe (avoids GPU memory conflicts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f57e9b",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architecture Definition (2D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee1b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test model created successfully!\n",
      "Conv output size: 16384\n",
      "Total parameters: 4,321,410\n",
      "Output shape: torch.Size([2, 2])\n",
      "Expected shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "class EvolvableCNN2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolvable CNN class for 2D image processing.\n",
    "    Uses Conv2D layers for spectrogram/image data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN2D, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Validate and fix genome structure\n",
    "        self._validate_genome()\n",
    "        \n",
    "        # Build convolutional layers (2D for images)\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calculate output size after convolutions\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "    \n",
    "    def _validate_genome(self):\n",
    "        \"\"\"Validates and fixes genome structure to ensure consistency.\"\"\"\n",
    "        num_conv = self.genome['num_conv_layers']\n",
    "        \n",
    "        # Fix filters list\n",
    "        if len(self.genome['filters']) != num_conv:\n",
    "            self.genome['filters'] = self.genome['filters'][:num_conv]\n",
    "            while len(self.genome['filters']) < num_conv:\n",
    "                self.genome['filters'].append(\n",
    "                    random.randint(self.config['min_filters'], self.config['max_filters'])\n",
    "                )\n",
    "        \n",
    "        # Fix kernel_sizes list\n",
    "        if len(self.genome['kernel_sizes']) != num_conv:\n",
    "            self.genome['kernel_sizes'] = self.genome['kernel_sizes'][:num_conv]\n",
    "            while len(self.genome['kernel_sizes']) < num_conv:\n",
    "                self.genome['kernel_sizes'].append(\n",
    "                    random.choice(self.config['kernel_size_options'])\n",
    "                )\n",
    "        \n",
    "        # Fix use_pooling list\n",
    "        if len(self.genome['use_pooling']) != num_conv:\n",
    "            self.genome['use_pooling'] = self.genome['use_pooling'][:num_conv]\n",
    "            while len(self.genome['use_pooling']) < num_conv:\n",
    "                self.genome['use_pooling'].append(random.choice([True, False]))\n",
    "        \n",
    "        # Fix use_batch_norm list\n",
    "        if len(self.genome['use_batch_norm']) != num_conv:\n",
    "            self.genome['use_batch_norm'] = self.genome['use_batch_norm'][:num_conv]\n",
    "            while len(self.genome['use_batch_norm']) < num_conv:\n",
    "                self.genome['use_batch_norm'].append(random.choice([True, False]))\n",
    "        \n",
    "        # Fix fc_nodes list\n",
    "        num_fc = self.genome['num_fc_layers']\n",
    "        if len(self.genome['fc_nodes']) != num_fc:\n",
    "            self.genome['fc_nodes'] = self.genome['fc_nodes'][:num_fc]\n",
    "            while len(self.genome['fc_nodes']) < num_fc:\n",
    "                self.genome['fc_nodes'].append(\n",
    "                    random.randint(self.config['min_fc_nodes'], self.config['max_fc_nodes'])\n",
    "                )\n",
    "    \n",
    "    def _build_conv_layers(self):\n",
    "        \"\"\"Build the convolutional layers based on genome (2D).\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        \n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Conv2D layer\n",
    "            conv = nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=kernel_size // 2  # Same padding\n",
    "            )\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Batch normalization (2D)\n",
    "            if self.genome['use_batch_norm'][i]:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            # Activation\n",
    "            activation_class = ACTIVATION_FUNCTIONS[self.genome['activation']]\n",
    "            layers.append(activation_class())\n",
    "            \n",
    "            # Pooling (2D)\n",
    "            if self.genome['use_pooling'][i]:\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self):\n",
    "        \"\"\"Calculate the output size after all conv layers.\"\"\"\n",
    "        # Create a dummy input\n",
    "        dummy_input = torch.zeros(\n",
    "            1, \n",
    "            self.config['num_channels'],\n",
    "            self.config['image_height'],\n",
    "            self.config['image_width']\n",
    "        )\n",
    "        \n",
    "        # Pass through conv layers\n",
    "        x = dummy_input\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten and return size\n",
    "        return x.view(1, -1).size(1)\n",
    "    \n",
    "    def _build_fc_layers(self):\n",
    "        \"\"\"Build the fully connected layers.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_features = self.conv_output_size\n",
    "        \n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            out_features = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Fully connected layer\n",
    "            fc = nn.Linear(in_features, out_features)\n",
    "            layers.append(fc)\n",
    "            \n",
    "            # Activation\n",
    "            activation_class = ACTIVATION_FUNCTIONS[self.genome['activation']]\n",
    "            layers.append(activation_class())\n",
    "            \n",
    "            # Dropout\n",
    "            layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            in_features = out_features\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(in_features, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Test the architecture\n",
    "test_genome = {\n",
    "    'num_conv_layers': 3,\n",
    "    'filters': [32, 64, 128],\n",
    "    'kernel_sizes': [3, 3, 3],\n",
    "    'use_pooling': [True, True, False],\n",
    "    'use_batch_norm': [True, True, True],\n",
    "    'num_fc_layers': 2,\n",
    "    'fc_nodes': [256, 128],\n",
    "    'activation': 'relu',\n",
    "    'dropout_rate': 0.3,\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.0001\n",
    "}\n",
    "\n",
    "test_model = EvolvableCNN2D(test_genome, CONFIG)\n",
    "print(f\"\\nTest model created successfully!\")\n",
    "print(f\"Conv output size: {test_model.conv_output_size}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(2, CONFIG['num_channels'], CONFIG['image_height'], CONFIG['image_width'])\n",
    "test_output = test_model(test_input)\n",
    "print(f\"Output shape: {test_output.shape}\")\n",
    "print(f\"Expected shape: torch.Size([2, {CONFIG['num_classes']}])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd318ac2",
   "metadata": {},
   "source": [
    "## 5. Genetic Algorithm Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f52c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Genetic functions defined for 2D CNN (create, mutate, crossover)\n"
     ]
    }
   ],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"Creates a random genome for 2D CNN architectures.\"\"\"\n",
    "    num_conv_layers = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "    # Filters (progressive increase)\n",
    "    filters = []\n",
    "    base_filters = random.randint(config['min_filters'], config['min_filters'] * 2)\n",
    "    for i in range(num_conv_layers):\n",
    "        layer_filters = min(base_filters * (2 ** i), config['max_filters'])\n",
    "        filters.append(layer_filters)\n",
    "\n",
    "    # Kernel sizes for 2D\n",
    "    kernel_sizes = [random.choice(config['kernel_size_options']) for _ in range(num_conv_layers)]\n",
    "\n",
    "    # Pooling and batch norm decisions\n",
    "    use_pooling = [random.choice([True, False]) for _ in range(num_conv_layers)]\n",
    "    use_batch_norm = [random.choice([True, False]) for _ in range(num_conv_layers)]\n",
    "\n",
    "    # FC nodes (progressive decrease)\n",
    "    fc_nodes = []\n",
    "    base_fc = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "    for i in range(num_fc_layers):\n",
    "        layer_nodes = max(config['min_fc_nodes'], base_fc // (2 ** i))\n",
    "        fc_nodes.append(layer_nodes)\n",
    "\n",
    "    # Activation function (single for all layers)\n",
    "    activation = random.choice(list(ACTIVATION_FUNCTIONS.keys()))\n",
    "\n",
    "    # Other parameters\n",
    "    dropout_rate = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "    learning_rate = random.choice(config['learning_rate_options'])\n",
    "    optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "\n",
    "    genome = {\n",
    "        'num_conv_layers': num_conv_layers,\n",
    "        'num_fc_layers': num_fc_layers,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'use_pooling': use_pooling,\n",
    "        'use_batch_norm': use_batch_norm,\n",
    "        'fc_nodes': fc_nodes,\n",
    "        'activation': activation,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "    return genome\n",
    "\n",
    "\n",
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"Mutates a genome for 2D CNN.\"\"\"\n",
    "    mutated = copy.deepcopy(genome)\n",
    "    mutation_rate = config['current_mutation_rate']\n",
    "\n",
    "    # Mutate layer counts\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['num_conv_layers'] = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['num_fc_layers'] = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "    # Adjust lists to match new sizes\n",
    "    while len(mutated['filters']) < mutated['num_conv_layers']:\n",
    "        mutated['filters'].append(random.randint(config['min_filters'], config['max_filters']))\n",
    "    mutated['filters'] = mutated['filters'][:mutated['num_conv_layers']]\n",
    "\n",
    "    while len(mutated['kernel_sizes']) < mutated['num_conv_layers']:\n",
    "        mutated['kernel_sizes'].append(random.choice(config['kernel_size_options']))\n",
    "    mutated['kernel_sizes'] = mutated['kernel_sizes'][:mutated['num_conv_layers']]\n",
    "\n",
    "    while len(mutated['use_pooling']) < mutated['num_conv_layers']:\n",
    "        mutated['use_pooling'].append(random.choice([True, False]))\n",
    "    mutated['use_pooling'] = mutated['use_pooling'][:mutated['num_conv_layers']]\n",
    "\n",
    "    while len(mutated['use_batch_norm']) < mutated['num_conv_layers']:\n",
    "        mutated['use_batch_norm'].append(random.choice([True, False]))\n",
    "    mutated['use_batch_norm'] = mutated['use_batch_norm'][:mutated['num_conv_layers']]\n",
    "\n",
    "    while len(mutated['fc_nodes']) < mutated['num_fc_layers']:\n",
    "        mutated['fc_nodes'].append(random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    mutated['fc_nodes'] = mutated['fc_nodes'][:mutated['num_fc_layers']]\n",
    "\n",
    "    # Mutate individual values\n",
    "    for i in range(len(mutated['filters'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated['filters'][i] = random.randint(config['min_filters'], config['max_filters'])\n",
    "\n",
    "    for i in range(len(mutated['kernel_sizes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated['kernel_sizes'][i] = random.choice(config['kernel_size_options'])\n",
    "\n",
    "    for i in range(len(mutated['fc_nodes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated['fc_nodes'][i] = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['activation'] = random.choice(list(ACTIVATION_FUNCTIONS.keys()))\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['dropout_rate'] = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['learning_rate'] = random.choice(config['learning_rate_options'])\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "\n",
    "    mutated['id'] = str(uuid.uuid4())[:8]\n",
    "    mutated['fitness'] = 0.0\n",
    "    return mutated\n",
    "\n",
    "\n",
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"Crossover between two genomes.\"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "\n",
    "    # Crossover scalar parameters\n",
    "    for key in ['num_conv_layers', 'num_fc_layers', 'dropout_rate', 'learning_rate', 'optimizer', 'activation']:\n",
    "        if random.random() < 0.5:\n",
    "            child1[key], child2[key] = child2[key], child1[key]\n",
    "\n",
    "    # Crossover lists\n",
    "    for list_key in ['filters', 'kernel_sizes', 'use_pooling', 'use_batch_norm', 'fc_nodes']:\n",
    "        if random.random() < 0.5 and len(child1[list_key]) > 1 and len(child2[list_key]) > 1:\n",
    "            point1 = random.randint(1, len(child1[list_key]) - 1)\n",
    "            point2 = random.randint(1, len(child2[list_key]) - 1)\n",
    "            child1[list_key] = child1[list_key][:point1] + child2[list_key][point2:]\n",
    "            child2[list_key] = child2[list_key][:point2] + child1[list_key][point1:]\n",
    "\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "\n",
    "    # Fix sizes\n",
    "    for child in [child1, child2]:\n",
    "        while len(child['filters']) < child['num_conv_layers']:\n",
    "            child['filters'].append(random.randint(config['min_filters'], config['max_filters']))\n",
    "        child['filters'] = child['filters'][:child['num_conv_layers']]\n",
    "        \n",
    "        while len(child['kernel_sizes']) < child['num_conv_layers']:\n",
    "            child['kernel_sizes'].append(random.choice(config['kernel_size_options']))\n",
    "        child['kernel_sizes'] = child['kernel_sizes'][:child['num_conv_layers']]\n",
    "        \n",
    "        while len(child['use_pooling']) < child['num_conv_layers']:\n",
    "            child['use_pooling'].append(random.choice([True, False]))\n",
    "        child['use_pooling'] = child['use_pooling'][:child['num_conv_layers']]\n",
    "        \n",
    "        while len(child['use_batch_norm']) < child['num_conv_layers']:\n",
    "            child['use_batch_norm'].append(random.choice([True, False]))\n",
    "        child['use_batch_norm'] = child['use_batch_norm'][:child['num_conv_layers']]\n",
    "        \n",
    "        while len(child['fc_nodes']) < child['num_fc_layers']:\n",
    "            child['fc_nodes'].append(random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "        child['fc_nodes'] = child['fc_nodes'][:child['num_fc_layers']]\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "print(\"âœ“ Genetic functions defined for 2D CNN (create, mutate, crossover)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec13653",
   "metadata": {},
   "source": [
    "## 6. Hybrid Neuroevolution Implementation with 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83c6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolutionImage class defined (with 5-fold sequential CV, CUDA-safe)\n"
     ]
    }
   ],
   "source": [
    "class HybridNeuroevolutionImage:\n",
    "    \"\"\"Hybrid neuroevolution for 2D image classification with 5-fold CV (sequential).\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        self.generations_without_improvement = 0\n",
    "        self.best_fitness_overall = -float('inf')\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize random population.\"\"\"\n",
    "        print(f\"Initializing population of {self.config['population_size']} individuals...\")\n",
    "        self.population = [create_random_genome(self.config) for _ in range(self.config['population_size'])]\n",
    "        print(f\"âœ“ Population initialized with {len(self.population)} individuals\")\n",
    "\n",
    "    def _load_fold_data(self, fold_num: int) -> Tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"Load train and test data for a specific fold.\"\"\"\n",
    "        # Image transforms\n",
    "        print(f\"      Loading data for Fold {fold_num}...\")\n",
    "        print(f\"         Target resize: {self.config['image_height']}x{self.config['image_width']} (HxW), Channels: {self.config['num_channels']}\")\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.config['image_height'], self.config['image_width'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=self.config['normalization']['mean'],\n",
    "                std=self.config['normalization']['std']\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Load image paths and labels\n",
    "        train_paths, train_labels = load_fold_images(self.config['data_path'], fold_num, 'train')\n",
    "        test_paths, test_labels = load_fold_images(self.config['data_path'], fold_num, 'test')\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = SpectrogramDataset(train_paths, train_labels, transform=transform)\n",
    "        test_dataset = SpectrogramDataset(test_paths, test_labels, transform=transform)\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def _train_one_fold(self, model, optimizer, criterion, train_loader, test_loader, genome_id: str, fold_num: int) -> float:\n",
    "        \"\"\"Train and evaluate model on one fold.\"\"\"\n",
    "        best_acc = 0.0\n",
    "        patience_left = self.config['epoch_patience']\n",
    "        last_improvement_acc = 0.0\n",
    "        max_epochs = self.config['num_epochs']\n",
    "\n",
    "        for epoch in range(1, max_epochs + 1):\n",
    "            # Training\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            batch_count = 0\n",
    "            max_batches = min(len(train_loader), self.config['early_stopping_patience'])\n",
    "\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                if batch_count >= max_batches:\n",
    "                    break\n",
    "\n",
    "            avg_loss = running_loss / max(1, batch_count)\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            eval_batches = 0\n",
    "            max_eval_batches = min(len(test_loader), 20)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "                    output = model(data)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                    eval_batches += 1\n",
    "                    if eval_batches >= max_eval_batches:\n",
    "                        break\n",
    "\n",
    "            acc = 100.0 * correct / max(1, total)\n",
    "\n",
    "            # Early stopping\n",
    "            improvement = acc - last_improvement_acc\n",
    "            if improvement >= self.config['improvement_threshold']:\n",
    "                patience_left = self.config['epoch_patience']\n",
    "                last_improvement_acc = acc\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "\n",
    "            # Log every 1 epochs (including first)\n",
    "            if epoch % 1 == 0 or epoch == 1:\n",
    "                print(f\"          Fold {fold_num} Epoch {epoch}/{max_epochs}: loss={avg_loss:.4f}, acc={acc:.2f}%, best={best_acc:.2f}%, patience={patience_left}\")\n",
    "\n",
    "            if patience_left <= 0:\n",
    "                print(f\"          Fold {fold_num}: Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        return best_acc\n",
    "\n",
    "    def _train_fold_in_thread(self, genome: dict, fold_num: int) -> Tuple[int, float]:\n",
    "        \"\"\"Train model on a specific fold (designed for threading).\"\"\"\n",
    "        try:\n",
    "            # Load fold data\n",
    "            fold_train_loader, fold_test_loader = self._load_fold_data(fold_num)\n",
    "\n",
    "            # Create model for this fold\n",
    "            model = EvolvableCNN2D(genome, self.config).to(device)\n",
    "            optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "            optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            # Train and evaluate\n",
    "            fold_acc = self._train_one_fold(\n",
    "                model, optimizer, criterion,\n",
    "                fold_train_loader, fold_test_loader,\n",
    "                genome['id'], fold_num\n",
    "            )\n",
    "\n",
    "            print(f\"      â†’ Fold {fold_num} completed: {fold_acc:.2f}%\")\n",
    "\n",
    "            return fold_num, fold_acc\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      ERROR in Fold {fold_num}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return fold_num, 0.0\n",
    "\n",
    "    def _display_architecture(self, genome: dict):\n",
    "        \"\"\"Display architecture details of an individual.\"\"\"\n",
    "        print(f\"\\n   ðŸ“ Architecture of Individual {genome['id']}:\")\n",
    "        print(f\"      Conv2D Layers: {genome['num_conv_layers']}\")\n",
    "        for i in range(genome['num_conv_layers']):\n",
    "            pooling = \"Pool\" if genome['use_pooling'][i] else \"No-Pool\"\n",
    "            bn = \"BN\" if genome['use_batch_norm'][i] else \"No-BN\"\n",
    "            print(f\"         L{i+1}: {genome['filters'][i]:3d} filters, K={genome['kernel_sizes'][i]}x{genome['kernel_sizes'][i]}, {pooling}, {bn}\")\n",
    "        \n",
    "        print(f\"      FC Layers: {genome['num_fc_layers']}\")\n",
    "        for i in range(genome['num_fc_layers']):\n",
    "            print(f\"         FC{i+1}: {genome['fc_nodes'][i]:4d} nodes\")\n",
    "        \n",
    "        print(f\"      Activation: {genome['activation']}, Dropout: {genome['dropout_rate']:.3f}\")\n",
    "        print(f\"      Optimizer: {genome['optimizer']}, LR: {genome['learning_rate']}\")\n",
    "\n",
    "    def evaluate_individual(self, genome: dict) -> float:\n",
    "        \"\"\"Evaluate individual on ALL 5 folds SEQUENTIALLY (CUDA-safe).\"\"\"\n",
    "        print(f\"\\n   Evaluating Individual {genome['id']}...\")\n",
    "        \n",
    "        # Display architecture before training\n",
    "        self._display_architecture(genome)\n",
    "\n",
    "        # Train all 5 folds sequentially to avoid CUDA conflicts\n",
    "        fold_accuracies = {}\n",
    "\n",
    "        for fold_num in range(1, 6):\n",
    "            # Clear CUDA cache before each fold\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            print(f\"      Training Fold {fold_num}/5...\")\n",
    "            fold_num_result, fold_acc = self._train_fold_in_thread(genome, fold_num)\n",
    "            fold_accuracies[fold_num_result] = fold_acc\n",
    "            print(f\"      â†’ Fold {fold_num} completed: {fold_acc:.2f}%\")\n",
    "\n",
    "        # Calculate average fitness across all 5 folds\n",
    "        avg_fitness = np.mean(list(fold_accuracies.values()))\n",
    "\n",
    "        print(f\"   â†’ Individual {genome['id']}: Average Fitness = {avg_fitness:.2f}%\")\n",
    "        print(f\"      Fold details: {fold_accuracies}\")\n",
    "\n",
    "        return avg_fitness\n",
    "\n",
    "    def evolve(self) -> dict:\n",
    "        \"\"\"Main evolution loop.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STARTING HYBRID NEUROEVOLUTION FOR IMAGES\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        self.initialize_population()\n",
    "\n",
    "        for generation in range(1, self.config['max_generations'] + 1):\n",
    "            self.generation = generation\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"GENERATION {generation}/{self.config['max_generations']}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "            # Evaluate all individuals\n",
    "            print(f\"\\nEvaluating {len(self.population)} individuals (5-fold CV)...\")\n",
    "            for idx, individual in enumerate(self.population, 1):\n",
    "                print(f\"\\nIndividual {idx}/{len(self.population)} - ID: {individual['id']}\")\n",
    "                fitness = self.evaluate_individual(individual)\n",
    "                individual['fitness'] = fitness\n",
    "\n",
    "            # Sort by fitness\n",
    "            self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "            best_current = self.population[0]\n",
    "            avg_fitness = np.mean([ind['fitness'] for ind in self.population])\n",
    "\n",
    "            # Update best overall\n",
    "            if best_current['fitness'] > self.best_fitness_overall:\n",
    "                improvement = best_current['fitness'] - self.best_fitness_overall\n",
    "                self.best_fitness_overall = best_current['fitness']\n",
    "                self.best_individual = copy.deepcopy(best_current)\n",
    "                self.generations_without_improvement = 0\n",
    "                print(f\"\\nðŸŽ‰ NEW BEST! Fitness: {best_current['fitness']:.2f}% (improvement: +{improvement:.2f}%)\")\n",
    "            else:\n",
    "                self.generations_without_improvement += 1\n",
    "\n",
    "            # Stats\n",
    "            self.fitness_history.append(avg_fitness)\n",
    "            self.generation_stats.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': best_current['fitness'],\n",
    "                'avg_fitness': avg_fitness,\n",
    "                'best_id': best_current['id']\n",
    "            })\n",
    "\n",
    "            print(f\"\\nGeneration {generation} Summary:\")\n",
    "            print(f\"   Best: {best_current['fitness']:.2f}% (ID: {best_current['id']})\")\n",
    "            print(f\"   Average: {avg_fitness:.2f}%\")\n",
    "            print(f\"   Generations without improvement: {self.generations_without_improvement}\")\n",
    "\n",
    "            # Check stopping criteria\n",
    "            if best_current['fitness'] >= self.config['fitness_threshold']:\n",
    "                print(f\"\\nâœ“ TARGET REACHED! Fitness {best_current['fitness']:.2f}% >= {self.config['fitness_threshold']}%\")\n",
    "                break\n",
    "\n",
    "            if self.generations_without_improvement >= self.config['early_stopping_generations']:\n",
    "                print(f\"\\nâ¹ Early stopping: No improvement for {self.generations_without_improvement} generations\")\n",
    "                break\n",
    "\n",
    "            # Create new generation (elitism + mutation + crossover)\n",
    "            num_elites = max(1, int(len(self.population) * self.config['elite_percentage']))\n",
    "            new_population = self.population[:num_elites]  # Keep best individuals\n",
    "\n",
    "            while len(new_population) < self.config['population_size']:\n",
    "                # Selection (tournament)\n",
    "                parent1 = random.choice(self.population[:len(self.population)//2])\n",
    "                parent2 = random.choice(self.population[:len(self.population)//2])\n",
    "\n",
    "                # Crossover\n",
    "                child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "\n",
    "                # Mutation\n",
    "                child1 = mutate_genome(child1, self.config)\n",
    "                child2 = mutate_genome(child2, self.config)\n",
    "\n",
    "                new_population.extend([child1, child2])\n",
    "\n",
    "            self.population = new_population[:self.config['population_size']]\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EVOLUTION COMPLETED\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        return self.best_individual if self.best_individual else self.population[0]\n",
    "\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolutionImage class defined (with 5-fold sequential CV, CUDA-safe)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f18f9",
   "metadata": {},
   "source": [
    "## 7. Execute Evolution and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feae937-d6e5-4740-931e-f49a2f7bcd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING HYBRID NEUROEVOLUTION FOR IMAGE CLASSIFICATION\n",
      "================================================================================\n",
      "Dataset: IMAGE\n",
      "Data path: data/sets/folds_5/images_all_real_syn_n\n",
      "Population size: 20\n",
      "Max generations: 100\n",
      "Fitness threshold: 80.0%\n",
      "Image size: 64x32\n",
      "Batch size: 64\n",
      "Using 5-fold cross-validation (sequential, CUDA-safe)\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "STARTING HYBRID NEUROEVOLUTION FOR IMAGES\n",
      "============================================================\n",
      "Initializing population of 20 individuals...\n",
      "âœ“ Population initialized with 20 individuals\n",
      "\n",
      "============================================================\n",
      "GENERATION 1/100\n",
      "============================================================\n",
      "\n",
      "Evaluating 20 individuals (5-fold CV)...\n",
      "\n",
      "Individual 1/20 - ID: b7b77b4c\n",
      "\n",
      "   Evaluating Individual b7b77b4c...\n",
      "\n",
      "   ðŸ“ Architecture of Individual b7b77b4c:\n",
      "      Conv2D Layers: 2\n",
      "         L1:  12 filters, K=3x3, Pool, BN\n",
      "         L2:  24 filters, K=3x3, Pool, No-BN\n",
      "      FC Layers: 1\n",
      "         FC1:   96 nodes\n",
      "      Activation: relu, Dropout: 0.228\n",
      "      Optimizer: adam, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6818, acc=61.80%, best=61.80%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6444, acc=63.28%, best=63.28%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6096, acc=57.89%, best=63.28%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.5603, acc=60.00%, best=63.28%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 63.28%\n",
      "      â†’ Fold 1 completed: 63.28%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6934, acc=71.17%, best=71.17%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6690, acc=60.55%, best=71.17%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6477, acc=60.55%, best=71.17%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6958, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6915, acc=69.22%, best=69.22%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6876, acc=71.95%, best=71.95%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6750, acc=76.33%, best=76.33%, patience=2\n",
      "          Fold 3 Epoch 5/10: loss=0.6569, acc=76.02%, best=76.33%, patience=1\n",
      "          Fold 3 Epoch 6/10: loss=0.6324, acc=73.12%, best=76.33%, patience=0\n",
      "          Fold 3: Early stopping at epoch 6\n",
      "      â†’ Fold 3 completed: 76.33%\n",
      "      â†’ Fold 3 completed: 76.33%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6911, acc=64.61%, best=64.61%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6621, acc=62.27%, best=64.61%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6412, acc=56.25%, best=64.61%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 64.61%\n",
      "      â†’ Fold 4 completed: 64.61%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6953, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6781, acc=52.42%, best=52.42%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6619, acc=57.11%, best=57.11%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.6394, acc=58.67%, best=58.67%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.6033, acc=62.27%, best=62.27%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.5741, acc=62.03%, best=62.27%, patience=1\n",
      "          Fold 5 Epoch 7/10: loss=0.5526, acc=48.83%, best=62.27%, patience=0\n",
      "          Fold 5: Early stopping at epoch 7\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "   â†’ Individual b7b77b4c: Average Fitness = 67.53%\n",
      "      Fold details: {1: 63.28125, 2: 71.171875, 3: 76.328125, 4: 64.609375, 5: 62.265625}\n",
      "\n",
      "Individual 2/20 - ID: 9b595988\n",
      "\n",
      "   Evaluating Individual 9b595988...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 9b595988:\n",
      "      Conv2D Layers: 4\n",
      "         L1:  11 filters, K=7x7, No-Pool, BN\n",
      "         L2:  22 filters, K=5x5, No-Pool, No-BN\n",
      "         L3:  44 filters, K=1x1, No-Pool, BN\n",
      "         L4:  88 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 7\n",
      "         FC1:  453 nodes\n",
      "         FC2:  226 nodes\n",
      "         FC3:  113 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "      Activation: relu, Dropout: 0.308\n",
      "      Optimizer: sgd, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6939, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6954, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6957, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6939, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6943, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6944, acc=51.41%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6928, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6927, acc=52.03%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6929, acc=52.03%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6941, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6936, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6932, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6979, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6950, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6958, acc=50.78%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 9b595988: Average Fitness = 51.03%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 52.03125, 4: 50.46875, 5: 50.78125}\n",
      "\n",
      "Individual 3/20 - ID: 97708acb\n",
      "\n",
      "   Evaluating Individual 97708acb...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 97708acb:\n",
      "      Conv2D Layers: 1\n",
      "         L1:  16 filters, K=1x1, No-Pool, BN\n",
      "      FC Layers: 8\n",
      "         FC1:  629 nodes\n",
      "         FC2:  314 nodes\n",
      "         FC3:  157 nodes\n",
      "         FC4:   78 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "         FC8:   64 nodes\n",
      "      Activation: tanh, Dropout: 0.449\n",
      "      Optimizer: sgd, LR: 1e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6958, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6970, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6952, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6941, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6945, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6944, acc=51.41%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6985, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6988, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6952, acc=47.97%, best=47.97%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6935, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6978, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6950, acc=49.53%, best=49.53%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6971, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6934, acc=49.22%, best=49.22%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6966, acc=49.22%, best=49.22%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "   â†’ Individual 97708acb: Average Fitness = 49.72%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 47.96875, 4: 49.53125, 5: 49.21875}\n",
      "\n",
      "Individual 4/20 - ID: 54da159d\n",
      "\n",
      "   Evaluating Individual 54da159d...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 54da159d:\n",
      "      Conv2D Layers: 4\n",
      "         L1:   8 filters, K=3x3, Pool, No-BN\n",
      "         L2:  16 filters, K=5x5, No-Pool, BN\n",
      "         L3:  32 filters, K=1x1, No-Pool, No-BN\n",
      "         L4:  64 filters, K=3x3, No-Pool, No-BN\n",
      "      FC Layers: 2\n",
      "         FC1:  278 nodes\n",
      "         FC2:  139 nodes\n",
      "      Activation: tanh, Dropout: 0.411\n",
      "      Optimizer: adamw, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7241, acc=53.75%, best=53.75%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7053, acc=60.16%, best=60.16%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6877, acc=51.56%, best=60.16%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.6957, acc=49.92%, best=60.16%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 60.16%\n",
      "      â†’ Fold 1 completed: 60.16%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7218, acc=54.84%, best=54.84%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7157, acc=66.80%, best=66.80%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.7023, acc=51.56%, best=66.80%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.6859, acc=61.25%, best=66.80%, patience=0\n",
      "          Fold 2: Early stopping at epoch 4\n",
      "      â†’ Fold 2 completed: 66.80%\n",
      "      â†’ Fold 2 completed: 66.80%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7420, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7329, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7210, acc=47.97%, best=47.97%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7186, acc=67.03%, best=67.03%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6935, acc=61.41%, best=67.03%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6852, acc=63.83%, best=67.03%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 67.03%\n",
      "      â†’ Fold 4 completed: 67.03%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7492, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7129, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7176, acc=49.22%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 54da159d: Average Fitness = 58.55%\n",
      "      Fold details: {1: 60.15625, 2: 66.796875, 3: 47.96875, 4: 67.03125, 5: 50.78125}\n",
      "\n",
      "Individual 5/20 - ID: 2c014b3b\n",
      "\n",
      "   Evaluating Individual 2c014b3b...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 2c014b3b:\n",
      "      Conv2D Layers: 4\n",
      "         L1:  15 filters, K=7x7, Pool, No-BN\n",
      "         L2:  30 filters, K=5x5, Pool, No-BN\n",
      "         L3:  60 filters, K=3x3, Pool, BN\n",
      "         L4: 120 filters, K=5x5, No-Pool, BN\n",
      "      FC Layers: 3\n",
      "         FC1:  999 nodes\n",
      "         FC2:  499 nodes\n",
      "         FC3:  249 nodes\n",
      "      Activation: selu, Dropout: 0.463\n",
      "      Optimizer: adamw, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7796, acc=51.02%, best=51.02%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7275, acc=51.02%, best=51.02%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6839, acc=54.92%, best=54.92%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6651, acc=53.52%, best=54.92%, patience=1\n",
      "          Fold 1 Epoch 5/10: loss=0.6372, acc=58.91%, best=58.91%, patience=2\n",
      "          Fold 1 Epoch 6/10: loss=0.5396, acc=54.06%, best=58.91%, patience=1\n",
      "          Fold 1 Epoch 7/10: loss=0.4962, acc=56.33%, best=58.91%, patience=0\n",
      "          Fold 1: Early stopping at epoch 7\n",
      "      â†’ Fold 1 completed: 58.91%\n",
      "      â†’ Fold 1 completed: 58.91%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7964, acc=65.55%, best=65.55%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7522, acc=55.94%, best=65.55%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7399, acc=55.94%, best=65.55%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 65.55%\n",
      "      â†’ Fold 2 completed: 65.55%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7878, acc=69.61%, best=69.61%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7640, acc=52.89%, best=69.61%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7256, acc=70.16%, best=70.16%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6380, acc=54.30%, best=70.16%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.5460, acc=53.59%, best=70.16%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7760, acc=61.25%, best=61.25%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7491, acc=60.94%, best=61.25%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.7148, acc=47.89%, best=61.25%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7829, acc=62.03%, best=62.03%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7850, acc=48.98%, best=62.03%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7598, acc=70.55%, best=70.55%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.7203, acc=49.38%, best=70.55%, patience=1\n",
      "          Fold 5 Epoch 5/10: loss=0.6564, acc=52.11%, best=70.55%, patience=0\n",
      "          Fold 5: Early stopping at epoch 5\n",
      "      â†’ Fold 5 completed: 70.55%\n",
      "      â†’ Fold 5 completed: 70.55%\n",
      "   â†’ Individual 2c014b3b: Average Fitness = 65.28%\n",
      "      Fold details: {1: 58.90625, 2: 65.546875, 3: 70.15625, 4: 61.25, 5: 70.546875}\n",
      "\n",
      "Individual 6/20 - ID: 48d52b4d\n",
      "\n",
      "   Evaluating Individual 48d52b4d...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 48d52b4d:\n",
      "      Conv2D Layers: 8\n",
      "         L1:  15 filters, K=3x3, Pool, No-BN\n",
      "         L2:  30 filters, K=5x5, Pool, BN\n",
      "         L3:  60 filters, K=3x3, No-Pool, No-BN\n",
      "         L4: 120 filters, K=3x3, Pool, No-BN\n",
      "         L5: 128 filters, K=5x5, Pool, No-BN\n",
      "         L6: 128 filters, K=7x7, Pool, No-BN\n",
      "         L7: 128 filters, K=7x7, Pool, BN\n",
      "         L8: 128 filters, K=5x5, Pool, BN\n",
      "      FC Layers: 7\n",
      "         FC1:  762 nodes\n",
      "         FC2:  381 nodes\n",
      "         FC3:  190 nodes\n",
      "         FC4:   95 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "      Activation: selu, Dropout: 0.425\n",
      "      Optimizer: adam, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "      ERROR in Fold 1: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "      â†’ Fold 1 completed: 0.00%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "      ERROR in Fold 2: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "      â†’ Fold 2 completed: 0.00%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "      ERROR in Fold 3: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "      â†’ Fold 3 completed: 0.00%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8936/2496447629.py\", line 137, in _train_fold_in_thread\n",
      "    model = EvolvableCNN2D(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 113, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 224, in forward\n",
      "    return F.max_pool2d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 827, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8936/2496447629.py\", line 137, in _train_fold_in_thread\n",
      "    model = EvolvableCNN2D(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 113, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 224, in forward\n",
      "    return F.max_pool2d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 827, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8936/2496447629.py\", line 137, in _train_fold_in_thread\n",
      "    model = EvolvableCNN2D(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 113, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 224, in forward\n",
      "    return F.max_pool2d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 827, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8936/2496447629.py\", line 137, in _train_fold_in_thread\n",
      "    model = EvolvableCNN2D(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 113, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 224, in forward\n",
      "    return F.max_pool2d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 827, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8936/2496447629.py\", line 137, in _train_fold_in_thread\n",
      "    model = EvolvableCNN2D(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_8936/4096732920.py\", line 113, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 224, in forward\n",
      "    return F.max_pool2d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 827, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 4: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "      â†’ Fold 4 completed: 0.00%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "      ERROR in Fold 5: Given input size: (128x1x2). Calculated output size: (128x0x1). Output size is too small\n",
      "      â†’ Fold 5 completed: 0.00%\n",
      "   â†’ Individual 48d52b4d: Average Fitness = 0.00%\n",
      "      Fold details: {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0}\n",
      "\n",
      "Individual 7/20 - ID: 596cd63e\n",
      "\n",
      "   Evaluating Individual 596cd63e...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 596cd63e:\n",
      "      Conv2D Layers: 5\n",
      "         L1:  10 filters, K=7x7, No-Pool, BN\n",
      "         L2:  20 filters, K=1x1, Pool, No-BN\n",
      "         L3:  40 filters, K=5x5, Pool, No-BN\n",
      "         L4:  80 filters, K=3x3, No-Pool, BN\n",
      "         L5: 128 filters, K=1x1, Pool, BN\n",
      "      FC Layers: 7\n",
      "         FC1: 1015 nodes\n",
      "         FC2:  507 nodes\n",
      "         FC3:  253 nodes\n",
      "         FC4:  126 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "      Activation: tanh, Dropout: 0.464\n",
      "      Optimizer: adamw, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6960, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6975, acc=56.64%, best=56.64%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6953, acc=55.23%, best=56.64%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.6955, acc=53.67%, best=56.64%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 56.64%\n",
      "      â†’ Fold 1 completed: 56.64%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6968, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6963, acc=63.36%, best=63.36%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6932, acc=61.48%, best=63.36%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.6882, acc=66.09%, best=66.09%, patience=2\n",
      "          Fold 2 Epoch 5/10: loss=0.6842, acc=61.72%, best=66.09%, patience=1\n",
      "          Fold 2 Epoch 6/10: loss=0.6778, acc=63.44%, best=66.09%, patience=0\n",
      "          Fold 2: Early stopping at epoch 6\n",
      "      â†’ Fold 2 completed: 66.09%\n",
      "      â†’ Fold 2 completed: 66.09%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6955, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6973, acc=47.97%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6964, acc=52.03%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6960, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6922, acc=52.42%, best=52.42%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6894, acc=58.20%, best=58.20%, patience=2\n",
      "          Fold 4 Epoch 4/10: loss=0.6796, acc=61.56%, best=61.56%, patience=2\n",
      "          Fold 4 Epoch 5/10: loss=0.6837, acc=60.00%, best=61.56%, patience=1\n",
      "          Fold 4 Epoch 6/10: loss=0.6654, acc=46.41%, best=61.56%, patience=0\n",
      "          Fold 4: Early stopping at epoch 6\n",
      "      â†’ Fold 4 completed: 61.56%\n",
      "      â†’ Fold 4 completed: 61.56%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6962, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6960, acc=49.22%, best=49.22%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6966, acc=49.22%, best=49.22%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "   â†’ Individual 596cd63e: Average Fitness = 57.11%\n",
      "      Fold details: {1: 56.640625, 2: 66.09375, 3: 52.03125, 4: 61.5625, 5: 49.21875}\n",
      "\n",
      "Individual 8/20 - ID: b6c7fa8d\n",
      "\n",
      "   Evaluating Individual b6c7fa8d...\n",
      "\n",
      "   ðŸ“ Architecture of Individual b6c7fa8d:\n",
      "      Conv2D Layers: 1\n",
      "         L1:   9 filters, K=1x1, No-Pool, BN\n",
      "      FC Layers: 4\n",
      "         FC1:  842 nodes\n",
      "         FC2:  421 nodes\n",
      "         FC3:  210 nodes\n",
      "         FC4:  105 nodes\n",
      "      Activation: selu, Dropout: 0.430\n",
      "      Optimizer: rmsprop, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=4.6210, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.8598, acc=56.72%, best=56.72%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.8374, acc=56.09%, best=56.72%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.8170, acc=50.47%, best=56.72%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 56.72%\n",
      "      â†’ Fold 1 completed: 56.72%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=3.3553, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.8406, acc=52.58%, best=52.58%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.8130, acc=69.30%, best=69.30%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.8203, acc=48.59%, best=69.30%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.7693, acc=48.59%, best=69.30%, patience=0\n",
      "          Fold 2: Early stopping at epoch 5\n",
      "      â†’ Fold 2 completed: 69.30%\n",
      "      â†’ Fold 2 completed: 69.30%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=3.4560, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.8621, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.7988, acc=47.97%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 4/10: loss=0.7797, acc=47.97%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 4\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=3.1973, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.8244, acc=61.64%, best=61.64%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.7915, acc=61.64%, best=61.64%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.7663, acc=63.52%, best=63.52%, patience=2\n",
      "          Fold 4 Epoch 5/10: loss=0.7662, acc=64.84%, best=64.84%, patience=2\n",
      "          Fold 4 Epoch 6/10: loss=0.7534, acc=57.50%, best=64.84%, patience=1\n",
      "          Fold 4 Epoch 7/10: loss=0.7270, acc=56.33%, best=64.84%, patience=0\n",
      "          Fold 4: Early stopping at epoch 7\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=3.3379, acc=52.42%, best=52.42%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.8480, acc=54.77%, best=54.77%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.8340, acc=50.78%, best=54.77%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.8057, acc=61.48%, best=61.48%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.7770, acc=50.78%, best=61.48%, patience=1\n",
      "          Fold 5 Epoch 6/10: loss=0.7560, acc=50.78%, best=61.48%, patience=0\n",
      "          Fold 5: Early stopping at epoch 6\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "   â†’ Individual b6c7fa8d: Average Fitness = 60.88%\n",
      "      Fold details: {1: 56.71875, 2: 69.296875, 3: 52.03125, 4: 64.84375, 5: 61.484375}\n",
      "\n",
      "Individual 9/20 - ID: 5a79c4e4\n",
      "\n",
      "   Evaluating Individual 5a79c4e4...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 5a79c4e4:\n",
      "      Conv2D Layers: 3\n",
      "         L1:  16 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  32 filters, K=3x3, No-Pool, No-BN\n",
      "         L3:  64 filters, K=3x3, No-Pool, BN\n",
      "      FC Layers: 5\n",
      "         FC1:  317 nodes\n",
      "         FC2:  158 nodes\n",
      "         FC3:   79 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "      Activation: leaky_relu, Dropout: 0.219\n",
      "      Optimizer: adamw, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7326, acc=46.48%, best=46.48%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7050, acc=47.34%, best=47.34%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6942, acc=49.45%, best=49.45%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6979, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.6945, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 6/10: loss=0.6950, acc=47.19%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 6\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7265, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7015, acc=48.59%, best=48.59%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7013, acc=48.59%, best=48.59%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7486, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7118, acc=47.97%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7066, acc=47.97%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7372, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7034, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.7015, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7429, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7047, acc=54.77%, best=54.77%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.7015, acc=49.22%, best=54.77%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.6980, acc=49.22%, best=54.77%, patience=0\n",
      "          Fold 5: Early stopping at epoch 4\n",
      "      â†’ Fold 5 completed: 54.77%\n",
      "      â†’ Fold 5 completed: 54.77%\n",
      "   â†’ Individual 5a79c4e4: Average Fitness = 51.27%\n",
      "      Fold details: {1: 50.46875, 2: 48.59375, 3: 52.03125, 4: 50.46875, 5: 54.765625}\n",
      "\n",
      "Individual 10/20 - ID: 65923405\n",
      "\n",
      "   Evaluating Individual 65923405...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 65923405:\n",
      "      Conv2D Layers: 4\n",
      "         L1:   9 filters, K=1x1, No-Pool, No-BN\n",
      "         L2:  18 filters, K=3x3, Pool, BN\n",
      "         L3:  36 filters, K=1x1, Pool, BN\n",
      "         L4:  72 filters, K=1x1, No-Pool, No-BN\n",
      "      FC Layers: 1\n",
      "         FC1:  312 nodes\n",
      "      Activation: sigmoid, Dropout: 0.442\n",
      "      Optimizer: adam, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.8520, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7170, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.7123, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7531, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7269, acc=48.59%, best=48.59%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7150, acc=48.59%, best=48.59%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7935, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7173, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.7203, acc=52.03%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 4/10: loss=0.7073, acc=47.97%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 4\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7328, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7125, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.7070, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.7031, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.8518, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7193, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7126, acc=49.22%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 65923405: Average Fitness = 50.47%\n",
      "      Fold details: {1: 50.46875, 2: 48.59375, 3: 52.03125, 4: 50.46875, 5: 50.78125}\n",
      "\n",
      "Individual 11/20 - ID: 1d2c8195\n",
      "\n",
      "   Evaluating Individual 1d2c8195...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 1d2c8195:\n",
      "      Conv2D Layers: 2\n",
      "         L1:  13 filters, K=7x7, No-Pool, BN\n",
      "         L2:  26 filters, K=7x7, Pool, BN\n",
      "      FC Layers: 7\n",
      "         FC1:  476 nodes\n",
      "         FC2:  238 nodes\n",
      "         FC3:  119 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "      Activation: tanh, Dropout: 0.440\n",
      "      Optimizer: adamw, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6971, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7007, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6998, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6981, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6992, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6954, acc=51.41%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6978, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6987, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6990, acc=47.97%, best=47.97%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6964, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7020, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6955, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 4/10: loss=0.6993, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 5/10: loss=0.6972, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 4: Early stopping at epoch 5\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7004, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6964, acc=49.22%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6964, acc=49.22%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 1d2c8195: Average Fitness = 50.22%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 47.96875, 4: 50.46875, 5: 50.78125}\n",
      "\n",
      "Individual 12/20 - ID: a6a0c4ca\n",
      "\n",
      "   Evaluating Individual a6a0c4ca...\n",
      "\n",
      "   ðŸ“ Architecture of Individual a6a0c4ca:\n",
      "      Conv2D Layers: 4\n",
      "         L1:  16 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  32 filters, K=3x3, No-Pool, BN\n",
      "         L3:  64 filters, K=7x7, Pool, BN\n",
      "         L4: 128 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 4\n",
      "         FC1:  159 nodes\n",
      "         FC2:   79 nodes\n",
      "         FC3:   64 nodes\n",
      "         FC4:   64 nodes\n",
      "      Activation: leaky_relu, Dropout: 0.250\n",
      "      Optimizer: rmsprop, LR: 5e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6945, acc=44.38%, best=44.38%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6931, acc=47.50%, best=47.50%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6833, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6814, acc=54.45%, best=54.45%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.6751, acc=57.81%, best=57.81%, patience=2\n",
      "          Fold 1 Epoch 6/10: loss=0.6719, acc=56.80%, best=57.81%, patience=1\n",
      "          Fold 1 Epoch 7/10: loss=0.6570, acc=59.61%, best=59.61%, patience=2\n",
      "          Fold 1 Epoch 8/10: loss=0.6330, acc=65.31%, best=65.31%, patience=2\n",
      "          Fold 1 Epoch 9/10: loss=0.6169, acc=58.28%, best=65.31%, patience=1\n",
      "          Fold 1 Epoch 10/10: loss=0.5967, acc=61.25%, best=65.31%, patience=0\n",
      "          Fold 1: Early stopping at epoch 10\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7061, acc=66.48%, best=66.48%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6929, acc=61.72%, best=66.48%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6919, acc=61.95%, best=66.48%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6983, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6945, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6920, acc=48.12%, best=48.12%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6861, acc=70.78%, best=70.78%, patience=2\n",
      "          Fold 3 Epoch 5/10: loss=0.6677, acc=70.70%, best=70.78%, patience=1\n",
      "          Fold 3 Epoch 6/10: loss=0.6311, acc=62.97%, best=70.78%, patience=0\n",
      "          Fold 3: Early stopping at epoch 6\n",
      "      â†’ Fold 3 completed: 70.78%\n",
      "      â†’ Fold 3 completed: 70.78%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6910, acc=63.91%, best=63.91%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6773, acc=64.22%, best=64.22%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6652, acc=58.12%, best=64.22%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.6334, acc=61.25%, best=64.22%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 64.22%\n",
      "      â†’ Fold 4 completed: 64.22%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7026, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6940, acc=49.22%, best=49.22%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6934, acc=68.44%, best=68.44%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.6910, acc=68.36%, best=68.44%, patience=1\n",
      "          Fold 5 Epoch 5/10: loss=0.6881, acc=68.52%, best=68.52%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.6857, acc=70.00%, best=70.00%, patience=2\n",
      "          Fold 5 Epoch 7/10: loss=0.6785, acc=56.95%, best=70.00%, patience=1\n",
      "          Fold 5 Epoch 8/10: loss=0.6556, acc=47.81%, best=70.00%, patience=0\n",
      "          Fold 5: Early stopping at epoch 8\n",
      "      â†’ Fold 5 completed: 70.00%\n",
      "      â†’ Fold 5 completed: 70.00%\n",
      "   â†’ Individual a6a0c4ca: Average Fitness = 67.36%\n",
      "      Fold details: {1: 65.3125, 2: 66.484375, 3: 70.78125, 4: 64.21875, 5: 70.0}\n",
      "\n",
      "Individual 13/20 - ID: e557be6e\n",
      "\n",
      "   Evaluating Individual e557be6e...\n",
      "\n",
      "   ðŸ“ Architecture of Individual e557be6e:\n",
      "      Conv2D Layers: 4\n",
      "         L1:   8 filters, K=3x3, No-Pool, No-BN\n",
      "         L2:  16 filters, K=7x7, No-Pool, BN\n",
      "         L3:  32 filters, K=1x1, No-Pool, BN\n",
      "         L4:  64 filters, K=7x7, No-Pool, No-BN\n",
      "      FC Layers: 7\n",
      "         FC1:  286 nodes\n",
      "         FC2:  143 nodes\n",
      "         FC3:   71 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "      Activation: relu, Dropout: 0.374\n",
      "      Optimizer: adam, LR: 1e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6968, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6980, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6973, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6925, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6932, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6937, acc=51.41%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6955, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6942, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6960, acc=47.97%, best=47.97%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6989, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6977, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6944, acc=49.53%, best=49.53%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6931, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6974, acc=49.22%, best=49.22%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6982, acc=49.22%, best=49.22%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "      â†’ Fold 5 completed: 49.22%\n",
      "   â†’ Individual e557be6e: Average Fitness = 49.72%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 47.96875, 4: 49.53125, 5: 49.21875}\n",
      "\n",
      "Individual 14/20 - ID: fe0c7023\n",
      "\n",
      "   Evaluating Individual fe0c7023...\n",
      "\n",
      "   ðŸ“ Architecture of Individual fe0c7023:\n",
      "      Conv2D Layers: 6\n",
      "         L1:   8 filters, K=7x7, Pool, BN\n",
      "         L2:  16 filters, K=3x3, Pool, No-BN\n",
      "         L3:  32 filters, K=1x1, No-Pool, No-BN\n",
      "         L4:  64 filters, K=1x1, Pool, No-BN\n",
      "         L5: 128 filters, K=3x3, Pool, BN\n",
      "         L6: 128 filters, K=1x1, Pool, No-BN\n",
      "      FC Layers: 1\n",
      "         FC1:  308 nodes\n",
      "      Activation: tanh, Dropout: 0.319\n",
      "      Optimizer: rmsprop, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6800, acc=63.52%, best=63.52%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6379, acc=51.09%, best=63.52%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.5757, acc=52.58%, best=63.52%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6913, acc=61.64%, best=61.64%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6646, acc=62.73%, best=62.73%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6487, acc=63.52%, best=63.52%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.6198, acc=57.27%, best=63.52%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.5807, acc=54.38%, best=63.52%, patience=0\n",
      "          Fold 2: Early stopping at epoch 5\n",
      "      â†’ Fold 2 completed: 63.52%\n",
      "      â†’ Fold 2 completed: 63.52%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6787, acc=54.06%, best=54.06%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6100, acc=52.73%, best=54.06%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.5119, acc=46.80%, best=54.06%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 54.06%\n",
      "      â†’ Fold 3 completed: 54.06%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6689, acc=60.08%, best=60.08%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6176, acc=48.75%, best=60.08%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.5587, acc=50.70%, best=60.08%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 60.08%\n",
      "      â†’ Fold 4 completed: 60.08%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6876, acc=66.02%, best=66.02%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6351, acc=49.14%, best=66.02%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.5595, acc=49.06%, best=66.02%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 66.02%\n",
      "      â†’ Fold 5 completed: 66.02%\n",
      "   â†’ Individual fe0c7023: Average Fitness = 61.44%\n",
      "      Fold details: {1: 63.515625, 2: 63.515625, 3: 54.0625, 4: 60.078125, 5: 66.015625}\n",
      "\n",
      "Individual 15/20 - ID: d1cf38cd\n",
      "\n",
      "   Evaluating Individual d1cf38cd...\n",
      "\n",
      "   ðŸ“ Architecture of Individual d1cf38cd:\n",
      "      Conv2D Layers: 6\n",
      "         L1:   8 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  16 filters, K=1x1, Pool, No-BN\n",
      "         L3:  32 filters, K=1x1, Pool, BN\n",
      "         L4:  64 filters, K=3x3, No-Pool, No-BN\n",
      "         L5: 128 filters, K=5x5, No-Pool, BN\n",
      "         L6: 128 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 2\n",
      "         FC1:  334 nodes\n",
      "         FC2:  167 nodes\n",
      "      Activation: relu, Dropout: 0.467\n",
      "      Optimizer: adamw, LR: 1e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6907, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6776, acc=58.83%, best=58.83%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6742, acc=55.00%, best=58.83%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.6672, acc=58.83%, best=58.83%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6976, acc=55.62%, best=55.62%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6893, acc=66.48%, best=66.48%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6869, acc=77.58%, best=77.58%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.6809, acc=59.22%, best=77.58%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.6723, acc=73.98%, best=77.58%, patience=0\n",
      "          Fold 2: Early stopping at epoch 5\n",
      "      â†’ Fold 2 completed: 77.58%\n",
      "      â†’ Fold 2 completed: 77.58%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6922, acc=52.11%, best=52.11%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6847, acc=71.41%, best=71.41%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6767, acc=76.02%, best=76.02%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6673, acc=72.11%, best=76.02%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.6554, acc=70.47%, best=76.02%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 76.02%\n",
      "      â†’ Fold 3 completed: 76.02%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6840, acc=54.53%, best=54.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6738, acc=62.73%, best=62.73%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6631, acc=63.36%, best=63.36%, patience=2\n",
      "          Fold 4 Epoch 4/10: loss=0.6564, acc=60.00%, best=63.36%, patience=1\n",
      "          Fold 4 Epoch 5/10: loss=0.6465, acc=58.91%, best=63.36%, patience=0\n",
      "          Fold 4: Early stopping at epoch 5\n",
      "      â†’ Fold 4 completed: 63.36%\n",
      "      â†’ Fold 4 completed: 63.36%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6962, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6889, acc=63.83%, best=63.83%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6788, acc=56.33%, best=63.83%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.6770, acc=54.14%, best=63.83%, patience=0\n",
      "          Fold 5: Early stopping at epoch 4\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "   â†’ Individual d1cf38cd: Average Fitness = 67.92%\n",
      "      Fold details: {1: 58.828125, 2: 77.578125, 3: 76.015625, 4: 63.359375, 5: 63.828125}\n",
      "\n",
      "Individual 16/20 - ID: d949c585\n",
      "\n",
      "   Evaluating Individual d949c585...\n",
      "\n",
      "   ðŸ“ Architecture of Individual d949c585:\n",
      "      Conv2D Layers: 5\n",
      "         L1:  11 filters, K=5x5, Pool, BN\n",
      "         L2:  22 filters, K=3x3, Pool, No-BN\n",
      "         L3:  44 filters, K=5x5, No-Pool, BN\n",
      "         L4:  88 filters, K=7x7, No-Pool, No-BN\n",
      "         L5: 128 filters, K=5x5, Pool, BN\n",
      "      FC Layers: 5\n",
      "         FC1:  823 nodes\n",
      "         FC2:  411 nodes\n",
      "         FC3:  205 nodes\n",
      "         FC4:  102 nodes\n",
      "         FC5:   64 nodes\n",
      "      Activation: sigmoid, Dropout: 0.366\n",
      "      Optimizer: adam, LR: 5e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7076, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7060, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.7037, acc=50.47%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7260, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7102, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7038, acc=51.41%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7495, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7243, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7138, acc=47.97%, best=47.97%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      â†’ Fold 3 completed: 47.97%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7441, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7175, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.7134, acc=49.53%, best=49.53%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7087, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7072, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7101, acc=49.22%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual d949c585: Average Fitness = 50.03%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 47.96875, 4: 49.53125, 5: 50.78125}\n",
      "\n",
      "Individual 17/20 - ID: 827f8b68\n",
      "\n",
      "   Evaluating Individual 827f8b68...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 827f8b68:\n",
      "      Conv2D Layers: 2\n",
      "         L1:  10 filters, K=1x1, Pool, BN\n",
      "         L2:  20 filters, K=5x5, No-Pool, BN\n",
      "      FC Layers: 2\n",
      "         FC1:  379 nodes\n",
      "         FC2:  189 nodes\n",
      "      Activation: tanh, Dropout: 0.470\n",
      "      Optimizer: sgd, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6958, acc=52.66%, best=52.66%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6918, acc=52.19%, best=52.66%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6863, acc=49.22%, best=52.66%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 52.66%\n",
      "      â†’ Fold 1 completed: 52.66%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6988, acc=61.41%, best=61.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6881, acc=61.95%, best=61.95%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6908, acc=61.95%, best=61.95%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.6833, acc=61.95%, best=61.95%, patience=0\n",
      "          Fold 2: Early stopping at epoch 4\n",
      "      â†’ Fold 2 completed: 61.95%\n",
      "      â†’ Fold 2 completed: 61.95%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6995, acc=70.00%, best=70.00%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6919, acc=73.52%, best=73.52%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6906, acc=72.97%, best=73.52%, patience=1\n",
      "          Fold 3 Epoch 4/10: loss=0.6817, acc=66.56%, best=73.52%, patience=0\n",
      "          Fold 3: Early stopping at epoch 4\n",
      "      â†’ Fold 3 completed: 73.52%\n",
      "      â†’ Fold 3 completed: 73.52%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7006, acc=55.62%, best=55.62%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6827, acc=59.77%, best=59.77%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6808, acc=58.12%, best=59.77%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.6738, acc=59.30%, best=59.77%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 59.77%\n",
      "      â†’ Fold 4 completed: 59.77%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7056, acc=40.47%, best=40.47%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7031, acc=53.05%, best=53.05%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6948, acc=53.98%, best=53.98%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.6954, acc=49.06%, best=53.98%, patience=1\n",
      "          Fold 5 Epoch 5/10: loss=0.6891, acc=62.50%, best=62.50%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.6830, acc=56.02%, best=62.50%, patience=1\n",
      "          Fold 5 Epoch 7/10: loss=0.6797, acc=61.17%, best=62.50%, patience=0\n",
      "          Fold 5: Early stopping at epoch 7\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "   â†’ Individual 827f8b68: Average Fitness = 62.08%\n",
      "      Fold details: {1: 52.65625, 2: 61.953125, 3: 73.515625, 4: 59.765625, 5: 62.5}\n",
      "\n",
      "Individual 18/20 - ID: dcbc3edb\n",
      "\n",
      "   Evaluating Individual dcbc3edb...\n",
      "\n",
      "   ðŸ“ Architecture of Individual dcbc3edb:\n",
      "      Conv2D Layers: 4\n",
      "         L1:   9 filters, K=5x5, Pool, BN\n",
      "         L2:  18 filters, K=7x7, Pool, No-BN\n",
      "         L3:  36 filters, K=3x3, No-Pool, No-BN\n",
      "         L4:  72 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 4\n",
      "         FC1:  337 nodes\n",
      "         FC2:  168 nodes\n",
      "         FC3:   84 nodes\n",
      "         FC4:   64 nodes\n",
      "      Activation: leaky_relu, Dropout: 0.436\n",
      "      Optimizer: rmsprop, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7666, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6955, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6962, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.6932, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7957, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6982, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6943, acc=51.41%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.6957, acc=48.59%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 4\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.8077, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6979, acc=66.64%, best=66.64%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6965, acc=69.53%, best=69.53%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6936, acc=45.94%, best=69.53%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.6928, acc=47.97%, best=69.53%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 69.53%\n",
      "      â†’ Fold 3 completed: 69.53%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.8011, acc=65.94%, best=65.94%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6873, acc=63.28%, best=65.94%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6928, acc=59.92%, best=65.94%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7480, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6970, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6943, acc=49.22%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual dcbc3edb: Average Fitness = 57.62%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 69.53125, 4: 65.9375, 5: 50.78125}\n",
      "\n",
      "Individual 19/20 - ID: 566bc4d0\n",
      "\n",
      "   Evaluating Individual 566bc4d0...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 566bc4d0:\n",
      "      Conv2D Layers: 1\n",
      "         L1:  11 filters, K=3x3, No-Pool, No-BN\n",
      "      FC Layers: 8\n",
      "         FC1:  376 nodes\n",
      "         FC2:  188 nodes\n",
      "         FC3:   94 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "         FC8:   64 nodes\n",
      "      Activation: leaky_relu, Dropout: 0.267\n",
      "      Optimizer: rmsprop, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6965, acc=55.08%, best=55.08%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6923, acc=44.45%, best=55.08%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6851, acc=47.73%, best=55.08%, patience=0\n",
      "          Fold 1: Early stopping at epoch 3\n",
      "      â†’ Fold 1 completed: 55.08%\n",
      "      â†’ Fold 1 completed: 55.08%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6953, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6921, acc=68.36%, best=68.36%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6852, acc=72.81%, best=72.81%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.6756, acc=62.19%, best=72.81%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.6670, acc=61.88%, best=72.81%, patience=0\n",
      "          Fold 2: Early stopping at epoch 5\n",
      "      â†’ Fold 2 completed: 72.81%\n",
      "      â†’ Fold 2 completed: 72.81%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6979, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6945, acc=47.97%, best=47.97%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6939, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6940, acc=47.97%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.6934, acc=47.97%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6952, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6930, acc=63.28%, best=63.28%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6861, acc=59.84%, best=63.28%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.6633, acc=57.66%, best=63.28%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 63.28%\n",
      "      â†’ Fold 4 completed: 63.28%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6980, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6933, acc=50.78%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6941, acc=50.78%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 566bc4d0: Average Fitness = 58.80%\n",
      "      Fold details: {1: 55.078125, 2: 72.8125, 3: 52.03125, 4: 63.28125, 5: 50.78125}\n",
      "\n",
      "Individual 20/20 - ID: bd06c6e4\n",
      "\n",
      "   Evaluating Individual bd06c6e4...\n",
      "\n",
      "   ðŸ“ Architecture of Individual bd06c6e4:\n",
      "      Conv2D Layers: 6\n",
      "         L1:   9 filters, K=5x5, No-Pool, No-BN\n",
      "         L2:  18 filters, K=5x5, Pool, No-BN\n",
      "         L3:  36 filters, K=7x7, No-Pool, No-BN\n",
      "         L4:  72 filters, K=5x5, Pool, BN\n",
      "         L5: 128 filters, K=1x1, Pool, No-BN\n",
      "         L6: 128 filters, K=1x1, No-Pool, BN\n",
      "      FC Layers: 5\n",
      "         FC1:  324 nodes\n",
      "         FC2:  162 nodes\n",
      "         FC3:   81 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "      Activation: relu, Dropout: 0.413\n",
      "      Optimizer: adamw, LR: 0.001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6947, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6864, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6721, acc=51.25%, best=51.25%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6498, acc=56.48%, best=56.48%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.6042, acc=64.84%, best=64.84%, patience=2\n",
      "          Fold 1 Epoch 6/10: loss=0.5688, acc=52.97%, best=64.84%, patience=1\n",
      "          Fold 1 Epoch 7/10: loss=0.5219, acc=63.83%, best=64.84%, patience=0\n",
      "          Fold 1: Early stopping at epoch 7\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6923, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6840, acc=48.59%, best=48.59%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6720, acc=48.59%, best=48.59%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6987, acc=66.56%, best=66.56%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6950, acc=47.97%, best=66.56%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6924, acc=56.72%, best=66.56%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 66.56%\n",
      "      â†’ Fold 3 completed: 66.56%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6957, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6917, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6919, acc=55.55%, best=55.55%, patience=2\n",
      "          Fold 4 Epoch 4/10: loss=0.6765, acc=52.19%, best=55.55%, patience=1\n",
      "          Fold 4 Epoch 5/10: loss=0.6592, acc=50.31%, best=55.55%, patience=0\n",
      "          Fold 4: Early stopping at epoch 5\n",
      "      â†’ Fold 4 completed: 55.55%\n",
      "      â†’ Fold 4 completed: 55.55%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6991, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6949, acc=49.22%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.6952, acc=50.78%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual bd06c6e4: Average Fitness = 57.27%\n",
      "      Fold details: {1: 64.84375, 2: 48.59375, 3: 66.5625, 4: 55.546875, 5: 50.78125}\n",
      "\n",
      "ðŸŽ‰ NEW BEST! Fitness: 67.92% (improvement: +inf%)\n",
      "\n",
      "Generation 1 Summary:\n",
      "   Best: 67.92% (ID: d1cf38cd)\n",
      "   Average: 54.71%\n",
      "   Generations without improvement: 0\n",
      "\n",
      "============================================================\n",
      "GENERATION 2/100\n",
      "============================================================\n",
      "\n",
      "Evaluating 20 individuals (5-fold CV)...\n",
      "\n",
      "Individual 1/20 - ID: d1cf38cd\n",
      "\n",
      "   Evaluating Individual d1cf38cd...\n",
      "\n",
      "   ðŸ“ Architecture of Individual d1cf38cd:\n",
      "      Conv2D Layers: 6\n",
      "         L1:   8 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  16 filters, K=1x1, Pool, No-BN\n",
      "         L3:  32 filters, K=1x1, Pool, BN\n",
      "         L4:  64 filters, K=3x3, No-Pool, No-BN\n",
      "         L5: 128 filters, K=5x5, No-Pool, BN\n",
      "         L6: 128 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 2\n",
      "         FC1:  334 nodes\n",
      "         FC2:  167 nodes\n",
      "      Activation: relu, Dropout: 0.467\n",
      "      Optimizer: adamw, LR: 1e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6865, acc=48.12%, best=48.12%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6709, acc=45.55%, best=48.12%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6610, acc=56.09%, best=56.09%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6526, acc=59.38%, best=59.38%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.6362, acc=57.73%, best=59.38%, patience=1\n",
      "          Fold 1 Epoch 6/10: loss=0.6157, acc=63.91%, best=63.91%, patience=2\n",
      "          Fold 1 Epoch 7/10: loss=0.5992, acc=64.22%, best=64.22%, patience=2\n",
      "          Fold 1 Epoch 8/10: loss=0.5839, acc=60.70%, best=64.22%, patience=1\n",
      "          Fold 1 Epoch 9/10: loss=0.5711, acc=67.73%, best=67.73%, patience=2\n",
      "          Fold 1 Epoch 10/10: loss=0.5444, acc=67.81%, best=67.81%, patience=2\n",
      "      â†’ Fold 1 completed: 67.81%\n",
      "      â†’ Fold 1 completed: 67.81%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6951, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6902, acc=71.95%, best=71.95%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6855, acc=73.36%, best=73.36%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.6829, acc=65.62%, best=73.36%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.6789, acc=73.52%, best=73.52%, patience=2\n",
      "          Fold 2 Epoch 6/10: loss=0.6806, acc=69.69%, best=73.52%, patience=1\n",
      "          Fold 2 Epoch 7/10: loss=0.6735, acc=74.84%, best=74.84%, patience=2\n",
      "          Fold 2 Epoch 8/10: loss=0.6691, acc=64.77%, best=74.84%, patience=1\n",
      "          Fold 2 Epoch 9/10: loss=0.6625, acc=68.98%, best=74.84%, patience=0\n",
      "          Fold 2: Early stopping at epoch 9\n",
      "      â†’ Fold 2 completed: 74.84%\n",
      "      â†’ Fold 2 completed: 74.84%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6997, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6882, acc=78.52%, best=78.52%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6827, acc=76.48%, best=78.52%, patience=1\n",
      "          Fold 3 Epoch 4/10: loss=0.6777, acc=74.69%, best=78.52%, patience=0\n",
      "          Fold 3: Early stopping at epoch 4\n",
      "      â†’ Fold 3 completed: 78.52%\n",
      "      â†’ Fold 3 completed: 78.52%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6895, acc=64.45%, best=64.45%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6764, acc=63.52%, best=64.45%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6714, acc=56.72%, best=64.45%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 64.45%\n",
      "      â†’ Fold 4 completed: 64.45%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6975, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6972, acc=52.42%, best=52.42%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6918, acc=66.41%, best=66.41%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.6890, acc=67.27%, best=67.27%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.6858, acc=52.19%, best=67.27%, patience=1\n",
      "          Fold 5 Epoch 6/10: loss=0.6844, acc=56.09%, best=67.27%, patience=0\n",
      "          Fold 5: Early stopping at epoch 6\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "   â†’ Individual d1cf38cd: Average Fitness = 70.58%\n",
      "      Fold details: {1: 67.8125, 2: 74.84375, 3: 78.515625, 4: 64.453125, 5: 67.265625}\n",
      "\n",
      "Individual 2/20 - ID: b7b77b4c\n",
      "\n",
      "   Evaluating Individual b7b77b4c...\n",
      "\n",
      "   ðŸ“ Architecture of Individual b7b77b4c:\n",
      "      Conv2D Layers: 2\n",
      "         L1:  12 filters, K=3x3, Pool, BN\n",
      "         L2:  24 filters, K=3x3, Pool, No-BN\n",
      "      FC Layers: 1\n",
      "         FC1:   96 nodes\n",
      "      Activation: relu, Dropout: 0.228\n",
      "      Optimizer: adam, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6991, acc=52.66%, best=52.66%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6713, acc=54.06%, best=54.06%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6520, acc=62.19%, best=62.19%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6243, acc=62.58%, best=62.58%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.5646, acc=54.45%, best=62.58%, patience=1\n",
      "          Fold 1 Epoch 6/10: loss=0.4898, acc=66.80%, best=66.80%, patience=2\n",
      "          Fold 1 Epoch 7/10: loss=0.3513, acc=87.81%, best=87.81%, patience=2\n",
      "          Fold 1 Epoch 8/10: loss=0.1639, acc=95.62%, best=95.62%, patience=2\n",
      "          Fold 1 Epoch 9/10: loss=0.0581, acc=96.56%, best=96.56%, patience=2\n",
      "          Fold 1 Epoch 10/10: loss=0.0339, acc=96.80%, best=96.80%, patience=2\n",
      "      â†’ Fold 1 completed: 96.80%\n",
      "      â†’ Fold 1 completed: 96.80%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.6919, acc=66.02%, best=66.02%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6635, acc=63.36%, best=66.02%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6342, acc=61.33%, best=66.02%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 66.02%\n",
      "      â†’ Fold 2 completed: 66.02%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6911, acc=83.20%, best=83.20%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6683, acc=75.39%, best=83.20%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.6072, acc=62.66%, best=83.20%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 83.20%\n",
      "      â†’ Fold 3 completed: 83.20%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6887, acc=58.83%, best=58.83%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6576, acc=59.84%, best=59.84%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6316, acc=56.48%, best=59.84%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.6073, acc=59.53%, best=59.84%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 59.84%\n",
      "      â†’ Fold 4 completed: 59.84%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6986, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6854, acc=59.77%, best=59.77%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6617, acc=61.48%, best=61.48%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.5945, acc=78.91%, best=78.91%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.4331, acc=81.33%, best=81.33%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.1725, acc=90.16%, best=90.16%, patience=2\n",
      "          Fold 5 Epoch 7/10: loss=0.0574, acc=93.98%, best=93.98%, patience=2\n",
      "          Fold 5 Epoch 8/10: loss=0.0385, acc=96.64%, best=96.64%, patience=2\n",
      "          Fold 5 Epoch 9/10: loss=0.0242, acc=94.30%, best=96.64%, patience=1\n",
      "          Fold 5 Epoch 10/10: loss=0.0228, acc=97.19%, best=97.19%, patience=2\n",
      "      â†’ Fold 5 completed: 97.19%\n",
      "      â†’ Fold 5 completed: 97.19%\n",
      "   â†’ Individual b7b77b4c: Average Fitness = 80.61%\n",
      "      Fold details: {1: 96.796875, 2: 66.015625, 3: 83.203125, 4: 59.84375, 5: 97.1875}\n",
      "\n",
      "Individual 3/20 - ID: a6a0c4ca\n",
      "\n",
      "   Evaluating Individual a6a0c4ca...\n",
      "\n",
      "   ðŸ“ Architecture of Individual a6a0c4ca:\n",
      "      Conv2D Layers: 4\n",
      "         L1:  16 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  32 filters, K=3x3, No-Pool, BN\n",
      "         L3:  64 filters, K=7x7, Pool, BN\n",
      "         L4: 128 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 4\n",
      "         FC1:  159 nodes\n",
      "         FC2:   79 nodes\n",
      "         FC3:   64 nodes\n",
      "         FC4:   64 nodes\n",
      "      Activation: leaky_relu, Dropout: 0.250\n",
      "      Optimizer: rmsprop, LR: 5e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6973, acc=52.66%, best=52.66%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6792, acc=61.95%, best=61.95%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6529, acc=65.47%, best=65.47%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6319, acc=63.91%, best=65.47%, patience=1\n",
      "          Fold 1 Epoch 5/10: loss=0.6172, acc=60.94%, best=65.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 5\n",
      "      â†’ Fold 1 completed: 65.47%\n",
      "      â†’ Fold 1 completed: 65.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7000, acc=62.66%, best=62.66%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6928, acc=51.41%, best=62.66%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6895, acc=56.88%, best=62.66%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 62.66%\n",
      "      â†’ Fold 2 completed: 62.66%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.6997, acc=47.97%, best=47.97%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6924, acc=54.84%, best=54.84%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6894, acc=58.12%, best=58.12%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6885, acc=69.69%, best=69.69%, patience=2\n",
      "          Fold 3 Epoch 5/10: loss=0.6786, acc=68.83%, best=69.69%, patience=1\n",
      "          Fold 3 Epoch 6/10: loss=0.6567, acc=64.14%, best=69.69%, patience=0\n",
      "          Fold 3: Early stopping at epoch 6\n",
      "      â†’ Fold 3 completed: 69.69%\n",
      "      â†’ Fold 3 completed: 69.69%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.6950, acc=67.27%, best=67.27%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6733, acc=63.83%, best=67.27%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6590, acc=57.89%, best=67.27%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 67.27%\n",
      "      â†’ Fold 4 completed: 67.27%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.6997, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6963, acc=65.00%, best=65.00%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6967, acc=49.22%, best=65.00%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.6924, acc=67.27%, best=67.27%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.6938, acc=70.47%, best=70.47%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.6885, acc=70.47%, best=70.47%, patience=1\n",
      "          Fold 5 Epoch 7/10: loss=0.6872, acc=50.94%, best=70.47%, patience=0\n",
      "          Fold 5: Early stopping at epoch 7\n",
      "      â†’ Fold 5 completed: 70.47%\n",
      "      â†’ Fold 5 completed: 70.47%\n",
      "   â†’ Individual a6a0c4ca: Average Fitness = 67.11%\n",
      "      Fold details: {1: 65.46875, 2: 62.65625, 3: 69.6875, 4: 67.265625, 5: 70.46875}\n",
      "\n",
      "Individual 4/20 - ID: 2c014b3b\n",
      "\n",
      "   Evaluating Individual 2c014b3b...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 2c014b3b:\n",
      "      Conv2D Layers: 4\n",
      "         L1:  15 filters, K=7x7, Pool, No-BN\n",
      "         L2:  30 filters, K=5x5, Pool, No-BN\n",
      "         L3:  60 filters, K=3x3, Pool, BN\n",
      "         L4: 120 filters, K=5x5, No-Pool, BN\n",
      "      FC Layers: 3\n",
      "         FC1:  999 nodes\n",
      "         FC2:  499 nodes\n",
      "         FC3:  249 nodes\n",
      "      Activation: selu, Dropout: 0.463\n",
      "      Optimizer: adamw, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7968, acc=51.09%, best=51.09%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7846, acc=58.83%, best=58.83%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.7531, acc=53.12%, best=58.83%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.7299, acc=55.16%, best=58.83%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7845, acc=51.80%, best=51.80%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7696, acc=67.19%, best=67.19%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.7792, acc=60.31%, best=67.19%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.7549, acc=63.98%, best=67.19%, patience=0\n",
      "          Fold 2: Early stopping at epoch 4\n",
      "      â†’ Fold 2 completed: 67.19%\n",
      "      â†’ Fold 2 completed: 67.19%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.8103, acc=68.67%, best=68.67%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7611, acc=54.84%, best=68.67%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7170, acc=66.02%, best=68.67%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 68.67%\n",
      "      â†’ Fold 3 completed: 68.67%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7563, acc=62.97%, best=62.97%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7176, acc=51.95%, best=62.97%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.7062, acc=50.78%, best=62.97%, patience=0\n",
      "          Fold 4: Early stopping at epoch 3\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.8103, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7933, acc=56.72%, best=56.72%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.7458, acc=67.81%, best=67.81%, patience=2\n",
      "          Fold 5 Epoch 4/10: loss=0.7152, acc=60.23%, best=67.81%, patience=1\n",
      "          Fold 5 Epoch 5/10: loss=0.6595, acc=56.09%, best=67.81%, patience=0\n",
      "          Fold 5: Early stopping at epoch 5\n",
      "      â†’ Fold 5 completed: 67.81%\n",
      "      â†’ Fold 5 completed: 67.81%\n",
      "   â†’ Individual 2c014b3b: Average Fitness = 65.09%\n",
      "      Fold details: {1: 58.828125, 2: 67.1875, 3: 68.671875, 4: 62.96875, 5: 67.8125}\n",
      "\n",
      "Individual 5/20 - ID: cd114d28\n",
      "\n",
      "   Evaluating Individual cd114d28...\n",
      "\n",
      "   ðŸ“ Architecture of Individual cd114d28:\n",
      "      Conv2D Layers: 6\n",
      "         L1:   8 filters, K=7x7, Pool, BN\n",
      "         L2:  16 filters, K=3x3, Pool, No-BN\n",
      "         L3:  32 filters, K=1x1, No-Pool, No-BN\n",
      "         L4:  44 filters, K=7x7, Pool, No-BN\n",
      "         L5: 108 filters, K=3x3, Pool, BN\n",
      "         L6: 128 filters, K=1x1, Pool, No-BN\n",
      "      FC Layers: 4\n",
      "         FC1:  308 nodes\n",
      "         FC2:  494 nodes\n",
      "         FC3:  744 nodes\n",
      "         FC4:  452 nodes\n",
      "      Activation: selu, Dropout: 0.486\n",
      "      Optimizer: adamw, LR: 0.0001\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7240, acc=56.95%, best=56.95%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7154, acc=60.08%, best=60.08%, patience=2\n",
      "          Fold 1 Epoch 3/10: loss=0.6971, acc=55.62%, best=60.08%, patience=1\n",
      "          Fold 1 Epoch 4/10: loss=0.6564, acc=59.92%, best=60.08%, patience=0\n",
      "          Fold 1: Early stopping at epoch 4\n",
      "      â†’ Fold 1 completed: 60.08%\n",
      "      â†’ Fold 1 completed: 60.08%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7183, acc=67.81%, best=67.81%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7096, acc=51.02%, best=67.81%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7023, acc=65.00%, best=67.81%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7259, acc=57.58%, best=57.58%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7138, acc=69.38%, best=69.38%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6963, acc=72.11%, best=72.11%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.6781, acc=51.33%, best=72.11%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.6225, acc=47.03%, best=72.11%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 72.11%\n",
      "      â†’ Fold 3 completed: 72.11%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7122, acc=61.33%, best=61.33%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6980, acc=64.06%, best=64.06%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6682, acc=56.33%, best=64.06%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.6599, acc=47.73%, best=64.06%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 64.06%\n",
      "      â†’ Fold 4 completed: 64.06%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7375, acc=81.72%, best=81.72%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7201, acc=49.22%, best=81.72%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7126, acc=49.22%, best=81.72%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 81.72%\n",
      "      â†’ Fold 5 completed: 81.72%\n",
      "   â†’ Individual cd114d28: Average Fitness = 69.16%\n",
      "      Fold details: {1: 60.078125, 2: 67.8125, 3: 72.109375, 4: 64.0625, 5: 81.71875}\n",
      "\n",
      "Individual 6/20 - ID: 52dedf75\n",
      "\n",
      "   Evaluating Individual 52dedf75...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 52dedf75:\n",
      "      Conv2D Layers: 1\n",
      "         L1:   9 filters, K=7x7, No-Pool, BN\n",
      "      FC Layers: 8\n",
      "         FC1:  842 nodes\n",
      "         FC2:  735 nodes\n",
      "         FC3:  934 nodes\n",
      "         FC4:  850 nodes\n",
      "         FC5:  138 nodes\n",
      "         FC6:  530 nodes\n",
      "         FC7:  488 nodes\n",
      "         FC8:  887 nodes\n",
      "      Activation: tanh, Dropout: 0.319\n",
      "      Optimizer: rmsprop, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=1.0008, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7110, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.7073, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.7093, acc=50.47%, best=50.47%, patience=1\n",
      "          Fold 1 Epoch 5/10: loss=0.7046, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 1: Early stopping at epoch 5\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      â†’ Fold 1 completed: 50.47%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.9451, acc=48.59%, best=48.59%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7123, acc=51.41%, best=51.41%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.7112, acc=48.59%, best=51.41%, patience=1\n",
      "          Fold 2 Epoch 4/10: loss=0.7124, acc=48.59%, best=51.41%, patience=0\n",
      "          Fold 2: Early stopping at epoch 4\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.9214, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7085, acc=52.03%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7068, acc=47.97%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.9570, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7218, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.7221, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.7227, acc=49.53%, best=50.47%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.9092, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7063, acc=49.22%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 3/10: loss=0.7022, acc=50.78%, best=50.78%, patience=0\n",
      "          Fold 5: Early stopping at epoch 3\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "      â†’ Fold 5 completed: 50.78%\n",
      "   â†’ Individual 52dedf75: Average Fitness = 51.03%\n",
      "      Fold details: {1: 50.46875, 2: 51.40625, 3: 52.03125, 4: 50.46875, 5: 50.78125}\n",
      "\n",
      "Individual 7/20 - ID: ddad6e80\n",
      "\n",
      "   Evaluating Individual ddad6e80...\n",
      "\n",
      "   ðŸ“ Architecture of Individual ddad6e80:\n",
      "      Conv2D Layers: 1\n",
      "         L1:  12 filters, K=3x3, Pool, BN\n",
      "      FC Layers: 1\n",
      "         FC1:   96 nodes\n",
      "      Activation: sigmoid, Dropout: 0.286\n",
      "      Optimizer: adam, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.7023, acc=53.20%, best=53.20%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.7002, acc=50.47%, best=53.20%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.7061, acc=56.64%, best=56.64%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6971, acc=58.75%, best=58.75%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.6936, acc=56.48%, best=58.75%, patience=1\n",
      "          Fold 1 Epoch 6/10: loss=0.6894, acc=63.20%, best=63.20%, patience=2\n",
      "          Fold 1 Epoch 7/10: loss=0.6900, acc=52.34%, best=63.20%, patience=1\n",
      "          Fold 1 Epoch 8/10: loss=0.6903, acc=54.53%, best=63.20%, patience=0\n",
      "          Fold 1: Early stopping at epoch 8\n",
      "      â†’ Fold 1 completed: 63.20%\n",
      "      â†’ Fold 1 completed: 63.20%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.7369, acc=50.70%, best=50.70%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6983, acc=65.62%, best=65.62%, patience=2\n",
      "          Fold 2 Epoch 3/10: loss=0.6969, acc=66.25%, best=66.25%, patience=2\n",
      "          Fold 2 Epoch 4/10: loss=0.7002, acc=61.72%, best=66.25%, patience=1\n",
      "          Fold 2 Epoch 5/10: loss=0.6938, acc=63.52%, best=66.25%, patience=0\n",
      "          Fold 2: Early stopping at epoch 5\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.7352, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7065, acc=52.03%, best=52.03%, patience=1\n",
      "          Fold 3 Epoch 3/10: loss=0.7037, acc=52.03%, best=52.03%, patience=0\n",
      "          Fold 3: Early stopping at epoch 3\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.7119, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7043, acc=49.53%, best=50.47%, patience=1\n",
      "          Fold 4 Epoch 3/10: loss=0.6978, acc=57.42%, best=57.42%, patience=2\n",
      "          Fold 4 Epoch 4/10: loss=0.6980, acc=64.84%, best=64.84%, patience=2\n",
      "          Fold 4 Epoch 5/10: loss=0.6902, acc=59.92%, best=64.84%, patience=1\n",
      "          Fold 4 Epoch 6/10: loss=0.6846, acc=64.84%, best=64.84%, patience=0\n",
      "          Fold 4: Early stopping at epoch 6\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.7219, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6992, acc=56.64%, best=56.64%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6980, acc=49.22%, best=56.64%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.6979, acc=50.78%, best=56.64%, patience=0\n",
      "          Fold 5: Early stopping at epoch 4\n",
      "      â†’ Fold 5 completed: 56.64%\n",
      "      â†’ Fold 5 completed: 56.64%\n",
      "   â†’ Individual ddad6e80: Average Fitness = 60.59%\n",
      "      Fold details: {1: 63.203125, 2: 66.25, 3: 52.03125, 4: 64.84375, 5: 56.640625}\n",
      "\n",
      "Individual 8/20 - ID: a9ebe872\n",
      "\n",
      "   Evaluating Individual a9ebe872...\n",
      "\n",
      "   ðŸ“ Architecture of Individual a9ebe872:\n",
      "      Conv2D Layers: 2\n",
      "         L1:  11 filters, K=7x7, No-Pool, No-BN\n",
      "         L2:  35 filters, K=7x7, No-Pool, No-BN\n",
      "      FC Layers: 4\n",
      "         FC1:  376 nodes\n",
      "         FC2:  916 nodes\n",
      "         FC3:   94 nodes\n",
      "         FC4:   64 nodes\n",
      "      Activation: relu, Dropout: 0.267\n",
      "      Optimizer: rmsprop, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.9301, acc=54.61%, best=54.61%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6818, acc=52.42%, best=54.61%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.6286, acc=64.22%, best=64.22%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.6069, acc=58.44%, best=64.22%, patience=1\n",
      "          Fold 1 Epoch 5/10: loss=0.4970, acc=52.58%, best=64.22%, patience=0\n",
      "          Fold 1: Early stopping at epoch 5\n",
      "      â†’ Fold 1 completed: 64.22%\n",
      "      â†’ Fold 1 completed: 64.22%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=1.0591, acc=77.81%, best=77.81%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.6902, acc=65.31%, best=77.81%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.6771, acc=64.92%, best=77.81%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 77.81%\n",
      "      â†’ Fold 2 completed: 77.81%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.9152, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.6882, acc=65.31%, best=65.31%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.6628, acc=73.83%, best=73.83%, patience=2\n",
      "          Fold 3 Epoch 4/10: loss=0.5919, acc=53.59%, best=73.83%, patience=1\n",
      "          Fold 3 Epoch 5/10: loss=0.5522, acc=72.73%, best=73.83%, patience=0\n",
      "          Fold 3: Early stopping at epoch 5\n",
      "      â†’ Fold 3 completed: 73.83%\n",
      "      â†’ Fold 3 completed: 73.83%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.8572, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.6828, acc=65.23%, best=65.23%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.6394, acc=43.12%, best=65.23%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.5809, acc=44.38%, best=65.23%, patience=0\n",
      "          Fold 4: Early stopping at epoch 4\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=1.2261, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.6925, acc=64.38%, best=64.38%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.6941, acc=50.86%, best=64.38%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.6926, acc=49.22%, best=64.38%, patience=0\n",
      "          Fold 5: Early stopping at epoch 4\n",
      "      â†’ Fold 5 completed: 64.38%\n",
      "      â†’ Fold 5 completed: 64.38%\n",
      "   â†’ Individual a9ebe872: Average Fitness = 69.09%\n",
      "      Fold details: {1: 64.21875, 2: 77.8125, 3: 73.828125, 4: 65.234375, 5: 64.375}\n",
      "\n",
      "Individual 9/20 - ID: 48b07985\n",
      "\n",
      "   Evaluating Individual 48b07985...\n",
      "\n",
      "   ðŸ“ Architecture of Individual 48b07985:\n",
      "      Conv2D Layers: 1\n",
      "         L1:   9 filters, K=7x7, No-Pool, BN\n",
      "      FC Layers: 4\n",
      "         FC1:  842 nodes\n",
      "         FC2:   64 nodes\n",
      "         FC3:   64 nodes\n",
      "         FC4:   64 nodes\n",
      "      Activation: selu, Dropout: 0.430\n",
      "      Optimizer: rmsprop, LR: 5e-05\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.8950, acc=49.53%, best=49.53%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.8038, acc=49.53%, best=49.53%, patience=1\n",
      "          Fold 1 Epoch 3/10: loss=0.7771, acc=49.69%, best=49.69%, patience=2\n",
      "          Fold 1 Epoch 4/10: loss=0.7885, acc=56.72%, best=56.72%, patience=2\n",
      "          Fold 1 Epoch 5/10: loss=0.7765, acc=52.66%, best=56.72%, patience=1\n",
      "          Fold 1 Epoch 6/10: loss=0.7656, acc=60.39%, best=60.39%, patience=2\n",
      "          Fold 1 Epoch 7/10: loss=0.7630, acc=52.11%, best=60.39%, patience=1\n",
      "          Fold 1 Epoch 8/10: loss=0.7268, acc=57.34%, best=60.39%, patience=0\n",
      "          Fold 1: Early stopping at epoch 8\n",
      "      â†’ Fold 1 completed: 60.39%\n",
      "      â†’ Fold 1 completed: 60.39%\n",
      "      Training Fold 2/5...\n",
      "      Loading data for Fold 2...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 2 Epoch 1/10: loss=0.8416, acc=71.09%, best=71.09%, patience=2\n",
      "          Fold 2 Epoch 2/10: loss=0.7618, acc=62.73%, best=71.09%, patience=1\n",
      "          Fold 2 Epoch 3/10: loss=0.7632, acc=62.19%, best=71.09%, patience=0\n",
      "          Fold 2: Early stopping at epoch 3\n",
      "      â†’ Fold 2 completed: 71.09%\n",
      "      â†’ Fold 2 completed: 71.09%\n",
      "      Training Fold 3/5...\n",
      "      Loading data for Fold 3...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 3 Epoch 1/10: loss=0.8356, acc=52.03%, best=52.03%, patience=2\n",
      "          Fold 3 Epoch 2/10: loss=0.7586, acc=72.58%, best=72.58%, patience=2\n",
      "          Fold 3 Epoch 3/10: loss=0.7525, acc=70.00%, best=72.58%, patience=1\n",
      "          Fold 3 Epoch 4/10: loss=0.7473, acc=72.81%, best=72.81%, patience=2\n",
      "          Fold 3 Epoch 5/10: loss=0.7413, acc=73.12%, best=73.12%, patience=2\n",
      "          Fold 3 Epoch 6/10: loss=0.7416, acc=74.92%, best=74.92%, patience=2\n",
      "          Fold 3 Epoch 7/10: loss=0.7247, acc=79.69%, best=79.69%, patience=2\n",
      "          Fold 3 Epoch 8/10: loss=0.7217, acc=68.44%, best=79.69%, patience=1\n",
      "          Fold 3 Epoch 9/10: loss=0.6947, acc=79.06%, best=79.69%, patience=0\n",
      "          Fold 3: Early stopping at epoch 9\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "      Training Fold 4/5...\n",
      "      Loading data for Fold 4...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 4 Epoch 1/10: loss=0.9089, acc=59.38%, best=59.38%, patience=2\n",
      "          Fold 4 Epoch 2/10: loss=0.7919, acc=59.77%, best=59.77%, patience=2\n",
      "          Fold 4 Epoch 3/10: loss=0.7628, acc=56.80%, best=59.77%, patience=1\n",
      "          Fold 4 Epoch 4/10: loss=0.7444, acc=64.53%, best=64.53%, patience=2\n",
      "          Fold 4 Epoch 5/10: loss=0.7241, acc=62.81%, best=64.53%, patience=1\n",
      "          Fold 4 Epoch 6/10: loss=0.6963, acc=60.86%, best=64.53%, patience=0\n",
      "          Fold 4: Early stopping at epoch 6\n",
      "      â†’ Fold 4 completed: 64.53%\n",
      "      â†’ Fold 4 completed: 64.53%\n",
      "      Training Fold 5/5...\n",
      "      Loading data for Fold 5...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 5 Epoch 1/10: loss=0.8389, acc=49.22%, best=49.22%, patience=2\n",
      "          Fold 5 Epoch 2/10: loss=0.7850, acc=50.78%, best=50.78%, patience=2\n",
      "          Fold 5 Epoch 3/10: loss=0.7602, acc=49.22%, best=50.78%, patience=1\n",
      "          Fold 5 Epoch 4/10: loss=0.7732, acc=55.70%, best=55.70%, patience=2\n",
      "          Fold 5 Epoch 5/10: loss=0.7496, acc=62.27%, best=62.27%, patience=2\n",
      "          Fold 5 Epoch 6/10: loss=0.7410, acc=67.73%, best=67.73%, patience=2\n",
      "          Fold 5 Epoch 7/10: loss=0.7395, acc=61.56%, best=67.73%, patience=1\n",
      "          Fold 5 Epoch 8/10: loss=0.7252, acc=67.11%, best=67.73%, patience=0\n",
      "          Fold 5: Early stopping at epoch 8\n",
      "      â†’ Fold 5 completed: 67.73%\n",
      "      â†’ Fold 5 completed: 67.73%\n",
      "   â†’ Individual 48b07985: Average Fitness = 68.69%\n",
      "      Fold details: {1: 60.390625, 2: 71.09375, 3: 79.6875, 4: 64.53125, 5: 67.734375}\n",
      "\n",
      "Individual 10/20 - ID: f99f1958\n",
      "\n",
      "   Evaluating Individual f99f1958...\n",
      "\n",
      "   ðŸ“ Architecture of Individual f99f1958:\n",
      "      Conv2D Layers: 5\n",
      "         L1:  11 filters, K=3x3, No-Pool, No-BN\n",
      "         L2:  35 filters, K=7x7, Pool, No-BN\n",
      "         L3:  10 filters, K=5x5, No-Pool, BN\n",
      "         L4:  49 filters, K=7x7, Pool, BN\n",
      "         L5:  68 filters, K=1x1, Pool, BN\n",
      "      FC Layers: 8\n",
      "         FC1:  376 nodes\n",
      "         FC2:  382 nodes\n",
      "         FC3:   90 nodes\n",
      "         FC4:   64 nodes\n",
      "         FC5:   64 nodes\n",
      "         FC6:   64 nodes\n",
      "         FC7:   64 nodes\n",
      "         FC8:   64 nodes\n",
      "      Activation: selu, Dropout: 0.267\n",
      "      Optimizer: sgd, LR: 0.0005\n",
      "      Training Fold 1/5...\n",
      "      Loading data for Fold 1...\n",
      "         Target resize: 32x64 (HxW), Channels: 3\n",
      "          Fold 1 Epoch 1/10: loss=0.6986, acc=50.47%, best=50.47%, patience=2\n",
      "          Fold 1 Epoch 2/10: loss=0.6996, acc=50.47%, best=50.47%, patience=1\n"
     ]
    }
   ],
   "source": [
    "## Execute the hybrid neuroevolution\n",
    "import time\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING HYBRID NEUROEVOLUTION FOR IMAGE CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset: {CONFIG['dataset']}\")\n",
    "print(f\"Data path: {CONFIG['data_path']}\")\n",
    "print(f\"Population size: {CONFIG['population_size']}\")\n",
    "print(f\"Max generations: {CONFIG['max_generations']}\")\n",
    "print(f\"Fitness threshold: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"Image size: {CONFIG['image_width']}x{CONFIG['image_height']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Using 5-fold cross-validation (sequential, CUDA-safe)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create neuroevolution instance\n",
    "neuroevolution = HybridNeuroevolutionImage(CONFIG)\n",
    "\n",
    "# Start evolution\n",
    "start_time = time.time()\n",
    "best_genome = neuroevolution.evolve()\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EVOLUTION COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total execution time: {execution_time:.2f} seconds ({execution_time/60:.2f} minutes)\")\n",
    "print(f\"Generations completed: {neuroevolution.generation}\")\n",
    "print(f\"Best fitness achieved: {best_genome['fitness']:.2f}%\")\n",
    "print(f\"Best individual ID: {best_genome['id']}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best architecture\n",
    "def display_best_architecture(genome: dict, config: dict):\n",
    "    \"\"\"Display detailed information about the best architecture found.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BEST ARCHITECTURE DETAILS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nGenome ID: {genome['id']}\")\n",
    "    print(f\"Fitness (5-fold CV average): {genome['fitness']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n--- ARCHITECTURE ---\")\n",
    "    print(f\"Convolutional Layers (2D): {genome['num_conv_layers']}\")\n",
    "    for i in range(genome['num_conv_layers']):\n",
    "        print(f\"  Layer {i+1}: {genome['filters'][i]} filters, kernel={genome['kernel_sizes'][i]}x{genome['kernel_sizes'][i]}, \" +\n",
    "              f\"pool={'Yes' if genome['use_pooling'][i] else 'No'}, \" +\n",
    "              f\"bn={'Yes' if genome['use_batch_norm'][i] else 'No'}\")\n",
    "    \n",
    "    print(f\"\\nFully Connected Layers: {genome['num_fc_layers']}\")\n",
    "    for i in range(genome['num_fc_layers']):\n",
    "        print(f\"  FC Layer {i+1}: {genome['fc_nodes'][i]} nodes\")\n",
    "    \n",
    "    print(f\"\\n--- HYPERPARAMETERS ---\")\n",
    "    print(f\"Activation: {genome['activation']}\")\n",
    "    print(f\"Dropout rate: {genome['dropout_rate']:.3f}\")\n",
    "    print(f\"Optimizer: {genome['optimizer']}\")\n",
    "    print(f\"Learning rate: {genome['learning_rate']}\")\n",
    "    \n",
    "    print(f\"\\n--- DATASET INFO ---\")\n",
    "    print(f\"Dataset: Images (Spectrograms)\")\n",
    "    print(f\"Image size: {config['image_width']}x{config['image_height']}\")\n",
    "    print(f\"Channels: {config['num_channels']} (RGB)\")\n",
    "    print(f\"Classes: {config['num_classes']} (Control vs Pathological)\")\n",
    "    print(f\"Batch size: {config['batch_size']}\")\n",
    "    \n",
    "    print(f\"\\n--- PERFORMANCE ---\")\n",
    "    if genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"âœ“ TARGET REACHED: {genome['fitness']:.2f}% >= {config['fitness_threshold']}%\")\n",
    "    else:\n",
    "        print(f\"âœ— TARGET NOT REACHED: {genome['fitness']:.2f}% < {config['fitness_threshold']}%\")\n",
    "        print(f\"  Gap: {config['fitness_threshold'] - genome['fitness']:.2f}%\")\n",
    "    \n",
    "    # Save results to JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_images_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'dataset_type': 'image_2D',\n",
    "        'dataset_id': config.get('dataset_id', 'N/A'),\n",
    "        'best_genome': genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats,\n",
    "        'config': {k: v for k, v in config.items() if k not in ['normalization']}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\nâœ“ Results saved to: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— WARNING: Error saving results: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"HYBRID NEUROEVOLUTION FOR IMAGES COMPLETED!\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Display the best architecture\n",
    "display_best_architecture(best_genome, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize evolution progress\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Fitness over generations\n",
    "plt.subplot(1, 2, 1)\n",
    "generations = [stat['generation'] for stat in neuroevolution.generation_stats]\n",
    "best_fitnesses = [stat['best_fitness'] for stat in neuroevolution.generation_stats]\n",
    "avg_fitnesses = [stat['avg_fitness'] for stat in neuroevolution.generation_stats]\n",
    "\n",
    "plt.plot(generations, best_fitnesses, 'b-o', label='Best Fitness', linewidth=2, markersize=6)\n",
    "plt.plot(generations, avg_fitnesses, 'r--s', label='Average Fitness', linewidth=2, markersize=4)\n",
    "plt.axhline(y=CONFIG['fitness_threshold'], color='g', linestyle=':', label=f'Target ({CONFIG[\"fitness_threshold\"]}%)')\n",
    "plt.xlabel('Generation', fontsize=12)\n",
    "plt.ylabel('Fitness (%)', fontsize=12)\n",
    "plt.title('Evolution Progress - Image Classification', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Architecture complexity over generations\n",
    "plt.subplot(1, 2, 2)\n",
    "# Get architecture info from generation stats\n",
    "conv_layers = []\n",
    "fc_layers = []\n",
    "\n",
    "for gen in generations:\n",
    "    # Find best individual of this generation\n",
    "    gen_stat = neuroevolution.generation_stats[gen-1]\n",
    "    best_id = gen_stat['best_id']\n",
    "    \n",
    "    # Find genome (from population or best)\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['id'] == best_id:\n",
    "        genome = neuroevolution.best_individual\n",
    "    else:\n",
    "        # Try to find in current population\n",
    "        genome = next((ind for ind in neuroevolution.population if ind['id'] == best_id), None)\n",
    "        if not genome:\n",
    "            # Use current best as fallback\n",
    "            genome = neuroevolution.best_individual if neuroevolution.best_individual else neuroevolution.population[0]\n",
    "    \n",
    "    conv_layers.append(genome['num_conv_layers'])\n",
    "    fc_layers.append(genome['num_fc_layers'])\n",
    "\n",
    "plt.plot(generations, conv_layers, 'b-o', label='Conv2D Layers', linewidth=2, markersize=6)\n",
    "plt.plot(generations, fc_layers, 'r--s', label='FC Layers', linewidth=2, markersize=4)\n",
    "plt.xlabel('Generation', fontsize=12)\n",
    "plt.ylabel('Number of Layers', fontsize=12)\n",
    "plt.title('Architecture Complexity Evolution', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Build filename using an f-string and single quotes inside strftime to avoid nested quote conflicts\n",
    "filename = f\"evolution_progress_images_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
