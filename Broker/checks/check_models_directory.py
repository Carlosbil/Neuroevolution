#!/usr/bin/env python3
"""
Script para verificar el estado del directorio de modelos y ayudar con el debug.
"""

import os
import sys
import json
from dotenv import load_dotenv
import logging
from datetime import datetime
import argparse

# Cargar variables de entorno
load_dotenv()

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# Configuraci√≥n del path de storage
STORAGE_PATH = os.environ.get("BROKER_STORAGE_PATH", os.path.join(os.path.dirname(__file__), 'models'))

def check_storage_directory():
    """Verifica el estado del directorio de storage."""
    logger.info(f"üìÅ Verificando directorio de storage: {STORAGE_PATH}")
    
    if not os.path.exists(STORAGE_PATH):
        logger.error(f"‚ùå El directorio de storage no existe: {STORAGE_PATH}")
        return False
    
    # Listar todos los archivos
    try:
        files = os.listdir(STORAGE_PATH)
        logger.info(f"üìÇ Archivos encontrados en el directorio: {len(files)}")
        
        if not files:
            logger.warning("‚ö†Ô∏è El directorio de storage est√° vac√≠o")
            return True
        
        # Analizar cada archivo
        json_files = []
        other_files = []
        
        for file in files:
            file_path = os.path.join(STORAGE_PATH, file)
            if file.endswith('.json'):
                json_files.append(file)
            else:
                other_files.append(file)
        
        logger.info(f"üìÑ Archivos JSON: {len(json_files)}")
        logger.info(f"üìÑ Otros archivos: {len(other_files)}")
        
        # Mostrar archivos JSON
        for json_file in json_files:
            logger.info(f"  ‚Ä¢ {json_file}")
            
        # Mostrar otros archivos
        for other_file in other_files:
            logger.info(f"  ‚Ä¢ {other_file} (no JSON)")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error leyendo directorio de storage: {e}")
        return False

def analyze_json_file(filename):
    """Analiza un archivo JSON espec√≠fico."""
    file_path = os.path.join(STORAGE_PATH, filename)
    
    if not os.path.exists(file_path):
        logger.error(f"‚ùå Archivo no encontrado: {file_path}")
        return False
    
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        logger.info(f"üîç Analizando archivo: {filename}")
        logger.info(f"üìä Tipo de datos: {type(data)}")
        
        if isinstance(data, dict):
            logger.info(f"üìã Claves principales: {list(data.keys())}")
            logger.info(f"üìä N√∫mero de elementos: {len(data)}")
            
            # Analizar cada elemento
            for key, value in data.items():
                logger.info(f"  ‚Ä¢ {key}: {type(value)}")
                if isinstance(value, dict):
                    logger.info(f"    - Subclaves: {list(value.keys())}")
                elif isinstance(value, list):
                    logger.info(f"    - Elementos en lista: {len(value)}")
                    if value:
                        logger.info(f"    - Tipo de primer elemento: {type(value[0])}")
        
        elif isinstance(data, list):
            logger.info(f"üìä Elementos en lista: {len(data)}")
            if data:
                logger.info(f"üìã Tipo de primer elemento: {type(data[0])}")
                if isinstance(data[0], dict):
                    logger.info(f"üìã Claves del primer elemento: {list(data[0].keys())}")
        
        return True
        
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Error decodificando JSON: {e}")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error analizando archivo: {e}")
        return False

def create_test_model():
    """Crea un archivo de modelo de prueba."""
    test_uuid = "test-model-" + datetime.now().strftime("%Y%m%d-%H%M%S")
    test_file = f"{test_uuid}.json"
    test_path = os.path.join(STORAGE_PATH, test_file)
    
    # Crear directorio si no existe
    os.makedirs(STORAGE_PATH, exist_ok=True)
    
    # Crear modelo de prueba
    test_data = {
        "model_1": {
            "layers": [
                {"type": "Conv2D", "filters": 32, "kernel_size": 3},
                {"type": "MaxPooling2D", "pool_size": 2},
                {"type": "Conv2D", "filters": 64, "kernel_size": 3},
                {"type": "MaxPooling2D", "pool_size": 2},
                {"type": "Flatten"},
                {"type": "Dense", "units": 128, "activation": "relu"},
                {"type": "Dense", "units": 10, "activation": "softmax"}
            ],
            "total_params": 1000000,
            "created_at": datetime.now().isoformat()
        },
        "model_2": {
            "layers": [
                {"type": "Conv2D", "filters": 16, "kernel_size": 5},
                {"type": "MaxPooling2D", "pool_size": 2},
                {"type": "Conv2D", "filters": 32, "kernel_size": 3},
                {"type": "GlobalAveragePooling2D"},
                {"type": "Dense", "units": 10, "activation": "softmax"}
            ],
            "total_params": 500000,
            "created_at": datetime.now().isoformat()
        }
    }
    
    try:
        with open(test_path, 'w') as f:
            json.dump(test_data, f, indent=2)
        
        logger.info(f"‚úÖ Archivo de prueba creado: {test_file}")
        logger.info(f"üìÅ Ruta completa: {test_path}")
        logger.info(f"üß™ UUID de prueba: {test_uuid}")
        
        return test_uuid
        
    except Exception as e:
        logger.error(f"‚ùå Error creando archivo de prueba: {e}")
        return None

def main():
    """Funci√≥n principal."""
    parser = argparse.ArgumentParser(description='Verificador del directorio de modelos')
    parser.add_argument('--analyze', '-a', type=str, help='Analizar un archivo JSON espec√≠fico')
    parser.add_argument('--create-test', '-c', action='store_true', help='Crear un archivo de modelo de prueba')
    parser.add_argument('--list-all', '-l', action='store_true', help='Listar y analizar todos los archivos JSON')
    
    args = parser.parse_args()
    
    logger.info("üîç Iniciando verificaci√≥n del directorio de modelos")
    
    # Verificar directorio de storage
    if not check_storage_directory():
        return 1
    
    # Crear archivo de prueba si se solicita
    if args.create_test:
        test_uuid = create_test_model()
        if test_uuid:
            logger.info(f"üí° Puedes usar este UUID para pruebas: {test_uuid}")
    
    # Analizar archivo espec√≠fico
    if args.analyze:
        if not args.analyze.endswith('.json'):
            args.analyze += '.json'
        analyze_json_file(args.analyze)
    
    # Listar y analizar todos los archivos JSON
    if args.list_all:
        try:
            files = os.listdir(STORAGE_PATH)
            json_files = [f for f in files if f.endswith('.json')]
            
            if not json_files:
                logger.info("üìÇ No hay archivos JSON para analizar")
            else:
                logger.info(f"üìÇ Analizando {len(json_files)} archivos JSON...")
                for json_file in json_files:
                    logger.info(f"\n{'='*60}")
                    analyze_json_file(json_file)
                    
        except Exception as e:
            logger.error(f"‚ùå Error listando archivos: {e}")
    
    # Si no se especifica ninguna acci√≥n, solo mostrar el estado
    if not any([args.analyze, args.create_test, args.list_all]):
        logger.info("üí° Usa --help para ver las opciones disponibles")
        logger.info("üí° Ejemplos:")
        logger.info("  python check_models_directory.py --list-all")
        logger.info("  python check_models_directory.py --analyze <uuid>")
        logger.info("  python check_models_directory.py --create-test")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
