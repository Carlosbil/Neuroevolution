import json
import os
import logging
import requests
from confluent_kafka import Consumer, KafkaException, KafkaError
from topic_process.create_initial_population import process_create_initial_population
from topic_process.evaluate_population import process_evaluate_population
from topic_process.select_best_architectures import process_select_best_architectures
from responses_process.create_initial_population_response import process_create_initial_population_response
from responses_process.evaluate_population_response import process_evaluate_population_response
from database import init_db

from utils import (
    logger,
    check_initial_poblation,
    generate_uuid,
    create_producer,
    produce_message,
    create_consumer
)
from responses import (
    ok_message,
    bad_model_message,
    bad_optimizer_message,
    runtime_error_message,
    response_message,
    bad_request_message,
)

# Kafka configuration
# Function to create a Kafka consumer
def create_kafka_consumer():
    consumer = create_consumer()
    consumer.subscribe(list(TOPIC_PROCESSORS.keys()))  # Subscribe to all topics
    return consumer


# Dictionary-based topic-to-function mapping
TOPIC_PROCESSORS = {
    "create-initial-population": process_create_initial_population,
    "evaluate-population": process_evaluate_population,
    "select-best-architectures": process_select_best_architectures,
    "genome-create-initial-population-response": process_create_initial_population_response,
    "evolutioner-create-cnn-model-response": process_evaluate_population_response,
}


def main():
    # Initialize database
    logger.info("üöÄ Starting Neuroevolution Broker...")
    logger.info("üîß Initializing database...")
    init_db()
    
    # Log available topics
    logger.info(f"üìã Available topics: {list(TOPIC_PROCESSORS.keys())}")
    
    consumer = create_kafka_consumer()
    logger.info("üéØ Started Kafka Consumer and subscribed to topics")
    logger.info("üëÇ Listening for messages...")

    try:
        while True:
            msg = consumer.poll(timeout=1.0)
            if msg is None:
                continue
            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    logger.info(f"üìç Reached end of partition: {msg.topic()} [{msg.partition()}]")
                else:
                    logger.error(f"‚ùå Kafka error: {msg.error()}")
                continue

            topic = msg.topic()
            try:
                data = json.loads(msg.value().decode('utf-8'))
                logger.info(f"‚úÖ Received message on topic '{topic}': {data}")
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Failed to decode JSON message on topic '{topic}': {e}")
                logger.error(f"üìÑ Raw message: {msg.value().decode('utf-8', errors='replace')}")
                continue

            processor = TOPIC_PROCESSORS.get(topic)
            if processor:
                try:
                    logger.info(f"üîÑ Processing message with {processor.__name__}")
                    processor(topic, data)
                    logger.info(f"‚úÖ Successfully processed message on topic '{topic}'")
                except Exception as e:
                    logger.error(f"‚ùå Error processing message on topic '{topic}': {e}")
                    logger.error(f"üîç Error type: {type(e).__name__}")
                    logger.error(f"üìÑ Data that caused error: {data}")
            else:
                logger.error(f"‚ùå Unknown topic: {topic}")
                logger.error(f"üìã Available topics: {list(TOPIC_PROCESSORS.keys())}")

    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è Shutting down consumer via keyboard interrupt... ‚ö†Ô∏è")
    except Exception as e:
        logger.error(f"‚ùå Unexpected error in main loop: {e}")
        logger.error(f"üîç Error type: {type(e).__name__}")
    finally:
        consumer.close()
        logger.info("üîí Kafka consumer closed")


if __name__ == "__main__":
    main()
