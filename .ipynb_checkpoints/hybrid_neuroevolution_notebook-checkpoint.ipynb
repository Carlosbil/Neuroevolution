{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77d426",
   "metadata": {},
   "source": [
    "# Synchronous Hybrid Neuroevolution Notebook\n",
    "\n",
    "Hello Mr. Carlos!\n",
    "\n",
    "This notebook implements the complete hybrid neuroevolution process synchronously, without the need for databases or external Kafka services. The system combines genetic algorithms with convolutional neural networks to evolve optimal architectures.\n",
    "\n",
    "## Main Features:\n",
    "- **Hybrid genetic algorithm**: Combines architecture and weight evolution\n",
    "- **Synchronous processing**: Complete workflow executed in a single session\n",
    "- **Configurable dataset**: Supports MNIST by default or custom dataset\n",
    "- **Intelligent stopping criteria**: By target fitness or maximum generations\n",
    "- **Complete visualization**: Shows progress and final best architecture\n",
    "\n",
    "## Objectives:\n",
    "1. Create initial population of CNN architectures\n",
    "2. Evaluate fitness of each individual\n",
    "3. Select best architectures (top 50%)\n",
    "4. Apply crossover and mutation to create new generation\n",
    "5. Repeat process until convergence\n",
    "6. Display the best architecture found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3cfb",
   "metadata": {},
   "source": [
    "## 1. Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50120a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dependency installation for Hybrid Neuroevolution...\n",
      "============================================================\n",
      "Installing torch>=2.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torch>=2.0.0 installed correctly\n",
      "Installing torchvision>=0.15.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision>=0.15.0 in /opt/conda/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (1.24.4)\n",
      "Requirement already satisfied: torch==2.8.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (10.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->torchvision>=0.15.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision>=0.15.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.8.0->torchvision>=0.15.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torchvision>=0.15.0 installed correctly\n",
      "Installing numpy>=1.21.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK numpy>=1.21.0 installed correctly\n",
      "Installing matplotlib>=3.5.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK matplotlib>=3.5.0 installed correctly\n",
      "Installing seaborn>=0.11.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK seaborn>=0.11.0 installed correctly\n",
      "Installing tqdm>=4.64.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (4.65.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK tqdm>=4.64.0 installed correctly\n",
      "Installing jupyter>=1.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter>=1.0.0 in /opt/conda/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.5.4)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (8.0.6)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (4.0.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (3.0.7)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.0.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (3.1.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.7.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (3.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter>=1.0.0) (4.14.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (0.5.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0) (3.8.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.7.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (7.3.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.6.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0) (2.17.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->notebook->jupyter>=1.0.0) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0) (2.3.2.post1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.19.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (2.21)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.9.0.20250708)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK jupyter>=1.0.0 installed correctly\n",
      "Installing ipywidgets>=8.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets>=8.0.0 in /opt/conda/lib/python3.11/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (6.3.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ipywidgets>=8.0.0 installed correctly\n",
      "\n",
      "All dependencies have been verified/installed\n",
      "Restart the kernel if this is the first time installing torch\n",
      "============================================================\n",
      "\n",
      "PyTorch 2.8.0+cu128 installed correctly\n",
      "CUDA available: Yes\n",
      "GPU detected: NVIDIA A100-PCIE-40GB MIG 7g.40gb\n",
      "GPU memory: 39 GB\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if not available.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"OK {package.split('==')[0]} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"OK {package} installed correctly\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Starting dependency installation for Hybrid Neuroevolution...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nAll dependencies have been verified/installed\")\n",
    "print(\"Restart the kernel if this is the first time installing torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch {torch.__version__} installed correctly\")\n",
    "    print(f\"CUDA available: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: PyTorch could not be installed correctly\")\n",
    "    print(\"Try installing manually with: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865869c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configured: cuda\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device configured: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1181c2a",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a6e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "   Selected dataset: CIFAR10\n",
      "   population_size: 10\n",
      "   max_generations: 30\n",
      "   fitness_threshold: 99.9\n",
      "   mutation_rate: 0.6\n",
      "   crossover_rate: 0.99\n",
      "   elite_percentage: 0.4\n",
      "   dataset: CIFAR10\n",
      "   num_channels: 3\n",
      "   px_h: 32\n",
      "   px_w: 32\n",
      "   num_classes: 10\n",
      "   batch_size: 128\n",
      "   test_split: 0.4\n",
      "   num_epochs: 10\n",
      "   learning_rate: 0.01\n",
      "   early_stopping_patience: 1000\n",
      "   min_conv_layers: 1\n",
      "   max_conv_layers: 4\n",
      "   min_fc_layers: 1\n",
      "   max_fc_layers: 4\n",
      "   min_filters: 2\n",
      "   max_filters: 128\n",
      "   min_fc_nodes: 128\n",
      "   max_fc_nodes: 1028\n",
      "   dataset_path: None\n",
      "\n",
      "Available activation functions: ['relu', 'leaky_relu', 'tanh', 'sigmoid', 'selu']\n",
      "Available optimizers: ['adam', 'adamw', 'sgd', 'rmsprop']\n",
      "Available datasets: ['MNIST', 'CIFAR10', 'CUSTOM']\n"
     ]
    }
   ],
   "source": [
    "# Main genetic algorithm configuration\n",
    "CONFIG = {\n",
    "    # Genetic algorithm parameters\n",
    "    'population_size': 10,           # Population size\n",
    "    'max_generations': 30,          # Maximum number of generations\n",
    "    'fitness_threshold': 99.9,      # Target fitness (% accuracy)\n",
    "    'mutation_rate': 0.6,          # Mutation rate\n",
    "    'crossover_rate': 0.99,          # Crossover rate\n",
    "    'elite_percentage': 0.4,        # Elite percentage to preserve\n",
    "    \n",
    "    # Dataset selection\n",
    "    'dataset': 'CIFAR10',             # Options: 'MNIST', 'CIFAR10', 'CUSTOM'\n",
    "    \n",
    "    # Dataset parameters (auto-configured based on dataset)\n",
    "    'num_channels': 3,              # Input channels (1=grayscale, 3=RGB)\n",
    "    'px_h': 32,                     # Image height\n",
    "    'px_w': 32,                     # Image width\n",
    "    'num_classes': 10,              # Number of classes\n",
    "    'batch_size': 128,               # Batch size\n",
    "    'test_split': 0.35,              # Validation percentage\n",
    "    \n",
    "    # Training parameters\n",
    "    'num_epochs': 10,                # Training epochs per evaluation\n",
    "    'learning_rate': 0.01,         # Base learning rate\n",
    "    'early_stopping_patience': 1000,  # Maximum batches for quick evaluation\n",
    "    \n",
    "    # Allowed architecture range\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 7,\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 7,\n",
    "    'min_filters': 2,\n",
    "    'max_filters': 256,\n",
    "    'min_fc_nodes': 128,\n",
    "    'max_fc_nodes': 2048,\n",
    "    \n",
    "    # Custom dataset configuration (only used if dataset='CUSTOM')\n",
    "    'dataset_path': None,           # Custom dataset path\n",
    "}\n",
    "\n",
    "# Dataset configurations\n",
    "DATASET_CONFIGS = {\n",
    "    'MNIST': {\n",
    "        'num_channels': 1,\n",
    "        'px_h': 28,\n",
    "        'px_w': 28,\n",
    "        'num_classes': 10,\n",
    "        'normalization': {'mean': (0.1307,), 'std': (0.3081,)}\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'num_channels': 3,\n",
    "        'px_h': 32,\n",
    "        'px_w': 32,\n",
    "        'num_classes': 10,\n",
    "        'normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.2010)}\n",
    "    },\n",
    "    'CUSTOM': {\n",
    "        'num_channels': 1,  # Default, will be overridden\n",
    "        'px_h': 28,         # Default, will be overridden\n",
    "        'px_w': 28,         # Default, will be overridden\n",
    "        'num_classes': 10,  # Default, will be overridden\n",
    "        'normalization': {'mean': (0.5,), 'std': (0.5,)}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Auto-configure based on selected dataset\n",
    "def configure_dataset(config, dataset_name):\n",
    "    \"\"\"Auto-configures dataset parameters based on selected dataset.\"\"\"\n",
    "    if dataset_name in DATASET_CONFIGS:\n",
    "        dataset_config = DATASET_CONFIGS[dataset_name]\n",
    "        config['num_channels'] = dataset_config['num_channels']\n",
    "        config['px_h'] = dataset_config['px_h']\n",
    "        config['px_w'] = dataset_config['px_w']\n",
    "        config['num_classes'] = dataset_config['num_classes']\n",
    "        config['_normalization'] = dataset_config['normalization']\n",
    "    return config\n",
    "\n",
    "# Configure the selected dataset\n",
    "CONFIG = configure_dataset(CONFIG, CONFIG['dataset'])\n",
    "\n",
    "# Activation function mapping\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Optimizer mapping\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"   Selected dataset: {CONFIG['dataset']}\")\n",
    "for key, value in CONFIG.items():\n",
    "    if not key.startswith('_'):  # Hide internal config\n",
    "        print(f\"   {key}: {value}\")\n",
    "print(f\"\\nAvailable activation functions: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"Available optimizers: {list(OPTIMIZERS.keys())}\")\n",
    "print(f\"Available datasets: {list(DATASET_CONFIGS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4964cc1",
   "metadata": {},
   "source": [
    "### Información sobre Datasets Disponibles\n",
    "\n",
    "**MNIST**: \n",
    "- Dígitos escritos a mano (0-9)\n",
    "- Imágenes en escala de grises (1 canal)\n",
    "- Tamaño: 28x28 píxeles\n",
    "- Dificultad: **Fácil** - Ideal para pruebas rápidas\n",
    "- Fitness objetivo recomendado: >95%\n",
    "\n",
    "**CIFAR-10**: \n",
    "- Objetos del mundo real (aviones, coches, pájaros, etc.)\n",
    "- Imágenes en color (3 canales RGB)\n",
    "- Tamaño: 32x32 píxeles\n",
    "- Dificultad: **Media-Alta** - Más realista y desafiante\n",
    "- Fitness objetivo recomendado: >80%\n",
    "- Clases: plane, car, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\n",
    "**CUSTOM**: \n",
    "- Tu propio dataset\n",
    "- Configuración manual requerida\n",
    "- Estructura de carpetas por clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6d37",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f98ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10 dataset...\n",
      "CIFAR-10 dataset loaded:\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Training samples: 50000\n",
      "   Test samples: 10000\n",
      "\n",
      "Dataset loaded successfully:\n",
      "   Batch shape: torch.Size([128, 3, 32, 32])\n",
      "   Data type: torch.float32\n",
      "   Device: cpu\n",
      "   Value range: [-2.429, 2.754]\n",
      "   CIFAR-10 classes: ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Labels in this batch: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(config: dict) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Loads the dataset according to configuration.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_type = config['dataset']\n",
    "    \n",
    "    if dataset_type == 'CUSTOM' and config['dataset_path']:\n",
    "        print(f\"Loading custom dataset from: {config['dataset_path']}\")\n",
    "        \n",
    "        # Transformations for custom dataset\n",
    "        if config['num_channels'] == 1:\n",
    "            normalize = transforms.Normalize(config['_normalization']['mean'], config['_normalization']['std'])\n",
    "        else:\n",
    "            normalize = transforms.Normalize(config['_normalization']['mean'], config['_normalization']['std'])\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "        \n",
    "        # Load dataset from folders organized by class\n",
    "        full_dataset = datasets.ImageFolder(root=config['dataset_path'], transform=transform)\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_size = int((1 - config['test_split']) * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "        \n",
    "        print(f\"Custom dataset loaded:\")\n",
    "        print(f\"   Classes found: {len(full_dataset.classes)}\")\n",
    "        print(f\"   Total samples: {len(full_dataset)}\")\n",
    "        \n",
    "    elif dataset_type == 'MNIST':\n",
    "        print(\"Loading MNIST dataset...\")\n",
    "        \n",
    "        # Transformations for MNIST\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(config['_normalization']['mean'], config['_normalization']['std'])\n",
    "        ])\n",
    "        \n",
    "        # Load MNIST\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "        print(f\"MNIST dataset loaded:\")\n",
    "        print(f\"   Classes: {len(train_dataset.classes)}\")\n",
    "        print(f\"   Training samples: {len(train_dataset)}\")\n",
    "        print(f\"   Test samples: {len(test_dataset)}\")\n",
    "        \n",
    "    elif dataset_type == 'CIFAR10':\n",
    "        print(\"Loading CIFAR-10 dataset...\")\n",
    "        \n",
    "        # Transformations for CIFAR-10\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),  # Data augmentation for training\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(config['_normalization']['mean'], config['_normalization']['std'])\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(config['_normalization']['mean'], config['_normalization']['std'])\n",
    "        ])\n",
    "        \n",
    "        # Load CIFAR-10\n",
    "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "        \n",
    "        print(f\"CIFAR-10 dataset loaded:\")\n",
    "        print(f\"   Classes: {train_dataset.classes}\")\n",
    "        print(f\"   Training samples: {len(train_dataset)}\")\n",
    "        print(f\"   Test samples: {len(test_dataset)}\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Dataset '{dataset_type}' not supported. Available: MNIST, CIFAR10, CUSTOM\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Load the dataset\n",
    "train_loader, test_loader = load_dataset(CONFIG)\n",
    "\n",
    "# Get a sample to verify dimensions\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_data, sample_labels = sample_batch\n",
    "print(f\"\\nDataset loaded successfully:\")\n",
    "print(f\"   Batch shape: {sample_data.shape}\")\n",
    "print(f\"   Data type: {sample_data.dtype}\")\n",
    "print(f\"   Device: {sample_data.device}\")\n",
    "print(f\"   Value range: [{sample_data.min():.3f}, {sample_data.max():.3f}]\")\n",
    "\n",
    "# Show some class information for CIFAR-10\n",
    "if CONFIG['dataset'] == 'CIFAR10':\n",
    "    cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    print(f\"   CIFAR-10 classes: {cifar10_classes}\")\n",
    "    unique_labels = torch.unique(sample_labels)\n",
    "    print(f\"   Labels in this batch: {unique_labels.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52de67",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc6abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvolvableCNN class defined correctly\n"
     ]
    }
   ],
   "source": [
    "class EvolvableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolvable CNN class that can be dynamically configured\n",
    "    according to genome parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Build convolutional layers\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calculate output size after convolutions\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "        \n",
    "    def _build_conv_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds convolutional layers according to genome.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        \n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Convolutional layer\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Batch normalization\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            # Activation function\n",
    "            activation_name = self.genome['activations'][i % len(self.genome['activations'])]\n",
    "            activation_func = ACTIVATION_FUNCTIONS[activation_name]()\n",
    "            layers.append(activation_func)\n",
    "            \n",
    "            # Max pooling (except in last layer)\n",
    "            if i < self.genome['num_conv_layers'] - 1:\n",
    "                layers.append(nn.MaxPool2d(2, 2))\n",
    "            else:\n",
    "                layers.append(nn.MaxPool2d(2, 1))  # Stride 1 in last layer\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self) -> int:\n",
    "        \"\"\"Calculates output size after convolutional layers.\"\"\"\n",
    "        # Create dummy tensor to calculate size\n",
    "        dummy_input = torch.zeros(1, self.config['num_channels'], \n",
    "                                 self.config['px_h'], self.config['px_w'])\n",
    "        \n",
    "        # Pass through convolutional layers\n",
    "        x = dummy_input\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten and get size\n",
    "        return x.view(-1).shape[0]\n",
    "    \n",
    "    def _build_fc_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds fully connected layers.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        input_size = self.conv_output_size\n",
    "        \n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            output_size = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "            # Dropout if not last layer\n",
    "            if i < self.genome['num_fc_layers'] - 1:\n",
    "                layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            input_size = output_size\n",
    "        \n",
    "        # Final classification layer\n",
    "        layers.append(nn.Linear(input_size, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            x = layer(x)\n",
    "            # Apply activation except on last layer\n",
    "            if i < len(self.fc_layers) - 1 and not isinstance(layer, nn.Dropout):\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_architecture_summary(self) -> str:\n",
    "        \"\"\"Returns an architecture summary.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(f\"Conv Layers: {self.genome['num_conv_layers']}\")\n",
    "        summary.append(f\"Filters: {self.genome['filters']}\")\n",
    "        summary.append(f\"Kernel Sizes: {self.genome['kernel_sizes']}\")\n",
    "        summary.append(f\"FC Layers: {self.genome['num_fc_layers']}\")\n",
    "        summary.append(f\"FC Nodes: {self.genome['fc_nodes']}\")\n",
    "        summary.append(f\"Activations: {self.genome['activations']}\")\n",
    "        summary.append(f\"Dropout: {self.genome['dropout_rate']:.3f}\")\n",
    "        summary.append(f\"Optimizer: {self.genome['optimizer']}\")\n",
    "        summary.append(f\"Learning Rate: {self.genome['learning_rate']:.4f}\")\n",
    "        return \" | \".join(summary)\n",
    "\n",
    "print(\"EvolvableCNN class defined correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021c7d8",
   "metadata": {},
   "source": [
    "## 5. Genetic Algorithm Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be19766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic functions defined correctly\n"
     ]
    }
   ],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"Creates a random genome within specified ranges.\"\"\"\n",
    "    \n",
    "    # Number of layers\n",
    "    num_conv_layers = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "    \n",
    "    # Filters for each convolutional layer\n",
    "    filters = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        filters.append(random.randint(config['min_filters'], config['max_filters']))\n",
    "    \n",
    "    # Kernel sizes\n",
    "    kernel_sizes = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        kernel_sizes.append(random.choice([3, 5, 7]))\n",
    "    \n",
    "    # Nodes in fully connected layers\n",
    "    fc_nodes = []\n",
    "    for _ in range(num_fc_layers):\n",
    "        fc_nodes.append(random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Activation functions for each layer\n",
    "    activations = []\n",
    "    for _ in range(max(num_conv_layers, num_fc_layers)):\n",
    "        activations.append(random.choice(list(ACTIVATION_FUNCTIONS.keys())))\n",
    "    \n",
    "    # Other parameters\n",
    "    dropout_rate = random.uniform(0.1, 0.5)\n",
    "    learning_rate = random.choice([0.001, 0.0001, 0.01, 0.005])\n",
    "    optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    genome = {\n",
    "        'num_conv_layers': num_conv_layers,\n",
    "        'num_fc_layers': num_fc_layers,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'fc_nodes': fc_nodes,\n",
    "        'activations': activations,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "    \n",
    "    return genome\n",
    "\n",
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"Applies mutation to a genome.\"\"\"\n",
    "    mutated_genome = copy.deepcopy(genome)\n",
    "    mutation_rate = config['mutation_rate']\n",
    "    \n",
    "    # Mutate number of convolutional layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_conv_layers'] = random.randint(\n",
    "            config['min_conv_layers'], config['max_conv_layers'])\n",
    "        # Adjust related lists\n",
    "        num_conv = mutated_genome['num_conv_layers']\n",
    "        mutated_genome['filters'] = mutated_genome['filters'][:num_conv]\n",
    "        mutated_genome['kernel_sizes'] = mutated_genome['kernel_sizes'][:num_conv]\n",
    "        \n",
    "        # Fill if necessary\n",
    "        while len(mutated_genome['filters']) < num_conv:\n",
    "            mutated_genome['filters'].append(\n",
    "                random.randint(config['min_filters'], config['max_filters']))\n",
    "        while len(mutated_genome['kernel_sizes']) < num_conv:\n",
    "            mutated_genome['kernel_sizes'].append(random.choice([1, 3, 5, 7]))\n",
    "    \n",
    "    # Mutate filters\n",
    "    for i in range(len(mutated_genome['filters'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['filters'][i] = random.randint(\n",
    "                config['min_filters'], config['max_filters'])\n",
    "    \n",
    "    # Mutate kernel sizes\n",
    "    for i in range(len(mutated_genome['kernel_sizes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['kernel_sizes'][i] = random.choice([1, 3, 5, 7])\n",
    "    \n",
    "    # Mutate number of FC layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_fc_layers'] = random.randint(\n",
    "            config['min_fc_layers'], config['max_fc_layers'])\n",
    "        # Adjust FC nodes\n",
    "        num_fc = mutated_genome['num_fc_layers']\n",
    "        mutated_genome['fc_nodes'] = mutated_genome['fc_nodes'][:num_fc]\n",
    "        while len(mutated_genome['fc_nodes']) < num_fc:\n",
    "            mutated_genome['fc_nodes'].append(\n",
    "                random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Mutate FC nodes\n",
    "    for i in range(len(mutated_genome['fc_nodes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['fc_nodes'][i] = random.randint(\n",
    "                config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "    \n",
    "    # Mutate activation functions\n",
    "    for i in range(len(mutated_genome['activations'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['activations'][i] = random.choice(\n",
    "                list(ACTIVATION_FUNCTIONS.keys()))\n",
    "    \n",
    "    # Mutate dropout\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['dropout_rate'] = random.uniform(0.1, 0.8)\n",
    "    \n",
    "    # Mutate learning rate\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['learning_rate'] = random.choice([0.001, 0.0001, 0.01, 0.005, 0.000001, 0.05, 0.00005, 0.0005])\n",
    "    \n",
    "    # Mutate optimizer\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    # New ID for mutated genome\n",
    "    mutated_genome['id'] = str(uuid.uuid4())[:8]\n",
    "    mutated_genome['fitness'] = 0.0  # Reset fitness\n",
    "    \n",
    "    return mutated_genome\n",
    "\n",
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"Performs crossover between two genomes.\"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "    \n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    # Crossover scalar parameters\n",
    "    if random.random() < 0.5:\n",
    "        child1['num_conv_layers'], child2['num_conv_layers'] = \\\n",
    "            child2['num_conv_layers'], child1['num_conv_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['num_fc_layers'], child2['num_fc_layers'] = \\\n",
    "            child2['num_fc_layers'], child1['num_fc_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['dropout_rate'], child2['dropout_rate'] = \\\n",
    "            child2['dropout_rate'], child1['dropout_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['learning_rate'], child2['learning_rate'] = \\\n",
    "            child2['learning_rate'], child1['learning_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['optimizer'], child2['optimizer'] = \\\n",
    "            child2['optimizer'], child1['optimizer']\n",
    "    \n",
    "    # Crossover lists (random cut point)\n",
    "    for list_key in ['filters', 'kernel_sizes', 'fc_nodes', 'activations']:\n",
    "        if random.random() < 0.5:\n",
    "            list1 = child1[list_key]\n",
    "            list2 = child2[list_key]\n",
    "            \n",
    "            if len(list1) > 1 and len(list2) > 1:\n",
    "                point1 = random.randint(1, len(list1) - 1)\n",
    "                point2 = random.randint(1, len(list2) - 1)\n",
    "                \n",
    "                # Exchange parts\n",
    "                new_list1 = list1[:point1] + list2[point2:]\n",
    "                new_list2 = list2[:point2] + list1[point1:]\n",
    "                \n",
    "                child1[list_key] = new_list1\n",
    "                child2[list_key] = new_list2\n",
    "    \n",
    "    # Assign new IDs\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "print(\"Genetic functions defined correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a74a50",
   "metadata": {},
   "source": [
    "## 6. Hybrid Neuroevolution Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda046ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridNeuroevolution class defined correctly (without tqdm, with detailed prints)\n"
     ]
    }
   ],
   "source": [
    "class HybridNeuroevolution:\n",
    "    \"\"\"Main class that implements hybrid neuroevolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, train_loader: DataLoader, test_loader: DataLoader):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initializes population with random genomes.\"\"\"\n",
    "        print(f\"Initializing population of {self.config['population_size']} individuals...\")\n",
    "        \n",
    "        self.population = []\n",
    "        for i in range(self.config['population_size']):\n",
    "            genome = create_random_genome(self.config)\n",
    "            self.population.append(genome)\n",
    "            \n",
    "        print(f\"Population initialized with {len(self.population)} individuals\")\n",
    "    \n",
    "    def evaluate_fitness(self, genome: dict) -> float:\n",
    "        \"\"\"Evaluates genome fitness by training the neural network.\"\"\"\n",
    "        try:\n",
    "            print(self.config)\n",
    "            # Create model\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "            \n",
    "            # Create optimizer\n",
    "            optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "            optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "            \n",
    "            # Loss function\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Training\n",
    "            model.train()\n",
    "            total_train_batches = min(len(self.train_loader), self.config['early_stopping_patience'])\n",
    "            \n",
    "            print(f\"      Training model {genome['id']} ({self.config['num_epochs']} epochs, max {total_train_batches} batches/epoch)\")\n",
    "            \n",
    "            for epoch in range(self.config['num_epochs']):\n",
    "                running_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for data, target in self.train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Early stopping for quick evaluation\n",
    "                    if batch_count >= self.config['early_stopping_patience']:\n",
    "                        break\n",
    "                \n",
    "                # Epoch statistics\n",
    "                avg_loss = running_loss / batch_count\n",
    "                print(f\"          Epoch {epoch+1}/{self.config['num_epochs']}: Average loss = {avg_loss:.4f} ({batch_count} batches processed)\")\n",
    "            \n",
    "            print(f\"      Training completed for model {genome['id']}\")\n",
    "            \n",
    "            # Evaluation\n",
    "            print(f\"      Evaluating model {genome['id']} on test set...\")\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            eval_batches = 0\n",
    "            max_eval_batches = min(len(self.test_loader), 20)\n",
    "            total_eval_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, target in self.test_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    \n",
    "                    # Calculate evaluation loss\n",
    "                    eval_loss = criterion(output, target)\n",
    "                    total_eval_loss += eval_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                    eval_batches += 1\n",
    "                    \n",
    "                    # Early stopping in evaluation\n",
    "                    if eval_batches >= max_eval_batches:\n",
    "                        break\n",
    "            \n",
    "            accuracy = 100.0 * correct / total\n",
    "            avg_eval_loss = total_eval_loss / eval_batches\n",
    "            \n",
    "            print(f\"         Evaluation: {correct}/{total} correct = {accuracy:.2f}% accuracy\")\n",
    "            print(f\"         Evaluation loss: {avg_eval_loss:.4f} ({eval_batches} batches evaluated)\")\n",
    "            print(f\"      Evaluation completed for model {genome['id']} - Final fitness: {accuracy:.2f}%\")\n",
    "            \n",
    "            return accuracy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ERROR evaluating genome {genome['id']}: {e}\")\n",
    "            logger.warning(f\"Error evaluating genome {genome['id']}: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_population(self):\n",
    "        \"\"\"Evaluates entire population and updates fitness.\"\"\"\n",
    "        print(f\"\\nEvaluating population (Generation {self.generation})...\")\n",
    "        print(f\"Processing {len(self.population)} individuals...\")\n",
    "        \n",
    "        fitness_scores = []\n",
    "        best_fitness_so_far = 0.0\n",
    "        \n",
    "        for i, genome in enumerate(self.population):\n",
    "            print(f\"\\n   Evaluating individual {i+1}/{len(self.population)} (ID: {genome['id']})\")\n",
    "            print(f\"      Architecture: {genome['num_conv_layers']} conv + {genome['num_fc_layers']} fc, opt={genome['optimizer']}, lr={genome['learning_rate']}\")\n",
    "            \n",
    "            fitness = self.evaluate_fitness(genome)\n",
    "            genome['fitness'] = fitness\n",
    "            fitness_scores.append(fitness)\n",
    "            \n",
    "            # Update best fitness found so far\n",
    "            if fitness > best_fitness_so_far:\n",
    "                best_fitness_so_far = fitness\n",
    "                print(f\"      New best fitness in this generation: {fitness:.2f}%!\")\n",
    "            \n",
    "            print(f\"      Fitness obtained: {fitness:.2f}% | Best so far: {best_fitness_so_far:.2f}%\")\n",
    "        \n",
    "        # Generation statistics\n",
    "        avg_fitness = np.mean(fitness_scores)\n",
    "        max_fitness = np.max(fitness_scores)\n",
    "        min_fitness = np.min(fitness_scores)\n",
    "        std_fitness = np.std(fitness_scores)\n",
    "        \n",
    "        stats = {\n",
    "            'generation': self.generation,\n",
    "            'avg_fitness': avg_fitness,\n",
    "            'max_fitness': max_fitness,\n",
    "            'min_fitness': min_fitness,\n",
    "            'std_fitness': std_fitness\n",
    "        }\n",
    "        \n",
    "        self.generation_stats.append(stats)\n",
    "        self.fitness_history.append(max_fitness)\n",
    "        \n",
    "        # Update best individual\n",
    "        best_genome = max(self.population, key=lambda x: x['fitness'])\n",
    "        if self.best_individual is None or best_genome['fitness'] > self.best_individual['fitness']:\n",
    "            self.best_individual = copy.deepcopy(best_genome)\n",
    "            print(f\"\\nNew global best individual found!\")\n",
    "        \n",
    "        print(f\"\\nGENERATION {self.generation} STATISTICS:\")\n",
    "        print(f\"   Maximum fitness: {max_fitness:.2f}%\")\n",
    "        print(f\"   Average fitness: {avg_fitness:.2f}%\")\n",
    "        print(f\"   Minimum fitness: {min_fitness:.2f}%\")\n",
    "        print(f\"   Standard deviation: {std_fitness:.2f}%\")\n",
    "        print(f\"   Best individual: {best_genome['id']} with {best_genome['fitness']:.2f}%\")\n",
    "        print(f\"   Global best individual: {self.best_individual['id']} with {self.best_individual['fitness']:.2f}%\")\n",
    "        \n",
    "    def selection_and_reproduction(self):\n",
    "        \"\"\"Selects best individuals and creates new generation.\"\"\"\n",
    "        print(f\"\\nStarting selection and reproduction...\")\n",
    "        \n",
    "        # Sort population by fitness\n",
    "        self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        # Select elite\n",
    "        elite_size = int(self.config['population_size'] * self.config['elite_percentage'])\n",
    "        elite = self.population[:elite_size]\n",
    "        \n",
    "        print(f\"Selecting {elite_size} elite individuals:\")\n",
    "        for i, individual in enumerate(elite):\n",
    "            print(f\"   Elite {i+1}: {individual['id']} (fitness: {individual['fitness']:.2f}%)\")\n",
    "        \n",
    "        # Create new generation\n",
    "        new_population = copy.deepcopy(elite)  # Preserve elite\n",
    "        \n",
    "        # Complete population with crossover and mutation\n",
    "        offspring_needed = self.config['population_size'] - len(new_population)\n",
    "        print(f\"Creating {offspring_needed} new individuals through crossover and mutation...\")\n",
    "        \n",
    "        offspring_created = 0\n",
    "        while len(new_population) < self.config['population_size']:\n",
    "            # Parent selection (tournament)\n",
    "            parent1 = self.tournament_selection()\n",
    "            parent2 = self.tournament_selection()\n",
    "            \n",
    "            # Crossover\n",
    "            child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "            \n",
    "            # Mutation\n",
    "            child1 = mutate_genome(child1, self.config)\n",
    "            child2 = mutate_genome(child2, self.config)\n",
    "            \n",
    "            new_population.extend([child1, child2])\n",
    "            offspring_created += 2\n",
    "            \n",
    "            if offspring_created % 4 == 0:  # Show progress every 4 individuals\n",
    "                print(f\"   Created {min(offspring_created, offspring_needed)} of {offspring_needed} new individuals...\")\n",
    "        \n",
    "        # Adjust size if necessary\n",
    "        self.population = new_population[:self.config['population_size']]\n",
    "        \n",
    "        print(f\"New generation created with {len(self.population)} individuals\")\n",
    "        print(f\"   Elite preserved: {elite_size}\")\n",
    "        print(f\"   New individuals: {len(self.population) - elite_size}\")\n",
    "    \n",
    "    def tournament_selection(self, tournament_size: int = 3) -> dict:\n",
    "        \"\"\"Tournament selection.\"\"\"\n",
    "        tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
    "        return max(tournament, key=lambda x: x['fitness'])\n",
    "    \n",
    "    def check_convergence(self) -> bool:\n",
    "        \"\"\"Checks if algorithm has converged.\"\"\"\n",
    "        # Check target fitness\n",
    "        if self.best_individual and self.best_individual['fitness'] >= self.config['fitness_threshold']:\n",
    "            print(f\"Target fitness reached! ({self.best_individual['fitness']:.2f}% >= {self.config['fitness_threshold']}%)\")\n",
    "            return True\n",
    "        \n",
    "        # Check maximum generations\n",
    "        if self.generation >= self.config['max_generations']:\n",
    "            print(f\"Maximum generations reached ({self.generation}/{self.config['max_generations']})\")\n",
    "            return True\n",
    "        \n",
    "        # Check stagnation (last 3 generations without significant improvement)\n",
    "        if len(self.fitness_history) >= 3:\n",
    "            recent_fitness = self.fitness_history[-3:]\n",
    "            if max(recent_fitness) - min(recent_fitness) < 0.5:  # Less than 0.5% improvement\n",
    "                print(f\"Stagnation detected in last 3 generations\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def evolve(self) -> dict:\n",
    "        \"\"\"Executes complete evolution process.\"\"\"\n",
    "        print(\"STARTING HYBRID NEUROEVOLUTION PROCESS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"   Population: {self.config['population_size']} individuals\")\n",
    "        print(f\"   Maximum generations: {self.config['max_generations']}\")\n",
    "        print(f\"   Target fitness: {self.config['fitness_threshold']}%\")\n",
    "        print(f\"   Device: {device}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Initialize population\n",
    "        self.initialize_population()\n",
    "        \n",
    "        # Main evolution loop\n",
    "        while not self.check_convergence():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"GENERATION {self.generation}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Evaluate population\n",
    "            self.evaluate_population()\n",
    "            \n",
    "            # Check convergence before continuing\n",
    "            if self.check_convergence():\n",
    "                break\n",
    "            \n",
    "            # Selection and reproduction\n",
    "            self.selection_and_reproduction()\n",
    "            \n",
    "            # Next generation\n",
    "            self.generation += 1\n",
    "            \n",
    "            print(f\"\\nPreparing for next generation...\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EVOLUTION COMPLETED!\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Best individual found:\")\n",
    "        print(f\"   ID: {self.best_individual['id']}\")\n",
    "        print(f\"   Fitness: {self.best_individual['fitness']:.2f}%\")\n",
    "        print(f\"   Origin generation: {self.generation}\")\n",
    "        print(f\"   Total generations processed: {self.generation + 1}\")\n",
    "        \n",
    "        return self.best_individual\n",
    "\n",
    "print(\"HybridNeuroevolution class defined correctly (without tqdm, with detailed prints)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59597ef1",
   "metadata": {},
   "source": [
    "## 7. Evolution Process Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current configuration:\n",
      "   Dataset: CIFAR10\n",
      "   Image size: 32x32x3\n",
      "   Number of classes: 10\n",
      "   Population: 10 individuals\n",
      "   Maximum generations: 30\n",
      "   Target fitness: 99.9%\n",
      "   Device: cuda\n",
      "\n",
      "Reloading dataset with new configuration...\n",
      "Loading CIFAR-10 dataset...\n",
      "CIFAR-10 dataset loaded:\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Training samples: 50000\n",
      "   Test samples: 10000\n",
      "\n",
      "Starting neuroevolution at 10:59:14\n",
      "STARTING HYBRID NEUROEVOLUTION PROCESS\n",
      "============================================================\n",
      "Configuration:\n",
      "   Population: 10 individuals\n",
      "   Maximum generations: 30\n",
      "   Target fitness: 99.9%\n",
      "   Device: cuda\n",
      "============================================================\n",
      "Initializing population of 10 individuals...\n",
      "Population initialized with 10 individuals\n",
      "\n",
      "================================================================================\n",
      "GENERATION 0\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 0)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 394428f1)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 394428f1 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.6768 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5267 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3972 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3244 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2632 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2343 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2031 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1842 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1661 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1530 (391 batches processed)\n",
      "      Training completed for model 394428f1\n",
      "      Evaluating model 394428f1 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:00:20,375 - WARNING - Error evaluating genome 3a4e4de5: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "2025-08-08 11:00:20,383 - WARNING - Error evaluating genome c25232a3: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1642/2560 correct = 64.14% accuracy\n",
      "         Evaluation loss: 1.0265 (20 batches evaluated)\n",
      "      Evaluation completed for model 394428f1 - Final fitness: 64.14%\n",
      "      New best fitness in this generation: 64.14%!\n",
      "      Fitness obtained: 64.14% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 3a4e4de5)\n",
      "      Architecture: 4 conv + 1 fc, opt=adamw, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 3a4e4de5: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: c25232a3)\n",
      "      Architecture: 4 conv + 3 fc, opt=rmsprop, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome c25232a3: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1, 1])\n",
      "      Fitness obtained: 0.00% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: 56c02fc0)\n",
      "      Architecture: 1 conv + 3 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 56c02fc0 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2970 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2802 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2612 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2401 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2179 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.1935 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.1689 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1445 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1205 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.0964 (391 batches processed)\n",
      "      Training completed for model 56c02fc0\n",
      "      Evaluating model 56c02fc0 on test set...\n",
      "         Evaluation: 742/2560 correct = 28.98% accuracy\n",
      "         Evaluation loss: 2.0742 (20 batches evaluated)\n",
      "      Evaluation completed for model 56c02fc0 - Final fitness: 28.98%\n",
      "      Fitness obtained: 28.98% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: dbfa671f)\n",
      "      Architecture: 1 conv + 2 fc, opt=adamw, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model dbfa671f (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 11.3979 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 3.1426 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3033 (391 batches processed)\n",
      "      Training completed for model dbfa671f\n",
      "      Evaluating model dbfa671f on test set...\n",
      "         Evaluation: 264/2560 correct = 10.31% accuracy\n",
      "         Evaluation loss: 2.3030 (20 batches evaluated)\n",
      "      Evaluation completed for model dbfa671f - Final fitness: 10.31%\n",
      "      Fitness obtained: 10.31% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 061b208d)\n",
      "      Architecture: 3 conv + 1 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 061b208d (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3073 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2843 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2672 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2517 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2377 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2238 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2110 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1987 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1862 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.1746 (391 batches processed)\n",
      "      Training completed for model 061b208d\n",
      "      Evaluating model 061b208d on test set...\n",
      "         Evaluation: 679/2560 correct = 26.52% accuracy\n",
      "         Evaluation loss: 2.1585 (20 batches evaluated)\n",
      "      Evaluation completed for model 061b208d - Final fitness: 26.52%\n",
      "      Fitness obtained: 26.52% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 5ac6b34a)\n",
      "      Architecture: 1 conv + 2 fc, opt=adamw, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5ac6b34a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 23.0671 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.4763 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.7166 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3033 (391 batches processed)\n",
      "      Training completed for model 5ac6b34a\n",
      "      Evaluating model 5ac6b34a on test set...\n",
      "         Evaluation: 254/2560 correct = 9.92% accuracy\n",
      "         Evaluation loss: 2.3030 (20 batches evaluated)\n",
      "      Evaluation completed for model 5ac6b34a - Final fitness: 9.92%\n",
      "      Fitness obtained: 9.92% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8191 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5689 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4156 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3110 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2323 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1617 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1085 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0573 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0211 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9884 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n",
      "         Evaluation: 1620/2560 correct = 63.28% accuracy\n",
      "         Evaluation loss: 1.0641 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 63.28%\n",
      "      Fitness obtained: 63.28% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 717476fb)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 717476fb (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 8.2252 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3029 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3029 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3029 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3030 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3030 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3030 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3030 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3030 (391 batches processed)\n",
      "      Training completed for model 717476fb\n",
      "      Evaluating model 717476fb on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:06:56,068 - WARNING - Error evaluating genome 694368de: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 240/2560 correct = 9.38% accuracy\n",
      "         Evaluation loss: 2.3032 (20 batches evaluated)\n",
      "      Evaluation completed for model 717476fb - Final fitness: 9.38%\n",
      "      Fitness obtained: 9.38% | Best so far: 64.14%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 694368de)\n",
      "      Architecture: 4 conv + 4 fc, opt=adam, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 694368de: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 64.14%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 0 STATISTICS:\n",
      "   Maximum fitness: 64.14%\n",
      "   Average fitness: 21.25%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 23.32%\n",
      "   Best individual: 394428f1 with 64.14%\n",
      "   Global best individual: 394428f1 with 64.14%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 394428f1 (fitness: 64.14%)\n",
      "   Elite 2: c5ebb690 (fitness: 63.28%)\n",
      "   Elite 3: 56c02fc0 (fitness: 28.98%)\n",
      "   Elite 4: 061b208d (fitness: 26.52%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 1\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 1)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 394428f1)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 394428f1 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.8767 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5794 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4691 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4087 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3657 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.3402 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.3027 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.2807 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.2594 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.2505 (391 batches processed)\n",
      "      Training completed for model 394428f1\n",
      "      Evaluating model 394428f1 on test set...\n",
      "         Evaluation: 1439/2560 correct = 56.21% accuracy\n",
      "         Evaluation loss: 1.1724 (20 batches evaluated)\n",
      "      Evaluation completed for model 394428f1 - Final fitness: 56.21%\n",
      "      New best fitness in this generation: 56.21%!\n",
      "      Fitness obtained: 56.21% | Best so far: 56.21%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8172 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5645 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4405 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3314 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2399 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1687 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1095 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0650 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0335 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9940 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n",
      "         Evaluation: 1543/2560 correct = 60.27% accuracy\n",
      "         Evaluation loss: 1.1241 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 60.27%\n",
      "      New best fitness in this generation: 60.27%!\n",
      "      Fitness obtained: 60.27% | Best so far: 60.27%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 56c02fc0)\n",
      "      Architecture: 1 conv + 3 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 56c02fc0 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2935 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2746 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2532 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2296 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2037 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.1777 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.1514 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1249 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1007 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.0765 (391 batches processed)\n",
      "      Training completed for model 56c02fc0\n",
      "      Evaluating model 56c02fc0 on test set...\n",
      "         Evaluation: 761/2560 correct = 29.73% accuracy\n",
      "         Evaluation loss: 2.0558 (20 batches evaluated)\n",
      "      Evaluation completed for model 56c02fc0 - Final fitness: 29.73%\n",
      "      Fitness obtained: 29.73% | Best so far: 60.27%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: 061b208d)\n",
      "      Architecture: 3 conv + 1 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 061b208d (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3168 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2995 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2857 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2731 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2612 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2496 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2379 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.2259 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.2128 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.2007 (391 batches processed)\n",
      "      Training completed for model 061b208d\n",
      "      Evaluating model 061b208d on test set...\n",
      "         Evaluation: 710/2560 correct = 27.73% accuracy\n",
      "         Evaluation loss: 2.1832 (20 batches evaluated)\n",
      "      Evaluation completed for model 061b208d - Final fitness: 27.73%\n",
      "      Fitness obtained: 27.73% | Best so far: 60.27%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 5c7a57f6)\n",
      "      Architecture: 1 conv + 1 fc, opt=rmsprop, lr=1e-06\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5c7a57f6 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7254 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5890 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5332 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4984 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.4710 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.4519 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.4309 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.4160 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.4023 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.3892 (391 batches processed)\n",
      "      Training completed for model 5c7a57f6\n",
      "      Evaluating model 5c7a57f6 on test set...\n",
      "         Evaluation: 1361/2560 correct = 53.16% accuracy\n",
      "         Evaluation loss: 1.3573 (20 batches evaluated)\n",
      "      Evaluation completed for model 5c7a57f6 - Final fitness: 53.16%\n",
      "      Fitness obtained: 53.16% | Best so far: 60.27%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 6736c98a)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 6736c98a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.6913 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3494 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2111 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1231 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0596 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0041 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9625 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9265 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8941 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8649 (391 batches processed)\n",
      "      Training completed for model 6736c98a\n",
      "      Evaluating model 6736c98a on test set...\n",
      "         Evaluation: 1759/2560 correct = 68.71% accuracy\n",
      "         Evaluation loss: 0.9343 (20 batches evaluated)\n",
      "      Evaluation completed for model 6736c98a - Final fitness: 68.71%\n",
      "      New best fitness in this generation: 68.71%!\n",
      "      Fitness obtained: 68.71% | Best so far: 68.71%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 02eebdf8)\n",
      "      Architecture: 1 conv + 4 fc, opt=adam, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 02eebdf8 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 3.3153 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.0745 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.1118 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.1071 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.1354 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.1207 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.1627 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1110 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.0911 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.0966 (391 batches processed)\n",
      "      Training completed for model 02eebdf8\n",
      "      Evaluating model 02eebdf8 on test set...\n",
      "         Evaluation: 521/2560 correct = 20.35% accuracy\n",
      "         Evaluation loss: 2.0381 (20 batches evaluated)\n",
      "      Evaluation completed for model 02eebdf8 - Final fitness: 20.35%\n",
      "      Fitness obtained: 20.35% | Best so far: 68.71%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 3ba64a9a)\n",
      "      Architecture: 1 conv + 2 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 3ba64a9a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2735 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2059 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.1489 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.1022 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.0674 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.0350 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.0111 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.9877 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.9692 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.9533 (391 batches processed)\n",
      "      Training completed for model 3ba64a9a\n",
      "      Evaluating model 3ba64a9a on test set...\n",
      "         Evaluation: 908/2560 correct = 35.47% accuracy\n",
      "         Evaluation loss: 1.8787 (20 batches evaluated)\n",
      "      Evaluation completed for model 3ba64a9a - Final fitness: 35.47%\n",
      "      Fitness obtained: 35.47% | Best so far: 68.71%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7650 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4553 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3047 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2008 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1321 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0690 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0221 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9754 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9440 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9138 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1795/2560 correct = 70.12% accuracy\n",
      "         Evaluation loss: 0.8457 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 70.12%\n",
      "      New best fitness in this generation: 70.12%!\n",
      "      Fitness obtained: 70.12% | Best so far: 70.12%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2025 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5305 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3026 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1338 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0276 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9486 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.8959 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8570 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8219 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7861 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1875/2560 correct = 73.24% accuracy\n",
      "         Evaluation loss: 0.7933 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 73.24%\n",
      "      New best fitness in this generation: 73.24%!\n",
      "      Fitness obtained: 73.24% | Best so far: 73.24%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 1 STATISTICS:\n",
      "   Maximum fitness: 73.24%\n",
      "   Average fitness: 49.50%\n",
      "   Minimum fitness: 20.35%\n",
      "   Standard deviation: 18.56%\n",
      "   Best individual: fdfd5c50 with 73.24%\n",
      "   Global best individual: fdfd5c50 with 73.24%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: fdfd5c50 (fitness: 73.24%)\n",
      "   Elite 2: 5574ad75 (fitness: 70.12%)\n",
      "   Elite 3: 6736c98a (fitness: 68.71%)\n",
      "   Elite 4: c5ebb690 (fitness: 60.27%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 2\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 2)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1753 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5592 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3300 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1736 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0457 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9559 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.8915 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8354 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.7930 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7565 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1838/2560 correct = 71.80% accuracy\n",
      "         Evaluation loss: 0.8334 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 71.80%\n",
      "      New best fitness in this generation: 71.80%!\n",
      "      Fitness obtained: 71.80% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7511 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4352 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2978 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2024 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1321 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0716 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0280 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9831 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9535 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9159 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1820/2560 correct = 71.09% accuracy\n",
      "         Evaluation loss: 0.8526 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 71.09%\n",
      "      Fitness obtained: 71.09% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 6736c98a)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 6736c98a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7276 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3852 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2369 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1445 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0716 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0155 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9702 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9288 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8946 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8614 (391 batches processed)\n",
      "      Training completed for model 6736c98a\n",
      "      Evaluating model 6736c98a on test set...\n",
      "         Evaluation: 1758/2560 correct = 68.67% accuracy\n",
      "         Evaluation loss: 0.9424 (20 batches evaluated)\n",
      "      Evaluation completed for model 6736c98a - Final fitness: 68.67%\n",
      "      Fitness obtained: 68.67% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8315 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5861 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4509 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3470 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2507 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1748 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1189 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0696 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0291 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0022 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:22:16,907 - WARNING - Error evaluating genome 1f94e8ad: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1486/2560 correct = 58.05% accuracy\n",
      "         Evaluation loss: 1.1740 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 58.05%\n",
      "      Fitness obtained: 58.05% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 1f94e8ad)\n",
      "      Architecture: 4 conv + 2 fc, opt=sgd, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 1f94e8ad: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 597ae7bc)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 597ae7bc (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2579 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.9332 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.8804 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.8585 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.8457 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.8321 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.8135 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.7674 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.7128 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.6643 (391 batches processed)\n",
      "      Training completed for model 597ae7bc\n",
      "      Evaluating model 597ae7bc on test set...\n",
      "         Evaluation: 833/2560 correct = 32.54% accuracy\n",
      "         Evaluation loss: 1.6974 (20 batches evaluated)\n",
      "      Evaluation completed for model 597ae7bc - Final fitness: 32.54%\n",
      "      Fitness obtained: 32.54% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: ac80e686)\n",
      "      Architecture: 1 conv + 2 fc, opt=adamw, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model ac80e686 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 10.4752 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3032 (391 batches processed)\n",
      "      Training completed for model ac80e686\n",
      "      Evaluating model ac80e686 on test set...\n",
      "         Evaluation: 247/2560 correct = 9.65% accuracy\n",
      "         Evaluation loss: 2.3030 (20 batches evaluated)\n",
      "      Evaluation completed for model ac80e686 - Final fitness: 9.65%\n",
      "      Fitness obtained: 9.65% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: fb234b50)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fb234b50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 3.1635 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8706 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.7834 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.6714 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.6185 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.5684 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.5176 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.4900 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.4602 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.4304 (391 batches processed)\n",
      "      Training completed for model fb234b50\n",
      "      Evaluating model fb234b50 on test set...\n",
      "         Evaluation: 1285/2560 correct = 50.20% accuracy\n",
      "         Evaluation loss: 1.3528 (20 batches evaluated)\n",
      "      Evaluation completed for model fb234b50 - Final fitness: 50.20%\n",
      "      Fitness obtained: 50.20% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: ffc137de)\n",
      "      Architecture: 1 conv + 3 fc, opt=sgd, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model ffc137de (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3016 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2980 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2945 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2899 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2835 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2745 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2601 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.2403 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.2115 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.1742 (391 batches processed)\n",
      "      Training completed for model ffc137de\n",
      "      Evaluating model ffc137de on test set...\n",
      "         Evaluation: 611/2560 correct = 23.87% accuracy\n",
      "         Evaluation loss: 2.1061 (20 batches evaluated)\n",
      "      Evaluation completed for model ffc137de - Final fitness: 23.87%\n",
      "      Fitness obtained: 23.87% | Best so far: 71.80%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: c115e84f)\n",
      "      Architecture: 1 conv + 4 fc, opt=rmsprop, lr=1e-06\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c115e84f (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3025 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3011 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3001 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2981 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2954 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2911 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2844 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.2738 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.2577 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.2367 (391 batches processed)\n",
      "      Training completed for model c115e84f\n",
      "      Evaluating model c115e84f on test set...\n",
      "         Evaluation: 607/2560 correct = 23.71% accuracy\n",
      "         Evaluation loss: 2.2087 (20 batches evaluated)\n",
      "      Evaluation completed for model c115e84f - Final fitness: 23.71%\n",
      "      Fitness obtained: 23.71% | Best so far: 71.80%\n",
      "\n",
      "GENERATION 2 STATISTICS:\n",
      "   Maximum fitness: 71.80%\n",
      "   Average fitness: 40.96%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 25.15%\n",
      "   Best individual: fdfd5c50 with 71.80%\n",
      "   Global best individual: fdfd5c50 with 73.24%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: fdfd5c50 (fitness: 71.80%)\n",
      "   Elite 2: 5574ad75 (fitness: 71.09%)\n",
      "   Elite 3: 6736c98a (fitness: 68.67%)\n",
      "   Elite 4: c5ebb690 (fitness: 58.05%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 3\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 3)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2078 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5662 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3618 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1880 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0631 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9675 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9100 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8581 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8128 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7704 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1839/2560 correct = 71.84% accuracy\n",
      "         Evaluation loss: 0.8337 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 71.84%\n",
      "      New best fitness in this generation: 71.84%!\n",
      "      Fitness obtained: 71.84% | Best so far: 71.84%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7504 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4501 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2971 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1965 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1228 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0649 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0151 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9730 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9397 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9047 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1864/2560 correct = 72.81% accuracy\n",
      "         Evaluation loss: 0.7756 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 72.81%\n",
      "      New best fitness in this generation: 72.81%!\n",
      "      Fitness obtained: 72.81% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 6736c98a)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 6736c98a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7442 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4003 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2408 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1379 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0742 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0181 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9793 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9436 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9025 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8802 (391 batches processed)\n",
      "      Training completed for model 6736c98a\n",
      "      Evaluating model 6736c98a on test set...\n",
      "         Evaluation: 1446/2560 correct = 56.48% accuracy\n",
      "         Evaluation loss: 1.2367 (20 batches evaluated)\n",
      "      Evaluation completed for model 6736c98a - Final fitness: 56.48%\n",
      "      Fitness obtained: 56.48% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8346 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6025 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4327 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3246 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2529 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1906 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1292 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0782 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0403 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0127 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n",
      "         Evaluation: 1626/2560 correct = 63.52% accuracy\n",
      "         Evaluation loss: 1.0483 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 63.52%\n",
      "      Fitness obtained: 63.52% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 640ee6c5)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 640ee6c5 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 29.2853 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.5271 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.6318 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.8706 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3030 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.4917 (391 batches processed)\n",
      "      Training completed for model 640ee6c5\n",
      "      Evaluating model 640ee6c5 on test set...\n",
      "         Evaluation: 276/2560 correct = 10.78% accuracy\n",
      "         Evaluation loss: 2.3025 (20 batches evaluated)\n",
      "      Evaluation completed for model 640ee6c5 - Final fitness: 10.78%\n",
      "      Fitness obtained: 10.78% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 026a2764)\n",
      "      Architecture: 2 conv + 3 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 026a2764 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 3.1067 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3032 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3032 (391 batches processed)\n",
      "      Training completed for model 026a2764\n",
      "      Evaluating model 026a2764 on test set...\n",
      "         Evaluation: 240/2560 correct = 9.38% accuracy\n",
      "         Evaluation loss: 2.3028 (20 batches evaluated)\n",
      "      Evaluation completed for model 026a2764 - Final fitness: 9.38%\n",
      "      Fitness obtained: 9.38% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 116e25d8)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 116e25d8 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7283 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3948 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2547 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1771 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1173 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0688 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0268 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9960 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9659 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9347 (391 batches processed)\n",
      "      Training completed for model 116e25d8\n",
      "      Evaluating model 116e25d8 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:35:25,111 - WARNING - Error evaluating genome 98d7f589: list index out of range\n",
      "2025-08-08 11:35:25,125 - WARNING - Error evaluating genome c573836a: Calculated padded input size per channel: (5 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "2025-08-08 11:35:25,130 - WARNING - Error evaluating genome e0c5a44c: Expected more than 1 value per channel when training, got input size torch.Size([1, 22, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1793/2560 correct = 70.04% accuracy\n",
      "         Evaluation loss: 0.8403 (20 batches evaluated)\n",
      "      Evaluation completed for model 116e25d8 - Final fitness: 70.04%\n",
      "      Fitness obtained: 70.04% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 98d7f589)\n",
      "      Architecture: 4 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 98d7f589: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: c573836a)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome c573836a: Calculated padded input size per channel: (5 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 72.81%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: e0c5a44c)\n",
      "      Architecture: 4 conv + 3 fc, opt=adamw, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome e0c5a44c: Expected more than 1 value per channel when training, got input size torch.Size([1, 22, 1, 1])\n",
      "      Fitness obtained: 0.00% | Best so far: 72.81%\n",
      "\n",
      "GENERATION 3 STATISTICS:\n",
      "   Maximum fitness: 72.81%\n",
      "   Average fitness: 35.48%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 31.95%\n",
      "   Best individual: 5574ad75 with 72.81%\n",
      "   Global best individual: fdfd5c50 with 73.24%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 5574ad75 (fitness: 72.81%)\n",
      "   Elite 2: fdfd5c50 (fitness: 71.84%)\n",
      "   Elite 3: 116e25d8 (fitness: 70.04%)\n",
      "   Elite 4: c5ebb690 (fitness: 63.52%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 4\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 4)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7418 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4498 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2985 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2015 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1307 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0683 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0165 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9798 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9473 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9132 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1707/2560 correct = 66.68% accuracy\n",
      "         Evaluation loss: 0.9510 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 66.68%\n",
      "      New best fitness in this generation: 66.68%!\n",
      "      Fitness obtained: 66.68% | Best so far: 66.68%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3619 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6128 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4193 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2551 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1475 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0642 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9901 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9337 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8889 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8496 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1789/2560 correct = 69.88% accuracy\n",
      "         Evaluation loss: 0.9141 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 69.88%\n",
      "      New best fitness in this generation: 69.88%!\n",
      "      Fitness obtained: 69.88% | Best so far: 69.88%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 116e25d8)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 116e25d8 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7231 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3992 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2661 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1815 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1196 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0737 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0370 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9950 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9692 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9447 (391 batches processed)\n",
      "      Training completed for model 116e25d8\n",
      "      Evaluating model 116e25d8 on test set...\n",
      "         Evaluation: 1809/2560 correct = 70.66% accuracy\n",
      "         Evaluation loss: 0.8489 (20 batches evaluated)\n",
      "      Evaluation completed for model 116e25d8 - Final fitness: 70.66%\n",
      "      New best fitness in this generation: 70.66%!\n",
      "      Fitness obtained: 70.66% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8148 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5526 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4251 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3242 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2383 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1680 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1159 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0738 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0264 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9965 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n",
      "         Evaluation: 1673/2560 correct = 65.35% accuracy\n",
      "         Evaluation loss: 0.9646 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 65.35%\n",
      "      Fitness obtained: 65.35% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 9713c605)\n",
      "      Architecture: 1 conv + 2 fc, opt=adam, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 9713c605 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8794 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6633 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5793 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.5192 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.4746 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.4414 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.4066 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.3819 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.3629 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.3319 (391 batches processed)\n",
      "      Training completed for model 9713c605\n",
      "      Evaluating model 9713c605 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:40:56,034 - WARNING - Error evaluating genome 0edda83b: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1493/2560 correct = 58.32% accuracy\n",
      "         Evaluation loss: 1.1670 (20 batches evaluated)\n",
      "      Evaluation completed for model 9713c605 - Final fitness: 58.32%\n",
      "      Fitness obtained: 58.32% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 0edda83b)\n",
      "      Architecture: 4 conv + 1 fc, opt=adamw, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 0edda83b: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 09f0baa6)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 09f0baa6 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8457 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6289 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5170 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4439 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3877 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.3460 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.3085 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.2777 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.2542 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.2295 (391 batches processed)\n",
      "      Training completed for model 09f0baa6\n",
      "      Evaluating model 09f0baa6 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:42:01,838 - WARNING - Error evaluating genome faa099d9: list index out of range\n",
      "2025-08-08 11:42:01,840 - WARNING - Error evaluating genome 180d7235: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1513/2560 correct = 59.10% accuracy\n",
      "         Evaluation loss: 1.3059 (20 batches evaluated)\n",
      "      Evaluation completed for model 09f0baa6 - Final fitness: 59.10%\n",
      "      Fitness obtained: 59.10% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: faa099d9)\n",
      "      Architecture: 3 conv + 3 fc, opt=sgd, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome faa099d9: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 180d7235)\n",
      "      Architecture: 3 conv + 1 fc, opt=sgd, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 180d7235: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 70.66%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 739f3b56)\n",
      "      Architecture: 2 conv + 1 fc, opt=sgd, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 739f3b56 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.0772 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8391 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.7240 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.6333 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.5664 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.5195 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.4789 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.4424 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.4122 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.3780 (391 batches processed)\n",
      "      Training completed for model 739f3b56\n",
      "      Evaluating model 739f3b56 on test set...\n",
      "         Evaluation: 1382/2560 correct = 53.98% accuracy\n",
      "         Evaluation loss: 1.2987 (20 batches evaluated)\n",
      "      Evaluation completed for model 739f3b56 - Final fitness: 53.98%\n",
      "      Fitness obtained: 53.98% | Best so far: 70.66%\n",
      "\n",
      "GENERATION 4 STATISTICS:\n",
      "   Maximum fitness: 70.66%\n",
      "   Average fitness: 44.40%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 29.48%\n",
      "   Best individual: 116e25d8 with 70.66%\n",
      "   Global best individual: fdfd5c50 with 73.24%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 116e25d8 (fitness: 70.66%)\n",
      "   Elite 2: fdfd5c50 (fitness: 69.88%)\n",
      "   Elite 3: 5574ad75 (fitness: 66.68%)\n",
      "   Elite 4: c5ebb690 (fitness: 65.35%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 5\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 5)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 116e25d8)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 116e25d8 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7222 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4116 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2703 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1856 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1245 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0754 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0351 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0028 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9724 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9423 (391 batches processed)\n",
      "      Training completed for model 116e25d8\n",
      "      Evaluating model 116e25d8 on test set...\n",
      "         Evaluation: 1789/2560 correct = 69.88% accuracy\n",
      "         Evaluation loss: 0.8343 (20 batches evaluated)\n",
      "      Evaluation completed for model 116e25d8 - Final fitness: 69.88%\n",
      "      New best fitness in this generation: 69.88%!\n",
      "      Fitness obtained: 69.88% | Best so far: 69.88%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2257 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6066 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3940 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2098 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0808 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9914 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9303 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8776 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8344 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7985 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1915/2560 correct = 74.80% accuracy\n",
      "         Evaluation loss: 0.7490 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 74.80%\n",
      "      New best fitness in this generation: 74.80%!\n",
      "      Fitness obtained: 74.80% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7476 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4442 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2955 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1914 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1138 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0623 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0155 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9695 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9367 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9023 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1796/2560 correct = 70.16% accuracy\n",
      "         Evaluation loss: 0.8798 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 70.16%\n",
      "      Fitness obtained: 70.16% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: c5ebb690)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5ebb690 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8574 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5832 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4518 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3415 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2511 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1779 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1221 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0843 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0436 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0122 (391 batches processed)\n",
      "      Training completed for model c5ebb690\n",
      "      Evaluating model c5ebb690 on test set...\n",
      "         Evaluation: 1513/2560 correct = 59.10% accuracy\n",
      "         Evaluation loss: 1.1464 (20 batches evaluated)\n",
      "      Evaluation completed for model c5ebb690 - Final fitness: 59.10%\n",
      "      Fitness obtained: 59.10% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: fca58dfd)\n",
      "      Architecture: 2 conv + 3 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fca58dfd (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8009 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5668 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4604 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3981 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3406 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2953 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2605 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.2361 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.2067 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1761 (391 batches processed)\n",
      "      Training completed for model fca58dfd\n",
      "      Evaluating model fca58dfd on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 11:48:37,459 - WARNING - Error evaluating genome a7bec0c2: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1537/2560 correct = 60.04% accuracy\n",
      "         Evaluation loss: 1.2265 (20 batches evaluated)\n",
      "      Evaluation completed for model fca58dfd - Final fitness: 60.04%\n",
      "      Fitness obtained: 60.04% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: a7bec0c2)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome a7bec0c2: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 0ff29b5e)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 0ff29b5e (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.9353 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.7427 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.6695 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.5849 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.5307 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.4886 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.4546 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.4260 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.4021 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.3760 (391 batches processed)\n",
      "      Training completed for model 0ff29b5e\n",
      "      Evaluating model 0ff29b5e on test set...\n",
      "         Evaluation: 1076/2560 correct = 42.03% accuracy\n",
      "         Evaluation loss: 1.6971 (20 batches evaluated)\n",
      "      Evaluation completed for model 0ff29b5e - Final fitness: 42.03%\n",
      "      Fitness obtained: 42.03% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 8be095f0)\n",
      "      Architecture: 3 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8be095f0 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8609 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5283 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3981 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3088 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2443 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1969 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1559 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1175 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0910 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0631 (391 batches processed)\n",
      "      Training completed for model 8be095f0\n",
      "      Evaluating model 8be095f0 on test set...\n",
      "         Evaluation: 1675/2560 correct = 65.43% accuracy\n",
      "         Evaluation loss: 0.9385 (20 batches evaluated)\n",
      "      Evaluation completed for model 8be095f0 - Final fitness: 65.43%\n",
      "      Fitness obtained: 65.43% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 4cfb584a)\n",
      "      Architecture: 3 conv + 1 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 4cfb584a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7485 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4389 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2851 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1812 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1021 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0408 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9903 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9526 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9192 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8877 (391 batches processed)\n",
      "      Training completed for model 4cfb584a\n",
      "      Evaluating model 4cfb584a on test set...\n",
      "         Evaluation: 1616/2560 correct = 63.12% accuracy\n",
      "         Evaluation loss: 1.0627 (20 batches evaluated)\n",
      "      Evaluation completed for model 4cfb584a - Final fitness: 63.12%\n",
      "      Fitness obtained: 63.12% | Best so far: 74.80%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 9015561d)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 9015561d (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.9472 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6929 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5833 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4990 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.4369 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.3802 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.3310 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.2914 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.2501 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.2199 (391 batches processed)\n",
      "      Training completed for model 9015561d\n",
      "      Evaluating model 9015561d on test set...\n",
      "         Evaluation: 1173/2560 correct = 45.82% accuracy\n",
      "         Evaluation loss: 1.5523 (20 batches evaluated)\n",
      "      Evaluation completed for model 9015561d - Final fitness: 45.82%\n",
      "      Fitness obtained: 45.82% | Best so far: 74.80%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 5 STATISTICS:\n",
      "   Maximum fitness: 74.80%\n",
      "   Average fitness: 55.04%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 20.83%\n",
      "   Best individual: fdfd5c50 with 74.80%\n",
      "   Global best individual: fdfd5c50 with 74.80%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: fdfd5c50 (fitness: 74.80%)\n",
      "   Elite 2: 5574ad75 (fitness: 70.16%)\n",
      "   Elite 3: 116e25d8 (fitness: 69.88%)\n",
      "   Elite 4: 8be095f0 (fitness: 65.43%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 6\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 6)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2302 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6196 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4016 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2249 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1108 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0265 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9600 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8979 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8571 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8142 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1845/2560 correct = 72.07% accuracy\n",
      "         Evaluation loss: 0.8302 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 72.07%\n",
      "      New best fitness in this generation: 72.07%!\n",
      "      Fitness obtained: 72.07% | Best so far: 72.07%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7548 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4463 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2962 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1930 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1317 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0667 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0155 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9856 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9501 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9183 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1874/2560 correct = 73.20% accuracy\n",
      "         Evaluation loss: 0.7904 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 73.20%\n",
      "      New best fitness in this generation: 73.20%!\n",
      "      Fitness obtained: 73.20% | Best so far: 73.20%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 116e25d8)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 116e25d8 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7168 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3839 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2493 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1720 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1141 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0674 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0270 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9931 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9658 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9380 (391 batches processed)\n",
      "      Training completed for model 116e25d8\n",
      "      Evaluating model 116e25d8 on test set...\n",
      "         Evaluation: 1816/2560 correct = 70.94% accuracy\n",
      "         Evaluation loss: 0.8329 (20 batches evaluated)\n",
      "      Evaluation completed for model 116e25d8 - Final fitness: 70.94%\n",
      "      Fitness obtained: 70.94% | Best so far: 73.20%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: 8be095f0)\n",
      "      Architecture: 3 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8be095f0 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8521 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5353 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3949 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2938 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2284 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1777 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1367 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1057 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0707 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0492 (391 batches processed)\n",
      "      Training completed for model 8be095f0\n",
      "      Evaluating model 8be095f0 on test set...\n",
      "         Evaluation: 1707/2560 correct = 66.68% accuracy\n",
      "         Evaluation loss: 0.9376 (20 batches evaluated)\n",
      "      Evaluation completed for model 8be095f0 - Final fitness: 66.68%\n",
      "      Fitness obtained: 66.68% | Best so far: 73.20%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: f357318f)\n",
      "      Architecture: 2 conv + 1 fc, opt=adamw, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model f357318f (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8012 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5237 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4064 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3329 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2832 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2450 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2134 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1971 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1695 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1497 (391 batches processed)\n",
      "      Training completed for model f357318f\n",
      "      Evaluating model f357318f on test set...\n",
      "         Evaluation: 1546/2560 correct = 60.39% accuracy\n",
      "         Evaluation loss: 1.0856 (20 batches evaluated)\n",
      "      Evaluation completed for model f357318f - Final fitness: 60.39%\n",
      "      Fitness obtained: 60.39% | Best so far: 73.20%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5950 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3124 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1706 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0847 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0143 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9680 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9277 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8935 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8636 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8369 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1874/2560 correct = 73.20% accuracy\n",
      "         Evaluation loss: 0.7468 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 73.20%\n",
      "      Fitness obtained: 73.20% | Best so far: 73.20%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3504 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0016 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8730 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.7967 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7406 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.6959 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6621 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6324 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.6016 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5726 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:00:44,395 - WARNING - Error evaluating genome c8d01d27: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 2045/2560 correct = 79.88% accuracy\n",
      "         Evaluation loss: 0.5822 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 79.88%\n",
      "      New best fitness in this generation: 79.88%!\n",
      "      Fitness obtained: 79.88% | Best so far: 79.88%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: c8d01d27)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome c8d01d27: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 79.88%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: c0f22553)\n",
      "      Architecture: 4 conv + 3 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c0f22553 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7354 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4382 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2895 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1849 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1005 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0417 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9962 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9537 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9325 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9047 (391 batches processed)\n",
      "      Training completed for model c0f22553\n",
      "      Evaluating model c0f22553 on test set...\n",
      "         Evaluation: 1685/2560 correct = 65.82% accuracy\n",
      "         Evaluation loss: 0.9929 (20 batches evaluated)\n",
      "      Evaluation completed for model c0f22553 - Final fitness: 65.82%\n",
      "      Fitness obtained: 65.82% | Best so far: 79.88%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 6d6e19de)\n",
      "      Architecture: 3 conv + 3 fc, opt=rmsprop, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 6d6e19de (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 177836.0326 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 57.4051 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 4.1750 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3125 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3079 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3073 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3060 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3064 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3063 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3061 (391 batches processed)\n",
      "      Training completed for model 6d6e19de\n",
      "      Evaluating model 6d6e19de on test set...\n",
      "         Evaluation: 267/2560 correct = 10.43% accuracy\n",
      "         Evaluation loss: 2.3044 (20 batches evaluated)\n",
      "      Evaluation completed for model 6d6e19de - Final fitness: 10.43%\n",
      "      Fitness obtained: 10.43% | Best so far: 79.88%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 6 STATISTICS:\n",
      "   Maximum fitness: 79.88%\n",
      "   Average fitness: 57.26%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 26.59%\n",
      "   Best individual: 8f35d972 with 79.88%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 79.88%)\n",
      "   Elite 2: 5574ad75 (fitness: 73.20%)\n",
      "   Elite 3: 8134e1ce (fitness: 73.20%)\n",
      "   Elite 4: fdfd5c50 (fitness: 72.07%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 7\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 7)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3583 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0168 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8863 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.8122 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7484 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.7056 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6649 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6345 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.6098 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5810 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 1974/2560 correct = 77.11% accuracy\n",
      "         Evaluation loss: 0.6449 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 77.11%\n",
      "      New best fitness in this generation: 77.11%!\n",
      "      Fitness obtained: 77.11% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 5574ad75)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 5574ad75 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7527 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4493 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3013 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2011 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1255 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0715 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0190 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9769 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9376 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9079 (391 batches processed)\n",
      "      Training completed for model 5574ad75\n",
      "      Evaluating model 5574ad75 on test set...\n",
      "         Evaluation: 1787/2560 correct = 69.80% accuracy\n",
      "         Evaluation loss: 0.8517 (20 batches evaluated)\n",
      "      Evaluation completed for model 5574ad75 - Final fitness: 69.80%\n",
      "      Fitness obtained: 69.80% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.6045 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3100 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1686 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0809 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0193 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9702 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9311 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8911 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8588 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8362 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1815/2560 correct = 70.90% accuracy\n",
      "         Evaluation loss: 0.8402 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 70.90%\n",
      "      Fitness obtained: 70.90% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2088 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5823 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3864 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2349 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1021 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0186 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9317 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8777 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8372 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7938 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1790/2560 correct = 69.92% accuracy\n",
      "         Evaluation loss: 0.8938 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 69.92%\n",
      "      Fitness obtained: 69.92% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: c43c845b)\n",
      "      Architecture: 2 conv + 2 fc, opt=adamw, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c43c845b (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7059 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5045 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4141 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3492 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2940 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2608 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2279 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1992 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1726 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1507 (391 batches processed)\n",
      "      Training completed for model c43c845b\n",
      "      Evaluating model c43c845b on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:08:22,530 - WARNING - Error evaluating genome 00525bac: Expected more than 1 value per channel when training, got input size torch.Size([1, 117, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1641/2560 correct = 64.10% accuracy\n",
      "         Evaluation loss: 1.0322 (20 batches evaluated)\n",
      "      Evaluation completed for model c43c845b - Final fitness: 64.10%\n",
      "      Fitness obtained: 64.10% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 00525bac)\n",
      "      Architecture: 4 conv + 3 fc, opt=adamw, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 00525bac: Expected more than 1 value per channel when training, got input size torch.Size([1, 117, 1, 1])\n",
      "      Fitness obtained: 0.00% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 9e7c2ba2)\n",
      "      Architecture: 3 conv + 4 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 9e7c2ba2 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.0518 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8435 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.7928 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.7294 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.7047 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.6709 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.6575 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.6380 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.5988 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.5767 (391 batches processed)\n",
      "      Training completed for model 9e7c2ba2\n",
      "      Evaluating model 9e7c2ba2 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:09:28,069 - WARNING - Error evaluating genome 023b9f17: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1038/2560 correct = 40.55% accuracy\n",
      "         Evaluation loss: 1.5306 (20 batches evaluated)\n",
      "      Evaluation completed for model 9e7c2ba2 - Final fitness: 40.55%\n",
      "      Fitness obtained: 40.55% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 023b9f17)\n",
      "      Architecture: 3 conv + 3 fc, opt=sgd, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 023b9f17: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 49a1ffbe)\n",
      "      Architecture: 1 conv + 2 fc, opt=adam, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 49a1ffbe (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 326.5432 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.6965 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3058 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3058 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3059 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3054 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3910 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3054 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3065 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3109 (391 batches processed)\n",
      "      Training completed for model 49a1ffbe\n",
      "      Evaluating model 49a1ffbe on test set...\n",
      "         Evaluation: 245/2560 correct = 9.57% accuracy\n",
      "         Evaluation loss: 2.3471 (20 batches evaluated)\n",
      "      Evaluation completed for model 49a1ffbe - Final fitness: 9.57%\n",
      "      Fitness obtained: 9.57% | Best so far: 77.11%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5698 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2843 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1575 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0807 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0228 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9778 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9403 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9041 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8731 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8590 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1904/2560 correct = 74.38% accuracy\n",
      "         Evaluation loss: 0.7467 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 74.38%\n",
      "      Fitness obtained: 74.38% | Best so far: 77.11%\n",
      "\n",
      "GENERATION 7 STATISTICS:\n",
      "   Maximum fitness: 77.11%\n",
      "   Average fitness: 47.63%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 30.69%\n",
      "   Best individual: 8f35d972 with 77.11%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 77.11%)\n",
      "   Elite 2: e3f19d4a (fitness: 74.38%)\n",
      "   Elite 3: 8134e1ce (fitness: 70.90%)\n",
      "   Elite 4: fdfd5c50 (fitness: 69.92%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 8\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 8)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3455 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0038 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8761 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.7923 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7319 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.6926 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6532 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6226 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.5991 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5754 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 1989/2560 correct = 77.70% accuracy\n",
      "         Evaluation loss: 0.6429 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 77.70%\n",
      "      New best fitness in this generation: 77.70%!\n",
      "      Fitness obtained: 77.70% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5823 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2895 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1668 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0909 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0316 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9816 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9423 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9210 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8937 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8694 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1814/2560 correct = 70.86% accuracy\n",
      "         Evaluation loss: 0.8154 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 70.86%\n",
      "      Fitness obtained: 70.86% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5975 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3031 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1618 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0784 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0161 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9703 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9265 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8928 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8639 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8347 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1891/2560 correct = 73.87% accuracy\n",
      "         Evaluation loss: 0.7573 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 73.87%\n",
      "      Fitness obtained: 73.87% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1998 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5589 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3621 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2242 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1136 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0239 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9575 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9020 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8576 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8178 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1805/2560 correct = 70.51% accuracy\n",
      "         Evaluation loss: 0.8596 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 70.51%\n",
      "      Fitness obtained: 70.51% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 079854dc)\n",
      "      Architecture: 3 conv + 4 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 079854dc (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.6253 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3105 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3228 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3097 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3048 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3283 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.7518 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3038 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3035 (391 batches processed)\n",
      "      Training completed for model 079854dc\n",
      "      Evaluating model 079854dc on test set...\n",
      "         Evaluation: 276/2560 correct = 10.78% accuracy\n",
      "         Evaluation loss: 2.3026 (20 batches evaluated)\n",
      "      Evaluation completed for model 079854dc - Final fitness: 10.78%\n",
      "      Fitness obtained: 10.78% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: dc87179c)\n",
      "      Architecture: 1 conv + 4 fc, opt=adam, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model dc87179c (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2956 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2487 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2150 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.1956 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.1806 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.1756 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.1705 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1634 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1604 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.1572 (391 batches processed)\n",
      "      Training completed for model dc87179c\n",
      "      Evaluating model dc87179c on test set...\n",
      "         Evaluation: 357/2560 correct = 13.95% accuracy\n",
      "         Evaluation loss: 2.2033 (20 batches evaluated)\n",
      "      Evaluation completed for model dc87179c - Final fitness: 13.95%\n",
      "      Fitness obtained: 13.95% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 073f50a6)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 073f50a6 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1258 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.9181 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.8415 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.7993 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.7570 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.7197 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.6838 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.6592 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.6314 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.6114 (391 batches processed)\n",
      "      Training completed for model 073f50a6\n",
      "      Evaluating model 073f50a6 on test set...\n",
      "         Evaluation: 1150/2560 correct = 44.92% accuracy\n",
      "         Evaluation loss: 1.6559 (20 batches evaluated)\n",
      "      Evaluation completed for model 073f50a6 - Final fitness: 44.92%\n",
      "      Fitness obtained: 44.92% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 10254611)\n",
      "      Architecture: 2 conv + 4 fc, opt=rmsprop, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 10254611 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3057 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.7209 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5772 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4690 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3857 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.3326 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2738 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.2343 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.2045 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1683 (391 batches processed)\n",
      "      Training completed for model 10254611\n",
      "      Evaluating model 10254611 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:20:26,430 - WARNING - Error evaluating genome fd7be1aa: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "2025-08-08 12:20:26,438 - WARNING - Error evaluating genome 1939c69c: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1724/2560 correct = 67.34% accuracy\n",
      "         Evaluation loss: 1.0054 (20 batches evaluated)\n",
      "      Evaluation completed for model 10254611 - Final fitness: 67.34%\n",
      "      Fitness obtained: 67.34% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: fd7be1aa)\n",
      "      Architecture: 4 conv + 1 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome fd7be1aa: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 77.70%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 1939c69c)\n",
      "      Architecture: 4 conv + 2 fc, opt=sgd, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 1939c69c: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 77.70%\n",
      "\n",
      "GENERATION 8 STATISTICS:\n",
      "   Maximum fitness: 77.70%\n",
      "   Average fitness: 42.99%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 31.41%\n",
      "   Best individual: 8f35d972 with 77.70%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 77.70%)\n",
      "   Elite 2: 8134e1ce (fitness: 73.87%)\n",
      "   Elite 3: e3f19d4a (fitness: 70.86%)\n",
      "   Elite 4: fdfd5c50 (fitness: 70.51%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 9\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 9)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3231 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 0.9879 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8663 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.7843 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7261 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.6829 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6501 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6219 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.5890 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5717 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 1977/2560 correct = 77.23% accuracy\n",
      "         Evaluation loss: 0.6762 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 77.23%\n",
      "      New best fitness in this generation: 77.23%!\n",
      "      Fitness obtained: 77.23% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.6147 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3164 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1663 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0716 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0073 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9627 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9209 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8871 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8542 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8358 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1855/2560 correct = 72.46% accuracy\n",
      "         Evaluation loss: 0.7923 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 72.46%\n",
      "      Fitness obtained: 72.46% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5925 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3019 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1805 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0851 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0302 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9886 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9493 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9097 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8932 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8630 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1865/2560 correct = 72.85% accuracy\n",
      "         Evaluation loss: 0.7501 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 72.85%\n",
      "      Fitness obtained: 72.85% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3275 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6353 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4352 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2800 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1474 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0565 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9864 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9428 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8920 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8528 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1816/2560 correct = 70.94% accuracy\n",
      "         Evaluation loss: 0.8492 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 70.94%\n",
      "      Fitness obtained: 70.94% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: d4e62eb1)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model d4e62eb1 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2825 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2039 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.0875 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.0139 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.9529 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.8856 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.8241 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.7696 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.7272 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.6903 (391 batches processed)\n",
      "      Training completed for model d4e62eb1\n",
      "      Evaluating model d4e62eb1 on test set...\n",
      "         Evaluation: 1096/2560 correct = 42.81% accuracy\n",
      "         Evaluation loss: 1.5433 (20 batches evaluated)\n",
      "      Evaluation completed for model d4e62eb1 - Final fitness: 42.81%\n",
      "      Fitness obtained: 42.81% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 8418d55e)\n",
      "      Architecture: 3 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8418d55e (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3072 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3055 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3014 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3006 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2977 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2936 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2914 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.2880 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.2824 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.2769 (391 batches processed)\n",
      "      Training completed for model 8418d55e\n",
      "      Evaluating model 8418d55e on test set...\n",
      "         Evaluation: 573/2560 correct = 22.38% accuracy\n",
      "         Evaluation loss: 2.2563 (20 batches evaluated)\n",
      "      Evaluation completed for model 8418d55e - Final fitness: 22.38%\n",
      "      Fitness obtained: 22.38% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 9844195c)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=1e-06\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 9844195c (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3128 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3126 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3127 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.3127 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.3123 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3115 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3117 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3114 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3113 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3111 (391 batches processed)\n",
      "      Training completed for model 9844195c\n",
      "      Evaluating model 9844195c on test set...\n",
      "         Evaluation: 284/2560 correct = 11.09% accuracy\n",
      "         Evaluation loss: 2.3057 (20 batches evaluated)\n",
      "      Evaluation completed for model 9844195c - Final fitness: 11.09%\n",
      "      Fitness obtained: 11.09% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 68db4cab)\n",
      "      Architecture: 1 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:28:10,315 - WARNING - Error evaluating genome 68db4cab: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR evaluating genome 68db4cab: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: b3ffe364)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model b3ffe364 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.7544 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4502 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3549 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2861 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2486 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2134 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.1883 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1630 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1487 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1283 (391 batches processed)\n",
      "      Training completed for model b3ffe364\n",
      "      Evaluating model b3ffe364 on test set...\n",
      "         Evaluation: 1592/2560 correct = 62.19% accuracy\n",
      "         Evaluation loss: 1.0689 (20 batches evaluated)\n",
      "      Evaluation completed for model b3ffe364 - Final fitness: 62.19%\n",
      "      Fitness obtained: 62.19% | Best so far: 77.23%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: b331a069)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model b331a069 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1953 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8857 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.7608 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.6911 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.6273 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.5746 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.5282 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.4969 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.4670 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.4332 (391 batches processed)\n",
      "      Training completed for model b331a069\n",
      "      Evaluating model b331a069 on test set...\n",
      "         Evaluation: 1432/2560 correct = 55.94% accuracy\n",
      "         Evaluation loss: 1.2280 (20 batches evaluated)\n",
      "      Evaluation completed for model b331a069 - Final fitness: 55.94%\n",
      "      Fitness obtained: 55.94% | Best so far: 77.23%\n",
      "\n",
      "GENERATION 9 STATISTICS:\n",
      "   Maximum fitness: 77.23%\n",
      "   Average fitness: 48.79%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 26.84%\n",
      "   Best individual: 8f35d972 with 77.23%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 77.23%)\n",
      "   Elite 2: e3f19d4a (fitness: 72.85%)\n",
      "   Elite 3: 8134e1ce (fitness: 72.46%)\n",
      "   Elite 4: fdfd5c50 (fitness: 70.94%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 10\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 10)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3662 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0187 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8869 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.7985 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7441 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.7035 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6592 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6268 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.6003 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5787 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 2003/2560 correct = 78.24% accuracy\n",
      "         Evaluation loss: 0.6315 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 78.24%\n",
      "      New best fitness in this generation: 78.24%!\n",
      "      Fitness obtained: 78.24% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5679 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2832 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1627 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0820 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0263 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9870 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9389 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9120 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8810 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8540 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1908/2560 correct = 74.53% accuracy\n",
      "         Evaluation loss: 0.7374 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 74.53%\n",
      "      Fitness obtained: 74.53% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.6020 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3065 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1734 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0849 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0190 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9688 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9311 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8977 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8675 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8375 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1897/2560 correct = 74.10% accuracy\n",
      "         Evaluation loss: 0.7539 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 74.10%\n",
      "      Fitness obtained: 74.10% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2690 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6195 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4069 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2511 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1292 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.0373 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9698 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9116 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8704 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8193 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1813/2560 correct = 70.82% accuracy\n",
      "         Evaluation loss: 0.8988 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 70.82%\n",
      "      Fitness obtained: 70.82% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: ebd34832)\n",
      "      Architecture: 1 conv + 1 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model ebd34832 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.9955 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6106 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4862 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3940 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3259 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2679 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2221 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1836 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1464 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1160 (391 batches processed)\n",
      "      Training completed for model ebd34832\n",
      "      Evaluating model ebd34832 on test set...\n",
      "         Evaluation: 1638/2560 correct = 63.98% accuracy\n",
      "         Evaluation loss: 1.0524 (20 batches evaluated)\n",
      "      Evaluation completed for model ebd34832 - Final fitness: 63.98%\n",
      "      Fitness obtained: 63.98% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 52f4c2e9)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 52f4c2e9 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3066 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.2817 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2580 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2355 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2143 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.1948 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.1733 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.1534 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1372 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.1187 (391 batches processed)\n",
      "      Training completed for model 52f4c2e9\n",
      "      Evaluating model 52f4c2e9 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:36:59,652 - WARNING - Error evaluating genome ed7d4837: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 850/2560 correct = 33.20% accuracy\n",
      "         Evaluation loss: 2.0630 (20 batches evaluated)\n",
      "      Evaluation completed for model 52f4c2e9 - Final fitness: 33.20%\n",
      "      Fitness obtained: 33.20% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: ed7d4837)\n",
      "      Architecture: 3 conv + 2 fc, opt=rmsprop, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome ed7d4837: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: 571b0da4)\n",
      "      Architecture: 3 conv + 2 fc, opt=sgd, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 571b0da4 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.0372 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6910 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.5365 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.4347 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3576 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2966 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2357 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1915 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1483 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1133 (391 batches processed)\n",
      "      Training completed for model 571b0da4\n",
      "      Evaluating model 571b0da4 on test set...\n",
      "         Evaluation: 1244/2560 correct = 48.59% accuracy\n",
      "         Evaluation loss: 1.5020 (20 batches evaluated)\n",
      "      Evaluation completed for model 571b0da4 - Final fitness: 48.59%\n",
      "      Fitness obtained: 48.59% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 9b7879b9)\n",
      "      Architecture: 2 conv + 3 fc, opt=adamw, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 9b7879b9 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.0444 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8177 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.7470 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.7393 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.6768 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.6751 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.6428 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.6133 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.5961 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.5749 (391 batches processed)\n",
      "      Training completed for model 9b7879b9\n",
      "      Evaluating model 9b7879b9 on test set...\n",
      "         Evaluation: 1217/2560 correct = 47.54% accuracy\n",
      "         Evaluation loss: 1.4358 (20 batches evaluated)\n",
      "      Evaluation completed for model 9b7879b9 - Final fitness: 47.54%\n",
      "      Fitness obtained: 47.54% | Best so far: 78.24%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: f2ce896c)\n",
      "      Architecture: 3 conv + 4 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model f2ce896c (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.9014 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.6183 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4818 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3896 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3034 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2506 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2027 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1585 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1274 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.0950 (391 batches processed)\n",
      "      Training completed for model f2ce896c\n",
      "      Evaluating model f2ce896c on test set...\n",
      "         Evaluation: 1665/2560 correct = 65.04% accuracy\n",
      "         Evaluation loss: 1.0004 (20 batches evaluated)\n",
      "      Evaluation completed for model f2ce896c - Final fitness: 65.04%\n",
      "      Fitness obtained: 65.04% | Best so far: 78.24%\n",
      "\n",
      "GENERATION 10 STATISTICS:\n",
      "   Maximum fitness: 78.24%\n",
      "   Average fitness: 55.61%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 23.05%\n",
      "   Best individual: 8f35d972 with 78.24%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 78.24%)\n",
      "   Elite 2: e3f19d4a (fitness: 74.53%)\n",
      "   Elite 3: 8134e1ce (fitness: 74.10%)\n",
      "   Elite 4: fdfd5c50 (fitness: 70.82%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 11\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 11)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3532 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0167 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8936 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.8072 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7455 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.7058 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6660 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6344 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.6026 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5776 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 2020/2560 correct = 78.91% accuracy\n",
      "         Evaluation loss: 0.6227 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 78.91%\n",
      "      New best fitness in this generation: 78.91%!\n",
      "      Fitness obtained: 78.91% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5842 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2886 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1713 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0867 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0361 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9826 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9455 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9145 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8861 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8575 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1939/2560 correct = 75.74% accuracy\n",
      "         Evaluation loss: 0.7072 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 75.74%\n",
      "      Fitness obtained: 75.74% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5951 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2980 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1670 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0764 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0142 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9616 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9235 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8944 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8594 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8362 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1853/2560 correct = 72.38% accuracy\n",
      "         Evaluation loss: 0.7762 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 72.38%\n",
      "      Fitness obtained: 72.38% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1693 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5316 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3098 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1588 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0563 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9819 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9272 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8866 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8396 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8049 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n",
      "         Evaluation: 1779/2560 correct = 69.49% accuracy\n",
      "         Evaluation loss: 0.9144 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 69.49%\n",
      "      Fitness obtained: 69.49% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 8654ce00)\n",
      "      Architecture: 3 conv + 3 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8654ce00 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8446 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5418 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.4344 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.3647 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.3022 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.2563 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.2206 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.1904 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.1584 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.1327 (391 batches processed)\n",
      "      Training completed for model 8654ce00\n",
      "      Evaluating model 8654ce00 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:45:46,969 - WARNING - Error evaluating genome a13e3028: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1484/2560 correct = 57.97% accuracy\n",
      "         Evaluation loss: 1.1308 (20 batches evaluated)\n",
      "      Evaluation completed for model 8654ce00 - Final fitness: 57.97%\n",
      "      Fitness obtained: 57.97% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: a13e3028)\n",
      "      Architecture: 4 conv + 1 fc, opt=adam, lr=5e-05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome a13e3028: Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: c5056fd9)\n",
      "      Architecture: 3 conv + 2 fc, opt=adam, lr=1e-06\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model c5056fd9 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.3185 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.3013 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.2862 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.2722 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.2614 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.2455 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.2314 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.2154 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.1983 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.1814 (391 batches processed)\n",
      "      Training completed for model c5056fd9\n",
      "      Evaluating model c5056fd9 on test set...\n",
      "         Evaluation: 841/2560 correct = 32.85% accuracy\n",
      "         Evaluation loss: 2.1396 (20 batches evaluated)\n",
      "      Evaluation completed for model c5056fd9 - Final fitness: 32.85%\n",
      "      Fitness obtained: 32.85% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: eb4e8a6c)\n",
      "      Architecture: 4 conv + 2 fc, opt=sgd, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model eb4e8a6c (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.1701 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.8573 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.6900 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.6014 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.5267 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.4700 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.4133 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.3656 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.3245 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 1.2821 (391 batches processed)\n",
      "      Training completed for model eb4e8a6c\n",
      "      Evaluating model eb4e8a6c on test set...\n",
      "         Evaluation: 1457/2560 correct = 56.91% accuracy\n",
      "         Evaluation loss: 1.2010 (20 batches evaluated)\n",
      "      Evaluation completed for model eb4e8a6c - Final fitness: 56.91%\n",
      "      Fitness obtained: 56.91% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 056f23fc)\n",
      "      Architecture: 2 conv + 1 fc, opt=sgd, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 056f23fc (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.6657 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.4129 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.2978 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2118 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.1538 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1031 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0635 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0270 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.9982 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9728 (391 batches processed)\n",
      "      Training completed for model 056f23fc\n",
      "      Evaluating model 056f23fc on test set...\n",
      "         Evaluation: 1233/2560 correct = 48.16% accuracy\n",
      "         Evaluation loss: 1.6167 (20 batches evaluated)\n",
      "      Evaluation completed for model 056f23fc - Final fitness: 48.16%\n",
      "      Fitness obtained: 48.16% | Best so far: 78.91%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 365fe414)\n",
      "      Architecture: 3 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 365fe414 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.8237 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5442 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3693 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.2672 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.2034 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.1315 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 1.0801 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 1.0501 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 1.0126 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.9825 (391 batches processed)\n",
      "      Training completed for model 365fe414\n",
      "      Evaluating model 365fe414 on test set...\n",
      "         Evaluation: 1759/2560 correct = 68.71% accuracy\n",
      "         Evaluation loss: 0.8935 (20 batches evaluated)\n",
      "      Evaluation completed for model 365fe414 - Final fitness: 68.71%\n",
      "      Fitness obtained: 68.71% | Best so far: 78.91%\n",
      "\n",
      "GENERATION 11 STATISTICS:\n",
      "   Maximum fitness: 78.91%\n",
      "   Average fitness: 56.11%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 22.94%\n",
      "   Best individual: 8f35d972 with 78.91%\n",
      "   Global best individual: 8f35d972 with 79.88%\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8f35d972 (fitness: 78.91%)\n",
      "   Elite 2: e3f19d4a (fitness: 75.74%)\n",
      "   Elite 3: 8134e1ce (fitness: 72.38%)\n",
      "   Elite 4: fdfd5c50 (fitness: 69.49%)\n",
      "Creating 6 new individuals through crossover and mutation...\n",
      "   Created 4 of 6 new individuals...\n",
      "New generation created with 10 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 6\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "================================================================================\n",
      "GENERATION 12\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 12)...\n",
      "Processing 10 individuals...\n",
      "\n",
      "   Evaluating individual 1/10 (ID: 8f35d972)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8f35d972 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.3433 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.0061 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 0.8899 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 0.8037 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 0.7547 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.7070 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.6678 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.6364 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.6068 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.5869 (391 batches processed)\n",
      "      Training completed for model 8f35d972\n",
      "      Evaluating model 8f35d972 on test set...\n",
      "         Evaluation: 1998/2560 correct = 78.05% accuracy\n",
      "         Evaluation loss: 0.6296 (20 batches evaluated)\n",
      "      Evaluation completed for model 8f35d972 - Final fitness: 78.05%\n",
      "      New best fitness in this generation: 78.05%!\n",
      "      Fitness obtained: 78.05% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 2/10 (ID: e3f19d4a)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model e3f19d4a (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5740 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.2744 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1575 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0782 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0206 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9740 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9340 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.9047 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8770 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8573 (391 batches processed)\n",
      "      Training completed for model e3f19d4a\n",
      "      Evaluating model e3f19d4a on test set...\n",
      "         Evaluation: 1889/2560 correct = 73.79% accuracy\n",
      "         Evaluation loss: 0.7398 (20 batches evaluated)\n",
      "      Evaluation completed for model e3f19d4a - Final fitness: 73.79%\n",
      "      Fitness obtained: 73.79% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 3/10 (ID: 8134e1ce)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 8134e1ce (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 1.5997 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.3038 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.1636 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.0768 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0166 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9649 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9245 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8895 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8685 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.8395 (391 batches processed)\n",
      "      Training completed for model 8134e1ce\n",
      "      Evaluating model 8134e1ce on test set...\n",
      "         Evaluation: 1897/2560 correct = 74.10% accuracy\n",
      "         Evaluation loss: 0.7415 (20 batches evaluated)\n",
      "      Evaluation completed for model 8134e1ce - Final fitness: 74.10%\n",
      "      Fitness obtained: 74.10% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 4/10 (ID: fdfd5c50)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model fdfd5c50 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2070 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 1.5481 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.3531 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.1777 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.0539 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 0.9656 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 0.9013 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 0.8461 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 0.8136 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 0.7793 (391 batches processed)\n",
      "      Training completed for model fdfd5c50\n",
      "      Evaluating model fdfd5c50 on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:54:47,822 - WARNING - Error evaluating genome 95db9fc1: list index out of range\n",
      "2025-08-08 12:54:47,830 - WARNING - Error evaluating genome 6fe9be78: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1, 1])\n",
      "2025-08-08 12:54:47,841 - WARNING - Error evaluating genome 80167bd3: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size\n",
      "2025-08-08 12:54:47,848 - WARNING - Error evaluating genome b8569545: Expected more than 1 value per channel when training, got input size torch.Size([1, 16, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Evaluation: 1804/2560 correct = 70.47% accuracy\n",
      "         Evaluation loss: 0.8763 (20 batches evaluated)\n",
      "      Evaluation completed for model fdfd5c50 - Final fitness: 70.47%\n",
      "      Fitness obtained: 70.47% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 5/10 (ID: 95db9fc1)\n",
      "      Architecture: 3 conv + 1 fc, opt=adamw, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 95db9fc1: list index out of range\n",
      "      Fitness obtained: 0.00% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 6/10 (ID: 6fe9be78)\n",
      "      Architecture: 4 conv + 1 fc, opt=rmsprop, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 6fe9be78: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1, 1])\n",
      "      Fitness obtained: 0.00% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 7/10 (ID: 80167bd3)\n",
      "      Architecture: 4 conv + 2 fc, opt=sgd, lr=0.005\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome 80167bd3: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size\n",
      "      Fitness obtained: 0.00% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 8/10 (ID: b8569545)\n",
      "      Architecture: 3 conv + 1 fc, opt=adam, lr=0.0001\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      ERROR evaluating genome b8569545: Expected more than 1 value per channel when training, got input size torch.Size([1, 16, 1, 1])\n",
      "      Fitness obtained: 0.00% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 9/10 (ID: 66846637)\n",
      "      Architecture: 1 conv + 1 fc, opt=adam, lr=0.01\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 66846637 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 29.9723 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.6374 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 2.5632 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 2.4750 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 2.3031 (391 batches processed)\n",
      "          Epoch 7/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 8/10: Average loss = 2.3034 (391 batches processed)\n",
      "          Epoch 9/10: Average loss = 2.3033 (391 batches processed)\n",
      "          Epoch 10/10: Average loss = 2.3033 (391 batches processed)\n",
      "      Training completed for model 66846637\n",
      "      Evaluating model 66846637 on test set...\n",
      "         Evaluation: 247/2560 correct = 9.65% accuracy\n",
      "         Evaluation loss: 2.3037 (20 batches evaluated)\n",
      "      Evaluation completed for model 66846637 - Final fitness: 9.65%\n",
      "      Fitness obtained: 9.65% | Best so far: 78.05%\n",
      "\n",
      "   Evaluating individual 10/10 (ID: 88ffd688)\n",
      "      Architecture: 3 conv + 4 fc, opt=sgd, lr=0.05\n",
      "{'population_size': 10, 'max_generations': 30, 'fitness_threshold': 99.9, 'mutation_rate': 0.6, 'crossover_rate': 0.99, 'elite_percentage': 0.4, 'dataset': 'CIFAR10', 'num_channels': 3, 'px_h': 32, 'px_w': 32, 'num_classes': 10, 'batch_size': 128, 'test_split': 0.4, 'num_epochs': 10, 'learning_rate': 0.01, 'early_stopping_patience': 1000, 'min_conv_layers': 1, 'max_conv_layers': 4, 'min_fc_layers': 1, 'max_fc_layers': 4, 'min_filters': 2, 'max_filters': 128, 'min_fc_nodes': 128, 'max_fc_nodes': 1028, 'dataset_path': None, '_normalization': {'mean': (0.4914, 0.4822, 0.4465), 'std': (0.2023, 0.1994, 0.201)}}\n",
      "      Training model 88ffd688 (10 epochs, max 391 batches/epoch)\n",
      "          Epoch 1/10: Average loss = 2.2939 (391 batches processed)\n",
      "          Epoch 2/10: Average loss = 2.0668 (391 batches processed)\n",
      "          Epoch 3/10: Average loss = 1.9608 (391 batches processed)\n",
      "          Epoch 4/10: Average loss = 1.9239 (391 batches processed)\n",
      "          Epoch 5/10: Average loss = 1.9030 (391 batches processed)\n",
      "          Epoch 6/10: Average loss = 1.8840 (391 batches processed)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CONFIGURACIÓN DE DATASET - MODIFICAR AQUÍ\n",
    "# ==========================================\n",
    "\n",
    "# Para cambiar el dataset, modifica la línea correspondiente y ejecuta esta celda:\n",
    "\n",
    "# Opción 1: Usar MNIST (28x28, grayscale, 10 classes)\n",
    "# CONFIG['dataset'] = 'MNIST'\n",
    "\n",
    "# Opción 2: Usar CIFAR-10 (32x32, RGB, 10 classes) - RECOMENDADO para mayor challenge\n",
    "CONFIG['dataset'] = 'CIFAR10'\n",
    "\n",
    "# Opción 3: Usar dataset personalizado\n",
    "# CONFIG['dataset'] = 'CUSTOM'\n",
    "# CONFIG['dataset_path'] = r'E:\\Neuroevolution\\data\\phd_data'  # Ajustar ruta según tu dataset\n",
    "\n",
    "# ==========================================\n",
    "# OTRAS CONFIGURACIONES OPCIONALES\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# Reconfigurar el dataset con los nuevos parámetros\n",
    "CONFIG = configure_dataset(CONFIG, CONFIG['dataset'])\n",
    "\n",
    "print(\"Current configuration:\")\n",
    "print(f\"   Dataset: {CONFIG['dataset']}\")\n",
    "print(f\"   Image size: {CONFIG['px_h']}x{CONFIG['px_w']}x{CONFIG['num_channels']}\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']}\")\n",
    "print(f\"   Population: {CONFIG['population_size']} individuals\")\n",
    "print(f\"   Maximum generations: {CONFIG['max_generations']}\")\n",
    "print(f\"   Target fitness: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Recargar el dataset con la nueva configuración\n",
    "print(f\"\\nReloading dataset with new configuration...\")\n",
    "train_loader, test_loader = load_dataset(CONFIG)\n",
    "\n",
    "# Initialize neuroevolution system\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nStarting neuroevolution at {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Create system instance\n",
    "neuroevolution = HybridNeuroevolution(CONFIG, train_loader, test_loader)\n",
    "\n",
    "# Execute evolution process\n",
    "best_genome = neuroevolution.evolve()\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nProcess completed at {end_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Total execution time: {execution_time}\")\n",
    "print(f\"Total generations: {neuroevolution.generation}\")\n",
    "print(f\"Best fitness achieved: {best_genome['fitness']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555d9b",
   "metadata": {},
   "source": [
    "## 8. Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Function to visualize fitness evolution\n",
    "def plot_fitness_evolution(neuroevolution):\n",
    "    \"\"\"Plots fitness evolution across generations.\"\"\"\n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extract data and filter 0.00 fitness\n",
    "    generations = []\n",
    "    avg_fitness = []\n",
    "    max_fitness = []\n",
    "    min_fitness = []\n",
    "    std_fitness = []\n",
    "    \n",
    "    for stat in neuroevolution.generation_stats:\n",
    "        # Only include if valid fitness (> 0.00)\n",
    "        if stat['max_fitness'] > 0.00:\n",
    "            generations.append(stat['generation'])\n",
    "            avg_fitness.append(stat['avg_fitness'])\n",
    "            max_fitness.append(stat['max_fitness'])\n",
    "            min_fitness.append(stat['min_fitness'])\n",
    "            std_fitness.append(stat['std_fitness'])\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"WARNING: No valid fitness data to plot (all are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    # Graph 1: Fitness evolution\n",
    "    ax1.plot(generations, max_fitness, 'g-', linewidth=2, marker='o', label='Maximum Fitness')\n",
    "    ax1.plot(generations, avg_fitness, 'b-', linewidth=2, marker='s', label='Average Fitness')\n",
    "    ax1.plot(generations, min_fitness, 'r-', linewidth=2, marker='^', label='Minimum Fitness')\n",
    "    ax1.fill_between(generations, \n",
    "                     [max(0, avg - std) for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     [avg + std for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     alpha=0.2, color='blue')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness (%)')\n",
    "    ax1.set_title('Fitness Evolution by Generation (Excluding 0.00%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add target fitness line\n",
    "    ax1.axhline(y=CONFIG['fitness_threshold'], color='orange', linestyle='--', \n",
    "                label=f\"Target ({CONFIG['fitness_threshold']}%)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Set Y axis limits for better visualization\n",
    "    y_min = max(0, min(min_fitness) - 5)\n",
    "    y_max = min(100, max(max_fitness) + 5)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Graph 2: Diversity (standard deviation)\n",
    "    ax2.plot(generations, std_fitness, 'purple', linewidth=2, marker='D')\n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Fitness Standard Deviation')\n",
    "    ax2.set_title('Population Diversity (Excluding 0.00%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show additional information\n",
    "    print(f\"Plotted data:\")\n",
    "    print(f\"   Generations with valid fitness: {len(generations)}\")\n",
    "    print(f\"   Best fitness achieved: {max(max_fitness):.2f}%\")\n",
    "    print(f\"   Final average fitness: {avg_fitness[-1]:.2f}%\")\n",
    "    if len(generations) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(generations)\n",
    "        print(f\"   WARNING: Excluded generations (0.00 fitness): {excluded}\")\n",
    "\n",
    "# Function to show detailed statistics\n",
    "def show_evolution_statistics(neuroevolution):\n",
    "    \"\"\"Shows detailed evolution statistics.\"\"\"\n",
    "    print(\"DETAILED EVOLUTION STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics available\")\n",
    "        return\n",
    "    \n",
    "    # Filter statistics with valid fitness\n",
    "    valid_stats = [stat for stat in neuroevolution.generation_stats if stat['max_fitness'] > 0.00]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"WARNING: No valid statistics (all fitness are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    final_stats = valid_stats[-1]\n",
    "    \n",
    "    print(f\"Completed generations: {neuroevolution.generation}\")\n",
    "    print(f\"Generations with valid fitness: {len(valid_stats)}\")\n",
    "    if len(valid_stats) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(valid_stats)\n",
    "        print(f\"WARNING: Generations with 0.00 fitness (excluded): {excluded}\")\n",
    "    \n",
    "    print(f\"\\nFINAL STATISTICS (excluding 0.00 fitness):\")\n",
    "    print(f\"   Final best fitness: {final_stats['max_fitness']:.2f}%\")\n",
    "    print(f\"   Final average fitness: {final_stats['avg_fitness']:.2f}%\")\n",
    "    print(f\"   Final minimum fitness: {final_stats['min_fitness']:.2f}%\")\n",
    "    print(f\"   Final standard deviation: {final_stats['std_fitness']:.2f}%\")\n",
    "    \n",
    "    # Progress across generations\n",
    "    if len(valid_stats) > 1:\n",
    "        initial_max = valid_stats[0]['max_fitness']\n",
    "        final_max = valid_stats[-1]['max_fitness']\n",
    "        improvement = final_max - initial_max\n",
    "        \n",
    "        print(f\"\\nPROGRESS:\")\n",
    "        print(f\"   Initial fitness: {initial_max:.2f}%\")\n",
    "        print(f\"   Final fitness: {final_max:.2f}%\")\n",
    "        print(f\"   Total improvement: {improvement:.2f}%\")\n",
    "        if initial_max > 0:\n",
    "            print(f\"   Relative improvement: {(improvement/initial_max)*100:.1f}%\")\n",
    "    \n",
    "    # Convergence analysis\n",
    "    print(f\"\\nCONVERGENCE CRITERIA:\")\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['fitness'] >= CONFIG['fitness_threshold']:\n",
    "        print(f\"   OK: Target fitness reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   ERROR: Target fitness NOT reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    \n",
    "    if neuroevolution.generation >= CONFIG['max_generations']:\n",
    "        print(f\"   TIME: Maximum generations reached ({CONFIG['max_generations']})\")\n",
    "    \n",
    "    # Additional performance statistics\n",
    "    all_max_fitness = [stat['max_fitness'] for stat in valid_stats]\n",
    "    all_avg_fitness = [stat['avg_fitness'] for stat in valid_stats]\n",
    "    \n",
    "    print(f\"\\nGENERAL STATISTICS:\")\n",
    "    print(f\"   Best fitness of entire evolution: {max(all_max_fitness):.2f}%\")\n",
    "    print(f\"   Average fitness of entire evolution: {np.mean(all_avg_fitness):.2f}%\")\n",
    "    print(f\"   Average improvement per generation: {(max(all_max_fitness) - min(all_max_fitness))/len(valid_stats):.2f}%\")\n",
    "    \n",
    "    if neuroevolution.best_individual:\n",
    "        print(f\"\\nBest individual ID: {neuroevolution.best_individual['id']}\")\n",
    "        print(f\"Best individual fitness: {neuroevolution.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "# Additional function for failure analysis\n",
    "def analyze_failed_evaluations(neuroevolution):\n",
    "    \"\"\"Analyzes evaluations that resulted in 0.00 fitness.\"\"\"\n",
    "    print(\"\\nFAILED EVALUATIONS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_generations = len(neuroevolution.generation_stats)\n",
    "    failed_generations = len([stat for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00])\n",
    "    \n",
    "    if failed_generations == 0:\n",
    "        print(\"OK: No failed evaluations (0.00 fitness)\")\n",
    "        return\n",
    "    \n",
    "    success_rate = ((total_generations - failed_generations) / total_generations) * 100\n",
    "    \n",
    "    print(f\"Failure summary:\")\n",
    "    print(f\"   Total generations: {total_generations}\")\n",
    "    print(f\"   Failed generations: {failed_generations}\")\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    if failed_generations > 0:\n",
    "        failed_gens = [stat['generation'] for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00]\n",
    "        print(f\"   Generations with failures: {failed_gens}\")\n",
    "        \n",
    "        print(f\"\\nPossible causes of 0.00 fitness:\")\n",
    "        print(f\"   • Errors in model architecture\")\n",
    "        print(f\"   • Memory problems (GPU/RAM)\")\n",
    "        print(f\"   • Invalid hyperparameter configurations\")\n",
    "        print(f\"   • Errors during training\")\n",
    "\n",
    "# Execute visualizations\n",
    "plot_fitness_evolution(neuroevolution)\n",
    "show_evolution_statistics(neuroevolution)\n",
    "analyze_failed_evaluations(neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6688660",
   "metadata": {},
   "source": [
    "## 9. BEST ARCHITECTURE FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a847dd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_best_architecture(best_genome, config):\n",
    "    \"\"\"\n",
    "    Shows the best architecture found in detailed and visual format.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"        BEST EVOLVED ARCHITECTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # General information\n",
    "    print(f\"\\nGENERAL INFORMATION:\")\n",
    "    print(f\"   Genome ID: {best_genome['id']}\")\n",
    "    print(f\"   Fitness Achieved: {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Generation: {neuroevolution.generation}\")\n",
    "    \n",
    "    # Architecture details\n",
    "    print(f\"\\nNETWORK ARCHITECTURE:\")\n",
    "    print(f\"   Convolutional Layers: {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   Fully Connected Layers: {best_genome['num_fc_layers']}\")\n",
    "    \n",
    "    print(f\"\\nCONVOLUTIONAL LAYER DETAILS:\")\n",
    "    for i in range(best_genome['num_conv_layers']):\n",
    "        filters = best_genome['filters'][i]\n",
    "        kernel = best_genome['kernel_sizes'][i]\n",
    "        activation = best_genome['activations'][i % len(best_genome['activations'])]\n",
    "        print(f\"   Conv{i+1}: {filters} filters, kernel {kernel}x{kernel}, activation {activation}\")\n",
    "    \n",
    "    print(f\"\\nFULLY CONNECTED LAYER DETAILS:\")\n",
    "    for i, nodes in enumerate(best_genome['fc_nodes']):\n",
    "        print(f\"   FC{i+1}: {nodes} neurons\")\n",
    "    print(f\"   Output: {config['num_classes']} neurons (classes)\")\n",
    "    \n",
    "    print(f\"\\nHYPERPARAMETERS:\")\n",
    "    print(f\"   Optimizer: {best_genome['optimizer'].upper()}\")\n",
    "    print(f\"   Learning Rate: {best_genome['learning_rate']:.4f}\")\n",
    "    print(f\"   Dropout Rate: {best_genome['dropout_rate']:.3f}\")\n",
    "    print(f\"   Activation Functions: {', '.join(best_genome['activations'])}\")\n",
    "    \n",
    "    # Create and show final model\n",
    "    print(f\"\\nCREATING FINAL MODEL...\")\n",
    "    try:\n",
    "        final_model = EvolvableCNN(best_genome, config)\n",
    "        total_params = sum(p.numel() for p in final_model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"   Model created successfully\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Architecture summary\n",
    "        print(f\"\\nCOMPACT SUMMARY:\")\n",
    "        print(f\"   {final_model.get_architecture_summary()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR creating model: {e}\")\n",
    "    \n",
    "    # Visualization in table format\n",
    "    print(f\"\\nSUMMARY TABLE:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Parameter':<25} {'Value':<30} {'Description':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'ID':<25} {best_genome['id']:<30} {'Unique identifier':<25}\")\n",
    "    print(f\"{'Fitness':<25} {best_genome['fitness']:.2f}%{'':<25} {'Accuracy achieved':<25}\")\n",
    "    print(f\"{'Conv Layers':<25} {best_genome['num_conv_layers']:<30} {'Convolutional layers':<25}\")\n",
    "    print(f\"{'FC Layers':<25} {best_genome['num_fc_layers']:<30} {'FC layers':<25}\")\n",
    "    print(f\"{'Optimizer':<25} {best_genome['optimizer']:<30} {'Optimization algorithm':<25}\")\n",
    "    print(f\"{'Learning Rate':<25} {best_genome['learning_rate']:<30} {'Learning rate':<25}\")\n",
    "    print(f\"{'Dropout':<25} {best_genome['dropout_rate']:<30} {'Dropout rate':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Comparison with initial configuration\n",
    "    print(f\"\\nCOMPARISON WITH OBJECTIVES:\")\n",
    "    if best_genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"   TARGET: OK Fitness objective REACHED ({best_genome['fitness']:.2f}% >= {config['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   TARGET: ERROR Fitness objective NOT reached ({best_genome['fitness']:.2f}% < {config['fitness_threshold']}%)\")\n",
    "    \n",
    "    print(f\"   TIME: Generations used: {neuroevolution.generation}/{config['max_generations']}\")\n",
    "    \n",
    "    # Save information to JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'execution_time': str(execution_time),\n",
    "        'config_used': config,\n",
    "        'best_genome': best_genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\nResults saved to: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWARNING: Error saving results: {e}\")\n",
    "    \n",
    "    print(f\"\\nHYBRID NEUROEVOLUTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Show the best architecture found\n",
    "display_best_architecture(best_genome, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2964f-0098-4c42-bf72-e66c4ca0ed5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ceb16-25cf-428c-bd49-41db5c262038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
