{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77d426",
   "metadata": {},
   "source": [
    "# Synchronous Hybrid Neuroevolution Notebook\n",
    "\n",
    "Hello Mr. Carlos!\n",
    "\n",
    "This notebook implements the complete hybrid neuroevolution process synchronously, without the need for databases or external Kafka services. The system combines genetic algorithms with convolutional neural networks to evolve optimal architectures.\n",
    "\n",
    "## Main Features:\n",
    "- **Hybrid genetic algorithm**: Combines architecture and weight evolution\n",
    "- **Synchronous processing**: Complete workflow executed in a single session\n",
    "- **Configurable dataset**: Supports MNIST by default or custom dataset\n",
    "- **Intelligent stopping criteria**: By target fitness or maximum generations\n",
    "- **Complete visualization**: Shows progress and final best architecture\n",
    "\n",
    "## Objectives:\n",
    "1. Create initial population of CNN architectures\n",
    "2. Evaluate fitness of each individual\n",
    "3. Select best architectures (top 50%)\n",
    "4. Apply crossover and mutation to create new generation\n",
    "5. Repeat process until convergence\n",
    "6. Display the best architecture found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3cfb",
   "metadata": {},
   "source": [
    "## 1. Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50120a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all necessary libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if not available.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"OK {package.split('==')[0]} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"OK {package} installed correctly\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Starting dependency installation for Hybrid Neuroevolution...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nAll dependencies have been verified/installed\")\n",
    "print(\"Restart the kernel if this is the first time installing torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch {torch.__version__} installed correctly\")\n",
    "    print(f\"CUDA available: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: PyTorch could not be installed correctly\")\n",
    "    print(\"Try installing manually with: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865869c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device configured: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1181c2a",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main genetic algorithm configuration\n",
    "CONFIG = {\n",
    "    # Genetic algorithm parameters\n",
    "    'population_size': 8,           # Population size\n",
    "    'max_generations': 30,          # Maximum number of generations\n",
    "    'fitness_threshold': 99.9,      # Target fitness (% accuracy)\n",
    "    'mutation_rate': 0.15,          # Mutation rate\n",
    "    'crossover_rate': 0.8,          # Crossover rate\n",
    "    'elite_percentage': 0.5,        # Elite percentage to preserve\n",
    "    \n",
    "    # Dataset parameters\n",
    "    'num_channels': 1,              # Input channels (1=grayscale, 3=RGB)\n",
    "    'px_h': 28,                     # Image height\n",
    "    'px_w': 28,                     # Image width\n",
    "    'num_classes': 10,              # Number of classes\n",
    "    'batch_size': 64,               # Batch size\n",
    "    'test_split': 0.2,              # Validation percentage\n",
    "    \n",
    "    # Training parameters\n",
    "    'num_epochs': 2,                # Training epochs per evaluation\n",
    "    'learning_rate': 0.001,         # Base learning rate\n",
    "    'early_stopping_patience': 50,  # Maximum batches for quick evaluation\n",
    "    \n",
    "    # Allowed architecture range\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 4,\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 3,\n",
    "    'min_filters': 8,\n",
    "    'max_filters': 128,\n",
    "    'min_fc_nodes': 32,\n",
    "    'max_fc_nodes': 512,\n",
    "    \n",
    "    # Data configuration\n",
    "    'dataset_path': None,           # Custom dataset path (None = MNIST)\n",
    "    'use_custom_dataset': False,    # Whether to use custom dataset\n",
    "}\n",
    "\n",
    "# Activation function mapping\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Optimizer mapping\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(f\"\\nAvailable activation functions: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"Available optimizers: {list(OPTIMIZERS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6d37",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f98ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config: dict) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Loads the dataset according to configuration.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    if config['use_custom_dataset'] and config['dataset_path']:\n",
    "        print(f\"Loading custom dataset from: {config['dataset_path']}\")\n",
    "        \n",
    "        # Transformations for custom dataset\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)) if config['num_channels'] == 1 else \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # Load dataset from folders organized by class\n",
    "        full_dataset = datasets.ImageFolder(root=config['dataset_path'], transform=transform)\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_size = int((1 - config['test_split']) * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "        \n",
    "        print(f\"Custom dataset loaded:\")\n",
    "        print(f\"   Classes found: {len(full_dataset.classes)}\")\n",
    "        print(f\"   Total samples: {len(full_dataset)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Loading default MNIST dataset...\")\n",
    "        \n",
    "        # Transformations for MNIST\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        \n",
    "        # Load MNIST\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "        print(f\"MNIST dataset loaded:\")\n",
    "        print(f\"   Classes: {len(train_dataset.classes)}\")\n",
    "        print(f\"   Training samples: {len(train_dataset)}\")\n",
    "        print(f\"   Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Load the dataset\n",
    "train_loader, test_loader = load_dataset(CONFIG)\n",
    "\n",
    "# Get a sample to verify dimensions\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_data, sample_labels = sample_batch\n",
    "print(f\"\\nDataset loaded successfully:\")\n",
    "print(f\"   Batch shape: {sample_data.shape}\")\n",
    "print(f\"   Data type: {sample_data.dtype}\")\n",
    "print(f\"   Device: {sample_data.device}\")\n",
    "print(f\"   Value range: [{sample_data.min():.3f}, {sample_data.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52de67",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolvable CNN class that can be dynamically configured\n",
    "    according to genome parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Build convolutional layers\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calculate output size after convolutions\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "        \n",
    "    def _build_conv_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds convolutional layers according to genome.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        \n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Convolutional layer\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Batch normalization\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            # Activation function\n",
    "            activation_name = self.genome['activations'][i % len(self.genome['activations'])]\n",
    "            activation_func = ACTIVATION_FUNCTIONS[activation_name]()\n",
    "            layers.append(activation_func)\n",
    "            \n",
    "            # Max pooling (except in last layer)\n",
    "            if i < self.genome['num_conv_layers'] - 1:\n",
    "                layers.append(nn.MaxPool2d(2, 2))\n",
    "            else:\n",
    "                layers.append(nn.MaxPool2d(2, 1))  # Stride 1 in last layer\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self) -> int:\n",
    "        \"\"\"Calculates output size after convolutional layers.\"\"\"\n",
    "        # Create dummy tensor to calculate size\n",
    "        dummy_input = torch.zeros(1, self.config['num_channels'], \n",
    "                                 self.config['px_h'], self.config['px_w'])\n",
    "        \n",
    "        # Pass through convolutional layers\n",
    "        x = dummy_input\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten and get size\n",
    "        return x.view(-1).shape[0]\n",
    "    \n",
    "    def _build_fc_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds fully connected layers.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        input_size = self.conv_output_size\n",
    "        \n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            output_size = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "            # Dropout if not last layer\n",
    "            if i < self.genome['num_fc_layers'] - 1:\n",
    "                layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            input_size = output_size\n",
    "        \n",
    "        # Final classification layer\n",
    "        layers.append(nn.Linear(input_size, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            x = layer(x)\n",
    "            # Apply activation except on last layer\n",
    "            if i < len(self.fc_layers) - 1 and not isinstance(layer, nn.Dropout):\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_architecture_summary(self) -> str:\n",
    "        \"\"\"Returns an architecture summary.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(f\"Conv Layers: {self.genome['num_conv_layers']}\")\n",
    "        summary.append(f\"Filters: {self.genome['filters']}\")\n",
    "        summary.append(f\"Kernel Sizes: {self.genome['kernel_sizes']}\")\n",
    "        summary.append(f\"FC Layers: {self.genome['num_fc_layers']}\")\n",
    "        summary.append(f\"FC Nodes: {self.genome['fc_nodes']}\")\n",
    "        summary.append(f\"Activations: {self.genome['activations']}\")\n",
    "        summary.append(f\"Dropout: {self.genome['dropout_rate']:.3f}\")\n",
    "        summary.append(f\"Optimizer: {self.genome['optimizer']}\")\n",
    "        summary.append(f\"Learning Rate: {self.genome['learning_rate']:.4f}\")\n",
    "        return \" | \".join(summary)\n",
    "\n",
    "print(\"EvolvableCNN class defined correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021c7d8",
   "metadata": {},
   "source": [
    "## 5. Genetic Algorithm Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be19766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"Creates a random genome within specified ranges.\"\"\"\n",
    "    \n",
    "    # Number of layers\n",
    "    num_conv_layers = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "    \n",
    "    # Filters for each convolutional layer\n",
    "    filters = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        filters.append(random.randint(config['min_filters'], config['max_filters']))\n",
    "    \n",
    "    # Kernel sizes\n",
    "    kernel_sizes = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        kernel_sizes.append(random.choice([3, 5, 7]))\n",
    "    \n",
    "    # Nodes in fully connected layers\n",
    "    fc_nodes = []\n",
    "    for _ in range(num_fc_layers):\n",
    "        fc_nodes.append(random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Activation functions for each layer\n",
    "    activations = []\n",
    "    for _ in range(max(num_conv_layers, num_fc_layers)):\n",
    "        activations.append(random.choice(list(ACTIVATION_FUNCTIONS.keys())))\n",
    "    \n",
    "    # Other parameters\n",
    "    dropout_rate = random.uniform(0.1, 0.5)\n",
    "    learning_rate = random.choice([0.001, 0.0001, 0.01, 0.005])\n",
    "    optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    genome = {\n",
    "        'num_conv_layers': num_conv_layers,\n",
    "        'num_fc_layers': num_fc_layers,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'fc_nodes': fc_nodes,\n",
    "        'activations': activations,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "    \n",
    "    return genome\n",
    "\n",
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"Applies mutation to a genome.\"\"\"\n",
    "    mutated_genome = copy.deepcopy(genome)\n",
    "    mutation_rate = config['mutation_rate']\n",
    "    \n",
    "    # Mutate number of convolutional layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_conv_layers'] = random.randint(\n",
    "            config['min_conv_layers'], config['max_conv_layers'])\n",
    "        # Adjust related lists\n",
    "        num_conv = mutated_genome['num_conv_layers']\n",
    "        mutated_genome['filters'] = mutated_genome['filters'][:num_conv]\n",
    "        mutated_genome['kernel_sizes'] = mutated_genome['kernel_sizes'][:num_conv]\n",
    "        \n",
    "        # Fill if necessary\n",
    "        while len(mutated_genome['filters']) < num_conv:\n",
    "            mutated_genome['filters'].append(\n",
    "                random.randint(config['min_filters'], config['max_filters']))\n",
    "        while len(mutated_genome['kernel_sizes']) < num_conv:\n",
    "            mutated_genome['kernel_sizes'].append(random.choice([3, 5, 7]))\n",
    "    \n",
    "    # Mutate filters\n",
    "    for i in range(len(mutated_genome['filters'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['filters'][i] = random.randint(\n",
    "                config['min_filters'], config['max_filters'])\n",
    "    \n",
    "    # Mutate kernel sizes\n",
    "    for i in range(len(mutated_genome['kernel_sizes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['kernel_sizes'][i] = random.choice([3, 5, 7])\n",
    "    \n",
    "    # Mutate number of FC layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_fc_layers'] = random.randint(\n",
    "            config['min_fc_layers'], config['max_fc_layers'])\n",
    "        # Adjust FC nodes\n",
    "        num_fc = mutated_genome['num_fc_layers']\n",
    "        mutated_genome['fc_nodes'] = mutated_genome['fc_nodes'][:num_fc]\n",
    "        while len(mutated_genome['fc_nodes']) < num_fc:\n",
    "            mutated_genome['fc_nodes'].append(\n",
    "                random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Mutate FC nodes\n",
    "    for i in range(len(mutated_genome['fc_nodes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['fc_nodes'][i] = random.randint(\n",
    "                config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "    \n",
    "    # Mutate activation functions\n",
    "    for i in range(len(mutated_genome['activations'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['activations'][i] = random.choice(\n",
    "                list(ACTIVATION_FUNCTIONS.keys()))\n",
    "    \n",
    "    # Mutate dropout\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['dropout_rate'] = random.uniform(0.1, 0.5)\n",
    "    \n",
    "    # Mutate learning rate\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['learning_rate'] = random.choice([0.001, 0.0001, 0.01, 0.005])\n",
    "    \n",
    "    # Mutate optimizer\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    # New ID for mutated genome\n",
    "    mutated_genome['id'] = str(uuid.uuid4())[:8]\n",
    "    mutated_genome['fitness'] = 0.0  # Reset fitness\n",
    "    \n",
    "    return mutated_genome\n",
    "\n",
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"Performs crossover between two genomes.\"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "    \n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    # Crossover scalar parameters\n",
    "    if random.random() < 0.5:\n",
    "        child1['num_conv_layers'], child2['num_conv_layers'] = \\\n",
    "            child2['num_conv_layers'], child1['num_conv_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['num_fc_layers'], child2['num_fc_layers'] = \\\n",
    "            child2['num_fc_layers'], child1['num_fc_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['dropout_rate'], child2['dropout_rate'] = \\\n",
    "            child2['dropout_rate'], child1['dropout_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['learning_rate'], child2['learning_rate'] = \\\n",
    "            child2['learning_rate'], child1['learning_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['optimizer'], child2['optimizer'] = \\\n",
    "            child2['optimizer'], child1['optimizer']\n",
    "    \n",
    "    # Crossover lists (random cut point)\n",
    "    for list_key in ['filters', 'kernel_sizes', 'fc_nodes', 'activations']:\n",
    "        if random.random() < 0.5:\n",
    "            list1 = child1[list_key]\n",
    "            list2 = child2[list_key]\n",
    "            \n",
    "            if len(list1) > 1 and len(list2) > 1:\n",
    "                point1 = random.randint(1, len(list1) - 1)\n",
    "                point2 = random.randint(1, len(list2) - 1)\n",
    "                \n",
    "                # Exchange parts\n",
    "                new_list1 = list1[:point1] + list2[point2:]\n",
    "                new_list2 = list2[:point2] + list1[point1:]\n",
    "                \n",
    "                child1[list_key] = new_list1\n",
    "                child2[list_key] = new_list2\n",
    "    \n",
    "    # Assign new IDs\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "print(\"Genetic functions defined correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a74a50",
   "metadata": {},
   "source": [
    "## 6. Hybrid Neuroevolution Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNeuroevolution:\n",
    "    \"\"\"Main class that implements hybrid neuroevolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, train_loader: DataLoader, test_loader: DataLoader):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initializes population with random genomes.\"\"\"\n",
    "        print(f\"Initializing population of {self.config['population_size']} individuals...\")\n",
    "        \n",
    "        self.population = []\n",
    "        for i in range(self.config['population_size']):\n",
    "            genome = create_random_genome(self.config)\n",
    "            self.population.append(genome)\n",
    "            \n",
    "        print(f\"Population initialized with {len(self.population)} individuals\")\n",
    "    \n",
    "    def evaluate_fitness(self, genome: dict) -> float:\n",
    "        \"\"\"Evaluates genome fitness by training the neural network.\"\"\"\n",
    "        try:\n",
    "            # Create model\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "            \n",
    "            # Create optimizer\n",
    "            optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "            optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "            \n",
    "            # Loss function\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Training\n",
    "            model.train()\n",
    "            total_train_batches = min(len(self.train_loader), self.config['early_stopping_patience'])\n",
    "            \n",
    "            print(f\"      Training model {genome['id']} ({self.config['num_epochs']} epochs, max {total_train_batches} batches/epoch)\")\n",
    "            \n",
    "            for epoch in range(self.config['num_epochs']):\n",
    "                running_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for data, target in self.train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Early stopping for quick evaluation\n",
    "                    if batch_count >= self.config['early_stopping_patience']:\n",
    "                        break\n",
    "                \n",
    "                # Epoch statistics\n",
    "                avg_loss = running_loss / batch_count\n",
    "                print(f\"          Epoch {epoch+1}/{self.config['num_epochs']}: Average loss = {avg_loss:.4f} ({batch_count} batches processed)\")\n",
    "            \n",
    "            print(f\"      Training completed for model {genome['id']}\")\n",
    "            \n",
    "            # Evaluation\n",
    "            print(f\"      Evaluating model {genome['id']} on test set...\")\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            eval_batches = 0\n",
    "            max_eval_batches = min(len(self.test_loader), 20)\n",
    "            total_eval_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, target in self.test_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    \n",
    "                    # Calculate evaluation loss\n",
    "                    eval_loss = criterion(output, target)\n",
    "                    total_eval_loss += eval_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                    eval_batches += 1\n",
    "                    \n",
    "                    # Early stopping in evaluation\n",
    "                    if eval_batches >= max_eval_batches:\n",
    "                        break\n",
    "            \n",
    "            accuracy = 100.0 * correct / total\n",
    "            avg_eval_loss = total_eval_loss / eval_batches\n",
    "            \n",
    "            print(f\"         Evaluation: {correct}/{total} correct = {accuracy:.2f}% accuracy\")\n",
    "            print(f\"         Evaluation loss: {avg_eval_loss:.4f} ({eval_batches} batches evaluated)\")\n",
    "            print(f\"      Evaluation completed for model {genome['id']} - Final fitness: {accuracy:.2f}%\")\n",
    "            \n",
    "            return accuracy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ERROR evaluating genome {genome['id']}: {e}\")\n",
    "            logger.warning(f\"Error evaluating genome {genome['id']}: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_population(self):\n",
    "        \"\"\"Evaluates entire population and updates fitness.\"\"\"\n",
    "        print(f\"\\nEvaluating population (Generation {self.generation})...\")\n",
    "        print(f\"Processing {len(self.population)} individuals...\")\n",
    "        \n",
    "        fitness_scores = []\n",
    "        best_fitness_so_far = 0.0\n",
    "        \n",
    "        for i, genome in enumerate(self.population):\n",
    "            print(f\"\\n   Evaluating individual {i+1}/{len(self.population)} (ID: {genome['id']})\")\n",
    "            print(f\"      Architecture: {genome['num_conv_layers']} conv + {genome['num_fc_layers']} fc, opt={genome['optimizer']}, lr={genome['learning_rate']}\")\n",
    "            \n",
    "            fitness = self.evaluate_fitness(genome)\n",
    "            genome['fitness'] = fitness\n",
    "            fitness_scores.append(fitness)\n",
    "            \n",
    "            # Update best fitness found so far\n",
    "            if fitness > best_fitness_so_far:\n",
    "                best_fitness_so_far = fitness\n",
    "                print(f\"      New best fitness in this generation: {fitness:.2f}%!\")\n",
    "            \n",
    "            print(f\"      Fitness obtained: {fitness:.2f}% | Best so far: {best_fitness_so_far:.2f}%\")\n",
    "        \n",
    "        # Generation statistics\n",
    "        avg_fitness = np.mean(fitness_scores)\n",
    "        max_fitness = np.max(fitness_scores)\n",
    "        min_fitness = np.min(fitness_scores)\n",
    "        std_fitness = np.std(fitness_scores)\n",
    "        \n",
    "        stats = {\n",
    "            'generation': self.generation,\n",
    "            'avg_fitness': avg_fitness,\n",
    "            'max_fitness': max_fitness,\n",
    "            'min_fitness': min_fitness,\n",
    "            'std_fitness': std_fitness\n",
    "        }\n",
    "        \n",
    "        self.generation_stats.append(stats)\n",
    "        self.fitness_history.append(max_fitness)\n",
    "        \n",
    "        # Update best individual\n",
    "        best_genome = max(self.population, key=lambda x: x['fitness'])\n",
    "        if self.best_individual is None or best_genome['fitness'] > self.best_individual['fitness']:\n",
    "            self.best_individual = copy.deepcopy(best_genome)\n",
    "            print(f\"\\nNew global best individual found!\")\n",
    "        \n",
    "        print(f\"\\nGENERATION {self.generation} STATISTICS:\")\n",
    "        print(f\"   Maximum fitness: {max_fitness:.2f}%\")\n",
    "        print(f\"   Average fitness: {avg_fitness:.2f}%\")\n",
    "        print(f\"   Minimum fitness: {min_fitness:.2f}%\")\n",
    "        print(f\"   Standard deviation: {std_fitness:.2f}%\")\n",
    "        print(f\"   Best individual: {best_genome['id']} with {best_genome['fitness']:.2f}%\")\n",
    "        print(f\"   Global best individual: {self.best_individual['id']} with {self.best_individual['fitness']:.2f}%\")\n",
    "        \n",
    "    def selection_and_reproduction(self):\n",
    "        \"\"\"Selects best individuals and creates new generation.\"\"\"\n",
    "        print(f\"\\nStarting selection and reproduction...\")\n",
    "        \n",
    "        # Sort population by fitness\n",
    "        self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        # Select elite\n",
    "        elite_size = int(self.config['population_size'] * self.config['elite_percentage'])\n",
    "        elite = self.population[:elite_size]\n",
    "        \n",
    "        print(f\"Selecting {elite_size} elite individuals:\")\n",
    "        for i, individual in enumerate(elite):\n",
    "            print(f\"   Elite {i+1}: {individual['id']} (fitness: {individual['fitness']:.2f}%)\")\n",
    "        \n",
    "        # Create new generation\n",
    "        new_population = copy.deepcopy(elite)  # Preserve elite\n",
    "        \n",
    "        # Complete population with crossover and mutation\n",
    "        offspring_needed = self.config['population_size'] - len(new_population)\n",
    "        print(f\"Creating {offspring_needed} new individuals through crossover and mutation...\")\n",
    "        \n",
    "        offspring_created = 0\n",
    "        while len(new_population) < self.config['population_size']:\n",
    "            # Parent selection (tournament)\n",
    "            parent1 = self.tournament_selection()\n",
    "            parent2 = self.tournament_selection()\n",
    "            \n",
    "            # Crossover\n",
    "            child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "            \n",
    "            # Mutation\n",
    "            child1 = mutate_genome(child1, self.config)\n",
    "            child2 = mutate_genome(child2, self.config)\n",
    "            \n",
    "            new_population.extend([child1, child2])\n",
    "            offspring_created += 2\n",
    "            \n",
    "            if offspring_created % 4 == 0:  # Show progress every 4 individuals\n",
    "                print(f\"   Created {min(offspring_created, offspring_needed)} of {offspring_needed} new individuals...\")\n",
    "        \n",
    "        # Adjust size if necessary\n",
    "        self.population = new_population[:self.config['population_size']]\n",
    "        \n",
    "        print(f\"New generation created with {len(self.population)} individuals\")\n",
    "        print(f\"   Elite preserved: {elite_size}\")\n",
    "        print(f\"   New individuals: {len(self.population) - elite_size}\")\n",
    "    \n",
    "    def tournament_selection(self, tournament_size: int = 3) -> dict:\n",
    "        \"\"\"Tournament selection.\"\"\"\n",
    "        tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
    "        return max(tournament, key=lambda x: x['fitness'])\n",
    "    \n",
    "    def check_convergence(self) -> bool:\n",
    "        \"\"\"Checks if algorithm has converged.\"\"\"\n",
    "        # Check target fitness\n",
    "        if self.best_individual and self.best_individual['fitness'] >= self.config['fitness_threshold']:\n",
    "            print(f\"Target fitness reached! ({self.best_individual['fitness']:.2f}% >= {self.config['fitness_threshold']}%)\")\n",
    "            return True\n",
    "        \n",
    "        # Check maximum generations\n",
    "        if self.generation >= self.config['max_generations']:\n",
    "            print(f\"Maximum generations reached ({self.generation}/{self.config['max_generations']})\")\n",
    "            return True\n",
    "        \n",
    "        # Check stagnation (last 3 generations without significant improvement)\n",
    "        if len(self.fitness_history) >= 3:\n",
    "            recent_fitness = self.fitness_history[-3:]\n",
    "            if max(recent_fitness) - min(recent_fitness) < 0.5:  # Less than 0.5% improvement\n",
    "                print(f\"Stagnation detected in last 3 generations\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def evolve(self) -> dict:\n",
    "        \"\"\"Executes complete evolution process.\"\"\"\n",
    "        print(\"STARTING HYBRID NEUROEVOLUTION PROCESS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"   Population: {self.config['population_size']} individuals\")\n",
    "        print(f\"   Maximum generations: {self.config['max_generations']}\")\n",
    "        print(f\"   Target fitness: {self.config['fitness_threshold']}%\")\n",
    "        print(f\"   Device: {device}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Initialize population\n",
    "        self.initialize_population()\n",
    "        \n",
    "        # Main evolution loop\n",
    "        while not self.check_convergence():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"GENERATION {self.generation}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Evaluate population\n",
    "            self.evaluate_population()\n",
    "            \n",
    "            # Check convergence before continuing\n",
    "            if self.check_convergence():\n",
    "                break\n",
    "            \n",
    "            # Selection and reproduction\n",
    "            self.selection_and_reproduction()\n",
    "            \n",
    "            # Next generation\n",
    "            self.generation += 1\n",
    "            \n",
    "            print(f\"\\nPreparing for next generation...\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EVOLUTION COMPLETED!\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Best individual found:\")\n",
    "        print(f\"   ID: {self.best_individual['id']}\")\n",
    "        print(f\"   Fitness: {self.best_individual['fitness']:.2f}%\")\n",
    "        print(f\"   Origin generation: {self.generation}\")\n",
    "        print(f\"   Total generations processed: {self.generation + 1}\")\n",
    "        \n",
    "        return self.best_individual\n",
    "\n",
    "print(\"HybridNeuroevolution class defined correctly (without tqdm, with detailed prints)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59597ef1",
   "metadata": {},
   "source": [
    "## 7. Evolution Process Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Modify configuration to use custom dataset\n",
    "# Uncomment and modify the following lines if you want to use a custom dataset\n",
    "# CONFIG['use_custom_dataset'] = True\n",
    "# CONFIG['dataset_path'] = r'E:\\Neuroevolution\\data\\phd_data'  # Adjust path according to your dataset\n",
    "# CONFIG['num_channels'] = 3  # 3 for RGB, 1 for grayscale\n",
    "# CONFIG['num_classes'] = 2   # Adjust according to your number of classes\n",
    "\n",
    "print(\"Current configuration:\")\n",
    "print(f\"   Dataset: {'Custom' if CONFIG['use_custom_dataset'] else 'MNIST'}\")\n",
    "if CONFIG['use_custom_dataset']:\n",
    "    print(f\"   Path: {CONFIG['dataset_path']}\")\n",
    "print(f\"   Population: {CONFIG['population_size']} individuals\")\n",
    "print(f\"   Maximum generations: {CONFIG['max_generations']}\")\n",
    "print(f\"   Target fitness: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Initialize neuroevolution system\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nStarting neuroevolution at {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Create system instance\n",
    "neuroevolution = HybridNeuroevolution(CONFIG, train_loader, test_loader)\n",
    "\n",
    "# Execute evolution process\n",
    "best_genome = neuroevolution.evolve()\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nProcess completed at {end_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Total execution time: {execution_time}\")\n",
    "print(f\"Total generations: {neuroevolution.generation}\")\n",
    "print(f\"Best fitness achieved: {best_genome['fitness']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555d9b",
   "metadata": {},
   "source": [
    "## 8. Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Function to visualize fitness evolution\n",
    "def plot_fitness_evolution(neuroevolution):\n",
    "    \"\"\"Plots fitness evolution across generations.\"\"\"\n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extract data and filter 0.00 fitness\n",
    "    generations = []\n",
    "    avg_fitness = []\n",
    "    max_fitness = []\n",
    "    min_fitness = []\n",
    "    std_fitness = []\n",
    "    \n",
    "    for stat in neuroevolution.generation_stats:\n",
    "        # Only include if valid fitness (> 0.00)\n",
    "        if stat['max_fitness'] > 0.00:\n",
    "            generations.append(stat['generation'])\n",
    "            avg_fitness.append(stat['avg_fitness'])\n",
    "            max_fitness.append(stat['max_fitness'])\n",
    "            min_fitness.append(stat['min_fitness'])\n",
    "            std_fitness.append(stat['std_fitness'])\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"WARNING: No valid fitness data to plot (all are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    # Graph 1: Fitness evolution\n",
    "    ax1.plot(generations, max_fitness, 'g-', linewidth=2, marker='o', label='Maximum Fitness')\n",
    "    ax1.plot(generations, avg_fitness, 'b-', linewidth=2, marker='s', label='Average Fitness')\n",
    "    ax1.plot(generations, min_fitness, 'r-', linewidth=2, marker='^', label='Minimum Fitness')\n",
    "    ax1.fill_between(generations, \n",
    "                     [max(0, avg - std) for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     [avg + std for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     alpha=0.2, color='blue')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness (%)')\n",
    "    ax1.set_title('Fitness Evolution by Generation (Excluding 0.00%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add target fitness line\n",
    "    ax1.axhline(y=CONFIG['fitness_threshold'], color='orange', linestyle='--', \n",
    "                label=f\"Target ({CONFIG['fitness_threshold']}%)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Set Y axis limits for better visualization\n",
    "    y_min = max(0, min(min_fitness) - 5)\n",
    "    y_max = min(100, max(max_fitness) + 5)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Graph 2: Diversity (standard deviation)\n",
    "    ax2.plot(generations, std_fitness, 'purple', linewidth=2, marker='D')\n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Fitness Standard Deviation')\n",
    "    ax2.set_title('Population Diversity (Excluding 0.00%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show additional information\n",
    "    print(f\"Plotted data:\")\n",
    "    print(f\"   Generations with valid fitness: {len(generations)}\")\n",
    "    print(f\"   Best fitness achieved: {max(max_fitness):.2f}%\")\n",
    "    print(f\"   Final average fitness: {avg_fitness[-1]:.2f}%\")\n",
    "    if len(generations) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(generations)\n",
    "        print(f\"   WARNING: Excluded generations (0.00 fitness): {excluded}\")\n",
    "\n",
    "# Function to show detailed statistics\n",
    "def show_evolution_statistics(neuroevolution):\n",
    "    \"\"\"Shows detailed evolution statistics.\"\"\"\n",
    "    print(\"DETAILED EVOLUTION STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics available\")\n",
    "        return\n",
    "    \n",
    "    # Filter statistics with valid fitness\n",
    "    valid_stats = [stat for stat in neuroevolution.generation_stats if stat['max_fitness'] > 0.00]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"WARNING: No valid statistics (all fitness are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    final_stats = valid_stats[-1]\n",
    "    \n",
    "    print(f\"Completed generations: {neuroevolution.generation}\")\n",
    "    print(f\"Generations with valid fitness: {len(valid_stats)}\")\n",
    "    if len(valid_stats) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(valid_stats)\n",
    "        print(f\"WARNING: Generations with 0.00 fitness (excluded): {excluded}\")\n",
    "    \n",
    "    print(f\"\\nFINAL STATISTICS (excluding 0.00 fitness):\")\n",
    "    print(f\"   Final best fitness: {final_stats['max_fitness']:.2f}%\")\n",
    "    print(f\"   Final average fitness: {final_stats['avg_fitness']:.2f}%\")\n",
    "    print(f\"   Final minimum fitness: {final_stats['min_fitness']:.2f}%\")\n",
    "    print(f\"   Final standard deviation: {final_stats['std_fitness']:.2f}%\")\n",
    "    \n",
    "    # Progress across generations\n",
    "    if len(valid_stats) > 1:\n",
    "        initial_max = valid_stats[0]['max_fitness']\n",
    "        final_max = valid_stats[-1]['max_fitness']\n",
    "        improvement = final_max - initial_max\n",
    "        \n",
    "        print(f\"\\nPROGRESS:\")\n",
    "        print(f\"   Initial fitness: {initial_max:.2f}%\")\n",
    "        print(f\"   Final fitness: {final_max:.2f}%\")\n",
    "        print(f\"   Total improvement: {improvement:.2f}%\")\n",
    "        if initial_max > 0:\n",
    "            print(f\"   Relative improvement: {(improvement/initial_max)*100:.1f}%\")\n",
    "    \n",
    "    # Convergence analysis\n",
    "    print(f\"\\nCONVERGENCE CRITERIA:\")\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['fitness'] >= CONFIG['fitness_threshold']:\n",
    "        print(f\"   OK: Target fitness reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   ERROR: Target fitness NOT reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    \n",
    "    if neuroevolution.generation >= CONFIG['max_generations']:\n",
    "        print(f\"   TIME: Maximum generations reached ({CONFIG['max_generations']})\")\n",
    "    \n",
    "    # Additional performance statistics\n",
    "    all_max_fitness = [stat['max_fitness'] for stat in valid_stats]\n",
    "    all_avg_fitness = [stat['avg_fitness'] for stat in valid_stats]\n",
    "    \n",
    "    print(f\"\\nGENERAL STATISTICS:\")\n",
    "    print(f\"   Best fitness of entire evolution: {max(all_max_fitness):.2f}%\")\n",
    "    print(f\"   Average fitness of entire evolution: {np.mean(all_avg_fitness):.2f}%\")\n",
    "    print(f\"   Average improvement per generation: {(max(all_max_fitness) - min(all_max_fitness))/len(valid_stats):.2f}%\")\n",
    "    \n",
    "    if neuroevolution.best_individual:\n",
    "        print(f\"\\nBest individual ID: {neuroevolution.best_individual['id']}\")\n",
    "        print(f\"Best individual fitness: {neuroevolution.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "# Additional function for failure analysis\n",
    "def analyze_failed_evaluations(neuroevolution):\n",
    "    \"\"\"Analyzes evaluations that resulted in 0.00 fitness.\"\"\"\n",
    "    print(\"\\nFAILED EVALUATIONS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_generations = len(neuroevolution.generation_stats)\n",
    "    failed_generations = len([stat for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00])\n",
    "    \n",
    "    if failed_generations == 0:\n",
    "        print(\"OK: No failed evaluations (0.00 fitness)\")\n",
    "        return\n",
    "    \n",
    "    success_rate = ((total_generations - failed_generations) / total_generations) * 100\n",
    "    \n",
    "    print(f\"Failure summary:\")\n",
    "    print(f\"   Total generations: {total_generations}\")\n",
    "    print(f\"   Failed generations: {failed_generations}\")\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    if failed_generations > 0:\n",
    "        failed_gens = [stat['generation'] for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00]\n",
    "        print(f\"   Generations with failures: {failed_gens}\")\n",
    "        \n",
    "        print(f\"\\nPossible causes of 0.00 fitness:\")\n",
    "        print(f\"    Errors in model architecture\")\n",
    "        print(f\"    Memory problems (GPU/RAM)\")\n",
    "        print(f\"    Invalid hyperparameter configurations\")\n",
    "        print(f\"    Errors during training\")\n",
    "\n",
    "# Execute visualizations\n",
    "plot_fitness_evolution(neuroevolution)\n",
    "show_evolution_statistics(neuroevolution)\n",
    "analyze_failed_evaluations(neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6688660",
   "metadata": {},
   "source": [
    "## 9. BEST ARCHITECTURE FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a847dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_best_architecture(best_genome, config):\n",
    "    \"\"\"\n",
    "    Shows the best architecture found in detailed and visual format.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"        BEST EVOLVED ARCHITECTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # General information\n",
    "    print(f\"\\nGENERAL INFORMATION:\")\n",
    "    print(f\"   Genome ID: {best_genome['id']}\")\n",
    "    print(f\"   Fitness Achieved: {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Generation: {neuroevolution.generation}\")\n",
    "    \n",
    "    # Architecture details\n",
    "    print(f\"\\nNETWORK ARCHITECTURE:\")\n",
    "    print(f\"   Convolutional Layers: {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   Fully Connected Layers: {best_genome['num_fc_layers']}\")\n",
    "    \n",
    "    print(f\"\\nCONVOLUTIONAL LAYER DETAILS:\")\n",
    "    for i in range(best_genome['num_conv_layers']):\n",
    "        filters = best_genome['filters'][i]\n",
    "        kernel = best_genome['kernel_sizes'][i]\n",
    "        activation = best_genome['activations'][i % len(best_genome['activations'])]\n",
    "        print(f\"   Conv{i+1}: {filters} filters, kernel {kernel}x{kernel}, activation {activation}\")\n",
    "    \n",
    "    print(f\"\\nFULLY CONNECTED LAYER DETAILS:\")\n",
    "    for i, nodes in enumerate(best_genome['fc_nodes']):\n",
    "        print(f\"   FC{i+1}: {nodes} neurons\")\n",
    "    print(f\"   Output: {config['num_classes']} neurons (classes)\")\n",
    "    \n",
    "    print(f\"\\nHYPERPARAMETERS:\")\n",
    "    print(f\"   Optimizer: {best_genome['optimizer'].upper()}\")\n",
    "    print(f\"   Learning Rate: {best_genome['learning_rate']:.4f}\")\n",
    "    print(f\"   Dropout Rate: {best_genome['dropout_rate']:.3f}\")\n",
    "    print(f\"   Activation Functions: {', '.join(best_genome['activations'])}\")\n",
    "    \n",
    "    # Create and show final model\n",
    "    print(f\"\\nCREATING FINAL MODEL...\")\n",
    "    try:\n",
    "        final_model = EvolvableCNN(best_genome, config)\n",
    "        total_params = sum(p.numel() for p in final_model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"   Model created successfully\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Architecture summary\n",
    "        print(f\"\\nCOMPACT SUMMARY:\")\n",
    "        print(f\"   {final_model.get_architecture_summary()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR creating model: {e}\")\n",
    "    \n",
    "    # Visualization in table format\n",
    "    print(f\"\\nSUMMARY TABLE:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Parameter':<25} {'Value':<30} {'Description':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'ID':<25} {best_genome['id']:<30} {'Unique identifier':<25}\")\n",
    "    print(f\"{'Fitness':<25} {best_genome['fitness']:.2f}%{'':<25} {'Accuracy achieved':<25}\")\n",
    "    print(f\"{'Conv Layers':<25} {best_genome['num_conv_layers']:<30} {'Convolutional layers':<25}\")\n",
    "    print(f\"{'FC Layers':<25} {best_genome['num_fc_layers']:<30} {'FC layers':<25}\")\n",
    "    print(f\"{'Optimizer':<25} {best_genome['optimizer']:<30} {'Optimization algorithm':<25}\")\n",
    "    print(f\"{'Learning Rate':<25} {best_genome['learning_rate']:<30} {'Learning rate':<25}\")\n",
    "    print(f\"{'Dropout':<25} {best_genome['dropout_rate']:<30} {'Dropout rate':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Comparison with initial configuration\n",
    "    print(f\"\\nCOMPARISON WITH OBJECTIVES:\")\n",
    "    if best_genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"   TARGET: OK Fitness objective REACHED ({best_genome['fitness']:.2f}% >= {config['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   TARGET: ERROR Fitness objective NOT reached ({best_genome['fitness']:.2f}% < {config['fitness_threshold']}%)\")\n",
    "    \n",
    "    print(f\"   TIME: Generations used: {neuroevolution.generation}/{config['max_generations']}\")\n",
    "    \n",
    "    # Save information to JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'execution_time': str(execution_time),\n",
    "        'config_used': config,\n",
    "        'best_genome': best_genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\nResults saved to: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWARNING: Error saving results: {e}\")\n",
    "    \n",
    "    print(f\"\\nHYBRID NEUROEVOLUTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Show the best architecture found\n",
    "display_best_architecture(best_genome, CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
