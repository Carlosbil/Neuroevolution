{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77d426",
   "metadata": {},
   "source": [
    "# Cuaderno de Neuroevolución Híbrida Síncrona\n",
    "\n",
    "¡Muy Buenas señor Carlos! 🚀\n",
    "\n",
    "Este cuaderno implementa todo el proceso de neuroevolución híbrida de forma síncrona, sin necesidad de base de datos ni servicios externos de Kafka. El sistema combina algoritmos genéticos con redes neuronales convolucionales para evolucionar arquitecturas óptimas.\n",
    "\n",
    "## Características principales:\n",
    "- 🧬 **Algoritmo genético híbrido**: Combina evolución de arquitectura y pesos\n",
    "- 🔄 **Procesamiento síncrono**: Todo el flujo ejecutado en una sola sesión\n",
    "- 📊 **Dataset configurable**: Soporta MNIST por defecto o dataset personalizado\n",
    "- 🎯 **Criterios de parada inteligentes**: Por fitness objetivo o máximo de generaciones\n",
    "- 📈 **Visualización completa**: Muestra progreso y mejor arquitectura final\n",
    "\n",
    "## Objetivos:\n",
    "1. Crear población inicial de arquitecturas de CNN\n",
    "2. Evaluar fitness de cada individuo\n",
    "3. Seleccionar mejores arquitecturas (50% superior)\n",
    "4. Aplicar crossover y mutación para crear nueva generación\n",
    "5. Repetir proceso hasta convergencia\n",
    "6. Mostrar la mejor arquitectura encontrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3cfb",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías Requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50120a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar todas las librerías necesarias\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Instala un paquete usando pip si no está disponible.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"✅ {package.split('==')[0]} ya está instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} instalado correctamente\")\n",
    "\n",
    "# Lista de paquetes requeridos\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\"\n",
    "]\n",
    "\n",
    "print(\"🚀 Instalando dependencias para Neuroevolución Híbrida...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n✅ Todas las dependencias han sido verificadas/instaladas\")\n",
    "print(\"🔄 Reinicia el kernel si es la primera vez que instalas torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar instalación de PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\n🧠 PyTorch {torch.__version__} instalado correctamente\")\n",
    "    print(f\"🔥 CUDA disponible: {'Sí' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"🎮 GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"💾 Memoria GPU: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"❌ Error: PyTorch no se pudo instalar correctamente\")\n",
    "    print(\"🔧 Intenta instalar manualmente con: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865869c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Librerías científicas\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Visualización y progreso\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configurar seeds para reproducibilidad\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Dispositivo configurado: {device}\")\n",
    "print(f\"🔧 PyTorch versión: {torch.__version__}\")\n",
    "\n",
    "# Suprimir warnings innecesarios\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1181c2a",
   "metadata": {},
   "source": [
    "## 2. Configuración y Parámetros del Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración principal del algoritmo genético\n",
    "CONFIG = {\n",
    "    # Parámetros del algoritmo genético\n",
    "    'population_size': 8,           # Tamaño de la población\n",
    "    'max_generations': 30,           # Máximo número de generaciones\n",
    "    'fitness_threshold': 99.9,      # Fitness objetivo (% de precisión)\n",
    "    'mutation_rate': 0.15,          # Tasa de mutación\n",
    "    'crossover_rate': 0.8,          # Tasa de crossover\n",
    "    'elite_percentage': 0.5,        # Porcentaje de élite a conservar\n",
    "    \n",
    "    # Parámetros del dataset\n",
    "    'num_channels': 1,              # Canales de entrada (1=grayscale, 3=RGB)\n",
    "    'px_h': 28,                     # Altura de las imágenes\n",
    "    'px_w': 28,                     # Ancho de las imágenes\n",
    "    'num_classes': 10,              # Número de clases\n",
    "    'batch_size': 64,               # Tamaño del batch\n",
    "    'test_split': 0.2,              # Porcentaje para validación\n",
    "    \n",
    "    # Parámetros de entrenamiento\n",
    "    'num_epochs': 2,                # Épocas de entrenamiento por evaluación\n",
    "    'learning_rate': 0.001,         # Tasa de aprendizaje base\n",
    "    'early_stopping_patience': 50,  # Batches máximos para evaluación rápida\n",
    "    \n",
    "    # Rango de arquitecturas permitidas\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 4,\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 3,\n",
    "    'min_filters': 8,\n",
    "    'max_filters': 128,\n",
    "    'min_fc_nodes': 32,\n",
    "    'max_fc_nodes': 512,\n",
    "    \n",
    "    # Configuración de datos\n",
    "    'dataset_path': None,           # Path al dataset personalizado (None = MNIST)\n",
    "    'use_custom_dataset': False,    # Si usar dataset personalizado\n",
    "}\n",
    "\n",
    "# Mapeo de funciones de activación\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Mapeo de optimizadores\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"✅ Configuración cargada:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(f\"\\n🧬 Funciones de activación disponibles: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"🔧 Optimizadores disponibles: {list(OPTIMIZERS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6d37",
   "metadata": {},
   "source": [
    "## 3. Carga y Preprocesamiento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f98ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config: dict) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Carga el dataset según la configuración.\n",
    "    Retorna train_loader y test_loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    if config['use_custom_dataset'] and config['dataset_path']:\n",
    "        print(f\"📁 Cargando dataset personalizado desde: {config['dataset_path']}\")\n",
    "        \n",
    "        # Transformaciones para dataset personalizado\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)) if config['num_channels'] == 1 else \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # Cargar dataset desde carpetas organizadas por clase\n",
    "        full_dataset = datasets.ImageFolder(root=config['dataset_path'], transform=transform)\n",
    "        \n",
    "        # Dividir en train y test\n",
    "        train_size = int((1 - config['test_split']) * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "        \n",
    "        print(f\"📊 Dataset personalizado cargado:\")\n",
    "        print(f\"   Clases encontradas: {len(full_dataset.classes)}\")\n",
    "        print(f\"   Total de muestras: {len(full_dataset)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"📁 Cargando dataset MNIST por defecto...\")\n",
    "        \n",
    "        # Transformaciones para MNIST\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((config['px_h'], config['px_w'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        \n",
    "        # Cargar MNIST\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "        print(f\"📊 Dataset MNIST cargado:\")\n",
    "        print(f\"   Clases: {len(train_dataset.classes)}\")\n",
    "        print(f\"   Muestras de entrenamiento: {len(train_dataset)}\")\n",
    "        print(f\"   Muestras de prueba: {len(test_dataset)}\")\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Cargar el dataset\n",
    "train_loader, test_loader = load_dataset(CONFIG)\n",
    "\n",
    "# Obtener una muestra para verificar las dimensiones\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_data, sample_labels = sample_batch\n",
    "print(f\"\\n✅ Dataset cargado exitosamente:\")\n",
    "print(f\"   Forma del batch: {sample_data.shape}\")\n",
    "print(f\"   Tipo de datos: {sample_data.dtype}\")\n",
    "print(f\"   Dispositivo: {sample_data.device}\")\n",
    "print(f\"   Rango de valores: [{sample_data.min():.3f}, {sample_data.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52de67",
   "metadata": {},
   "source": [
    "## 4. Definición de Arquitectura de Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Clase de CNN evolucionable que puede ser configurada dinámicamente\n",
    "    según los parámetros del genoma.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Construir las capas convolucionales\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calcular el tamaño de salida después de las convoluciones\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Construir las capas completamente conectadas\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "        \n",
    "    def _build_conv_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Construye las capas convolucionales según el genoma.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        \n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Capa convolucional\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Batch normalization\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            # Función de activación\n",
    "            activation_name = self.genome['activations'][i % len(self.genome['activations'])]\n",
    "            activation_func = ACTIVATION_FUNCTIONS[activation_name]()\n",
    "            layers.append(activation_func)\n",
    "            \n",
    "            # Max pooling (excepto en la última capa)\n",
    "            if i < self.genome['num_conv_layers'] - 1:\n",
    "                layers.append(nn.MaxPool2d(2, 2))\n",
    "            else:\n",
    "                layers.append(nn.MaxPool2d(2, 1))  # Stride 1 en la última capa\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self) -> int:\n",
    "        \"\"\"Calcula el tamaño de salida después de las capas convolucionales.\"\"\"\n",
    "        # Crear un tensor dummy para calcular el tamaño\n",
    "        dummy_input = torch.zeros(1, self.config['num_channels'], \n",
    "                                 self.config['px_h'], self.config['px_w'])\n",
    "        \n",
    "        # Pasar por las capas convolucionales\n",
    "        x = dummy_input\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Aplanar y obtener el tamaño\n",
    "        return x.view(-1).shape[0]\n",
    "    \n",
    "    def _build_fc_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Construye las capas completamente conectadas.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        input_size = self.conv_output_size\n",
    "        \n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            output_size = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Capa lineal\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "            # Dropout si no es la última capa\n",
    "            if i < self.genome['num_fc_layers'] - 1:\n",
    "                layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            input_size = output_size\n",
    "        \n",
    "        # Capa final de clasificación\n",
    "        layers.append(nn.Linear(input_size, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass de la red.\"\"\"\n",
    "        # Capas convolucionales\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Aplanar\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Capas completamente conectadas\n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            x = layer(x)\n",
    "            # Aplicar activación excepto en la última capa\n",
    "            if i < len(self.fc_layers) - 1 and not isinstance(layer, nn.Dropout):\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_architecture_summary(self) -> str:\n",
    "        \"\"\"Retorna un resumen de la arquitectura.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(f\"Conv Layers: {self.genome['num_conv_layers']}\")\n",
    "        summary.append(f\"Filters: {self.genome['filters']}\")\n",
    "        summary.append(f\"Kernel Sizes: {self.genome['kernel_sizes']}\")\n",
    "        summary.append(f\"FC Layers: {self.genome['num_fc_layers']}\")\n",
    "        summary.append(f\"FC Nodes: {self.genome['fc_nodes']}\")\n",
    "        summary.append(f\"Activations: {self.genome['activations']}\")\n",
    "        summary.append(f\"Dropout: {self.genome['dropout_rate']:.3f}\")\n",
    "        summary.append(f\"Optimizer: {self.genome['optimizer']}\")\n",
    "        summary.append(f\"Learning Rate: {self.genome['learning_rate']:.4f}\")\n",
    "        return \" | \".join(summary)\n",
    "\n",
    "print(\"✅ Clase EvolvableCNN definida correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021c7d8",
   "metadata": {},
   "source": [
    "## 5. Componentes del Algoritmo Genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be19766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"Crea un genoma aleatorio dentro de los rangos especificados.\"\"\"\n",
    "    \n",
    "    # Número de capas\n",
    "    num_conv_layers = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "    \n",
    "    # Filtros para cada capa convolucional\n",
    "    filters = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        filters.append(random.randint(config['min_filters'], config['max_filters']))\n",
    "    \n",
    "    # Tamaños de kernel\n",
    "    kernel_sizes = []\n",
    "    for _ in range(num_conv_layers):\n",
    "        kernel_sizes.append(random.choice([3, 5, 7]))\n",
    "    \n",
    "    # Nodos en capas completamente conectadas\n",
    "    fc_nodes = []\n",
    "    for _ in range(num_fc_layers):\n",
    "        fc_nodes.append(random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Funciones de activación para cada capa\n",
    "    activations = []\n",
    "    for _ in range(max(num_conv_layers, num_fc_layers)):\n",
    "        activations.append(random.choice(list(ACTIVATION_FUNCTIONS.keys())))\n",
    "    \n",
    "    # Otros parámetros\n",
    "    dropout_rate = random.uniform(0.1, 0.5)\n",
    "    learning_rate = random.choice([0.001, 0.0001, 0.01, 0.005])\n",
    "    optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    genome = {\n",
    "        'num_conv_layers': num_conv_layers,\n",
    "        'num_fc_layers': num_fc_layers,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'fc_nodes': fc_nodes,\n",
    "        'activations': activations,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "    \n",
    "    return genome\n",
    "\n",
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"Aplica mutación a un genoma.\"\"\"\n",
    "    mutated_genome = copy.deepcopy(genome)\n",
    "    mutation_rate = config['mutation_rate']\n",
    "    \n",
    "    # Mutar número de capas convolucionales\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_conv_layers'] = random.randint(\n",
    "            config['min_conv_layers'], config['max_conv_layers'])\n",
    "        # Ajustar listas relacionadas\n",
    "        num_conv = mutated_genome['num_conv_layers']\n",
    "        mutated_genome['filters'] = mutated_genome['filters'][:num_conv]\n",
    "        mutated_genome['kernel_sizes'] = mutated_genome['kernel_sizes'][:num_conv]\n",
    "        \n",
    "        # Rellenar si es necesario\n",
    "        while len(mutated_genome['filters']) < num_conv:\n",
    "            mutated_genome['filters'].append(\n",
    "                random.randint(config['min_filters'], config['max_filters']))\n",
    "        while len(mutated_genome['kernel_sizes']) < num_conv:\n",
    "            mutated_genome['kernel_sizes'].append(random.choice([3, 5, 7]))\n",
    "    \n",
    "    # Mutar filtros\n",
    "    for i in range(len(mutated_genome['filters'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['filters'][i] = random.randint(\n",
    "                config['min_filters'], config['max_filters'])\n",
    "    \n",
    "    # Mutar tamaños de kernel\n",
    "    for i in range(len(mutated_genome['kernel_sizes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['kernel_sizes'][i] = random.choice([3, 5, 7])\n",
    "    \n",
    "    # Mutar número de capas FC\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_fc_layers'] = random.randint(\n",
    "            config['min_fc_layers'], config['max_fc_layers'])\n",
    "        # Ajustar nodos FC\n",
    "        num_fc = mutated_genome['num_fc_layers']\n",
    "        mutated_genome['fc_nodes'] = mutated_genome['fc_nodes'][:num_fc]\n",
    "        while len(mutated_genome['fc_nodes']) < num_fc:\n",
    "            mutated_genome['fc_nodes'].append(\n",
    "                random.randint(config['min_fc_nodes'], config['max_fc_nodes']))\n",
    "    \n",
    "    # Mutar nodos FC\n",
    "    for i in range(len(mutated_genome['fc_nodes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['fc_nodes'][i] = random.randint(\n",
    "                config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "    \n",
    "    # Mutar funciones de activación\n",
    "    for i in range(len(mutated_genome['activations'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['activations'][i] = random.choice(\n",
    "                list(ACTIVATION_FUNCTIONS.keys()))\n",
    "    \n",
    "    # Mutar dropout\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['dropout_rate'] = random.uniform(0.1, 0.5)\n",
    "    \n",
    "    # Mutar learning rate\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['learning_rate'] = random.choice([0.001, 0.0001, 0.01, 0.005])\n",
    "    \n",
    "    # Mutar optimizador\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "    \n",
    "    # Nuevo ID para el genoma mutado\n",
    "    mutated_genome['id'] = str(uuid.uuid4())[:8]\n",
    "    mutated_genome['fitness'] = 0.0  # Reset fitness\n",
    "    \n",
    "    return mutated_genome\n",
    "\n",
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"Realiza crossover entre dos genomas.\"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "    \n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    # Crossover de parámetros escalares\n",
    "    if random.random() < 0.5:\n",
    "        child1['num_conv_layers'], child2['num_conv_layers'] = \\\n",
    "            child2['num_conv_layers'], child1['num_conv_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['num_fc_layers'], child2['num_fc_layers'] = \\\n",
    "            child2['num_fc_layers'], child1['num_fc_layers']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['dropout_rate'], child2['dropout_rate'] = \\\n",
    "            child2['dropout_rate'], child1['dropout_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['learning_rate'], child2['learning_rate'] = \\\n",
    "            child2['learning_rate'], child1['learning_rate']\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        child1['optimizer'], child2['optimizer'] = \\\n",
    "            child2['optimizer'], child1['optimizer']\n",
    "    \n",
    "    # Crossover de listas (punto de corte aleatorio)\n",
    "    for list_key in ['filters', 'kernel_sizes', 'fc_nodes', 'activations']:\n",
    "        if random.random() < 0.5:\n",
    "            list1 = child1[list_key]\n",
    "            list2 = child2[list_key]\n",
    "            \n",
    "            if len(list1) > 1 and len(list2) > 1:\n",
    "                point1 = random.randint(1, len(list1) - 1)\n",
    "                point2 = random.randint(1, len(list2) - 1)\n",
    "                \n",
    "                # Intercambiar partes\n",
    "                new_list1 = list1[:point1] + list2[point2:]\n",
    "                new_list2 = list2[:point2] + list1[point1:]\n",
    "                \n",
    "                child1[list_key] = new_list1\n",
    "                child2[list_key] = new_list2\n",
    "    \n",
    "    # Asignar nuevos IDs\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "print(\"✅ Funciones genéticas definidas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a74a50",
   "metadata": {},
   "source": [
    "## 6. Implementación de Neuroevolución Híbrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNeuroevolution:\n",
    "    \"\"\"Clase principal que implementa la neuroevolución híbrida.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, train_loader: DataLoader, test_loader: DataLoader):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Inicializa la población con genomas aleatorios.\"\"\"\n",
    "        print(f\"🧬 Inicializando población de {self.config['population_size']} individuos...\")\n",
    "        \n",
    "        self.population = []\n",
    "        for i in range(self.config['population_size']):\n",
    "            genome = create_random_genome(self.config)\n",
    "            self.population.append(genome)\n",
    "            \n",
    "        print(f\"✅ Población inicializada con {len(self.population)} individuos\")\n",
    "    \n",
    "    def evaluate_fitness(self, genome: dict) -> float:\n",
    "        \"\"\"Evalúa el fitness de un genoma entrenando la red neuronal.\"\"\"\n",
    "        try:\n",
    "            # Crear el modelo\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "            \n",
    "            # Crear optimizador\n",
    "            optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "            optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "            \n",
    "            # Función de pérdida\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Entrenamiento\n",
    "            model.train()\n",
    "            total_train_batches = min(len(self.train_loader), self.config['early_stopping_patience'])\n",
    "            \n",
    "            print(f\"      🏋️ Entrenando modelo {genome['id']} ({self.config['num_epochs']} épocas, max {total_train_batches} batches/época)\")\n",
    "            \n",
    "            for epoch in range(self.config['num_epochs']):\n",
    "                running_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for data, target in self.train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Early stopping para evaluación rápida\n",
    "                    if batch_count >= self.config['early_stopping_patience']:\n",
    "                        break\n",
    "                \n",
    "                # Estadísticas de la época\n",
    "                avg_loss = running_loss / batch_count\n",
    "                print(f\"          Época {epoch+1}/{self.config['num_epochs']}: Loss promedio = {avg_loss:.4f} ({batch_count} batches procesados)\")\n",
    "            \n",
    "            print(f\"      ✅ Entrenamiento completado para modelo {genome['id']}\")\n",
    "            \n",
    "            # Evaluación\n",
    "            print(f\"      📊 Evaluando modelo {genome['id']} en conjunto de test...\")\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            eval_batches = 0\n",
    "            max_eval_batches = min(len(self.test_loader), 20)\n",
    "            total_eval_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, target in self.test_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    \n",
    "                    # Calcular loss de evaluación\n",
    "                    eval_loss = criterion(output, target)\n",
    "                    total_eval_loss += eval_loss.item()\n",
    "                    \n",
    "                    # Calcular accuracy\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "                    eval_batches += 1\n",
    "                    \n",
    "                    # Early stopping en evaluación\n",
    "                    if eval_batches >= max_eval_batches:\n",
    "                        break\n",
    "            \n",
    "            accuracy = 100.0 * correct / total\n",
    "            avg_eval_loss = total_eval_loss / eval_batches\n",
    "            \n",
    "            print(f\"         📈 Evaluación: {correct}/{total} correctos = {accuracy:.2f}% accuracy\")\n",
    "            print(f\"         📉 Loss de evaluación: {avg_eval_loss:.4f} ({eval_batches} batches evaluados)\")\n",
    "            print(f\"      ✅ Evaluación completada para modelo {genome['id']} - Fitness final: {accuracy:.2f}%\")\n",
    "            \n",
    "            return accuracy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Error evaluando genoma {genome['id']}: {e}\")\n",
    "            logger.warning(f\"Error evaluando genoma {genome['id']}: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_population(self):\n",
    "        \"\"\"Evalúa toda la población y actualiza fitness.\"\"\"\n",
    "        print(f\"\\n📊 Evaluando población (Generación {self.generation})...\")\n",
    "        print(f\"🔄 Procesando {len(self.population)} individuos...\")\n",
    "        \n",
    "        fitness_scores = []\n",
    "        best_fitness_so_far = 0.0\n",
    "        \n",
    "        for i, genome in enumerate(self.population):\n",
    "            print(f\"\\n   🧬 Evaluando individuo {i+1}/{len(self.population)} (ID: {genome['id']})\")\n",
    "            print(f\"      📋 Arquitectura: {genome['num_conv_layers']} conv + {genome['num_fc_layers']} fc, opt={genome['optimizer']}, lr={genome['learning_rate']}\")\n",
    "            \n",
    "            fitness = self.evaluate_fitness(genome)\n",
    "            genome['fitness'] = fitness\n",
    "            fitness_scores.append(fitness)\n",
    "            \n",
    "            # Actualizar mejor fitness encontrado hasta ahora\n",
    "            if fitness > best_fitness_so_far:\n",
    "                best_fitness_so_far = fitness\n",
    "                print(f\"      🏆 ¡Nuevo mejor fitness en esta generación: {fitness:.2f}%!\")\n",
    "            \n",
    "            print(f\"      📊 Fitness obtenido: {fitness:.2f}% | Mejor hasta ahora: {best_fitness_so_far:.2f}%\")\n",
    "        \n",
    "        # Estadísticas de la generación\n",
    "        avg_fitness = np.mean(fitness_scores)\n",
    "        max_fitness = np.max(fitness_scores)\n",
    "        min_fitness = np.min(fitness_scores)\n",
    "        std_fitness = np.std(fitness_scores)\n",
    "        \n",
    "        stats = {\n",
    "            'generation': self.generation,\n",
    "            'avg_fitness': avg_fitness,\n",
    "            'max_fitness': max_fitness,\n",
    "            'min_fitness': min_fitness,\n",
    "            'std_fitness': std_fitness\n",
    "        }\n",
    "        \n",
    "        self.generation_stats.append(stats)\n",
    "        self.fitness_history.append(max_fitness)\n",
    "        \n",
    "        # Actualizar mejor individuo\n",
    "        best_genome = max(self.population, key=lambda x: x['fitness'])\n",
    "        if self.best_individual is None or best_genome['fitness'] > self.best_individual['fitness']:\n",
    "            self.best_individual = copy.deepcopy(best_genome)\n",
    "            print(f\"\\n🎉 ¡Nuevo mejor individuo global encontrado!\")\n",
    "        \n",
    "        print(f\"\\n📈 ESTADÍSTICAS GENERACIÓN {self.generation}:\")\n",
    "        print(f\"   🏆 Fitness máximo: {max_fitness:.2f}%\")\n",
    "        print(f\"   📊 Fitness promedio: {avg_fitness:.2f}%\")\n",
    "        print(f\"   📉 Fitness mínimo: {min_fitness:.2f}%\")\n",
    "        print(f\"   📏 Desviación estándar: {std_fitness:.2f}%\")\n",
    "        print(f\"   🥇 Mejor individuo: {best_genome['id']} con {best_genome['fitness']:.2f}%\")\n",
    "        print(f\"   🌟 Mejor individuo global: {self.best_individual['id']} con {self.best_individual['fitness']:.2f}%\")\n",
    "        \n",
    "    def selection_and_reproduction(self):\n",
    "        \"\"\"Selecciona los mejores individuos y crea la nueva generación.\"\"\"\n",
    "        print(f\"\\n🔄 Iniciando selección y reproducción...\")\n",
    "        \n",
    "        # Ordenar población por fitness\n",
    "        self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        # Seleccionar élite\n",
    "        elite_size = int(self.config['population_size'] * self.config['elite_percentage'])\n",
    "        elite = self.population[:elite_size]\n",
    "        \n",
    "        print(f\"🏆 Seleccionando {elite_size} individuos élite:\")\n",
    "        for i, individual in enumerate(elite):\n",
    "            print(f\"   Élite {i+1}: {individual['id']} (fitness: {individual['fitness']:.2f}%)\")\n",
    "        \n",
    "        # Crear nueva generación\n",
    "        new_population = copy.deepcopy(elite)  # Conservar élite\n",
    "        \n",
    "        # Completar población con crossover y mutación\n",
    "        offspring_needed = self.config['population_size'] - len(new_population)\n",
    "        print(f\"🧬 Creando {offspring_needed} nuevos individuos mediante crossover y mutación...\")\n",
    "        \n",
    "        offspring_created = 0\n",
    "        while len(new_population) < self.config['population_size']:\n",
    "            # Selección de padres (torneo)\n",
    "            parent1 = self.tournament_selection()\n",
    "            parent2 = self.tournament_selection()\n",
    "            \n",
    "            # Crossover\n",
    "            child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "            \n",
    "            # Mutación\n",
    "            child1 = mutate_genome(child1, self.config)\n",
    "            child2 = mutate_genome(child2, self.config)\n",
    "            \n",
    "            new_population.extend([child1, child2])\n",
    "            offspring_created += 2\n",
    "            \n",
    "            if offspring_created % 4 == 0:  # Mostrar progreso cada 4 individuos\n",
    "                print(f\"   👥 Creados {min(offspring_created, offspring_needed)} de {offspring_needed} nuevos individuos...\")\n",
    "        \n",
    "        # Ajustar tamaño si es necesario\n",
    "        self.population = new_population[:self.config['population_size']]\n",
    "        \n",
    "        print(f\"✅ Nueva generación creada con {len(self.population)} individuos\")\n",
    "        print(f\"   🏆 Élite conservada: {elite_size}\")\n",
    "        print(f\"   👶 Nuevos individuos: {len(self.population) - elite_size}\")\n",
    "    \n",
    "    def tournament_selection(self, tournament_size: int = 3) -> dict:\n",
    "        \"\"\"Selección por torneo.\"\"\"\n",
    "        tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
    "        return max(tournament, key=lambda x: x['fitness'])\n",
    "    \n",
    "    def check_convergence(self) -> bool:\n",
    "        \"\"\"Verifica si el algoritmo ha convergido.\"\"\"\n",
    "        # Verificar fitness objetivo\n",
    "        if self.best_individual and self.best_individual['fitness'] >= self.config['fitness_threshold']:\n",
    "            print(f\"🎯 ¡Fitness objetivo alcanzado! ({self.best_individual['fitness']:.2f}% >= {self.config['fitness_threshold']}%)\")\n",
    "            return True\n",
    "        \n",
    "        # Verificar máximo de generaciones\n",
    "        if self.generation >= self.config['max_generations']:\n",
    "            print(f\"⏰ Máximo de generaciones alcanzado ({self.generation}/{self.config['max_generations']})\")\n",
    "            return True\n",
    "        \n",
    "        # Verificar estancamiento (últimas 3 generaciones sin mejora significativa)\n",
    "        if len(self.fitness_history) >= 3:\n",
    "            recent_fitness = self.fitness_history[-3:]\n",
    "            if max(recent_fitness) - min(recent_fitness) < 0.5:  # Menos de 0.5% de mejora\n",
    "                print(f\"📊 Estancamiento detectado en las últimas 3 generaciones\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def evolve(self) -> dict:\n",
    "        \"\"\"Ejecuta el proceso completo de evolución.\"\"\"\n",
    "        print(\"🚀 INICIANDO PROCESO DE NEUROEVOLUCIÓN HÍBRIDA\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"📋 Configuración:\")\n",
    "        print(f\"   👥 Población: {self.config['population_size']} individuos\")\n",
    "        print(f\"   🔄 Generaciones máximas: {self.config['max_generations']}\")\n",
    "        print(f\"   🎯 Fitness objetivo: {self.config['fitness_threshold']}%\")\n",
    "        print(f\"   💻 Dispositivo: {device}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Inicializar población\n",
    "        self.initialize_population()\n",
    "        \n",
    "        # Loop principal de evolución\n",
    "        while not self.check_convergence():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"🧬 GENERACIÓN {self.generation}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Evaluar población\n",
    "            self.evaluate_population()\n",
    "            \n",
    "            # Verificar convergencia antes de continuar\n",
    "            if self.check_convergence():\n",
    "                break\n",
    "            \n",
    "            # Selección y reproducción\n",
    "            self.selection_and_reproduction()\n",
    "            \n",
    "            # Siguiente generación\n",
    "            self.generation += 1\n",
    "            \n",
    "            print(f\"\\n🔄 Preparando para la siguiente generación...\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"🎉 ¡EVOLUCIÓN COMPLETADA!\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"🏆 Mejor individuo encontrado:\")\n",
    "        print(f\"   📌 ID: {self.best_individual['id']}\")\n",
    "        print(f\"   🎯 Fitness: {self.best_individual['fitness']:.2f}%\")\n",
    "        print(f\"   🧬 Generación de origen: {self.generation}\")\n",
    "        print(f\"   📊 Total de generaciones procesadas: {self.generation + 1}\")\n",
    "        \n",
    "        return self.best_individual\n",
    "\n",
    "print(\"✅ Clase HybridNeuroevolution definida correctamente (sin tqdm, con prints detallados)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59597ef1",
   "metadata": {},
   "source": [
    "## 7. Ejecución del Proceso de Evolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: Modificar configuración para usar dataset personalizado\n",
    "# Descomenta y modifica las siguientes líneas si quieres usar un dataset personalizado\n",
    "# CONFIG['use_custom_dataset'] = True\n",
    "# CONFIG['dataset_path'] = r'E:\\Neuroevolution\\data\\phd_data'  # Ajusta la ruta según tu dataset\n",
    "# CONFIG['num_channels'] = 3  # 3 para RGB, 1 para grayscale\n",
    "# CONFIG['num_classes'] = 2   # Ajusta según tu número de clases\n",
    "\n",
    "print(\"🎯 Configuración actual:\")\n",
    "print(f\"   Dataset: {'Personalizado' if CONFIG['use_custom_dataset'] else 'MNIST'}\")\n",
    "if CONFIG['use_custom_dataset']:\n",
    "    print(f\"   Ruta: {CONFIG['dataset_path']}\")\n",
    "print(f\"   Población: {CONFIG['population_size']} individuos\")\n",
    "print(f\"   Generaciones máximas: {CONFIG['max_generations']}\")\n",
    "print(f\"   Fitness objetivo: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"   Dispositivo: {device}\")\n",
    "\n",
    "# Inicializar el sistema de neuroevolución\n",
    "start_time = datetime.now()\n",
    "print(f\"\\n⏰ Iniciando neuroevolución a las {start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Crear instancia del sistema\n",
    "neuroevolution = HybridNeuroevolution(CONFIG, train_loader, test_loader)\n",
    "\n",
    "# Ejecutar el proceso de evolución\n",
    "best_genome = neuroevolution.evolve()\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n⏰ Proceso completado a las {end_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"⚡ Tiempo total de ejecución: {execution_time}\")\n",
    "print(f\"📊 Total de generaciones: {neuroevolution.generation}\")\n",
    "print(f\"🏆 Mejor fitness alcanzado: {best_genome['fitness']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555d9b",
   "metadata": {},
   "source": [
    "## 8. Visualización y Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar estilo de matplotlib\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Función para visualizar la evolución del fitness\n",
    "def plot_fitness_evolution(neuroevolution):\n",
    "    \"\"\"Grafica la evolución del fitness a lo largo de las generaciones.\"\"\"\n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"⚠️ No hay datos de estadísticas para graficar\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extraer datos y filtrar fitness 0.00\n",
    "    generations = []\n",
    "    avg_fitness = []\n",
    "    max_fitness = []\n",
    "    min_fitness = []\n",
    "    std_fitness = []\n",
    "    \n",
    "    for stat in neuroevolution.generation_stats:\n",
    "        # Solo incluir si hay fitness válido (> 0.00)\n",
    "        if stat['max_fitness'] > 0.00:\n",
    "            generations.append(stat['generation'])\n",
    "            avg_fitness.append(stat['avg_fitness'])\n",
    "            max_fitness.append(stat['max_fitness'])\n",
    "            min_fitness.append(stat['min_fitness'])\n",
    "            std_fitness.append(stat['std_fitness'])\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"⚠️ No hay datos válidos de fitness para graficar (todos son 0.00)\")\n",
    "        return\n",
    "    \n",
    "    # Gráfico 1: Evolución del fitness\n",
    "    ax1.plot(generations, max_fitness, 'g-', linewidth=2, marker='o', label='Fitness Máximo')\n",
    "    ax1.plot(generations, avg_fitness, 'b-', linewidth=2, marker='s', label='Fitness Promedio')\n",
    "    ax1.plot(generations, min_fitness, 'r-', linewidth=2, marker='^', label='Fitness Mínimo')\n",
    "    ax1.fill_between(generations, \n",
    "                     [max(0, avg - std) for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     [avg + std for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     alpha=0.2, color='blue')\n",
    "    \n",
    "    ax1.set_xlabel('Generación')\n",
    "    ax1.set_ylabel('Fitness (%)')\n",
    "    ax1.set_title('Evolución del Fitness por Generación (Excluyendo 0.00%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir línea del fitness objetivo\n",
    "    ax1.axhline(y=CONFIG['fitness_threshold'], color='orange', linestyle='--', \n",
    "                label=f\"Objetivo ({CONFIG['fitness_threshold']}%)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Establecer límites del eje Y para mejor visualización\n",
    "    y_min = max(0, min(min_fitness) - 5)\n",
    "    y_max = min(100, max(max_fitness) + 5)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Gráfico 2: Diversidad (desviación estándar)\n",
    "    ax2.plot(generations, std_fitness, 'purple', linewidth=2, marker='D')\n",
    "    ax2.set_xlabel('Generación')\n",
    "    ax2.set_ylabel('Desviación Estándar del Fitness')\n",
    "    ax2.set_title('Diversidad de la Población (Excluyendo 0.00%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar información adicional\n",
    "    print(f\"📊 Datos graficados:\")\n",
    "    print(f\"   Generaciones con fitness válido: {len(generations)}\")\n",
    "    print(f\"   Mejor fitness alcanzado: {max(max_fitness):.2f}%\")\n",
    "    print(f\"   Fitness promedio final: {avg_fitness[-1]:.2f}%\")\n",
    "    if len(generations) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(generations)\n",
    "        print(f\"   ⚠️ Generaciones excluidas (fitness 0.00): {excluded}\")\n",
    "\n",
    "# Función para mostrar estadísticas detalladas\n",
    "def show_evolution_statistics(neuroevolution):\n",
    "    \"\"\"Muestra estadísticas detalladas de la evolución.\"\"\"\n",
    "    print(\"📊 ESTADÍSTICAS DETALLADAS DE LA EVOLUCIÓN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"⚠️ No hay estadísticas disponibles\")\n",
    "        return\n",
    "    \n",
    "    # Filtrar estadísticas con fitness válido\n",
    "    valid_stats = [stat for stat in neuroevolution.generation_stats if stat['max_fitness'] > 0.00]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"⚠️ No hay estadísticas válidas (todos los fitness son 0.00)\")\n",
    "        return\n",
    "    \n",
    "    final_stats = valid_stats[-1]\n",
    "    \n",
    "    print(f\"🧬 Generaciones completadas: {neuroevolution.generation}\")\n",
    "    print(f\"🧬 Generaciones con fitness válido: {len(valid_stats)}\")\n",
    "    if len(valid_stats) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(valid_stats)\n",
    "        print(f\"⚠️ Generaciones con fitness 0.00 (excluidas): {excluded}\")\n",
    "    \n",
    "    print(f\"\\n🏆 ESTADÍSTICAS FINALES (excluyendo fitness 0.00):\")\n",
    "    print(f\"   Mejor fitness final: {final_stats['max_fitness']:.2f}%\")\n",
    "    print(f\"   Fitness promedio final: {final_stats['avg_fitness']:.2f}%\")\n",
    "    print(f\"   Fitness mínimo final: {final_stats['min_fitness']:.2f}%\")\n",
    "    print(f\"   Desviación estándar final: {final_stats['std_fitness']:.2f}%\")\n",
    "    \n",
    "    # Progreso a lo largo de las generaciones\n",
    "    if len(valid_stats) > 1:\n",
    "        initial_max = valid_stats[0]['max_fitness']\n",
    "        final_max = valid_stats[-1]['max_fitness']\n",
    "        improvement = final_max - initial_max\n",
    "        \n",
    "        print(f\"\\n🚀 PROGRESO:\")\n",
    "        print(f\"   Fitness inicial: {initial_max:.2f}%\")\n",
    "        print(f\"   Fitness final: {final_max:.2f}%\")\n",
    "        print(f\"   Mejora total: {improvement:.2f}%\")\n",
    "        if initial_max > 0:\n",
    "            print(f\"   Mejora relativa: {(improvement/initial_max)*100:.1f}%\")\n",
    "    \n",
    "    # Análisis de convergencia\n",
    "    print(f\"\\n🎯 CRITERIOS DE CONVERGENCIA:\")\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['fitness'] >= CONFIG['fitness_threshold']:\n",
    "        print(f\"   ✅ Fitness objetivo alcanzado ({CONFIG['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   ❌ Fitness objetivo NO alcanzado ({CONFIG['fitness_threshold']}%)\")\n",
    "    \n",
    "    if neuroevolution.generation >= CONFIG['max_generations']:\n",
    "        print(f\"   ⏰ Máximo de generaciones alcanzado ({CONFIG['max_generations']})\")\n",
    "    \n",
    "    # Estadísticas adicionales de rendimiento\n",
    "    all_max_fitness = [stat['max_fitness'] for stat in valid_stats]\n",
    "    all_avg_fitness = [stat['avg_fitness'] for stat in valid_stats]\n",
    "    \n",
    "    print(f\"\\n📈 ESTADÍSTICAS GENERALES:\")\n",
    "    print(f\"   Mejor fitness de toda la evolución: {max(all_max_fitness):.2f}%\")\n",
    "    print(f\"   Fitness promedio de toda la evolución: {np.mean(all_avg_fitness):.2f}%\")\n",
    "    print(f\"   Mejora promedio por generación: {(max(all_max_fitness) - min(all_max_fitness))/len(valid_stats):.2f}%\")\n",
    "    \n",
    "    if neuroevolution.best_individual:\n",
    "        print(f\"\\n💾 ID del mejor individuo: {neuroevolution.best_individual['id']}\")\n",
    "        print(f\"💾 Fitness del mejor individuo: {neuroevolution.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "# Función adicional para análisis de fallos\n",
    "def analyze_failed_evaluations(neuroevolution):\n",
    "    \"\"\"Analiza las evaluaciones que resultaron en fitness 0.00.\"\"\"\n",
    "    print(\"\\n🔍 ANÁLISIS DE EVALUACIONES FALLIDAS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_generations = len(neuroevolution.generation_stats)\n",
    "    failed_generations = len([stat for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00])\n",
    "    \n",
    "    if failed_generations == 0:\n",
    "        print(\"✅ No hubo evaluaciones fallidas (fitness 0.00)\")\n",
    "        return\n",
    "    \n",
    "    success_rate = ((total_generations - failed_generations) / total_generations) * 100\n",
    "    \n",
    "    print(f\"📊 Resumen de fallos:\")\n",
    "    print(f\"   Total de generaciones: {total_generations}\")\n",
    "    print(f\"   Generaciones fallidas: {failed_generations}\")\n",
    "    print(f\"   Tasa de éxito: {success_rate:.1f}%\")\n",
    "    \n",
    "    if failed_generations > 0:\n",
    "        failed_gens = [stat['generation'] for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00]\n",
    "        print(f\"   Generaciones con fallos: {failed_gens}\")\n",
    "        \n",
    "        print(f\"\\n💡 Posibles causas de fitness 0.00:\")\n",
    "        print(f\"   • Errores en la arquitectura del modelo\")\n",
    "        print(f\"   • Problemas de memoria (GPU/RAM)\")\n",
    "        print(f\"   • Configuraciones inválidas de hiperparámetros\")\n",
    "        print(f\"   • Errores durante el entrenamiento\")\n",
    "\n",
    "# Ejecutar visualizaciones\n",
    "plot_fitness_evolution(neuroevolution)\n",
    "show_evolution_statistics(neuroevolution)\n",
    "analyze_failed_evaluations(neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6688660",
   "metadata": {},
   "source": [
    "## 9. 🏆 MEJOR ARQUITECTURA ENCONTRADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a847dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_best_architecture(best_genome, config):\n",
    "    \"\"\"\n",
    "    Muestra la mejor arquitectura encontrada de forma detallada y visual.\n",
    "    \"\"\"\n",
    "    print(\"🏆\" * 60)\n",
    "    print(\"        MEJOR ARQUITECTURA EVOLUCIONADA\")\n",
    "    print(\"🏆\" * 60)\n",
    "    \n",
    "    # Información general\n",
    "    print(f\"\\n🔖 INFORMACIÓN GENERAL:\")\n",
    "    print(f\"   📌 ID del Genoma: {best_genome['id']}\")\n",
    "    print(f\"   🎯 Fitness Alcanzado: {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   🧬 Generación: {neuroevolution.generation}\")\n",
    "    \n",
    "    # Detalles de la arquitectura\n",
    "    print(f\"\\n🏗️ ARQUITECTURA DE LA RED:\")\n",
    "    print(f\"   🔵 Capas Convolucionales: {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   🔶 Capas Completamente Conectadas: {best_genome['num_fc_layers']}\")\n",
    "    \n",
    "    print(f\"\\n📊 DETALLES DE CAPAS CONVOLUCIONALES:\")\n",
    "    for i in range(best_genome['num_conv_layers']):\n",
    "        filters = best_genome['filters'][i]\n",
    "        kernel = best_genome['kernel_sizes'][i]\n",
    "        activation = best_genome['activations'][i % len(best_genome['activations'])]\n",
    "        print(f\"   Conv{i+1}: {filters} filtros, kernel {kernel}x{kernel}, activación {activation}\")\n",
    "    \n",
    "    print(f\"\\n🔗 DETALLES DE CAPAS COMPLETAMENTE CONECTADAS:\")\n",
    "    for i, nodes in enumerate(best_genome['fc_nodes']):\n",
    "        print(f\"   FC{i+1}: {nodes} neuronas\")\n",
    "    print(f\"   Output: {config['num_classes']} neuronas (clases)\")\n",
    "    \n",
    "    print(f\"\\n⚙️ HIPERPARÁMETROS:\")\n",
    "    print(f\"   🎛️ Optimizador: {best_genome['optimizer'].upper()}\")\n",
    "    print(f\"   📈 Learning Rate: {best_genome['learning_rate']:.4f}\")\n",
    "    print(f\"   🚫 Dropout Rate: {best_genome['dropout_rate']:.3f}\")\n",
    "    print(f\"   🧮 Funciones de Activación: {', '.join(best_genome['activations'])}\")\n",
    "    \n",
    "    # Crear y mostrar el modelo\n",
    "    print(f\"\\n🔧 CREANDO MODELO FINAL...\")\n",
    "    try:\n",
    "        final_model = EvolvableCNN(best_genome, config)\n",
    "        total_params = sum(p.numel() for p in final_model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"   ✅ Modelo creado exitosamente\")\n",
    "        print(f\"   📊 Total de parámetros: {total_params:,}\")\n",
    "        print(f\"   🎯 Parámetros entrenables: {trainable_params:,}\")\n",
    "        \n",
    "        # Resumen de la arquitectura\n",
    "        print(f\"\\n📋 RESUMEN COMPACTO:\")\n",
    "        print(f\"   {final_model.get_architecture_summary()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error creando el modelo: {e}\")\n",
    "    \n",
    "    # Visualización en formato tabla\n",
    "    print(f\"\\n📊 TABLA RESUMEN:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Parámetro':<25} {'Valor':<30} {'Descripción':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'ID':<25} {best_genome['id']:<30} {'Identificador único':<25}\")\n",
    "    print(f\"{'Fitness':<25} {best_genome['fitness']:.2f}%{'':<25} {'Precisión alcanzada':<25}\")\n",
    "    print(f\"{'Conv Layers':<25} {best_genome['num_conv_layers']:<30} {'Capas convolucionales':<25}\")\n",
    "    print(f\"{'FC Layers':<25} {best_genome['num_fc_layers']:<30} {'Capas FC':<25}\")\n",
    "    print(f\"{'Optimizer':<25} {best_genome['optimizer']:<30} {'Algoritmo optimización':<25}\")\n",
    "    print(f\"{'Learning Rate':<25} {best_genome['learning_rate']:<30} {'Tasa de aprendizaje':<25}\")\n",
    "    print(f\"{'Dropout':<25} {best_genome['dropout_rate']:<30} {'Tasa de dropout':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Comparación con configuración inicial\n",
    "    print(f\"\\n📈 COMPARACIÓN CON OBJETIVOS:\")\n",
    "    if best_genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"   🎯 ✅ Objetivo de fitness ALCANZADO ({best_genome['fitness']:.2f}% >= {config['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   🎯 ❌ Objetivo de fitness NO alcanzado ({best_genome['fitness']:.2f}% < {config['fitness_threshold']}%)\")\n",
    "    \n",
    "    print(f\"   ⏰ Generaciones utilizadas: {neuroevolution.generation}/{config['max_generations']}\")\n",
    "    \n",
    "    # Guardar información en JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'execution_time': str(execution_time),\n",
    "        'config_used': config,\n",
    "        'best_genome': best_genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\n💾 Resultados guardados en: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Error guardando resultados: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 ¡NEUROEVOLUCIÓN HÍBRIDA COMPLETADA EXITOSAMENTE!\")\n",
    "    print(f\"{'🏆' * 60}\")\n",
    "\n",
    "# Mostrar la mejor arquitectura encontrada\n",
    "display_best_architecture(best_genome, CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
