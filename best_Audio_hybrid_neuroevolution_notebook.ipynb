{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77d426",
   "metadata": {},
   "source": [
    "# Audio Hybrid Neuroevolution Notebook\n",
    "\n",
    "This notebook implements a hybrid neuroevolution process for audio classification (Parkinson detection). The system combines genetic algorithms with 1D convolutional neural networks to evolve optimal architectures for audio processing.\n",
    "\n",
    "## Main Features:\n",
    "- **Hybrid genetic algorithm**: Combines architecture and weight evolution\n",
    "- **1D Convolutional Networks**: Optimized for audio waveform processing\n",
    "- **Parallel 5-Fold Cross-Validation**: Each individual is evaluated on all 5 folds IN PARALLEL (fitness = average accuracy)\n",
    "- **Multi-threading**: Folds are trained simultaneously in separate threads for faster evaluation\n",
    "- **Adaptive mutation**: Dynamic mutation rate based on population diversity\n",
    "- **Audio dataset support**: Loads .npy files with train/val/test splits\n",
    "- **Intelligent stopping criteria**: By target fitness or maximum generations\n",
    "- **Complete visualization**: Shows progress and final best architecture\n",
    "\n",
    "## Objectives:\n",
    "1. Create initial population of 1D CNN architectures\n",
    "2. Evaluate fitness of each individual using **parallel 5-fold CV** (robust and faster with threading)\n",
    "3. Select best architectures (elitism)\n",
    "4. Apply crossover and mutation to create new generation\n",
    "5. Repeat process until convergence\n",
    "6. Display the best architecture found for Parkinson classification\n",
    "\n",
    "**âœ… Performance**: Multi-threaded 5-fold CV provides robustness against overfitting while being much faster than sequential training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f49a8",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ¨ CONFIGURACIÃ“N ACTUAL DEL DATASET âœ¨\n",
    "\n",
    "**Dataset configurado**: `files_all_real_syn_n` (Datos Reales + SintÃ©ticos Mezclados)\n",
    "\n",
    "Este notebook estÃ¡ configurado para usar el **nuevo dataset** que combina:\n",
    "- ðŸŽµ **Datos Reales**: Audios originales de pacientes  \n",
    "- ðŸ¤– **Datos SintÃ©ticos**: Audios generados por GANs (BigVSAN 40_1e5)\n",
    "\n",
    "**Ventajas de este dataset**:\n",
    "- Mayor diversidad de datos para entrenamiento\n",
    "- Combina la autenticidad de datos reales con la variedad de datos generados\n",
    "- Ideal para mejorar la generalizaciÃ³n del modelo\n",
    "- EstratificaciÃ³n balanceada entre clases (control/patolÃ³gico)\n",
    "\n",
    "**ðŸš€ Parallel 5-Fold Cross-Validation durante la EvoluciÃ³n**: \n",
    "- **CADA** individuo se evalÃºa en **TODOS** los 5 folds **EN PARALELO**\n",
    "- Los 5 folds se entrenan **simultÃ¡neamente** en threads separados\n",
    "- El fitness es el **promedio** de accuracy de los 5 folds\n",
    "- âœ… **Mucho mÃ¡s rÃ¡pido** que entrenamiento secuencial\n",
    "- âœ… **MÃ¡s robusto** - evita sobreajuste a un fold especÃ­fico\n",
    "\n",
    "**ðŸ“Š EvaluaciÃ³n Final**: \n",
    "- Al terminar la evoluciÃ³n, la mejor arquitectura se vuelve a evaluar con 5-fold CV\n",
    "- Se reportan mÃ©tricas completas (accuracy, sensitivity, specificity, F1, AUC)\n",
    "\n",
    "Para cambiar el dataset, modifica los parÃ¡metros `dataset_id` y `fold_id` en la celda de **ConfiguraciÃ³n** (SecciÃ³n 2).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3cfb",
   "metadata": {},
   "source": [
    "## 1. Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50120a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dependency installation for Hybrid Neuroevolution...\n",
      "============================================================\n",
      "Installing torch>=2.0.0...\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torch>=2.0.0 installed correctly\n",
      "Installing torchvision>=0.15.0...\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (1.24.4)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torchvision>=0.15.0) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (10.0.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->torchvision>=0.15.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision>=0.15.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.8.0->torchvision>=0.15.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torchvision>=0.15.0 installed correctly\n",
      "Installing numpy>=1.21.0...\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK numpy>=1.21.0 installed correctly\n",
      "Installing matplotlib>=3.5.0...\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK matplotlib>=3.5.0 installed correctly\n",
      "Installing seaborn>=0.11.0...\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK seaborn>=0.11.0 installed correctly\n",
      "Installing tqdm>=4.64.0...\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (4.65.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK tqdm>=4.64.0 installed correctly\n",
      "Installing jupyter>=1.0.0...\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.5.4)\n",
      "Requirement already satisfied: jupyter-console in /home/jovyan/.local/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (8.0.6)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (4.0.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (3.0.7)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.0.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (3.1.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.7.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (3.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter>=1.0.0) (4.14.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (0.5.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0) (3.8.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.7.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (7.3.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.6.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0) (2.17.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->notebook->jupyter>=1.0.0) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0) (2.3.2.post1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.19.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (2.21)\n",
      "Requirement already satisfied: fqdn in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0)\n",
      "Requirement already satisfied: uri-template in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/jovyan/.local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.9.0.20250809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK jupyter>=1.0.0 installed correctly\n",
      "Installing ipywidgets>=8.0.0...\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in /opt/conda/lib/python3.11/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (6.3.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ipywidgets>=8.0.0 installed correctly\n",
      "\n",
      "All dependencies have been verified/installed\n",
      "Restart the kernel if this is the first time installing torch\n",
      "============================================================\n",
      "\n",
      "PyTorch 2.8.0+cu128 installed correctly\n",
      "CUDA available: Yes\n",
      "GPU detected: NVIDIA A100-PCIE-40GB MIG 7g.40gb\n",
      "GPU memory: 39 GB\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if not available.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"OK {package.split('==')[0]} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"OK {package} installed correctly\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Starting dependency installation for Hybrid Neuroevolution...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nAll dependencies have been verified/installed\")\n",
    "print(\"Restart the kernel if this is the first time installing torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch {torch.__version__} installed correctly\")\n",
    "    print(f\"CUDA available: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: PyTorch could not be installed correctly\")\n",
    "    print(\"Try installing manually with: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865869c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configured: cuda\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Threading for parallel fold training\n",
    "import threading\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device configured: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1181c2a",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a6e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded (adaptive mutation enabled, 1D Conv for audio):\n",
      "   Dataset: Audio (Parkinson Classification)\n",
      "   population_size: 20\n",
      "   max_generations: 100\n",
      "   fitness_threshold: 80.0\n",
      "   base_mutation_rate: 0.25\n",
      "   mutation_rate_min: 0.1\n",
      "   mutation_rate_max: 0.8\n",
      "   current_mutation_rate: 0.25\n",
      "   crossover_rate: 0.99\n",
      "   elite_percentage: 0.2\n",
      "   dataset: AUDIO\n",
      "   num_channels: 1\n",
      "   sequence_length: 240000\n",
      "   num_classes: 2\n",
      "   batch_size: 64\n",
      "   test_split: 0.2\n",
      "   num_epochs: 100\n",
      "   learning_rate: 1e-05\n",
      "   early_stopping_patience: 100000\n",
      "   epoch_patience: 10\n",
      "   improvement_threshold: 0.01\n",
      "   early_stopping_generations: 20\n",
      "   min_improvement_threshold: 0.01\n",
      "   min_conv_layers: 1\n",
      "   max_conv_layers: 30\n",
      "   min_fc_layers: 1\n",
      "   max_fc_layers: 10\n",
      "   min_filters: 1\n",
      "   max_filters: 256\n",
      "   min_fc_nodes: 64\n",
      "   max_fc_nodes: 1024\n",
      "   kernel_size_options: [1, 3, 5, 7, 9, 11, 13, 15]\n",
      "   min_dropout: 0.2\n",
      "   max_dropout: 0.6\n",
      "   learning_rate_options: [0.001, 0.0005, 0.0001, 5e-05, 1e-05, 0.01, 0.1, 1e-05]\n",
      "   normalization_batch_weight: 0.8\n",
      "   normalization_layer_weight: 0.2\n",
      "   dataset_id: 40_1e5_N\n",
      "   fold_id: 40_1e5_N\n",
      "   num_folds: 5\n",
      "   data_path: data/sets/folds_5\n",
      "   fold_files_subdirectory: files_real_40_1e5_N\n",
      "\n",
      "Available activation functions: ['relu', 'leaky_relu', 'tanh', 'sigmoid', 'selu']\n",
      "Available optimizers: ['adam', 'adamw', 'sgd', 'rmsprop']\n",
      "\n",
      "OS-independent path configured: data/sets/folds_5\n"
     ]
    }
   ],
   "source": [
    "# Main genetic algorithm configuration (updated for adaptive mutation & moderate elitism)\n",
    "CONFIG = {\n",
    "    # Genetic algorithm parameters\n",
    "    'population_size': 20,            # Population size\n",
    "    'max_generations': 100,            # Maximum number of generations\n",
    "    'fitness_threshold': 80.0,        # Target fitness (% accuracy) - Adjusted for audio\n",
    "\n",
    "    # Adaptive mutation parameters\n",
    "    'base_mutation_rate': 0.25,       # Starting mutation rate (moderate)\n",
    "    'mutation_rate_min': 0.10,        # Lower bound for adaptive mutation\n",
    "    'mutation_rate_max': 0.80,        # Upper bound for adaptive mutation\n",
    "    'current_mutation_rate': 0.25,    # Will be updated dynamically each generation\n",
    "\n",
    "    'crossover_rate': 0.99,           # Crossover rate\n",
    "    'elite_percentage': 0.2,          # Moderate elitism (20%) instead of 40%\n",
    "\n",
    "    # Dataset selection (AUDIO ONLY)\n",
    "    'dataset': 'AUDIO',               # Audio dataset for Parkinson classification\n",
    "\n",
    "    # Dataset parameters for audio\n",
    "    'num_channels': 1,                # Input channels (1 for audio waveform)\n",
    "    'sequence_length': 240000,        # Audio sequence length (will be auto-detected)\n",
    "    'num_classes': 2,                 # Number of classes (control vs pathological)\n",
    "    'batch_size': 64,                 # Batch size for audio\n",
    "    'test_split': 0.2,                # Validation percentage\n",
    "\n",
    "    # Training parameters\n",
    "    'num_epochs': 100,                 # Max training epochs per evaluation (may stop earlier)\n",
    "    'learning_rate': 0.00001,           # Base learning rate\n",
    "    'early_stopping_patience': 100000,   # Max batches per epoch (quick partial epoch)\n",
    "\n",
    "    # Epoch-level early stopping\n",
    "    'epoch_patience': 10,              # Stop if no significant improvement after N evaluations\n",
    "    'improvement_threshold': 0.01,     # Minimum (absolute) accuracy gain (%) to reset patience\n",
    "\n",
    "    # Generation-level early stopping \n",
    "    'early_stopping_generations': 20, # Stop if no improvement in X generations\n",
    "    'min_improvement_threshold': 0.01, # Minimum fitness improvement (%) to reset counter\n",
    "\n",
    "    # Allowed architecture range for 1D Conv\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 30,             # Less layers for 1D audio\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 10,               # Less FC layers\n",
    "    'min_filters': 1,\n",
    "    'max_filters': 256,               # Adjusted for 1D\n",
    "    'min_fc_nodes': 64,\n",
    "    'max_fc_nodes': 1024,              # Smaller for audio classification\n",
    "\n",
    "    # Mutation parameters - Kernel sizes for 1D Conv\n",
    "    'kernel_size_options': [1, 3, 5, 7, 9, 11, 13, 15],  # Available kernel sizes for Conv1D\n",
    "    \n",
    "    # Mutation parameters - Dropout range\n",
    "    'min_dropout': 0.2,               # Minimum dropout rate\n",
    "    'max_dropout': 0.6,               # Maximum dropout rate\n",
    "    \n",
    "    # Mutation parameters - Learning rate options\n",
    "    'learning_rate_options': [0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.01, 0.1, 0.00001 ],  # Available learning rates\n",
    "    \n",
    "    # Mutation parameters - Normalization type weights\n",
    "    'normalization_batch_weight': 0.8,  # Probability to use batch normalization\n",
    "    'normalization_layer_weight': 0.2,  # Probability to use layer normalization\n",
    "\n",
    "    # Audio dataset configuration (OS-independent paths)\n",
    "    \n",
    "    'dataset_id': '40_1e5_N',   # Dataset ID - Mixed real + synthetic data\n",
    "    'fold_id': '40_1e5_N',      # Fold ID for files\n",
    "    'num_folds': 5,                   # Number of folds (all used during evolution)\n",
    "    'data_path': os.path.join('data', 'sets', 'folds_5'),  # OS-independent path\n",
    "    'fold_files_subdirectory': 'files_real_40_1e5_N',  # Subdirectory containing fold .npy files\n",
    "    'normalization': {'mean': (0.0,), 'std': (1.0,)}  # Audio normalization\n",
    "}\n",
    "\n",
    "# Activation function mapping\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Optimizer mapping\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded (adaptive mutation enabled, 1D Conv for audio):\")\n",
    "print(f\"   Dataset: Audio (Parkinson Classification)\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key not in ['normalization']:  # Hide normalization details\n",
    "        print(f\"   {key}: {value}\")\n",
    "print(f\"\\nAvailable activation functions: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"Available optimizers: {list(OPTIMIZERS.keys())}\")\n",
    "print(f\"\\nOS-independent path configured: {CONFIG['data_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d2e08",
   "metadata": {},
   "source": [
    "### ðŸ“‹ ParÃ¡metros de MutaciÃ³n Configurables\n",
    "\n",
    "**Todos los parÃ¡metros de mutaciÃ³n ahora son configurables desde `CONFIG`**:\n",
    "\n",
    "#### Kernel Sizes (TamaÃ±os de kernel para Conv1D)\n",
    "- **`kernel_size_options`**: `[3, 5, 7, 9, 11, 13, 15]`\n",
    "  - Opciones disponibles para los tamaÃ±os de kernel en capas convolucionales 1D\n",
    "  - Se usa tanto en la creaciÃ³n inicial como en la mutaciÃ³n\n",
    "\n",
    "#### Dropout Range (Rango de dropout)\n",
    "- **`min_dropout`**: `0.2` - Tasa mÃ­nima de dropout\n",
    "- **`max_dropout`**: `0.6` - Tasa mÃ¡xima de dropout\n",
    "  - Durante la creaciÃ³n y mutaciÃ³n, el dropout se selecciona aleatoriamente dentro de este rango\n",
    "\n",
    "#### Learning Rate Options (Opciones de learning rate)\n",
    "- **`learning_rate_options`**: `[0.001, 0.0005, 0.0001, 0.00005, 0.00001]`\n",
    "  - Opciones disponibles para el learning rate\n",
    "  - Se selecciona aleatoriamente de esta lista durante creaciÃ³n y mutaciÃ³n\n",
    "\n",
    "#### Normalization Type Weights (Pesos para tipo de normalizaciÃ³n)\n",
    "- **`normalization_batch_weight`**: `0.8` - Probabilidad de usar batch normalization (80%)\n",
    "- **`normalization_layer_weight`**: `0.2` - Probabilidad de usar layer normalization (20%)\n",
    "  - Durante la mutaciÃ³n, se selecciona el tipo de normalizaciÃ³n con estas probabilidades\n",
    "\n",
    "âœ… **Beneficio**: Ahora puedes ajustar todos estos parÃ¡metros desde un solo lugar (CONFIG) sin modificar las funciones de mutaciÃ³n o creaciÃ³n de genomas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4964cc1",
   "metadata": {},
   "source": [
    "### InformaciÃ³n sobre el Dataset de Audio\n",
    "\n",
    "**Dataset de Audio para ClasificaciÃ³n de Parkinson**: \n",
    "- Archivos de audio de voz (clasificaciÃ³n Parkinson)\n",
    "- Datos 1D de forma de onda procesada\n",
    "- Estructura: archivos .npy con train/val/test splits\n",
    "- Dificultad: **Alta** - ClasificaciÃ³n mÃ©dica\n",
    "- Fitness objetivo recomendado: >85%\n",
    "- Clases: Control vs Pathological\n",
    "- Formato de archivos: `{data_path}/files_{fold_id}/X_train_{dataset_id}_fold_{fold}.npy`\n",
    "- Arquitectura: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC Layers\n",
    "\n",
    "**ConfiguraciÃ³n del Dataset:**\n",
    "- Modifica los parÃ¡metros en la celda de configuraciÃ³n:\n",
    "  - `dataset_id`: ID del dataset (ej: 'all_real_syn_n')\n",
    "  - `fold_id`: ID de la carpeta de folds (ej: 'all_real_syn_n')\n",
    "  - `data_path`: Ruta base a los datos (usa `os.path.join` para compatibilidad multiplataforma)\n",
    "\n",
    "**ðŸ”„ Uso de 5-Fold CV:**\n",
    "- **Durante la evoluciÃ³n**: Cada individuo se evalÃºa en los 5 folds automÃ¡ticamente\n",
    "- **No se necesita** especificar `current_fold` (se usan todos)\n",
    "- El fitness es el **promedio** de los 5 folds\n",
    "\n",
    "**Nota sobre Rutas:**\n",
    "- Las rutas son **independientes del sistema operativo** (Windows/Linux/Mac)\n",
    "- Usa `os.path.join()` para construir rutas compatibles\n",
    "- Ejemplo: `os.path.join('data', 'sets', 'folds_5')` funciona en cualquier OS\n",
    "\n",
    "---\n",
    "\n",
    "### Tipos de Carpetas de Folds Disponibles (generadas por `create_5_folds.ipynb`)\n",
    "\n",
    "El notebook `generating_csv/create_5_folds.ipynb` genera **5 tipos de carpetas** con diferentes combinaciones de datos **reales** y **sintÃ©ticos** (generados por GANs) para experimentaciÃ³n:\n",
    "\n",
    "#### 1. **`files_real_N`** - Solo Datos Reales\n",
    "   - **Train**: Datos reales (`test_together_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Baseline con datos 100% reales\n",
    "   - **fold_id**: `'real_N'`\n",
    "   - **dataset_id**: `'real_N'`\n",
    "\n",
    "#### 2. **`files_real_40_1e5_N`** - Entrenamiento SintÃ©tico, Test Real\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Evaluar si modelos entrenados con sintÃ©ticos generalizan a datos reales\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 3. **`files_syn_40_1e5_N`** - Solo Datos SintÃ©ticos (mismo conjunto)\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Uso**: Evaluar capacidad del modelo con datos 100% sintÃ©ticos\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 4. **`files_syn_1_N`** - Entrenamiento SintÃ©tico, Test SintÃ©tico Diferente\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos sintÃ©ticos diferentes (`test_together_syn_1_N`)\n",
    "   - **Uso**: Evaluar generalizaciÃ³n entre diferentes conjuntos sintÃ©ticos\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 5. **`files_syn_all_N`** - Solo Datos Reales (mal nombrado probablemente)\n",
    "   - **Train**: Datos reales (`test_together_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Similar a `files_real_N` (posible duplicado o error de nomenclatura)\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 6. **`files_all_real_syn_n`** - âœ¨ Datos Reales + SintÃ©ticos Mezclados âœ¨ **(NUEVO)**\n",
    "   - **Train**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Validation**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Test**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Uso**: Entrenar y evaluar con una mezcla equilibrada de datos reales y generados por GANs\n",
    "   - **fold_id**: `'all_real_syn_n'`\n",
    "   - **dataset_id**: `'all_real_syn_n'`\n",
    "   - **Ventajas**: Combina diversidad de datos sintÃ©ticos con autenticidad de datos reales\n",
    "   - **ConfiguraciÃ³n actual**: ðŸ”µ **ESTE ES EL DATASET CONFIGURADO POR DEFECTO**\n",
    "\n",
    "**Nota**: Cada carpeta contiene 5 folds de validaciÃ³n cruzada con:\n",
    "- `X_train_{dataset_id}_fold_{1-5}.npy` y `y_train_{dataset_id}_fold_{1-5}.npy`\n",
    "- `X_val_{dataset_id}_fold_{1-5}.npy` y `y_val_{dataset_id}_fold_{1-5}.npy`\n",
    "- `X_test_{dataset_id}_fold_{1-5}.npy` y `y_test_{dataset_id}_fold_{1-5}.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6d37",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f98ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICANDO DISPONIBILIDAD DE DATOS\n",
      "============================================================\n",
      "Dataset ID: 40_1e5_N, Verificando los 5 folds...\n",
      "   Looking for: /home/jovyan/audio_test/data/sets/folds_5/files_real_40_1e5_N\n",
      "   âœ“ Directory found: /home/jovyan/audio_test/data/sets/folds_5/files_real_40_1e5_N\n",
      "\n",
      "Checking for all 5 folds...\n",
      "   âœ“ Fold 1: All files present\n",
      "   âœ“ Fold 2: All files present\n",
      "   âœ“ Fold 3: All files present\n",
      "   âœ“ Fold 4: All files present\n",
      "   âœ“ Fold 5: All files present\n",
      "\n",
      "âœ“ All 5 folds verified successfully!\n",
      "\n",
      "Loading Fold 1 to detect sequence length...\n",
      "   Train samples: (7200, 11520)\n",
      "   Sequence length detected: 11520\n",
      "\n",
      "âœ“ Dataset verification complete!\n",
      "   During evolution, each individual will train on all 5 folds.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET READY FOR 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "   Sequence length: 11520\n",
      "   Input channels: 1\n",
      "   Number of classes: 2\n",
      "   Batch size: 64\n",
      "   Audio classification task: Control (0) vs Pathological (1)\n",
      "\n",
      "   âš ï¸ Each individual will be evaluated on ALL 5 folds\n",
      "   âš ï¸ This makes evolution ~5x slower but much more robust\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(config: dict) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Loads the audio dataset according to configuration.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading audio dataset from: {config['data_path']}\")\n",
    "    print(f\"Dataset ID: {config['dataset_id']}, Fold: {config['current_fold']}\")\n",
    "    \n",
    "    # Construct paths following ResNet convention\n",
    "    fold_files_directory = os.path.join(\n",
    "        config['data_path'], \n",
    "        f\"files_real_{config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    # Check if directory exists\n",
    "    print(f\"\\nChecking data directory...\")\n",
    "    print(f\"   Looking for: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    if not os.path.exists(fold_files_directory):\n",
    "        print(f\"\\nâŒ ERROR: Directory not found!\")\n",
    "        print(f\"   Expected: {os.path.abspath(fold_files_directory)}\")\n",
    "        \n",
    "        # Try to find the correct path\n",
    "        possible_paths = [\n",
    "            os.path.join('..', 'data', 'sets', 'folds_5', f\"files_real_{config['fold_id']}\"),\n",
    "            os.path.join('data', 'sets', 'folds_5', f\"files_real_{config['fold_id']}\"),\n",
    "            os.path.join('.', 'data', 'sets', 'folds_5', f\"files_real_{config['fold_id']}\"),\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nSearching for data in alternative locations:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = os.path.exists(path)\n",
    "            print(f\"   {'âœ“' if exists else 'âœ—'} {abs_path}\")\n",
    "            if exists:\n",
    "                fold_files_directory = path\n",
    "                print(f\"\\nâœ“ Found data at: {os.path.abspath(fold_files_directory)}\")\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"\\nâŒ Could not find data directory!\\n\"\n",
    "                f\"   Tried paths:\\n\" + \n",
    "                \"\\n\".join([f\"      - {os.path.abspath(p)}\" for p in possible_paths]) +\n",
    "                f\"\\n\\n   Please check:\\n\"\n",
    "                f\"      1. CONFIG['data_path'] is correct\\n\"\n",
    "                f\"      2. The data files exist\\n\"\n",
    "                f\"      3. The fold_files_subdirectory '{config['fold_files_subdirectory']}' is correct\\n\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"   âœ“ Directory found: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "def load_dataset(config: dict):\n",
    "    \"\"\"\n",
    "    Verifica que los datos existen y carga el primer fold para detectar sequence_length.\n",
    "    Durante la evoluciÃ³n, cada individuo cargarÃ¡ todos los folds automÃ¡ticamente.\n",
    "    \n",
    "    Args:\n",
    "        config: Diccionario de configuraciÃ³n\n",
    "    \n",
    "    Returns:\n",
    "        None (solo actualiza config['sequence_length'])\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VERIFICANDO DISPONIBILIDAD DE DATOS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dataset ID: {config['dataset_id']}, Verificando los 5 folds...\")\n",
    "    \n",
    "    # Build directory path using the configured subdirectory\n",
    "    fold_files_directory = os.path.join(\n",
    "        config['data_path'], \n",
    "        config['fold_files_subdirectory']\n",
    "    )\n",
    "    \n",
    "    print(f\"   Looking for: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    # If directory not found, try alternative locations\n",
    "    if not os.path.exists(fold_files_directory):\n",
    "        possible_paths = [\n",
    "            os.path.join('..', 'data', 'sets', 'folds_5', config['fold_files_subdirectory']),\n",
    "            os.path.join('data', 'sets', 'folds_5', config['fold_files_subdirectory']),\n",
    "            os.path.join('.', 'data', 'sets', 'folds_5', config['fold_files_subdirectory']),\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nSearching for data in alternative locations:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = os.path.exists(path)\n",
    "            print(f\"   {'âœ“' if exists else 'âœ—'} {abs_path}\")\n",
    "            if exists:\n",
    "                fold_files_directory = path\n",
    "                print(f\"\\nâœ“ Found data at: {os.path.abspath(fold_files_directory)}\")\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"\\nâŒ Could not find data directory!\\n\"\n",
    "                f\"   Tried paths:\\n\" + \n",
    "                \"\\n\".join([f\"      - {os.path.abspath(p)}\" for p in possible_paths]) +\n",
    "                f\"\\n\\n   Please check:\\n\"\n",
    "                f\"      1. CONFIG['data_path'] is correct\\n\"\n",
    "                f\"      2. The data files exist\\n\"\n",
    "                f\"      3. The fold_id '{config['fold_id']}' is correct\\n\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"   âœ“ Directory found: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    dataset_id = config['dataset_id']\n",
    "    \n",
    "    # Check that all 5 folds exist\n",
    "    print(f\"\\nChecking for all 5 folds...\")\n",
    "    all_folds_ok = True\n",
    "    \n",
    "    for fold_num in range(1, 6):\n",
    "        required_files = [\n",
    "            f'X_train_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_train_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'X_val_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_val_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'X_test_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_test_{dataset_id}_fold_{fold_num}.npy',\n",
    "        ]\n",
    "        \n",
    "        fold_ok = True\n",
    "        for filename in required_files:\n",
    "            filepath = os.path.join(fold_files_directory, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                fold_ok = False\n",
    "                all_folds_ok = False\n",
    "                print(f\"   âœ— Fold {fold_num}: Missing {filename}\")\n",
    "                break\n",
    "        \n",
    "        if fold_ok:\n",
    "            print(f\"   âœ“ Fold {fold_num}: All files present\")\n",
    "    \n",
    "    if not all_folds_ok:\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\nâŒ Some fold files are missing!\\n\"\n",
    "            f\"   Please ensure all 5 folds have complete data files.\\n\"\n",
    "            f\"   dataset_id: '{dataset_id}'\\n\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nâœ“ All 5 folds verified successfully!\")\n",
    "    \n",
    "    # Load first fold to detect sequence_length\n",
    "    print(f\"\\nLoading Fold 1 to detect sequence length...\")\n",
    "    x_train = np.load(os.path.join(fold_files_directory, f'X_train_{dataset_id}_fold_1.npy'))\n",
    "    \n",
    "    print(f\"   Train samples: {x_train.shape}\")\n",
    "    \n",
    "    # Update sequence length from actual data\n",
    "    if len(x_train.shape) == 2:  # (samples, sequence_length)\n",
    "        config['sequence_length'] = x_train.shape[1]\n",
    "    elif len(x_train.shape) == 3:  # Already (samples, channels, sequence_length)\n",
    "        config['sequence_length'] = x_train.shape[2]\n",
    "    \n",
    "    print(f\"   Sequence length detected: {config['sequence_length']}\")\n",
    "    print(f\"\\nâœ“ Dataset verification complete!\")\n",
    "    print(f\"   During evolution, each individual will train on all 5 folds.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Verify dataset availability\n",
    "load_dataset(CONFIG)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET READY FOR 5-FOLD CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Sequence length: {CONFIG['sequence_length']}\")\n",
    "print(f\"   Input channels: {CONFIG['num_channels']}\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Audio classification task: Control (0) vs Pathological (1)\")\n",
    "print(f\"\\n   âš ï¸ Each individual will be evaluated on ALL 5 folds\")\n",
    "print(f\"   âš ï¸ This makes evolution ~5x slower but much more robust\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52de67",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc6abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvolvableCNN class defined correctly (Conv1D for audio with architecture validation)\n"
     ]
    }
   ],
   "source": [
    "class EvolvableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolvable CNN class for 1D audio processing.\n",
    "    Uses Conv1D layers for audio/sequential data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Validate and fix genome structure before building\n",
    "        self._validate_genome()\n",
    "        \n",
    "        # Build convolutional layers (1D for audio)\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calculate output size after convolutions\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "    \n",
    "    def _validate_genome(self):\n",
    "        \"\"\"Validates and fixes genome structure to ensure consistency.\"\"\"\n",
    "        # Ensure conv-related lists match num_conv_layers\n",
    "        num_conv = self.genome['num_conv_layers']\n",
    "        \n",
    "        if len(self.genome['filters']) != num_conv:\n",
    "            # Fix filters list\n",
    "            self.genome['filters'] = self.genome['filters'][:num_conv]\n",
    "            while len(self.genome['filters']) < num_conv:\n",
    "                self.genome['filters'].append(\n",
    "                    random.randint(self.config['min_filters'], self.config['max_filters'])\n",
    "                )\n",
    "        \n",
    "        if len(self.genome['kernel_sizes']) != num_conv:\n",
    "            # Fix kernel_sizes list\n",
    "            self.genome['kernel_sizes'] = self.genome['kernel_sizes'][:num_conv]\n",
    "            while len(self.genome['kernel_sizes']) < num_conv:\n",
    "                self.genome['kernel_sizes'].append(\n",
    "                    random.choice(self.config['kernel_size_options'])\n",
    "                )\n",
    "        \n",
    "        # Ensure fc-related lists match num_fc_layers\n",
    "        num_fc = self.genome['num_fc_layers']\n",
    "        \n",
    "        if len(self.genome['fc_nodes']) != num_fc:\n",
    "            # Fix fc_nodes list\n",
    "            self.genome['fc_nodes'] = self.genome['fc_nodes'][:num_fc]\n",
    "            while len(self.genome['fc_nodes']) < num_fc:\n",
    "                self.genome['fc_nodes'].append(\n",
    "                    random.randint(self.config['min_fc_nodes'], self.config['max_fc_nodes'])\n",
    "                )\n",
    "        \n",
    "    def _build_conv_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds 1D convolutional layers according to genome.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        normalization_type = self.genome.get('normalization_type', 'batch')  # Default to batch normalization\n",
    "\n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            # Safe access with validation\n",
    "            if i >= len(self.genome['filters']) or i >= len(self.genome['kernel_sizes']):\n",
    "                raise IndexError(\n",
    "                    f\"Genome list mismatch: i={i}, num_conv_layers={self.genome['num_conv_layers']}, \"\n",
    "                    f\"filters_len={len(self.genome['filters'])}, kernel_sizes_len={len(self.genome['kernel_sizes'])}\"\n",
    "                )\n",
    "            \n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Ensure kernel size is odd and reasonable for 1D\n",
    "            kernel_size = max(3, kernel_size if kernel_size % 2 == 1 else kernel_size + 1)\n",
    "            padding = kernel_size // 2\n",
    "            \n",
    "            # 1D Convolutional layer\n",
    "            conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Normalization layer (Layer Normalization or Batch Normalization)\n",
    "            if normalization_type == 'layer':\n",
    "                # Layer Normalization: normaliza sobre features, no sobre batch\n",
    "                # Para Conv1d output de shape (batch, channels, length), normalizamos los channels\n",
    "                layers.append(nn.LayerNorm(out_channels))\n",
    "            else:\n",
    "                # Batch normalization (default)\n",
    "                layers.append(nn.BatchNorm1d(out_channels))\n",
    "            \n",
    "            # Activation function\n",
    "            activation_name = self.genome['activations'][i % len(self.genome['activations'])]\n",
    "            activation_func = ACTIVATION_FUNCTIONS[activation_name]()\n",
    "            layers.append(activation_func)\n",
    "            \n",
    "            # Max pooling (1D) - reduce sequence length\n",
    "            pool_size = 2 if i < self.genome['num_conv_layers'] - 1 else 2\n",
    "            layers.append(nn.MaxPool1d(pool_size, pool_size))\n",
    "            \n",
    "            # Optional dropout after pooling\n",
    "            if i < self.genome['num_conv_layers'] - 1:\n",
    "                layers.append(nn.Dropout(0.1))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Calculates output size after convolutional layers.\n",
    "        Raises ValueError if the architecture produces invalid dimensions.\n",
    "        \"\"\"\n",
    "        # Create dummy tensor to calculate size\n",
    "        dummy_input = torch.zeros(1, self.config['num_channels'], \n",
    "                                 self.config['sequence_length'])\n",
    "        \n",
    "        # Pass through convolutional layers with validation\n",
    "        x = dummy_input\n",
    "        normalization_type = self.genome.get('normalization_type', 'batch')\n",
    "        \n",
    "        try:\n",
    "            # Set model to eval mode to avoid BatchNorm training issues with batch_size=1\n",
    "            self.eval()\n",
    "            \n",
    "            for layer in self.conv_layers:\n",
    "                # Check dimensions before BatchNorm layers\n",
    "                if isinstance(layer, nn.BatchNorm1d) and normalization_type == 'batch':\n",
    "                    # Check if spatial dimension is too small for BatchNorm\n",
    "                    if x.shape[2] <= 1:  # spatial dimension\n",
    "                        raise ValueError(\n",
    "                            f\"Invalid architecture: spatial dimension too small ({x.shape[2]}) \"\n",
    "                            f\"for BatchNorm1d. This genome produces architectures that are too deep. \"\n",
    "                            f\"Genome: num_conv_layers={self.genome['num_conv_layers']}, \"\n",
    "                            f\"sequence_length={self.config['sequence_length']}\"\n",
    "                        )\n",
    "                \n",
    "                x = layer(x)\n",
    "                \n",
    "                # Additional check after each layer\n",
    "                if x.shape[2] < 1:\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid architecture: sequence length became zero or negative. \"\n",
    "                        f\"Current shape: {x.shape}, \"\n",
    "                        f\"Genome: num_conv_layers={self.genome['num_conv_layers']}\"\n",
    "                    )\n",
    "            \n",
    "            # Back to training mode\n",
    "            self.train()\n",
    "            \n",
    "        except ValueError as e:\n",
    "            # Re-raise our custom validation errors\n",
    "            raise e\n",
    "        except Exception as e:\n",
    "            # Catch any other errors during size calculation\n",
    "            raise ValueError(\n",
    "                f\"Error calculating conv output size: {str(e)}. \"\n",
    "                f\"Genome may produce invalid architecture. \"\n",
    "                f\"num_conv_layers={self.genome['num_conv_layers']}, \"\n",
    "                f\"sequence_length={self.config['sequence_length']}\"\n",
    "            )\n",
    "        \n",
    "        # Flatten and get size\n",
    "        flattened_size = x.view(-1).shape[0]\n",
    "        \n",
    "        # Ensure we have a reasonable output size\n",
    "        if flattened_size < 1:\n",
    "            raise ValueError(\n",
    "                f\"Invalid architecture: flattened size is {flattened_size}. \"\n",
    "                f\"The architecture is too aggressive in dimension reduction.\"\n",
    "            )\n",
    "        \n",
    "        return flattened_size\n",
    "    \n",
    "    def _build_fc_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds fully connected layers.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        input_size = self.conv_output_size\n",
    "        normalization_type = self.genome.get('normalization_type', 'batch')  # Default to batch normalization\n",
    "\n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            # Safe access with validation\n",
    "            if i >= len(self.genome['fc_nodes']):\n",
    "                raise IndexError(\n",
    "                    f\"Genome list mismatch: i={i}, num_fc_layers={self.genome['num_fc_layers']}, \"\n",
    "                    f\"fc_nodes_len={len(self.genome['fc_nodes'])}\"\n",
    "                )\n",
    "            \n",
    "            output_size = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "            # Normalization layer (Layer Normalization or Batch Normalization)\n",
    "            if normalization_type == 'layer':\n",
    "                # Layer Normalization for FC layers\n",
    "                layers.append(nn.LayerNorm(output_size))\n",
    "            else:\n",
    "                # Batch normalization for FC layers (default)\n",
    "                layers.append(nn.BatchNorm1d(output_size))\n",
    "            \n",
    "            # Activation\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            # Dropout if not last layer\n",
    "            if i < self.genome['num_fc_layers'] - 1:\n",
    "                layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            input_size = output_size\n",
    "        \n",
    "        # Final classification layer\n",
    "        layers.append(nn.Linear(input_size, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        # Ensure input is in correct format for Conv1d\n",
    "        # Expected: (batch, channels, sequence_length)\n",
    "        if len(x.shape) == 2:  # (batch, sequence)\n",
    "            x = x.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_architecture_summary(self) -> str:\n",
    "        \"\"\"Returns an architecture summary.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(f\"Conv1D Layers: {self.genome['num_conv_layers']}\")\n",
    "        summary.append(f\"Filters: {self.genome['filters']}\")\n",
    "        summary.append(f\"Kernel Sizes: {self.genome['kernel_sizes']}\")\n",
    "        summary.append(f\"FC Layers: {self.genome['num_fc_layers']}\")\n",
    "        summary.append(f\"FC Nodes: {self.genome['fc_nodes']}\")\n",
    "        summary.append(f\"Activations: {self.genome['activations']}\")\n",
    "        summary.append(f\"Normalization: {self.genome.get('normalization_type', 'batch')}\")\n",
    "        summary.append(f\"Dropout: {self.genome['dropout_rate']:.3f}\")\n",
    "        summary.append(f\"Optimizer: {self.genome['optimizer']}\")\n",
    "        summary.append(f\"Learning Rate: {self.genome['learning_rate']:.4f}\")\n",
    "        return \" | \".join(summary)\n",
    "\n",
    "print(\"EvolvableCNN class defined correctly (Conv1D for audio with architecture validation)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021c7d8",
   "metadata": {},
   "source": [
    "## 5. Genetic Algorithm Components\n",
    "\n",
    "### 5.1 Genome Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be19766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ create_random_genome function defined (using configurable parameters with validation)\n"
     ]
    }
   ],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a random genome within specified ranges (optimized for 1D audio, using configurable parameters).\n",
    "    Ensures the genome will produce a valid architecture.\n",
    "    \"\"\"\n",
    "    max_attempts = 100\n",
    "    attempt = 0\n",
    "    \n",
    "    while attempt < max_attempts:\n",
    "        # Calculate maximum safe conv layers based on sequence length\n",
    "        sequence_length = config['sequence_length']\n",
    "        min_required_length = 4\n",
    "        max_safe_conv_layers = int(np.log2(sequence_length / min_required_length))\n",
    "        \n",
    "        # Limit conv layers to safe maximum\n",
    "        safe_max_conv = min(config['max_conv_layers'], max_safe_conv_layers)\n",
    "        \n",
    "        # Number of layers\n",
    "        num_conv_layers = random.randint(config['min_conv_layers'], safe_max_conv)\n",
    "        num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "        # Filters for each convolutional layer (progressive increase)\n",
    "        filters = []\n",
    "        base_filters = random.randint(config['min_filters'], config['min_filters'] * 2)\n",
    "        for i in range(num_conv_layers):\n",
    "            # Gradually increase filters in deeper layers\n",
    "            layer_filters = min(base_filters * (2 ** i), config['max_filters'])\n",
    "            filters.append(layer_filters)\n",
    "\n",
    "        # Kernel sizes (using configured options)\n",
    "        kernel_sizes = [random.choice(config['kernel_size_options']) for _ in range(num_conv_layers)]\n",
    "\n",
    "        # Nodes in fully connected layers (progressive decrease)\n",
    "        fc_nodes = []\n",
    "        base_fc = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "        for i in range(num_fc_layers):\n",
    "            layer_nodes = max(config['min_fc_nodes'], base_fc // (2 ** i))\n",
    "            fc_nodes.append(layer_nodes)\n",
    "\n",
    "        # Activation functions for each layer\n",
    "        activations = [random.choice(list(ACTIVATION_FUNCTIONS.keys())) for _ in range(max(num_conv_layers, num_fc_layers))]\n",
    "\n",
    "        # Other parameters (using configured ranges and options)\n",
    "        dropout_rate = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "        learning_rate = random.choice(config['learning_rate_options'])\n",
    "        optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "        normalization_type = 'batch'  # Default to batch normalization\n",
    "\n",
    "        genome = {\n",
    "            'num_conv_layers': num_conv_layers,\n",
    "            'num_fc_layers': num_fc_layers,\n",
    "            'filters': filters,\n",
    "            'kernel_sizes': kernel_sizes,\n",
    "            'fc_nodes': fc_nodes,\n",
    "            'activations': activations,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'learning_rate': learning_rate,\n",
    "            'optimizer': optimizer,\n",
    "            'normalization_type': normalization_type,\n",
    "            'fitness': 0.0,\n",
    "            'id': str(uuid.uuid4())[:8]\n",
    "        }\n",
    "        \n",
    "        # Validate genome\n",
    "        if is_genome_valid(genome, config):\n",
    "            return genome\n",
    "        \n",
    "        attempt += 1\n",
    "    \n",
    "    # If we couldn't create a valid genome, create a minimal safe one\n",
    "    print(f\"âš ï¸ Warning: Could not create random genome after {max_attempts} attempts. Creating minimal safe genome.\")\n",
    "    return {\n",
    "        'num_conv_layers': 1,\n",
    "        'num_fc_layers': 1,\n",
    "        'filters': [32],\n",
    "        'kernel_sizes': [3],\n",
    "        'fc_nodes': [64],\n",
    "        'activations': ['relu', 'relu'],\n",
    "        'dropout_rate': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam',\n",
    "        'normalization_type': 'batch',\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ create_random_genome function defined (using configurable parameters with validation)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc26f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ validate_and_fix_genome function defined\n"
     ]
    }
   ],
   "source": [
    "def validate_and_fix_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Validates and fixes a genome to ensure all lists match their corresponding layer counts.\n",
    "    This prevents IndexError when building the model.\n",
    "    \n",
    "    Args:\n",
    "        genome: The genome to validate\n",
    "        config: Configuration dictionary with min/max values\n",
    "    \n",
    "    Returns:\n",
    "        Fixed genome with correct list lengths\n",
    "    \"\"\"\n",
    "    # Fix filters and kernel_sizes to match num_conv_layers\n",
    "    num_conv = genome['num_conv_layers']\n",
    "    \n",
    "    # Fix filters list\n",
    "    if len(genome['filters']) != num_conv:\n",
    "        genome['filters'] = genome['filters'][:num_conv]\n",
    "        while len(genome['filters']) < num_conv:\n",
    "            genome['filters'].append(\n",
    "                random.randint(config['min_filters'], config['max_filters'])\n",
    "            )\n",
    "    \n",
    "    # Fix kernel_sizes list\n",
    "    if len(genome['kernel_sizes']) != num_conv:\n",
    "        genome['kernel_sizes'] = genome['kernel_sizes'][:num_conv]\n",
    "        while len(genome['kernel_sizes']) < num_conv:\n",
    "            genome['kernel_sizes'].append(\n",
    "                random.choice(config['kernel_size_options'])\n",
    "            )\n",
    "    \n",
    "    # Fix fc_nodes to match num_fc_layers\n",
    "    num_fc = genome['num_fc_layers']\n",
    "    \n",
    "    if len(genome['fc_nodes']) != num_fc:\n",
    "        genome['fc_nodes'] = genome['fc_nodes'][:num_fc]\n",
    "        while len(genome['fc_nodes']) < num_fc:\n",
    "            genome['fc_nodes'].append(\n",
    "                random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "            )\n",
    "    \n",
    "    return genome\n",
    "\n",
    "print(\"âœ“ validate_and_fix_genome function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b0659",
   "metadata": {},
   "source": [
    "### 5.2 Genome Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3205dc8",
   "metadata": {},
   "source": [
    "### 5.1.5 Genome Architecture Validation\n",
    "\n",
    "Esta funciÃ³n valida que un genoma no produzca arquitecturas invÃ¡lidas que causarÃ­an errores con BatchNorm.\n",
    "\n",
    "**Problema:** BatchNorm1d requiere mÃ¡s de 1 valor en la dimensiÃ³n espacial. Si tenemos demasiadas capas convolucionales con MaxPooling, la dimensiÃ³n espacial se reduce a 1 o menos, causando el error:\n",
    "```\n",
    "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
    "```\n",
    "\n",
    "**SoluciÃ³n:** Validamos que el nÃºmero de capas convolucionales no reduzca excesivamente las dimensiones:\n",
    "- Cada capa convolucional con MaxPool(2) divide la longitud de secuencia por 2\n",
    "- Necesitamos mantener al menos 4 valores en la dimensiÃ³n espacial para BatchNorm\n",
    "- Calculamos el mÃ¡ximo nÃºmero seguro de capas: `max_safe_conv_layers = log2(sequence_length / 4)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202ff89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ is_genome_valid function defined\n"
     ]
    }
   ],
   "source": [
    "def is_genome_valid(genome: dict, config: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Validates if a genome will produce a valid architecture.\n",
    "    Checks if the convolutional layers will reduce dimensions too much.\n",
    "    \n",
    "    Args:\n",
    "        genome: The genome to validate\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        True if genome is valid, False otherwise\n",
    "    \"\"\"\n",
    "    # Calculate expected output size after all conv layers\n",
    "    # Each MaxPool layer reduces by factor of 2\n",
    "    num_conv_layers = genome['num_conv_layers']\n",
    "    sequence_length = config['sequence_length']\n",
    "    \n",
    "    # Each conv layer has a MaxPool that divides by 2\n",
    "    expected_length = sequence_length / (2 ** num_conv_layers)\n",
    "    \n",
    "    # We need at least 2 values for BatchNorm to work properly\n",
    "    # Use a safety margin\n",
    "    min_required_length = 4\n",
    "    \n",
    "    if expected_length < min_required_length:\n",
    "        return False\n",
    "    \n",
    "    # Also check that we don't have too many conv layers for the sequence length\n",
    "    max_allowed_conv_layers = int(np.log2(sequence_length / min_required_length))\n",
    "    \n",
    "    if num_conv_layers > max_allowed_conv_layers:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"âœ“ is_genome_valid function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5895358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ mutate_genome function defined (using configurable parameters with validation)\n"
     ]
    }
   ],
   "source": [
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Applies mutation to a genome using adaptive mutation rate and configurable parameters.\n",
    "    Ensures the mutated genome produces a valid architecture.\n",
    "    \"\"\"\n",
    "    max_attempts = 50\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        mutated_genome = copy.deepcopy(genome)\n",
    "        mutation_rate = config['current_mutation_rate']  # adaptive\n",
    "\n",
    "        # Calculate maximum safe conv layers\n",
    "        sequence_length = config['sequence_length']\n",
    "        min_required_length = 4\n",
    "        max_safe_conv_layers = int(np.log2(sequence_length / min_required_length))\n",
    "        safe_max_conv = min(config['max_conv_layers'], max_safe_conv_layers)\n",
    "\n",
    "        # Mutate number of convolutional layers (with safety limit)\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['num_conv_layers'] = random.randint(config['min_conv_layers'], safe_max_conv)\n",
    "\n",
    "        # Mutate number of FC layers\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['num_fc_layers'] = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "        # Validate and fix lists to match layer counts\n",
    "        mutated_genome = validate_and_fix_genome(mutated_genome, config)\n",
    "\n",
    "        # Mutate filters\n",
    "        for i in range(len(mutated_genome['filters'])):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated_genome['filters'][i] = random.randint(config['min_filters'], config['max_filters'])\n",
    "\n",
    "        # Mutate kernel sizes (using configured options)\n",
    "        for i in range(len(mutated_genome['kernel_sizes'])):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated_genome['kernel_sizes'][i] = random.choice(config['kernel_size_options'])\n",
    "\n",
    "        # Mutate FC nodes\n",
    "        for i in range(len(mutated_genome['fc_nodes'])):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated_genome['fc_nodes'][i] = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "\n",
    "        # Mutate activation functions\n",
    "        for i in range(len(mutated_genome['activations'])):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated_genome['activations'][i] = random.choice(list(ACTIVATION_FUNCTIONS.keys()))\n",
    "\n",
    "        # Mutate dropout (using configured range)\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['dropout_rate'] = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "\n",
    "        # Mutate learning rate (using configured options)\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['learning_rate'] = random.choice(config['learning_rate_options'])\n",
    "\n",
    "        # Mutate optimizer\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "\n",
    "        # Mutate normalization type (using configured weights)\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['normalization_type'] = random.choices(\n",
    "                ['batch', 'layer'], \n",
    "                weights=[config['normalization_batch_weight'], config['normalization_layer_weight']]\n",
    "            )[0]\n",
    "\n",
    "        mutated_genome['id'] = str(uuid.uuid4())[:8]\n",
    "        mutated_genome['fitness'] = 0.0\n",
    "        \n",
    "        # Final validation to ensure consistency\n",
    "        mutated_genome = validate_and_fix_genome(mutated_genome, config)\n",
    "        \n",
    "        # Check if mutated genome is valid\n",
    "        if is_genome_valid(mutated_genome, config):\n",
    "            return mutated_genome\n",
    "    \n",
    "    # If we couldn't create a valid mutation, return a slightly modified version\n",
    "    # that we know is safe (reduce conv layers if needed)\n",
    "    print(f\"âš ï¸ Warning: Could not create valid mutation after {max_attempts} attempts. Using safe fallback.\")\n",
    "    safe_genome = copy.deepcopy(genome)\n",
    "    safe_genome['num_conv_layers'] = min(safe_genome['num_conv_layers'], safe_max_conv)\n",
    "    safe_genome = validate_and_fix_genome(safe_genome, config)\n",
    "    safe_genome['id'] = str(uuid.uuid4())[:8]\n",
    "    safe_genome['fitness'] = 0.0\n",
    "    \n",
    "    return safe_genome\n",
    "\n",
    "print(\"âœ“ mutate_genome function defined (using configurable parameters with validation)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b06729",
   "metadata": {},
   "source": [
    "### 5.3 Genome Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029effe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Genetic functions updated for adaptive mutation, 1D audio processing, and architecture validation\n"
     ]
    }
   ],
   "source": [
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "    Performs crossover between two genomes.\n",
    "    Ensures resulting children produce valid architectures.\n",
    "    \"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "\n",
    "    max_attempts = 20\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        child1 = copy.deepcopy(parent1)\n",
    "        child2 = copy.deepcopy(parent2)\n",
    "        \n",
    "        # Calculate maximum safe conv layers\n",
    "        sequence_length = config['sequence_length']\n",
    "        min_required_length = 4\n",
    "        max_safe_conv_layers = int(np.log2(sequence_length / min_required_length))\n",
    "        safe_max_conv = min(config['max_conv_layers'], max_safe_conv_layers)\n",
    "\n",
    "        # Crossover scalar parameters\n",
    "        for key in ['num_conv_layers', 'num_fc_layers', 'dropout_rate', 'learning_rate', 'optimizer', 'normalization_type']:\n",
    "            if random.random() < 0.5:\n",
    "                child1[key], child2[key] = child2[key], child1[key]\n",
    "        \n",
    "        # Ensure conv layers don't exceed safe maximum\n",
    "        child1['num_conv_layers'] = min(child1['num_conv_layers'], safe_max_conv)\n",
    "        child2['num_conv_layers'] = min(child2['num_conv_layers'], safe_max_conv)\n",
    "\n",
    "        # Crossover lists (random cut point)\n",
    "        for list_key in ['filters', 'kernel_sizes', 'fc_nodes', 'activations']:\n",
    "            if random.random() < 0.5:\n",
    "                list1 = child1[list_key]\n",
    "                list2 = child2[list_key]\n",
    "                if len(list1) > 1 and len(list2) > 1:\n",
    "                    point1 = random.randint(1, len(list1) - 1)\n",
    "                    point2 = random.randint(1, len(list2) - 1)\n",
    "                    child1[list_key] = list1[:point1] + list2[point2:]\n",
    "                    child2[list_key] = list2[:point2] + list1[point1:]\n",
    "\n",
    "        child1['id'] = str(uuid.uuid4())[:8]\n",
    "        child2['id'] = str(uuid.uuid4())[:8]\n",
    "        child1['fitness'] = 0.0\n",
    "        child2['fitness'] = 0.0\n",
    "        \n",
    "        # Validate and fix both children to ensure consistency\n",
    "        child1 = validate_and_fix_genome(child1, config)\n",
    "        child2 = validate_and_fix_genome(child2, config)\n",
    "        \n",
    "        # Check if both children are valid\n",
    "        if is_genome_valid(child1, config) and is_genome_valid(child2, config):\n",
    "            return child1, child2\n",
    "    \n",
    "    # If we couldn't create valid children, return copies of parents\n",
    "    print(f\"âš ï¸ Warning: Could not create valid crossover after {max_attempts} attempts. Returning parent copies.\")\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "print(\"âœ“ Genetic functions updated for adaptive mutation, 1D audio processing, and architecture validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a74a50",
   "metadata": {},
   "source": [
    "## 6. Hybrid Neuroevolution Implementation\n",
    "\n",
    "### 6.1 Class Initialization and Checkpoint Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda046ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 1/5): Initialization and Checkpoint Management\n"
     ]
    }
   ],
   "source": [
    "class HybridNeuroevolution:\n",
    "    \"\"\"Main class that implements hybrid neuroevolution with 5-fold CV and adaptive mutation.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        self.best_checkpoint_path = None  # Ruta del checkpoint del mejor modelo\n",
    "        \n",
    "        # Early stopping configuration at generation level\n",
    "        self.generations_without_improvement = 0\n",
    "        self.best_fitness_overall = -float('inf')\n",
    "        self.min_improvement_threshold = 0.1  # MÃ­nima mejora en fitness (%) para resetear contador\n",
    "        self.max_generations_without_improvement = config.get('early_stopping_generations', 10)\n",
    "\n",
    "    def initialize_population(self):\n",
    "        print(f\"Initializing population of {self.config['population_size']} individuals...\")\n",
    "        self.population = [create_random_genome(self.config) for _ in range(self.config['population_size'])]\n",
    "        print(f\"Population initialized with {len(self.population)} individuals\")\n",
    "    \n",
    "    def save_best_checkpoint(self, genome: dict, model: nn.Module):\n",
    "        \"\"\"\n",
    "        Guarda el checkpoint del mejor modelo global y elimina el anterior.\n",
    "        \n",
    "        Args:\n",
    "            genome: Genoma del mejor modelo\n",
    "            model: Modelo de PyTorch a guardar\n",
    "        \"\"\"\n",
    "        # Crear directorio para checkpoints si no existe\n",
    "        checkpoint_dir = \"checkpoints\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Eliminar checkpoint anterior si existe\n",
    "        if self.best_checkpoint_path and os.path.exists(self.best_checkpoint_path):\n",
    "            try:\n",
    "                os.remove(self.best_checkpoint_path)\n",
    "                print(f\"      âœ“ Checkpoint anterior eliminado: {self.best_checkpoint_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"      âœ— Error eliminando checkpoint anterior: {e}\")\n",
    "        \n",
    "        # Crear nuevo checkpoint\n",
    "        checkpoint_filename = f\"best_model_gen{self.generation}_id{genome['id']}_fitness{genome['fitness']:.2f}.pth\"\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_filename)\n",
    "        \n",
    "        # Guardar modelo y genoma\n",
    "        checkpoint_data = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'genome': genome,\n",
    "            'generation': self.generation,\n",
    "            'fitness': genome['fitness'],\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            torch.save(checkpoint_data, checkpoint_path)\n",
    "            self.best_checkpoint_path = checkpoint_path\n",
    "            print(f\"      âœ“ Nuevo checkpoint guardado: {checkpoint_path}\")\n",
    "            print(f\"        Fitness: {genome['fitness']:.2f}%, ID: {genome['id']}, Gen: {self.generation}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      âœ— Error guardando checkpoint: {e}\")\n",
    "    \n",
    "    def load_best_checkpoint(self):\n",
    "        \"\"\"\n",
    "        Carga el mejor checkpoint guardado.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple de (genome, model) o (None, None) si no hay checkpoint\n",
    "        \"\"\"\n",
    "        if not self.best_checkpoint_path or not os.path.exists(self.best_checkpoint_path):\n",
    "            print(\"No hay checkpoint disponible para cargar\")\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            checkpoint_data = torch.load(self.best_checkpoint_path, map_location=device, weights_only=False)\n",
    "            genome = checkpoint_data['genome']\n",
    "            \n",
    "            # Crear modelo y cargar pesos\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "            model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "            \n",
    "            print(f\"âœ“ Checkpoint cargado exitosamente: {self.best_checkpoint_path}\")\n",
    "            print(f\"  Fitness: {checkpoint_data['fitness']:.2f}%, Gen: {checkpoint_data['generation']}, ID: {genome['id']}\")\n",
    "            \n",
    "            return genome, model\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error cargando checkpoint: {e}\")\n",
    "            return None, None\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 1/5): Initialization and Checkpoint Management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a69b0",
   "metadata": {},
   "source": [
    "### 6.2 Training Functions (Single Fold & Thread-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a22a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 2/5): Training Functions (with invalid architecture handling)\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 1: Training Functions\n",
    "\n",
    "# Add training methods to HybridNeuroevolution class\n",
    "def _train_one_fold(self, model, optimizer, criterion, train_loader, test_loader, genome_id: str, fold_num: int):\n",
    "    \"\"\"\n",
    "    Entrena y evalÃºa un modelo en un fold especÃ­fico.\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy del fold\n",
    "    \"\"\"\n",
    "    best_acc = 0.0\n",
    "    best_epoch = -1\n",
    "    patience_left = self.config['epoch_patience']\n",
    "    last_improvement_acc = 0.0\n",
    "    max_epochs = self.config['num_epochs']\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "        max_batches = min(len(train_loader), self.config['early_stopping_patience'])\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            if batch_count >= max_batches:\n",
    "                break\n",
    "        \n",
    "        avg_loss = running_loss / max(1, batch_count)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        eval_batches = 0\n",
    "        max_eval_batches = min(len(test_loader), 20)\n",
    "        total_eval_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                total_eval_loss += loss.item()\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "                eval_batches += 1\n",
    "                if eval_batches >= max_eval_batches:\n",
    "                    break\n",
    "        \n",
    "        acc = 100.0 * correct / max(1, total)\n",
    "        avg_eval_loss = total_eval_loss / max(1, eval_batches)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        improvement = acc - last_improvement_acc\n",
    "        if improvement >= self.config['improvement_threshold']:\n",
    "            patience_left = self.config['epoch_patience']\n",
    "            last_improvement_acc = acc\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Solo mostrar cada 30 Ã©pocas para no saturar el log\n",
    "        if epoch % 30 == 0 or epoch == 1 or epoch == max_epochs:\n",
    "            print(f\"          Fold {fold_num} Epoch {epoch}: loss={avg_loss:.4f}, acc={acc:.2f}% (best={best_acc:.2f}%)\")\n",
    "\n",
    "        if patience_left <= 0:\n",
    "            print(f\"          Fold {fold_num}: Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "def _train_fold_in_thread(self, genome: dict, fold_num: int) -> Tuple[int, float, nn.Module]:\n",
    "    \"\"\"\n",
    "    Entrena un modelo en un fold especÃ­fico (diseÃ±ado para ejecutarse en un thread).\n",
    "    \n",
    "    Args:\n",
    "        genome: Genoma del modelo\n",
    "        fold_num: NÃºmero de fold (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (fold_num, accuracy, model)\n",
    "        Si la arquitectura es invÃ¡lida, retorna (fold_num, 0.0, None)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar datos del fold\n",
    "        fold_train_loader, fold_test_loader = self._load_fold_data(fold_num)\n",
    "        \n",
    "        # Crear nuevo modelo para este fold\n",
    "        try:\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "        except ValueError as e:\n",
    "            # Error de arquitectura invÃ¡lida\n",
    "            if \"Invalid architecture\" in str(e) or \"Expected more than 1 value per channel\" in str(e):\n",
    "                print(f\"      âœ— Fold {fold_num}: Invalid architecture detected - {str(e)[:100]}\")\n",
    "                return fold_num, 0.0, None\n",
    "            else:\n",
    "                # Otro tipo de ValueError\n",
    "                raise\n",
    "        \n",
    "        optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "        optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Entrenar y evaluar en este fold\n",
    "        fold_acc = self._train_one_fold(\n",
    "            model, optimizer, criterion, \n",
    "            fold_train_loader, fold_test_loader,\n",
    "            genome['id'], fold_num\n",
    "        )\n",
    "        \n",
    "        print(f\"      â†’ Fold {fold_num} completed: {fold_acc:.2f}%\")\n",
    "        \n",
    "        return fold_num, fold_acc, model\n",
    "        \n",
    "    except ValueError as e:\n",
    "        # Capturar especÃ­ficamente errores de arquitectura invÃ¡lida\n",
    "        if \"Invalid architecture\" in str(e) or \"Expected more than 1 value per channel\" in str(e):\n",
    "            print(f\"      âœ— Fold {fold_num}: Invalid architecture - genome will receive fitness 0.0\")\n",
    "            return fold_num, 0.0, None\n",
    "        else:\n",
    "            print(f\"      ERROR in Fold {fold_num}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return fold_num, 0.0, None\n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR in Fold {fold_num}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return fold_num, 0.0, None\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution._train_one_fold = _train_one_fold\n",
    "HybridNeuroevolution._train_fold_in_thread = _train_fold_in_thread\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 2/5): Training Functions (with invalid architecture handling)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c1fea",
   "metadata": {},
   "source": [
    "### 6.3 Fitness Evaluation and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0d74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 3/5): Fitness Evaluation and Data Loading\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 2: Fitness Evaluation\n",
    "\n",
    "def evaluate_fitness(self, genome: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    EvalÃºa el fitness de un genoma usando 5-fold cross-validation PARALELO.\n",
    "    Los 5 folds se entrenan en threads separados y se espera a que terminen todos.\n",
    "    El fitness final es el promedio de accuracy de los 5 folds.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (fitness, model) donde:\n",
    "            - fitness: promedio de accuracies de los 5 folds\n",
    "            - model: modelo entrenado en el mejor fold (para checkpoint)\n",
    "    \"\"\"\n",
    "    print(f\"      Training/Evaluating model {genome['id']} with PARALLEL 5-FOLD CROSS-VALIDATION\")\n",
    "    \n",
    "    fold_accuracies = {}\n",
    "    fold_models = {}\n",
    "    \n",
    "    try:\n",
    "        # Usar ThreadPoolExecutor para ejecutar los 5 folds en paralelo\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            # Enviar los 5 folds a threads separados\n",
    "            print(f\"      â†’ Submitting 5 folds to thread pool...\")\n",
    "            futures = {\n",
    "                executor.submit(self._train_fold_in_thread, genome, fold_num): fold_num\n",
    "                for fold_num in range(1, 6)\n",
    "            }\n",
    "            \n",
    "            # Esperar a que todos los folds terminen\n",
    "            print(f\"      â†’ Waiting for all 5 folds to complete...\")\n",
    "            for future in as_completed(futures):\n",
    "                fold_num, fold_acc, model = future.result()\n",
    "                fold_accuracies[fold_num] = fold_acc\n",
    "                fold_models[fold_num] = model\n",
    "        \n",
    "        # Ordenar resultados por fold_num\n",
    "        sorted_folds = sorted(fold_accuracies.keys())\n",
    "        accuracies_list = [fold_accuracies[f] for f in sorted_folds]\n",
    "        \n",
    "        # Encontrar el mejor modelo\n",
    "        best_fold_num = max(fold_accuracies, key=fold_accuracies.get)\n",
    "        best_fold_acc = fold_accuracies[best_fold_num]\n",
    "        best_model = fold_models[best_fold_num]\n",
    "        \n",
    "        # Calcular fitness como promedio de los 5 folds\n",
    "        avg_fitness = np.mean(accuracies_list)\n",
    "        std_fitness = np.std(accuracies_list)\n",
    "        \n",
    "        print(f\"      âœ“ PARALLEL 5-Fold CV Results for {genome['id']}:\")\n",
    "        print(f\"        Fold accuracies: {[f'{acc:.2f}%' for acc in accuracies_list]}\")\n",
    "        print(f\"        Average fitness: {avg_fitness:.2f}% Â± {std_fitness:.2f}%\")\n",
    "        print(f\"        Best fold: Fold {best_fold_num} with {best_fold_acc:.2f}%\")\n",
    "        \n",
    "        return avg_fitness, best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR evaluating genome {genome['id']}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0.0, None\n",
    "\n",
    "def _load_fold_data(self, fold_number: int):\n",
    "    \"\"\"\n",
    "    Carga los datos de un fold especÃ­fico para el entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        fold_number: NÃºmero de fold (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    fold_files_directory = os.path.join(\n",
    "        self.config['data_path'], \n",
    "        f\"files_real_{self.config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    dataset_id = self.config['dataset_id']\n",
    "    \n",
    "    # Cargar datos del fold\n",
    "    x_train = np.load(os.path.join(fold_files_directory, f'X_train_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_train = np.load(os.path.join(fold_files_directory, f'y_train_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    x_val = np.load(os.path.join(fold_files_directory, f'X_val_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_val = np.load(os.path.join(fold_files_directory, f'y_val_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    x_test = np.load(os.path.join(fold_files_directory, f'X_test_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_test = np.load(os.path.join(fold_files_directory, f'y_test_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    \n",
    "    # Reshape si es necesario\n",
    "    if len(x_train.shape) == 2:\n",
    "        x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "        x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "        x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "    \n",
    "    # Convertir a tensores\n",
    "    x_train_tensor = torch.FloatTensor(x_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train.astype(np.int64))\n",
    "    x_val_tensor = torch.FloatTensor(x_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val.astype(np.int64))\n",
    "    x_test_tensor = torch.FloatTensor(x_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test.astype(np.int64))\n",
    "    \n",
    "    # Crear datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    x_eval = torch.cat([x_val_tensor, x_test_tensor], dim=0)\n",
    "    y_eval = torch.cat([y_val_tensor, y_test_tensor], dim=0)\n",
    "    test_dataset = torch.utils.data.TensorDataset(x_eval, y_eval)\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    fold_train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=self.config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    fold_test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=self.config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return fold_train_loader, fold_test_loader\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution.evaluate_fitness = evaluate_fitness\n",
    "HybridNeuroevolution._load_fold_data = _load_fold_data\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 3/5): Fitness Evaluation and Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9ae0c",
   "metadata": {},
   "source": [
    "### 6.4 Population Evaluation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ce67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 4/5): Population Evaluation and Selection\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 3: Population Evaluation\n",
    "\n",
    "def evaluate_population(self):\n",
    "    print(f\"\\nEvaluating population (Generation {self.generation})...\")\n",
    "    print(f\"Processing {len(self.population)} individuals...\")\n",
    "    fitness_scores = []\n",
    "    best_fitness_so_far = 0.0\n",
    "    current_global_best_fitness = self.best_individual['fitness'] if self.best_individual else 0.0\n",
    "    \n",
    "    for i, genome in enumerate(self.population):\n",
    "        print(f\"\\n   Evaluating individual {i+1}/{len(self.population)} (ID: {genome['id']})\")\n",
    "        print(f\"      Architecture: {genome['num_conv_layers']} conv + {genome['num_fc_layers']} fc, opt={genome['optimizer']}, lr={genome['learning_rate']}\")\n",
    "        \n",
    "        # Evaluar y obtener fitness y modelo\n",
    "        fitness, model = self.evaluate_fitness(genome)\n",
    "        genome['fitness'] = fitness\n",
    "        fitness_scores.append(fitness)\n",
    "        \n",
    "        if fitness > best_fitness_so_far:\n",
    "            best_fitness_so_far = fitness\n",
    "            print(f\"      New best fitness in this generation: {fitness:.2f}%!\")\n",
    "        \n",
    "        # Verificar si es un nuevo mejor global\n",
    "        if fitness > current_global_best_fitness:\n",
    "            print(f\"      ðŸŒŸ NEW GLOBAL BEST! {fitness:.2f}% > {current_global_best_fitness:.2f}%\")\n",
    "            current_global_best_fitness = fitness\n",
    "            \n",
    "            # Guardar checkpoint (elimina el anterior automÃ¡ticamente)\n",
    "            if model is not None:\n",
    "                self.save_best_checkpoint(genome, model)\n",
    "        \n",
    "        print(f\"      Fitness obtained: {fitness:.2f}% | Best in generation: {best_fitness_so_far:.2f}% | Global best: {current_global_best_fitness:.2f}%\")\n",
    "    \n",
    "    # Generation statistics\n",
    "    if fitness_scores:\n",
    "        avg_fitness = np.mean(fitness_scores)\n",
    "        max_fitness = np.max(fitness_scores)\n",
    "        min_fitness = np.min(fitness_scores)\n",
    "        std_fitness = np.std(fitness_scores)\n",
    "    else:\n",
    "        avg_fitness = max_fitness = min_fitness = std_fitness = 0.0\n",
    "\n",
    "    stats = {\n",
    "        'generation': self.generation,\n",
    "        'avg_fitness': avg_fitness,\n",
    "        'max_fitness': max_fitness,\n",
    "        'min_fitness': min_fitness,\n",
    "        'std_fitness': std_fitness\n",
    "    }\n",
    "    self.generation_stats.append(stats)\n",
    "    self.fitness_history.append(max_fitness)\n",
    "\n",
    "    best_genome = max(self.population, key=lambda x: x['fitness'])\n",
    "    if self.best_individual is None or best_genome['fitness'] > self.best_individual['fitness']:\n",
    "        self.best_individual = copy.deepcopy(best_genome)\n",
    "        print(f\"\\nNew global best individual found!\")\n",
    "\n",
    "    print(f\"\\nGENERATION {self.generation} STATISTICS:\")\n",
    "    print(f\"   Maximum fitness: {max_fitness:.2f}%\")\n",
    "    print(f\"   Average fitness: {avg_fitness:.2f}%\")\n",
    "    print(f\"   Minimum fitness: {min_fitness:.2f}%\")\n",
    "    print(f\"   Standard deviation: {std_fitness:.2f}%\")\n",
    "    print(f\"   Best individual: {best_genome['id']} with {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Global best individual: {self.best_individual['id']} with {self.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "def selection_and_reproduction(self):\n",
    "    print(f\"\\nStarting selection and reproduction...\")\n",
    "    # Sort by fitness\n",
    "    self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "    elite_size = max(1, int(self.config['population_size'] * self.config['elite_percentage']))\n",
    "    elite = self.population[:elite_size]\n",
    "    print(f\"Selecting {elite_size} elite individuals:\")\n",
    "    for i, individual in enumerate(elite):\n",
    "        print(f\"   Elite {i+1}: {individual['id']} (fitness: {individual['fitness']:.2f}%)\")\n",
    "    new_population = copy.deepcopy(elite)\n",
    "    offspring_needed = self.config['population_size'] - len(new_population)\n",
    "    print(f\"Creating {offspring_needed} new individuals through crossover and mutation...\")\n",
    "    offspring_created = 0\n",
    "    while len(new_population) < self.config['population_size']:\n",
    "        parent1 = self.tournament_selection()\n",
    "        parent2 = self.tournament_selection()\n",
    "        child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "        child1 = mutate_genome(child1, self.config)\n",
    "        if len(new_population) < self.config['population_size']:\n",
    "            new_population.append(child1)\n",
    "        child2 = mutate_genome(child2, self.config)\n",
    "        if len(new_population) < self.config['population_size']:\n",
    "            new_population.append(child2)\n",
    "        offspring_created += 2\n",
    "        if offspring_created % 4 == 0:\n",
    "            print(f\"   Created {min(offspring_created, offspring_needed)} of {offspring_needed} new individuals...\")\n",
    "    self.population = new_population[:self.config['population_size']]\n",
    "    print(f\"New generation created with {len(self.population)} individuals\")\n",
    "    print(f\"   Elite preserved: {elite_size}\")\n",
    "    print(f\"   New individuals: {len(self.population) - elite_size}\")\n",
    "\n",
    "def tournament_selection(self, tournament_size: int = 3) -> dict:\n",
    "    tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
    "    return max(tournament, key=lambda x: x['fitness'])\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution.evaluate_population = evaluate_population\n",
    "HybridNeuroevolution.selection_and_reproduction = selection_and_reproduction\n",
    "HybridNeuroevolution.tournament_selection = tournament_selection\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 4/5): Population Evaluation and Selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4aae0",
   "metadata": {},
   "source": [
    "### 6.5 Convergence Check and Main Evolution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea180cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 5/5): Convergence and Main Evolution Loop\n",
      "âœ“ HybridNeuroevolution class COMPLETE with PARALLEL 5-fold CV and adaptive mutation\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 4: Convergence and Evolution\n",
    "\n",
    "def _update_adaptive_mutation(self):\n",
    "    # Diversity measured via std of fitness in last generation\n",
    "    if not self.generation_stats:\n",
    "        self.config['current_mutation_rate'] = self.config['base_mutation_rate']\n",
    "        return\n",
    "    last_std = self.generation_stats[-1]['std_fitness']\n",
    "    # Heuristic: more diversity -> lower mutation, low diversity -> higher\n",
    "    # Normalize std roughly assuming fitness in [0,100]\n",
    "    diversity_factor = min(1.0, last_std / 10.0)  # std 10% -> factor 1\n",
    "    # Invert: low diversity (small std) should raise mutation\n",
    "    inverted = 1 - diversity_factor\n",
    "    new_rate = self.config['base_mutation_rate'] + (inverted - 0.5) * 0.4  # adjust +/-0.2 range\n",
    "    new_rate = max(self.config['mutation_rate_min'], min(self.config['mutation_rate_max'], new_rate))\n",
    "    self.config['current_mutation_rate'] = round(new_rate, 4)\n",
    "    print(f\"Adaptive mutation rate updated to {self.config['current_mutation_rate']} (std_fitness={last_std:.2f})\")\n",
    "\n",
    "def check_convergence(self) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica criterios de convergencia:\n",
    "    1. Target fitness alcanzado\n",
    "    2. MÃ¡ximo de generaciones alcanzado\n",
    "    3. Early stopping: sin mejora en N generaciones\n",
    "    4. Estancamiento detectado en Ãºltimas generaciones\n",
    "    \"\"\"\n",
    "    # Criterion 1: Target fitness reached\n",
    "    if self.best_individual and self.best_individual['fitness'] >= self.config['fitness_threshold']:\n",
    "        print(f\"\\nâœ… Target fitness reached! ({self.best_individual['fitness']:.2f}% >= {self.config['fitness_threshold']}%)\")\n",
    "        return True\n",
    "    \n",
    "    # Criterion 2: Maximum generations reached\n",
    "    if self.generation >= self.config['max_generations']:\n",
    "        print(f\"\\nâ±ï¸ Maximum generations reached ({self.generation}/{self.config['max_generations']})\")\n",
    "        return True\n",
    "    \n",
    "    # Criterion 3: Early stopping - no improvement in N generations\n",
    "    if self.generation > 0:  # No check on generation 0\n",
    "        current_best = self.best_individual['fitness'] if self.best_individual else 0.0\n",
    "        \n",
    "        # Check if there's improvement compared to best overall\n",
    "        improvement = current_best - self.best_fitness_overall\n",
    "        \n",
    "        if improvement >= self.min_improvement_threshold:\n",
    "            # Significant improvement! Reset counter\n",
    "            self.best_fitness_overall = current_best\n",
    "            self.generations_without_improvement = 0\n",
    "            print(f\"\\nðŸ”„ Improvement detected: {improvement:.2f}% | Generations without improvement: {self.generations_without_improvement}\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.generations_without_improvement += 1\n",
    "            print(f\"\\nâ³ No significant improvement | Generations without improvement: {self.generations_without_improvement}/{self.max_generations_without_improvement}\")\n",
    "            \n",
    "            if self.generations_without_improvement >= self.max_generations_without_improvement:\n",
    "                print(f\"\\nðŸ›‘ EARLY STOPPING: No improvement for {self.max_generations_without_improvement} generations\")\n",
    "                print(f\"   Best fitness plateau: {self.best_fitness_overall:.2f}%\")\n",
    "                return True\n",
    "    \n",
    "    # Criterion 4: Stagnation in last 3 generations (additional safety check)\n",
    "    if len(self.fitness_history) >= 3:\n",
    "        recent = self.fitness_history[-3:]\n",
    "        if max(recent) - min(recent) < 0.5:\n",
    "            print(f\"\\nðŸ“‰ Stagnation detected in last 3 generations (all within {max(recent) - min(recent):.2f}%)\")\n",
    "            # Don't stop immediately, let generation-level early stopping handle it\n",
    "    \n",
    "    return False\n",
    "\n",
    "def evolve(self) -> dict:\n",
    "    print(\"STARTING HYBRID NEUROEVOLUTION PROCESS (adaptive mutation + generation-level early stopping)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"   Population: {self.config['population_size']} individuals\")\n",
    "    print(f\"   Maximum generations: {self.config['max_generations']}\")\n",
    "    print(f\"   Target fitness: {self.config['fitness_threshold']}%\")\n",
    "    print(f\"   Early stopping (generations): {self.config['early_stopping_generations']} without improvement\")\n",
    "    print(f\"   Min improvement threshold: {self.config['min_improvement_threshold']}%\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(\"=\"*80)\n",
    "    self.initialize_population()\n",
    "    while not self.check_convergence():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"GENERATION {self.generation}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        self.evaluate_population()\n",
    "        if self.check_convergence():\n",
    "            break\n",
    "        self._update_adaptive_mutation()\n",
    "        self.selection_and_reproduction()\n",
    "        self.generation += 1\n",
    "        print(f\"\\nPreparing for next generation...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EVOLUTION COMPLETED!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Best individual found:\")\n",
    "    print(f\"   ID: {self.best_individual['id']}\")\n",
    "    print(f\"   Fitness: {self.best_individual['fitness']:.2f}%\")\n",
    "    print(f\"   Origin generation: {self.generation}\")\n",
    "    print(f\"   Total generations processed: {self.generation + 1}\")\n",
    "    print(f\"   Generations without improvement: {self.generations_without_improvement}/{self.max_generations_without_improvement}\")\n",
    "    print(\"=\"*80)\n",
    "    return self.best_individual\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution._update_adaptive_mutation = _update_adaptive_mutation\n",
    "HybridNeuroevolution.check_convergence = check_convergence\n",
    "HybridNeuroevolution.evolve = evolve\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 5/5): Convergence and Main Evolution Loop\")\n",
    "print(\"âœ“ HybridNeuroevolution class COMPLETE with PARALLEL 5-fold CV and adaptive mutation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59597ef1",
   "metadata": {},
   "source": [
    "## 7. Evolution Process Execution\n",
    "\n",
    "### ðŸš€ Importante: Parallel 5-Fold Cross-Validation durante la EvoluciÃ³n\n",
    "\n",
    "**Cambio clave**: Ahora cada individuo se evalÃºa con **5-fold cross-validation PARALELO** durante el proceso evolutivo:\n",
    "\n",
    "1. **Durante la evoluciÃ³n**:\n",
    "   - Cada individuo se entrena y evalÃºa en **cada uno de los 5 folds SIMULTÃNEAMENTE**\n",
    "   - Los 5 folds se ejecutan en **threads separados** (paralelizaciÃ³n)\n",
    "   - El **fitness final** es el **promedio** de las accuracies de los 5 folds\n",
    "   - Se espera a que **todos los folds terminen** antes de calcular el fitness\n",
    "   - Esto garantiza que la arquitectura seleccionada no estÃ© sobreajustada a un fold especÃ­fico\n",
    "\n",
    "2. **Ventajas de la paralelizaciÃ³n**:\n",
    "   - ðŸš€ **Mucho mÃ¡s rÃ¡pido**: Los 5 folds se entrenan simultÃ¡neamente (en threads)\n",
    "   - âœ… **MÃ¡s robusto**: La mejor arquitectura generaliza mejor\n",
    "   - âœ… **Menos sesgado**: No depende de un solo split de datos\n",
    "   - ðŸ’¡ **Aprovecha multi-core**: Usa mÃºltiples nÃºcleos de CPU para acelerar\n",
    "   \n",
    "3. **Proceso paralelo**:\n",
    "   - GeneraciÃ³n 0: Se crean N individuos aleatorios\n",
    "   - Para cada individuo:\n",
    "     - **Thread Pool**: Se crean 5 threads (uno por fold)\n",
    "     - **Fold 1-5**: Se entrenan y evalÃºan **SIMULTÃNEAMENTE** â†’ accuracyâ‚...accuracyâ‚…\n",
    "     - **Espera**: Se espera a que **todos los threads terminen**\n",
    "     - **Fitness** = (accuracyâ‚ + accuracyâ‚‚ + accuracyâ‚ƒ + accuracyâ‚„ + accuracyâ‚…) / 5\n",
    "   - Se seleccionan los mejores segÃºn fitness promedio\n",
    "   - Se aplica crossover y mutaciÃ³n\n",
    "   - Siguiente generaciÃ³n...\n",
    "\n",
    "4. **Rendimiento**:\n",
    "   - Tiempo de evaluaciÃ³n â‰ˆ tiempo del fold mÃ¡s lento (en lugar de suma de todos)\n",
    "   - AceleraciÃ³n teÃ³rica: ~5x mÃ¡s rÃ¡pido que secuencial\n",
    "   - AceleraciÃ³n real: depende del nÃºmero de cores disponibles\n",
    "\n",
    "**Nota**: Para hacer pruebas rÃ¡pidas, puedes reducir `population_size` y `max_generations` en la configuraciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be51ada5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUDIO NEUROEVOLUTION CONFIGURATION\n",
      "============================================================\n",
      "   Dataset: Audio (Parkinson Classification)\n",
      "   Dataset ID: 40_1e5_N\n",
      "   Fold ID: 40_1e5_N\n",
      "   Number of folds: 5 (all used during evolution)\n",
      "   Data Path: data/sets/folds_5\n",
      "   Number of channels: 1 (1D audio)\n",
      "   Sequence length: 11520 (will be auto-detected)\n",
      "   Number of classes: 2 (Control vs Pathological)\n",
      "   Batch size: 64\n",
      "   Population: 20 individuals\n",
      "   Maximum generations: 100\n",
      "   Target fitness: 80.0%\n",
      "   Device: cuda\n",
      "   Platform: posix (Unix/Linux/Mac)\n",
      "   Parallelization: Enabled (5 threads per individual)\n",
      "============================================================\n",
      "\n",
      "Verifying audio dataset...\n",
      "\n",
      "============================================================\n",
      "VERIFICANDO DISPONIBILIDAD DE DATOS\n",
      "============================================================\n",
      "Dataset ID: 40_1e5_N, Verificando los 5 folds...\n",
      "   Looking for: /home/jovyan/audio_test/data/sets/folds_5/files_real_40_1e5_N\n",
      "   âœ“ Directory found: /home/jovyan/audio_test/data/sets/folds_5/files_real_40_1e5_N\n",
      "\n",
      "Checking for all 5 folds...\n",
      "   âœ“ Fold 1: All files present\n",
      "   âœ“ Fold 2: All files present\n",
      "   âœ“ Fold 3: All files present\n",
      "   âœ“ Fold 4: All files present\n",
      "   âœ“ Fold 5: All files present\n",
      "\n",
      "âœ“ All 5 folds verified successfully!\n",
      "\n",
      "Loading Fold 1 to detect sequence length...\n",
      "   Train samples: (7200, 11520)\n",
      "   Sequence length detected: 11520\n",
      "\n",
      "âœ“ Dataset verification complete!\n",
      "   During evolution, each individual will train on all 5 folds.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET VERIFIED - READY FOR PARALLEL 5-FOLD CV EVOLUTION\n",
      "============================================================\n",
      "\n",
      "Starting audio neuroevolution at 12:47:52\n",
      "Architecture: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC\n",
      "Each individual will be evaluated on all 5 folds IN PARALLEL\n",
      "Using ThreadPoolExecutor with 5 workers (one per fold)\n",
      "============================================================\n",
      "\n",
      "STARTING HYBRID NEUROEVOLUTION PROCESS (adaptive mutation + generation-level early stopping)\n",
      "================================================================================\n",
      "Configuration:\n",
      "   Population: 20 individuals\n",
      "   Maximum generations: 100\n",
      "   Target fitness: 80.0%\n",
      "   Early stopping (generations): 20 without improvement\n",
      "   Min improvement threshold: 0.01%\n",
      "   Device: cuda\n",
      "================================================================================\n",
      "Initializing population of 20 individuals...\n",
      "Population initialized with 20 individuals\n",
      "\n",
      "================================================================================\n",
      "GENERATION 0\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 0)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: bd448f4e)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model bd448f4e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5410, acc=67.81% (best=67.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6078, acc=69.53% (best=69.53%)\n",
      "          Fold 5 Epoch 1: loss=0.5480, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.5802, acc=81.56% (best=81.56%)\n",
      "          Fold 1 Epoch 1: loss=0.4134, acc=64.77% (best=64.77%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 81.56%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 69.53%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 66.64%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 70.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd448f4e:\n",
      "        Fold accuracies: ['70.78%', '67.81%', '81.56%', '69.53%', '66.64%']\n",
      "        Average fitness: 71.27% Â± 5.34%\n",
      "        Best fold: Fold 3 with 81.56%\n",
      "      New best fitness in this generation: 71.27%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 71.27% > 0.00%\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen0_idbd448f4e_fitness71.27.pth\n",
      "        Fitness: 71.27%, ID: bd448f4e, Gen: 0\n",
      "      Fitness obtained: 71.27% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 480da505)\n",
      "      Architecture: 7 conv + 6 fc, opt=adam, lr=0.1\n",
      "      Training/Evaluating model 480da505 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7036, acc=65.39% (best=65.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7086, acc=73.12% (best=73.12%)\n",
      "          Fold 5 Epoch 1: loss=0.7103, acc=54.45% (best=54.45%)\n",
      "          Fold 1 Epoch 1: loss=0.7330, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6902, acc=49.92% (best=49.92%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.12%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 64.53%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 67.89%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 65.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 480da505:\n",
      "        Fold accuracies: ['65.62%', '64.53%', '73.12%', '67.89%', '61.88%']\n",
      "        Average fitness: 66.61% Â± 3.79%\n",
      "        Best fold: Fold 3 with 73.12%\n",
      "      Fitness obtained: 66.61% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 14e3fec1)\n",
      "      Architecture: 9 conv + 5 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 14e3fec1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7046, acc=43.20% (best=43.20%)\n",
      "          Fold 2 Epoch 1: loss=0.7221, acc=49.92% (best=49.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7255, acc=47.03% (best=47.03%)\n",
      "          Fold 4 Epoch 1: loss=0.7145, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.7297, acc=52.81% (best=52.81%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 51.41%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 72.66%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 53.52%\n",
      "          Fold 2 Epoch 30: loss=0.6072, acc=71.95% (best=71.95%)\n",
      "          Fold 1 Epoch 30: loss=0.1391, acc=60.31% (best=63.98%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 1: Early stopping at epoch 41\n",
      "      â†’ Fold 1 completed: 65.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 14e3fec1:\n",
      "        Fold accuracies: ['65.86%', '71.95%', '72.66%', '53.52%', '51.41%']\n",
      "        Average fitness: 63.08% Â± 9.01%\n",
      "        Best fold: Fold 3 with 72.66%\n",
      "      Fitness obtained: 63.08% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 394c1d9b)\n",
      "      Architecture: 8 conv + 7 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 394c1d9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7359, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7468, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7447, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.7304, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7466, acc=49.61% (best=49.61%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 49.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 394c1d9b:\n",
      "        Fold accuracies: ['49.61%', '50.08%', '48.83%', '49.61%', '49.53%']\n",
      "        Average fitness: 49.53% Â± 0.40%\n",
      "        Best fold: Fold 2 with 50.08%\n",
      "      Fitness obtained: 49.53% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: a4438978)\n",
      "      Architecture: 10 conv + 7 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model a4438978 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.8175, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.7283, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7241, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 1: loss=0.7173, acc=49.92% (best=49.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7230, acc=49.61% (best=49.61%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.47%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 49.61%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.17%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a4438978:\n",
      "        Fold accuracies: ['49.61%', '49.92%', '51.17%', '49.61%', '50.47%']\n",
      "        Average fitness: 50.16% Â± 0.60%\n",
      "        Best fold: Fold 3 with 51.17%\n",
      "      Fitness obtained: 50.16% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: ddf77558)\n",
      "      Architecture: 2 conv + 5 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model ddf77558 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7244, acc=49.92% (best=49.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7102, acc=51.17% (best=51.17%)\n",
      "          Fold 3 Epoch 1: loss=0.7376, acc=52.66% (best=52.66%)\n",
      "          Fold 1 Epoch 1: loss=0.7281, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7274, acc=44.53% (best=44.53%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 51.17%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 52.81%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 57.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ddf77558:\n",
      "        Fold accuracies: ['50.39%', '57.50%', '52.81%', '49.61%', '51.17%']\n",
      "        Average fitness: 52.30% Â± 2.81%\n",
      "        Best fold: Fold 2 with 57.50%\n",
      "      Fitness obtained: 52.30% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 81f78663)\n",
      "      Architecture: 3 conv + 6 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 81f78663 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6496, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7054, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6926, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.6977, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7076, acc=49.61% (best=49.61%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 61.25%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 51.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 81f78663:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '61.25%', '49.61%', '51.88%']\n",
      "        Average fitness: 52.64% Â± 4.37%\n",
      "        Best fold: Fold 3 with 61.25%\n",
      "      Fitness obtained: 52.64% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 948fed18)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 948fed18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6831, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6654, acc=51.17% (best=51.17%)\n",
      "          Fold 5 Epoch 1: loss=0.6837, acc=50.47% (best=50.47%)\n",
      "          Fold 1 Epoch 1: loss=0.6621, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6662, acc=50.39% (best=50.39%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 54.30%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.56%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 59.38%\n",
      "          Fold 2 Epoch 30: loss=0.1473, acc=73.98% (best=78.36%)\n",
      "          Fold 5 Epoch 30: loss=0.1371, acc=59.53% (best=62.81%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 78.36%\n",
      "          Fold 5: Early stopping at epoch 41\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 948fed18:\n",
      "        Fold accuracies: ['76.56%', '78.36%', '54.30%', '59.38%', '63.44%']\n",
      "        Average fitness: 66.41% Â± 9.50%\n",
      "        Best fold: Fold 2 with 78.36%\n",
      "      Fitness obtained: 66.41% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 9c670e17)\n",
      "      Architecture: 1 conv + 2 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 9c670e17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7265, acc=43.67% (best=43.67%)\n",
      "          Fold 2 Epoch 1: loss=0.6980, acc=43.67% (best=43.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7194, acc=61.56% (best=61.56%)\n",
      "          Fold 5 Epoch 1: loss=0.7242, acc=39.61% (best=39.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7224, acc=55.00% (best=55.00%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.89%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 72.19%\n",
      "          Fold 4 Epoch 30: loss=0.4921, acc=53.36% (best=53.36%)\n",
      "          Fold 2 Epoch 30: loss=0.4852, acc=63.59% (best=64.45%)\n",
      "          Fold 5 Epoch 30: loss=0.5139, acc=57.73% (best=59.06%)\n",
      "          Fold 5: Early stopping at epoch 41\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 2: Early stopping at epoch 42\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "          Fold 4: Early stopping at epoch 54\n",
      "      â†’ Fold 4 completed: 61.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9c670e17:\n",
      "        Fold accuracies: ['72.19%', '66.48%', '62.89%', '61.48%', '60.23%']\n",
      "        Average fitness: 64.66% Â± 4.31%\n",
      "        Best fold: Fold 1 with 72.19%\n",
      "      Fitness obtained: 64.66% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 829c689b)\n",
      "      Architecture: 11 conv + 8 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 829c689b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7221, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7248, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.7197, acc=70.78% (best=70.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6630, acc=71.80% (best=71.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7027, acc=48.83% (best=48.83%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.78%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 71.80%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 70.86%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 61.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 829c689b:\n",
      "        Fold accuracies: ['71.80%', '70.78%', '61.95%', '50.39%', '70.86%']\n",
      "        Average fitness: 65.16% Â± 8.20%\n",
      "        Best fold: Fold 1 with 71.80%\n",
      "      Fitness obtained: 65.16% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: ac3c91e9)\n",
      "      Architecture: 5 conv + 8 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model ac3c91e9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6873, acc=64.06% (best=64.06%)\n",
      "          Fold 5 Epoch 1: loss=0.5420, acc=60.23% (best=60.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6525, acc=71.25% (best=71.25%)\n",
      "          Fold 1 Epoch 1: loss=0.6480, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6859, acc=50.23% (best=50.23%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 65.70%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 69.38%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 64.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ac3c91e9:\n",
      "        Fold accuracies: ['69.38%', '65.70%', '78.83%', '64.22%', '60.23%']\n",
      "        Average fitness: 67.67% Â± 6.30%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 67.67% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 27b6b45f)\n",
      "      Architecture: 5 conv + 8 fc, opt=adam, lr=0.0001\n",
      "      Training/Evaluating model 27b6b45f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7263, acc=55.31% (best=55.31%)\n",
      "          Fold 4 Epoch 1: loss=0.7195, acc=38.59% (best=38.59%)\n",
      "          Fold 3 Epoch 1: loss=0.7108, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.7055, acc=58.75% (best=58.75%)\n",
      "          Fold 1 Epoch 1: loss=0.7146, acc=54.92% (best=54.92%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 54.92%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 4 Epoch 30: loss=0.1435, acc=51.33% (best=55.00%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 55.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 27b6b45f:\n",
      "        Fold accuracies: ['54.92%', '65.16%', '48.83%', '55.00%', '66.48%']\n",
      "        Average fitness: 58.08% Â± 6.72%\n",
      "        Best fold: Fold 5 with 66.48%\n",
      "      Fitness obtained: 58.08% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: ad19ad66)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ad19ad66 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6288, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6056, acc=69.45% (best=69.45%)\n",
      "          Fold 3 Epoch 1: loss=0.6335, acc=69.14% (best=69.14%)\n",
      "          Fold 1 Epoch 1: loss=0.5316, acc=72.42% (best=72.42%)\n",
      "          Fold 5 Epoch 1: loss=0.6440, acc=54.61% (best=54.61%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 77.34%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 56.33%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 67.19%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 72.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ad19ad66:\n",
      "        Fold accuracies: ['77.34%', '56.33%', '72.66%', '70.31%', '67.19%']\n",
      "        Average fitness: 68.77% Â± 7.05%\n",
      "        Best fold: Fold 1 with 77.34%\n",
      "      Fitness obtained: 68.77% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 8183ee1b)\n",
      "      Architecture: 6 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 8183ee1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6104, acc=70.47% (best=70.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6221, acc=68.52% (best=68.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6374, acc=55.62% (best=55.62%)\n",
      "          Fold 2 Epoch 1: loss=0.6277, acc=56.72% (best=56.72%)\n",
      "          Fold 1 Epoch 1: loss=0.5351, acc=64.84% (best=64.84%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 73.44%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 57.03%\n",
      "          Fold 5 Epoch 30: loss=0.1569, acc=68.28% (best=69.84%)\n",
      "          Fold 5: Early stopping at epoch 35\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8183ee1b:\n",
      "        Fold accuracies: ['64.84%', '57.03%', '73.44%', '70.47%', '69.84%']\n",
      "        Average fitness: 67.12% Â± 5.75%\n",
      "        Best fold: Fold 3 with 73.44%\n",
      "      Fitness obtained: 67.12% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: fbb747d5)\n",
      "      Architecture: 11 conv + 9 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model fbb747d5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7184, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7210, acc=51.17% (best=51.17%)\n",
      "          Fold 4 Epoch 1: loss=0.7436, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7259, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7251, acc=50.39% (best=50.39%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.47%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.17%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 58.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fbb747d5:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '51.17%', '58.44%', '50.47%']\n",
      "        Average fitness: 52.11% Â± 3.18%\n",
      "        Best fold: Fold 4 with 58.44%\n",
      "      Fitness obtained: 52.11% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 8ebc4982)\n",
      "      Architecture: 8 conv + 9 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 8ebc4982 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7164, acc=44.92% (best=44.92%)\n",
      "          Fold 2 Epoch 1: loss=0.7227, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.7213, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7244, acc=51.17% (best=51.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7291, acc=49.61% (best=49.61%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 54.77%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 66.17%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 68.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8ebc4982:\n",
      "        Fold accuracies: ['68.52%', '66.17%', '54.77%', '50.39%', '58.52%']\n",
      "        Average fitness: 59.67% Â± 6.81%\n",
      "        Best fold: Fold 1 with 68.52%\n",
      "      Fitness obtained: 59.67% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: c985fa74)\n",
      "      Architecture: 4 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c985fa74 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.3107, acc=47.03% (best=47.03%)\n",
      "          Fold 4 Epoch 1: loss=0.2892, acc=46.64% (best=46.64%)\n",
      "          Fold 2 Epoch 1: loss=0.4453, acc=53.20% (best=53.20%)\n",
      "          Fold 3 Epoch 1: loss=0.2396, acc=62.03% (best=62.03%)\n",
      "          Fold 1 Epoch 1: loss=0.1003, acc=57.58% (best=57.58%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 63.91%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 71.64%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 67.89%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 54.61%\n",
      "          Fold 4 Epoch 30: loss=0.0684, acc=58.12% (best=62.50%)\n",
      "          Fold 4: Early stopping at epoch 35\n",
      "      â†’ Fold 4 completed: 62.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c985fa74:\n",
      "        Fold accuracies: ['67.89%', '63.91%', '71.64%', '62.50%', '54.61%']\n",
      "        Average fitness: 64.11% Â± 5.73%\n",
      "        Best fold: Fold 3 with 71.64%\n",
      "      Fitness obtained: 64.11% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 8d42246d)\n",
      "      Architecture: 1 conv + 8 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 8d42246d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7254, acc=47.73% (best=47.73%)\n",
      "          Fold 2 Epoch 1: loss=0.7448, acc=49.92% (best=49.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7182, acc=55.16% (best=55.16%)\n",
      "          Fold 4 Epoch 1: loss=0.7450, acc=51.80% (best=51.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7193, acc=46.33% (best=46.33%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 51.88%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 53.36%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 56.02%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 2 Epoch 30: loss=0.6710, acc=72.81% (best=72.81%)\n",
      "          Fold 2: Early stopping at epoch 59\n",
      "      â†’ Fold 2 completed: 76.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8d42246d:\n",
      "        Fold accuracies: ['56.02%', '76.95%', '53.36%', '51.88%', '58.98%']\n",
      "        Average fitness: 59.44% Â± 9.09%\n",
      "        Best fold: Fold 2 with 76.95%\n",
      "      Fitness obtained: 59.44% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 1b7968a4)\n",
      "      Architecture: 6 conv + 9 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 1b7968a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7227, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7440, acc=40.00% (best=40.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7149, acc=51.17% (best=51.17%)\n",
      "          Fold 5 Epoch 1: loss=0.7181, acc=49.45% (best=49.45%)\n",
      "          Fold 1 Epoch 1: loss=0.7511, acc=50.39% (best=50.39%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.17%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 45.86%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 58.36%\n",
      "          Fold 5 Epoch 30: loss=0.7187, acc=58.67% (best=58.67%)\n",
      "          Fold 5: Early stopping at epoch 36\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b7968a4:\n",
      "        Fold accuracies: ['50.39%', '45.86%', '51.17%', '58.36%', '58.67%']\n",
      "        Average fitness: 52.89% Â± 4.94%\n",
      "        Best fold: Fold 5 with 58.67%\n",
      "      Fitness obtained: 52.89% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 44696398)\n",
      "      Architecture: 1 conv + 7 fc, opt=sgd, lr=0.1\n",
      "      Training/Evaluating model 44696398 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6759, acc=46.33% (best=46.33%)\n",
      "          Fold 2 Epoch 1: loss=0.5960, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6877, acc=46.17% (best=46.17%)\n",
      "          Fold 5 Epoch 1: loss=0.6585, acc=51.48% (best=51.48%)\n",
      "          Fold 1 Epoch 1: loss=0.5330, acc=50.39% (best=50.39%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 51.48%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 53.52%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 44696398:\n",
      "        Fold accuracies: ['63.52%', '59.92%', '68.67%', '53.52%', '51.48%']\n",
      "        Average fitness: 59.42% Â± 6.33%\n",
      "        Best fold: Fold 3 with 68.67%\n",
      "      Fitness obtained: 59.42% | Best in generation: 71.27% | Global best: 71.27%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 0 STATISTICS:\n",
      "   Maximum fitness: 71.27%\n",
      "   Average fitness: 60.55%\n",
      "   Minimum fitness: 49.53%\n",
      "   Standard deviation: 6.72%\n",
      "   Best individual: bd448f4e with 71.27%\n",
      "   Global best individual: bd448f4e with 71.27%\n",
      "Adaptive mutation rate updated to 0.1811 (std_fitness=6.72)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: bd448f4e (fitness: 71.27%)\n",
      "   Elite 2: ad19ad66 (fitness: 68.77%)\n",
      "   Elite 3: ac3c91e9 (fitness: 67.67%)\n",
      "   Elite 4: 8183ee1b (fitness: 67.12%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "ðŸ”„ Improvement detected: inf% | Generations without improvement: 0\n",
      "\n",
      "================================================================================\n",
      "GENERATION 1\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 1)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: bd448f4e)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model bd448f4e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5209, acc=67.89% (best=67.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5565, acc=66.72% (best=66.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6023, acc=66.25% (best=66.25%)\n",
      "          Fold 1 Epoch 1: loss=0.4178, acc=70.23% (best=70.23%)\n",
      "          Fold 5 Epoch 1: loss=0.5679, acc=61.80% (best=61.80%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 77.73%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.36%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 76.09%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 75.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd448f4e:\n",
      "        Fold accuracies: ['76.09%', '68.36%', '77.73%', '75.39%', '61.80%']\n",
      "        Average fitness: 71.88% Â± 5.97%\n",
      "        Best fold: Fold 3 with 77.73%\n",
      "      New best fitness in this generation: 71.88%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 71.88% > 71.27%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen0_idbd448f4e_fitness71.27.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen1_idbd448f4e_fitness71.88.pth\n",
      "        Fitness: 71.88%, ID: bd448f4e, Gen: 1\n",
      "      Fitness obtained: 71.88% | Best in generation: 71.88% | Global best: 71.88%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: ad19ad66)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ad19ad66 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6243, acc=57.11% (best=57.11%)\n",
      "          Fold 2 Epoch 1: loss=0.5806, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 1: loss=0.5953, acc=63.36% (best=63.36%)\n",
      "          Fold 3 Epoch 1: loss=0.6173, acc=69.22% (best=69.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5264, acc=60.31% (best=60.31%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.97%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.36%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.62%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 67.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ad19ad66:\n",
      "        Fold accuracies: ['67.97%', '67.97%', '79.69%', '60.62%', '63.36%']\n",
      "        Average fitness: 67.92% Â± 6.52%\n",
      "        Best fold: Fold 3 with 79.69%\n",
      "      Fitness obtained: 67.92% | Best in generation: 71.88% | Global best: 71.88%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: ac3c91e9)\n",
      "      Architecture: 5 conv + 8 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model ac3c91e9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6334, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6888, acc=52.89% (best=52.89%)\n",
      "          Fold 2 Epoch 1: loss=0.5116, acc=60.78% (best=60.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6915, acc=46.02% (best=46.02%)\n",
      "          Fold 1 Epoch 1: loss=0.5313, acc=55.55% (best=55.55%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 76.72%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 66.95%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 66.80%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 60.62%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ac3c91e9:\n",
      "        Fold accuracies: ['66.80%', '73.75%', '76.72%', '60.62%', '66.95%']\n",
      "        Average fitness: 68.97% Â± 5.68%\n",
      "        Best fold: Fold 3 with 76.72%\n",
      "      Fitness obtained: 68.97% | Best in generation: 71.88% | Global best: 71.88%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 8183ee1b)\n",
      "      Architecture: 6 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 8183ee1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6216, acc=65.31% (best=65.31%)\n",
      "          Fold 4 Epoch 1: loss=0.5965, acc=63.91% (best=63.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6078, acc=66.41% (best=66.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6100, acc=77.42% (best=77.42%)\n",
      "          Fold 1 Epoch 1: loss=0.5694, acc=73.59% (best=73.59%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.59%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.92%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8183ee1b:\n",
      "        Fold accuracies: ['73.59%', '66.41%', '79.92%', '65.70%', '67.03%']\n",
      "        Average fitness: 70.53% Â± 5.48%\n",
      "        Best fold: Fold 3 with 79.92%\n",
      "      Fitness obtained: 70.53% | Best in generation: 71.88% | Global best: 71.88%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 8c6a6116)\n",
      "      Architecture: 7 conv + 5 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 8c6a6116 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6553, acc=64.45% (best=64.45%)\n",
      "          Fold 2 Epoch 1: loss=0.6562, acc=59.92% (best=59.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6827, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 1: loss=0.6594, acc=76.09% (best=76.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6573, acc=74.14% (best=74.14%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.14%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.22%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 67.19%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 83.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8c6a6116:\n",
      "        Fold accuracies: ['74.14%', '65.86%', '83.52%', '67.19%', '69.22%']\n",
      "        Average fitness: 71.98% Â± 6.42%\n",
      "        Best fold: Fold 3 with 83.52%\n",
      "      New best fitness in this generation: 71.98%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 71.98% > 71.88%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen1_idbd448f4e_fitness71.88.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen1_id8c6a6116_fitness71.98.pth\n",
      "        Fitness: 71.98%, ID: 8c6a6116, Gen: 1\n",
      "      Fitness obtained: 71.98% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 74eee741)\n",
      "      Architecture: 9 conv + 6 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 74eee741 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=1.1379, acc=51.17% (best=51.17%)\n",
      "          Fold 1 Epoch 1: loss=0.8941, acc=43.12% (best=43.12%)\n",
      "          Fold 3 Epoch 1: loss=1.0705, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=1.0836, acc=65.47% (best=65.47%)\n",
      "          Fold 4 Epoch 1: loss=1.0437, acc=49.61% (best=49.61%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.06%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 69.69%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 73.52%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 74.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 74eee741:\n",
      "        Fold accuracies: ['73.52%', '69.69%', '74.38%', '70.31%', '59.06%']\n",
      "        Average fitness: 69.39% Â± 5.47%\n",
      "        Best fold: Fold 3 with 74.38%\n",
      "      Fitness obtained: 69.39% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: ac2e90b7)\n",
      "      Architecture: 1 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model ac2e90b7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.2970, acc=63.12% (best=63.12%)\n",
      "          Fold 4 Epoch 1: loss=0.3198, acc=58.59% (best=58.59%)\n",
      "          Fold 5 Epoch 1: loss=0.2862, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.3172, acc=62.97% (best=62.97%)\n",
      "          Fold 1 Epoch 1: loss=0.2139, acc=67.27% (best=67.27%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.23%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 71.17%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 71.64%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 65.08%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 58.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ac2e90b7:\n",
      "        Fold accuracies: ['71.17%', '65.08%', '71.64%', '60.23%', '58.83%']\n",
      "        Average fitness: 65.39% Â± 5.33%\n",
      "        Best fold: Fold 3 with 71.64%\n",
      "      Fitness obtained: 65.39% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 1328bcee)\n",
      "      Architecture: 9 conv + 5 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 1328bcee with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7207, acc=54.22% (best=54.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7263, acc=53.44% (best=53.44%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 63.05%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 60.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1328bcee:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '60.70%', '0.00%', '63.05%']\n",
      "        Average fitness: 24.75% Â± 30.32%\n",
      "        Best fold: Fold 5 with 63.05%\n",
      "      Fitness obtained: 24.75% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 15f58951)\n",
      "      Architecture: 4 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 15f58951 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.2298, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.1078, acc=59.38% (best=59.38%)\n",
      "          Fold 3 Epoch 1: loss=0.2199, acc=62.73% (best=62.73%)\n",
      "          Fold 2 Epoch 1: loss=0.2195, acc=61.56% (best=61.56%)\n",
      "          Fold 5 Epoch 1: loss=0.1970, acc=47.27% (best=47.27%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.56%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 66.80%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.31%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 66.88%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15f58951:\n",
      "        Fold accuracies: ['70.16%', '66.80%', '66.88%', '61.56%', '55.31%']\n",
      "        Average fitness: 64.14% Â± 5.20%\n",
      "        Best fold: Fold 1 with 70.16%\n",
      "      Fitness obtained: 64.14% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 7536e5ea)\n",
      "      Architecture: 4 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7536e5ea with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4329, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 1: loss=0.5010, acc=71.64% (best=71.64%)\n",
      "          Fold 5 Epoch 1: loss=0.2426, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 1: loss=0.2509, acc=47.42% (best=47.42%)\n",
      "          Fold 1 Epoch 1: loss=0.2575, acc=59.92% (best=59.92%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 71.64%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 52.11%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 68.75%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 54.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7536e5ea:\n",
      "        Fold accuracies: ['68.75%', '68.20%', '71.64%', '52.11%', '54.84%']\n",
      "        Average fitness: 63.11% Â± 8.00%\n",
      "        Best fold: Fold 3 with 71.64%\n",
      "      Fitness obtained: 63.11% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 5716e0d9)\n",
      "      Architecture: 7 conv + 6 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5716e0d9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.7398, acc=50.94% (best=50.94%)\n",
      "          Fold 1 Epoch 1: loss=0.7253, acc=50.39% (best=50.39%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 52.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5716e0d9:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '52.97%']\n",
      "        Average fitness: 10.59% Â± 21.19%\n",
      "        Best fold: Fold 5 with 52.97%\n",
      "      Fitness obtained: 10.59% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: b964d32a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model b964d32a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6428, acc=61.02% (best=61.02%)\n",
      "          Fold 3 Epoch 1: loss=0.6706, acc=44.84% (best=44.84%)\n",
      "          Fold 1 Epoch 1: loss=0.6176, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6764, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 1: loss=0.6472, acc=61.33% (best=61.33%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 61.02%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.33%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.55%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 78.91%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b964d32a:\n",
      "        Fold accuracies: ['73.28%', '61.02%', '78.91%', '65.55%', '61.33%']\n",
      "        Average fitness: 68.02% Â± 7.02%\n",
      "        Best fold: Fold 3 with 78.91%\n",
      "      Fitness obtained: 68.02% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 32cc815c)\n",
      "      Architecture: 5 conv + 8 fc, opt=adam, lr=0.0001\n",
      "      Training/Evaluating model 32cc815c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7073, acc=61.33% (best=61.33%)\n",
      "          Fold 3 Epoch 1: loss=0.7219, acc=53.44% (best=53.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7032, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.7039, acc=69.38% (best=69.38%)\n",
      "          Fold 1 Epoch 1: loss=0.6616, acc=71.88% (best=71.88%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 69.38%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.47%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 73.36%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 32cc815c:\n",
      "        Fold accuracies: ['71.88%', '69.38%', '73.36%', '74.84%', '50.47%']\n",
      "        Average fitness: 67.98% Â± 8.94%\n",
      "        Best fold: Fold 4 with 74.84%\n",
      "      Fitness obtained: 67.98% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 19045720)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 19045720 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7132, acc=41.41% (best=41.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6992, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 1: loss=0.7263, acc=44.69% (best=44.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6771, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.7239, acc=49.92% (best=49.92%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 67.42%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 51.17%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 66.02%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 59.92%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 66.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19045720:\n",
      "        Fold accuracies: ['59.92%', '66.02%', '51.17%', '67.42%', '66.09%']\n",
      "        Average fitness: 62.12% Â± 6.06%\n",
      "        Best fold: Fold 4 with 67.42%\n",
      "      Fitness obtained: 62.12% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 9f92f2ee)\n",
      "      Architecture: 6 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9f92f2ee with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6617, acc=54.45% (best=54.45%)\n",
      "          Fold 1 Epoch 1: loss=0.5747, acc=47.34% (best=47.34%)\n",
      "          Fold 2 Epoch 1: loss=0.6719, acc=63.12% (best=63.12%)\n",
      "          Fold 5 Epoch 1: loss=0.6484, acc=55.08% (best=55.08%)\n",
      "          Fold 4 Epoch 1: loss=0.5948, acc=38.83% (best=38.83%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 63.12%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.08%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "          Fold 3 Epoch 30: loss=0.1609, acc=77.66% (best=82.73%)\n",
      "          Fold 4 Epoch 30: loss=0.1624, acc=49.06% (best=52.34%)\n",
      "          Fold 3: Early stopping at epoch 32\n",
      "      â†’ Fold 3 completed: 82.73%\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 52.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9f92f2ee:\n",
      "        Fold accuracies: ['69.22%', '63.12%', '82.73%', '52.34%', '55.08%']\n",
      "        Average fitness: 64.50% Â± 10.89%\n",
      "        Best fold: Fold 3 with 82.73%\n",
      "      Fitness obtained: 64.50% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: c10fb964)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model c10fb964 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5414, acc=68.52% (best=68.52%)\n",
      "          Fold 5 Epoch 1: loss=0.5683, acc=48.44% (best=48.44%)\n",
      "          Fold 2 Epoch 1: loss=0.5565, acc=75.31% (best=75.31%)\n",
      "          Fold 1 Epoch 1: loss=0.4563, acc=69.92% (best=69.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6047, acc=55.31% (best=55.31%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 75.31%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 55.62%\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 75.16%\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c10fb964:\n",
      "        Fold accuracies: ['77.11%', '75.31%', '75.16%', '67.58%', '55.62%']\n",
      "        Average fitness: 70.16% Â± 7.97%\n",
      "        Best fold: Fold 1 with 77.11%\n",
      "      Fitness obtained: 70.16% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 2b677fbd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2b677fbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6275, acc=74.06% (best=74.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6226, acc=64.22% (best=64.22%)\n",
      "          Fold 5 Epoch 1: loss=0.6196, acc=59.06% (best=59.06%)\n",
      "          Fold 1 Epoch 1: loss=0.5969, acc=69.22% (best=69.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6163, acc=80.86% (best=80.86%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 74.06%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.09%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 66.48%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 66.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2b677fbd:\n",
      "        Fold accuracies: ['69.22%', '74.06%', '81.09%', '66.48%', '66.33%']\n",
      "        Average fitness: 71.44% Â± 5.58%\n",
      "        Best fold: Fold 3 with 81.09%\n",
      "      Fitness obtained: 71.44% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: ac6edd96)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model ac6edd96 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.6423, acc=58.75% (best=58.75%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 63.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ac6edd96:\n",
      "        Fold accuracies: ['63.75%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 12.75% Â± 25.50%\n",
      "        Best fold: Fold 1 with 63.75%\n",
      "      Fitness obtained: 12.75% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 970166bd)\n",
      "      Architecture: 11 conv + 8 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 970166bd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6775, acc=50.08% (best=50.08%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 970166bd:\n",
      "        Fold accuracies: ['0.00%', '67.27%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 13.45% Â± 26.91%\n",
      "        Best fold: Fold 2 with 67.27%\n",
      "      Fitness obtained: 13.45% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 64a456d6)\n",
      "      Architecture: 7 conv + 6 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 64a456d6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.9897, acc=51.25% (best=51.25%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 70.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 64a456d6:\n",
      "        Fold accuracies: ['0.00%', '70.78%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 14.16% Â± 28.31%\n",
      "        Best fold: Fold 2 with 70.78%\n",
      "      Fitness obtained: 14.16% | Best in generation: 71.98% | Global best: 71.98%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 1 STATISTICS:\n",
      "   Maximum fitness: 71.98%\n",
      "   Average fitness: 54.66%\n",
      "   Minimum fitness: 10.59%\n",
      "   Standard deviation: 23.11%\n",
      "   Best individual: 8c6a6116 with 71.98%\n",
      "   Global best individual: 8c6a6116 with 71.98%\n",
      "\n",
      "ðŸ”„ Improvement detected: 0.72% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=23.11)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8c6a6116 (fitness: 71.98%)\n",
      "   Elite 2: bd448f4e (fitness: 71.88%)\n",
      "   Elite 3: 2b677fbd (fitness: 71.44%)\n",
      "   Elite 4: 8183ee1b (fitness: 70.53%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 2\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 2)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 8c6a6116)\n",
      "      Architecture: 7 conv + 5 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 8c6a6116 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6497, acc=68.36% (best=68.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6669, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=0.6623, acc=56.72% (best=56.72%)\n",
      "          Fold 2 Epoch 1: loss=0.6544, acc=59.69% (best=59.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6729, acc=78.83% (best=78.83%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 56.95%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 80.00%\n",
      "          Fold 5 Epoch 30: loss=0.0951, acc=69.38% (best=73.59%)\n",
      "          Fold 5: Early stopping at epoch 39\n",
      "      â†’ Fold 5 completed: 73.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8c6a6116:\n",
      "        Fold accuracies: ['68.36%', '59.69%', '80.00%', '56.95%', '73.59%']\n",
      "        Average fitness: 67.72% Â± 8.56%\n",
      "        Best fold: Fold 3 with 80.00%\n",
      "      New best fitness in this generation: 67.72%!\n",
      "      Fitness obtained: 67.72% | Best in generation: 67.72% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: bd448f4e)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model bd448f4e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5476, acc=51.48% (best=51.48%)\n",
      "          Fold 5 Epoch 1: loss=0.5842, acc=58.59% (best=58.59%)\n",
      "          Fold 3 Epoch 1: loss=0.5600, acc=57.97% (best=57.97%)\n",
      "          Fold 4 Epoch 1: loss=0.5884, acc=48.28% (best=48.28%)\n",
      "          Fold 1 Epoch 1: loss=0.5115, acc=54.06% (best=54.06%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 64.22%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 68.91%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 72.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd448f4e:\n",
      "        Fold accuracies: ['68.91%', '72.50%', '78.83%', '73.12%', '64.22%']\n",
      "        Average fitness: 71.52% Â± 4.84%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      New best fitness in this generation: 71.52%!\n",
      "      Fitness obtained: 71.52% | Best in generation: 71.52% | Global best: 71.98%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 2b677fbd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2b677fbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6197, acc=84.14% (best=84.14%)\n",
      "          Fold 1 Epoch 1: loss=0.5612, acc=76.17% (best=76.17%)\n",
      "          Fold 4 Epoch 1: loss=0.6349, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.6132, acc=65.16% (best=65.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6300, acc=51.56% (best=51.56%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.17%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 88.91%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 69.22%\n",
      "          Fold 4 Epoch 30: loss=0.2957, acc=55.62% (best=62.42%)\n",
      "          Fold 2 Epoch 30: loss=0.2847, acc=70.62% (best=71.17%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 62.42%\n",
      "          Fold 2: Early stopping at epoch 42\n",
      "      â†’ Fold 2 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2b677fbd:\n",
      "        Fold accuracies: ['76.17%', '73.28%', '88.91%', '62.42%', '69.22%']\n",
      "        Average fitness: 74.00% Â± 8.77%\n",
      "        Best fold: Fold 3 with 88.91%\n",
      "      New best fitness in this generation: 74.00%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 74.00% > 71.98%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen1_id8c6a6116_fitness71.98.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen2_id2b677fbd_fitness74.00.pth\n",
      "        Fitness: 74.00%, ID: 2b677fbd, Gen: 2\n",
      "      Fitness obtained: 74.00% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 8183ee1b)\n",
      "      Architecture: 6 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 8183ee1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6157, acc=76.56% (best=76.56%)\n",
      "          Fold 5 Epoch 1: loss=0.6202, acc=60.00% (best=60.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6183, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 1: loss=0.5878, acc=69.14% (best=69.14%)\n",
      "          Fold 1 Epoch 1: loss=0.5771, acc=69.69% (best=69.69%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 69.14%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 71.80%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 64.06%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 73.98%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 80.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8183ee1b:\n",
      "        Fold accuracies: ['73.98%', '69.14%', '80.70%', '64.06%', '71.80%']\n",
      "        Average fitness: 71.94% Â± 5.49%\n",
      "        Best fold: Fold 3 with 80.70%\n",
      "      Fitness obtained: 71.94% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 5f80eb67)\n",
      "      Architecture: 6 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 5f80eb67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7196, acc=52.03% (best=52.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6997, acc=62.03% (best=62.03%)\n",
      "          Fold 3 Epoch 1: loss=0.7195, acc=53.91% (best=53.91%)\n",
      "          Fold 2 Epoch 1: loss=0.7213, acc=47.03% (best=47.03%)\n",
      "          Fold 4 Epoch 1: loss=0.7674, acc=49.84% (best=49.84%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 59.45%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 69.53%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 65.47%\n",
      "          Fold 5 Epoch 30: loss=0.6674, acc=57.50% (best=59.61%)\n",
      "          Fold 5 Epoch 60: loss=0.6415, acc=59.61% (best=62.34%)\n",
      "          Fold 5: Early stopping at epoch 60\n",
      "      â†’ Fold 5 completed: 62.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5f80eb67:\n",
      "        Fold accuracies: ['63.52%', '65.47%', '59.45%', '69.53%', '62.34%']\n",
      "        Average fitness: 64.06% Â± 3.36%\n",
      "        Best fold: Fold 4 with 69.53%\n",
      "      Fitness obtained: 64.06% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 71864bec)\n",
      "      Architecture: 6 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 71864bec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6063, acc=55.62% (best=55.62%)\n",
      "          Fold 2 Epoch 1: loss=0.5873, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6301, acc=69.69% (best=69.69%)\n",
      "          Fold 4 Epoch 1: loss=0.5826, acc=55.23% (best=55.23%)\n",
      "          Fold 1 Epoch 1: loss=0.5596, acc=69.92% (best=69.92%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.62%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 55.23%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 69.92%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 63.12%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 70.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 71864bec:\n",
      "        Fold accuracies: ['69.92%', '63.12%', '70.08%', '55.23%', '55.62%']\n",
      "        Average fitness: 62.80% Â± 6.52%\n",
      "        Best fold: Fold 3 with 70.08%\n",
      "      Fitness obtained: 62.80% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 6c51246d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 6c51246d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4368, acc=62.58% (best=62.58%)\n",
      "          Fold 3 Epoch 1: loss=0.5818, acc=65.47% (best=65.47%)\n",
      "          Fold 5 Epoch 1: loss=0.4728, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 1: loss=0.4752, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 1: loss=0.4034, acc=49.53% (best=49.53%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 67.19%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 74.06%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 78.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6c51246d:\n",
      "        Fold accuracies: ['78.59%', '67.19%', '74.06%', '68.83%', '61.25%']\n",
      "        Average fitness: 69.98% Â± 5.94%\n",
      "        Best fold: Fold 1 with 78.59%\n",
      "      Fitness obtained: 69.98% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 0b0cd0ed)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 0b0cd0ed with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6577, acc=60.23% (best=60.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6725, acc=67.11% (best=67.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6412, acc=58.52% (best=58.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6811, acc=86.02% (best=86.02%)\n",
      "          Fold 1 Epoch 1: loss=0.6598, acc=61.25% (best=61.25%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 58.52%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.02%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 64.30%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 72.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0b0cd0ed:\n",
      "        Fold accuracies: ['64.30%', '58.52%', '86.02%', '72.97%', '69.84%']\n",
      "        Average fitness: 70.33% Â± 9.27%\n",
      "        Best fold: Fold 3 with 86.02%\n",
      "      Fitness obtained: 70.33% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 45c7d985)\n",
      "      Architecture: 5 conv + 8 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 45c7d985 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7188, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7171, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7120, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7232, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7163, acc=48.83% (best=48.83%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 45c7d985:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '50.39%', '49.53%']\n",
      "        Average fitness: 49.84% Â± 0.60%\n",
      "        Best fold: Fold 4 with 50.39%\n",
      "      Fitness obtained: 49.84% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: e4a9a33a)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model e4a9a33a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5246, acc=69.30% (best=69.30%)\n",
      "          Fold 1 Epoch 1: loss=0.4173, acc=62.27% (best=62.27%)\n",
      "          Fold 5 Epoch 1: loss=0.4706, acc=47.89% (best=47.89%)\n",
      "          Fold 2 Epoch 1: loss=0.4978, acc=51.33% (best=51.33%)\n",
      "          Fold 4 Epoch 1: loss=0.5036, acc=50.39% (best=50.39%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 60.86%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 71.72%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 2 Epoch 30: loss=0.0709, acc=58.28% (best=73.59%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 73.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e4a9a33a:\n",
      "        Fold accuracies: ['0.00%', '73.59%', '71.72%', '67.50%', '60.86%']\n",
      "        Average fitness: 54.73% Â± 27.71%\n",
      "        Best fold: Fold 2 with 73.59%\n",
      "      Fitness obtained: 54.73% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 19512b2b)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 19512b2b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5047, acc=44.22% (best=44.22%)\n",
      "          Fold 3 Epoch 1: loss=0.5836, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 1: loss=0.5225, acc=58.20% (best=58.20%)\n",
      "          Fold 5 Epoch 1: loss=0.5062, acc=60.47% (best=60.47%)\n",
      "          Fold 1 Epoch 1: loss=0.3700, acc=55.16% (best=55.16%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 83.83%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 72.81%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 67.89%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19512b2b:\n",
      "        Fold accuracies: ['72.81%', '66.72%', '83.83%', '67.34%', '67.89%']\n",
      "        Average fitness: 71.72% Â± 6.43%\n",
      "        Best fold: Fold 3 with 83.83%\n",
      "      Fitness obtained: 71.72% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 1d33bd50)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 1d33bd50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6237, acc=49.45% (best=49.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6119, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 1: loss=0.5995, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.5039, acc=48.98% (best=48.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6033, acc=68.59% (best=68.59%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 81.41%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "          Fold 3 Epoch 30: loss=0.0992, acc=83.67% (best=88.20%)\n",
      "          Fold 2 Epoch 30: loss=0.1005, acc=57.42% (best=68.83%)\n",
      "          Fold 3: Early stopping at epoch 32\n",
      "      â†’ Fold 3 completed: 88.20%\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d33bd50:\n",
      "        Fold accuracies: ['81.41%', '68.83%', '88.20%', '71.17%', '57.03%']\n",
      "        Average fitness: 73.33% Â± 10.74%\n",
      "        Best fold: Fold 3 with 88.20%\n",
      "      Fitness obtained: 73.33% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: defc536b)\n",
      "      Architecture: 7 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model defc536b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.3077, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.3289, acc=61.72% (best=61.72%)\n",
      "          Fold 3 Epoch 1: loss=0.2905, acc=71.80% (best=71.80%)\n",
      "          Fold 2 Epoch 1: loss=0.3495, acc=57.27% (best=57.27%)\n",
      "          Fold 1 Epoch 1: loss=0.1678, acc=71.56% (best=71.56%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 72.97%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 69.53%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 76.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for defc536b:\n",
      "        Fold accuracies: ['76.88%', '70.55%', '72.97%', '69.53%', '62.81%']\n",
      "        Average fitness: 70.55% Â± 4.62%\n",
      "        Best fold: Fold 1 with 76.88%\n",
      "      Fitness obtained: 70.55% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 21185973)\n",
      "      Architecture: 6 conv + 5 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 21185973 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6359, acc=43.59% (best=43.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6094, acc=77.66% (best=77.66%)\n",
      "          Fold 1 Epoch 1: loss=0.5592, acc=77.97% (best=77.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6236, acc=56.17% (best=56.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6374, acc=62.42% (best=62.42%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 77.66%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.97%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 65.31%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 70.23%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 21185973:\n",
      "        Fold accuracies: ['77.97%', '65.31%', '70.23%', '77.66%', '62.50%']\n",
      "        Average fitness: 70.73% Â± 6.29%\n",
      "        Best fold: Fold 1 with 77.97%\n",
      "      Fitness obtained: 70.73% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 1dc0009e)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1dc0009e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5617, acc=71.48% (best=71.48%)\n",
      "          Fold 3 Epoch 1: loss=0.5696, acc=71.17% (best=71.17%)\n",
      "          Fold 5 Epoch 1: loss=0.5832, acc=43.91% (best=43.91%)\n",
      "          Fold 1 Epoch 1: loss=0.5365, acc=56.56% (best=56.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6417, acc=50.31% (best=50.31%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 78.28%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 72.34%\n",
      "          Fold 4 Epoch 30: loss=0.0874, acc=76.48% (best=76.64%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 76.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1dc0009e:\n",
      "        Fold accuracies: ['72.34%', '71.48%', '78.28%', '76.64%', '65.00%']\n",
      "        Average fitness: 72.75% Â± 4.64%\n",
      "        Best fold: Fold 3 with 78.28%\n",
      "      Fitness obtained: 72.75% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: a043a515)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model a043a515 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6570, acc=53.36% (best=53.36%)\n",
      "          Fold 2 Epoch 1: loss=0.6605, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6605, acc=53.91% (best=53.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6623, acc=76.80% (best=76.80%)\n",
      "          Fold 1 Epoch 1: loss=0.6456, acc=66.17% (best=66.17%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.38%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 85.62%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 2 Epoch 30: loss=0.1974, acc=63.67% (best=67.27%)\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a043a515:\n",
      "        Fold accuracies: ['85.62%', '67.27%', '79.38%', '63.83%', '57.03%']\n",
      "        Average fitness: 70.62% Â± 10.43%\n",
      "        Best fold: Fold 1 with 85.62%\n",
      "      Fitness obtained: 70.62% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: f71a76d7)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model f71a76d7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4695, acc=49.92% (best=49.92%)\n",
      "          Fold 5 Epoch 1: loss=0.5466, acc=47.97% (best=47.97%)\n",
      "          Fold 3 Epoch 1: loss=0.5478, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 1: loss=0.5698, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6245, acc=44.92% (best=44.92%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 55.31%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 72.42%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 70.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f71a76d7:\n",
      "        Fold accuracies: ['70.31%', '55.31%', '72.42%', '64.84%', '67.27%']\n",
      "        Average fitness: 66.03% Â± 5.95%\n",
      "        Best fold: Fold 3 with 72.42%\n",
      "      Fitness obtained: 66.03% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 32399d60)\n",
      "      Architecture: 5 conv + 8 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 32399d60 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6796, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7019, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7079, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6660, acc=56.72% (best=56.72%)\n",
      "          Fold 5 Epoch 1: loss=0.6895, acc=49.53% (best=49.53%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.72%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 57.97%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 54.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 32399d60:\n",
      "        Fold accuracies: ['56.72%', '50.08%', '48.83%', '54.69%', '57.97%']\n",
      "        Average fitness: 53.66% Â± 3.61%\n",
      "        Best fold: Fold 5 with 57.97%\n",
      "      Fitness obtained: 53.66% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 3a7f4534)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 3a7f4534 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5842, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 1: loss=0.5813, acc=63.52% (best=63.52%)\n",
      "          Fold 4 Epoch 1: loss=0.5889, acc=71.95% (best=71.95%)\n",
      "          Fold 3 Epoch 1: loss=0.5564, acc=78.83% (best=78.83%)\n",
      "          Fold 1 Epoch 1: loss=0.4601, acc=57.97% (best=57.97%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 71.33%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 75.39%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 74.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3a7f4534:\n",
      "        Fold accuracies: ['75.39%', '71.33%', '78.83%', '74.30%', '56.88%']\n",
      "        Average fitness: 71.34% Â± 7.62%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 71.34% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: f3832ea2)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model f3832ea2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f3832ea2:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 74.00% | Global best: 74.00%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 2 STATISTICS:\n",
      "   Maximum fitness: 74.00%\n",
      "   Average fitness: 63.88%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 16.14%\n",
      "   Best individual: 2b677fbd with 74.00%\n",
      "   Global best individual: 2b677fbd with 74.00%\n",
      "\n",
      "ðŸ”„ Improvement detected: 2.02% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=16.14)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 2b677fbd (fitness: 74.00%)\n",
      "   Elite 2: 1d33bd50 (fitness: 73.33%)\n",
      "   Elite 3: 1dc0009e (fitness: 72.75%)\n",
      "   Elite 4: 8183ee1b (fitness: 71.94%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 3\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 3)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 2b677fbd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2b677fbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6812, acc=63.91% (best=63.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6188, acc=77.27% (best=77.27%)\n",
      "          Fold 5 Epoch 1: loss=0.6032, acc=71.48% (best=71.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6080, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5292, acc=64.84% (best=64.84%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.27%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 73.05%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 65.62%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2b677fbd:\n",
      "        Fold accuracies: ['65.62%', '66.25%', '77.27%', '68.83%', '73.05%']\n",
      "        Average fitness: 70.20% Â± 4.39%\n",
      "        Best fold: Fold 3 with 77.27%\n",
      "      New best fitness in this generation: 70.20%!\n",
      "      Fitness obtained: 70.20% | Best in generation: 70.20% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 1d33bd50)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 1d33bd50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5564, acc=48.59% (best=48.59%)\n",
      "          Fold 3 Epoch 1: loss=0.5988, acc=67.81% (best=67.81%)\n",
      "          Fold 4 Epoch 1: loss=0.5740, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=0.4605, acc=66.09% (best=66.09%)\n",
      "          Fold 2 Epoch 1: loss=0.6006, acc=39.84% (best=39.84%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 72.34%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 74.84%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 60.16%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 83.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d33bd50:\n",
      "        Fold accuracies: ['72.34%', '74.84%', '83.12%', '67.50%', '60.16%']\n",
      "        Average fitness: 71.59% Â± 7.64%\n",
      "        Best fold: Fold 3 with 83.12%\n",
      "      New best fitness in this generation: 71.59%!\n",
      "      Fitness obtained: 71.59% | Best in generation: 71.59% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 1dc0009e)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1dc0009e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6127, acc=74.22% (best=74.22%)\n",
      "          Fold 2 Epoch 1: loss=0.6301, acc=42.34% (best=42.34%)\n",
      "          Fold 5 Epoch 1: loss=0.5675, acc=60.70% (best=60.70%)\n",
      "          Fold 4 Epoch 1: loss=0.6085, acc=61.95% (best=61.95%)\n",
      "          Fold 1 Epoch 1: loss=0.4842, acc=57.89% (best=57.89%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 74.22%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 79.53%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.98%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 71.41%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 71.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1dc0009e:\n",
      "        Fold accuracies: ['79.53%', '68.98%', '74.22%', '71.41%', '71.41%']\n",
      "        Average fitness: 73.11% Â± 3.61%\n",
      "        Best fold: Fold 1 with 79.53%\n",
      "      New best fitness in this generation: 73.11%!\n",
      "      Fitness obtained: 73.11% | Best in generation: 73.11% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 8183ee1b)\n",
      "      Architecture: 6 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 8183ee1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5959, acc=68.36% (best=68.36%)\n",
      "          Fold 5 Epoch 1: loss=0.6454, acc=50.16% (best=50.16%)\n",
      "          Fold 3 Epoch 1: loss=0.6140, acc=76.64% (best=76.64%)\n",
      "          Fold 2 Epoch 1: loss=0.5928, acc=62.11% (best=62.11%)\n",
      "          Fold 1 Epoch 1: loss=0.5836, acc=66.48% (best=66.48%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 76.64%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 78.12%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 56.95%\n",
      "          Fold 4 Epoch 30: loss=0.1258, acc=69.69% (best=70.47%)\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8183ee1b:\n",
      "        Fold accuracies: ['78.12%', '65.16%', '76.64%', '70.47%', '56.95%']\n",
      "        Average fitness: 69.47% Â± 7.78%\n",
      "        Best fold: Fold 1 with 78.12%\n",
      "      Fitness obtained: 69.47% | Best in generation: 73.11% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 0658938a)\n",
      "      Architecture: 6 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 0658938a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6663, acc=44.38% (best=44.38%)\n",
      "          Fold 3 Epoch 1: loss=0.4692, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 1: loss=0.5595, acc=48.36% (best=48.36%)\n",
      "          Fold 5 Epoch 1: loss=0.4074, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.5857, acc=81.41% (best=81.41%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 81.41%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 64.77%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.78%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 70.62%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0658938a:\n",
      "        Fold accuracies: ['81.41%', '65.23%', '70.62%', '64.77%', '55.78%']\n",
      "        Average fitness: 67.56% Â± 8.40%\n",
      "        Best fold: Fold 1 with 81.41%\n",
      "      Fitness obtained: 67.56% | Best in generation: 73.11% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 01b2ecaf)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 01b2ecaf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7026, acc=63.36% (best=63.36%)\n",
      "          Fold 5 Epoch 1: loss=0.6981, acc=58.98% (best=58.98%)\n",
      "          Fold 2 Epoch 1: loss=0.6958, acc=62.42% (best=62.42%)\n",
      "          Fold 4 Epoch 1: loss=0.7073, acc=55.00% (best=55.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6854, acc=68.28% (best=68.28%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 55.00%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.28%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 69.61%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 66.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 01b2ecaf:\n",
      "        Fold accuracies: ['68.28%', '68.52%', '69.61%', '55.00%', '66.80%']\n",
      "        Average fitness: 65.64% Â± 5.40%\n",
      "        Best fold: Fold 3 with 69.61%\n",
      "      Fitness obtained: 65.64% | Best in generation: 73.11% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: a11f019e)\n",
      "      Architecture: 6 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model a11f019e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5328, acc=73.75% (best=73.75%)\n",
      "          Fold 4 Epoch 1: loss=0.5399, acc=74.61% (best=74.61%)\n",
      "          Fold 5 Epoch 1: loss=0.4915, acc=57.66% (best=57.66%)\n",
      "          Fold 3 Epoch 1: loss=0.5485, acc=77.73% (best=77.73%)\n",
      "          Fold 1 Epoch 1: loss=0.4436, acc=74.14% (best=74.14%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 74.61%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.73%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.14%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 78.91%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 62.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a11f019e:\n",
      "        Fold accuracies: ['74.14%', '78.91%', '77.73%', '74.61%', '62.89%']\n",
      "        Average fitness: 73.66% Â± 5.68%\n",
      "        Best fold: Fold 2 with 78.91%\n",
      "      New best fitness in this generation: 73.66%!\n",
      "      Fitness obtained: 73.66% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: bc8e5699)\n",
      "      Architecture: 11 conv + 5 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model bc8e5699 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6596, acc=36.02% (best=36.02%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 73.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bc8e5699:\n",
      "        Fold accuracies: ['0.00%', '73.44%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 14.69% Â± 29.38%\n",
      "        Best fold: Fold 2 with 73.44%\n",
      "      Fitness obtained: 14.69% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: f5ceeac2)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model f5ceeac2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f5ceeac2:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: e0fa8cba)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model e0fa8cba with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=11, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.5826, acc=53.36% (best=53.36%)\n",
      "          Fold 2 Epoch 1: loss=0.5766, acc=32.66% (best=32.66%)\n",
      "          Fold 3 Epoch 1: loss=0.5205, acc=65.47% (best=65.47%)\n",
      "          Fold 5 Epoch 1: loss=0.4998, acc=44.61% (best=44.61%)\n",
      "          Fold 1 Epoch 1: loss=0.3655, acc=60.16% (best=60.16%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 75.47%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 63.28%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 68.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e0fa8cba:\n",
      "        Fold accuracies: ['63.28%', '68.36%', '75.47%', '65.86%', '60.55%']\n",
      "        Average fitness: 66.70% Â± 5.10%\n",
      "        Best fold: Fold 3 with 75.47%\n",
      "      Fitness obtained: 66.70% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: fe82aec6)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model fe82aec6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.5267, acc=70.00% (best=70.00%)\n",
      "          Fold 2 Epoch 1: loss=0.5858, acc=67.42% (best=67.42%)\n",
      "          Fold 3 Epoch 1: loss=0.5887, acc=77.34% (best=77.34%)\n",
      "          Fold 1: Early stopping at epoch 11          Fold 3: Early stopping at epoch 11\n",
      "\n",
      "      â†’ Fold 3 completed: 77.34%\n",
      "      â†’ Fold 1 completed: 70.00%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 70.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fe82aec6:\n",
      "        Fold accuracies: ['70.00%', '70.08%', '77.34%', '0.00%', '0.00%']\n",
      "        Average fitness: 43.48% Â± 35.60%\n",
      "        Best fold: Fold 3 with 77.34%\n",
      "      Fitness obtained: 43.48% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 46d74a68)\n",
      "      Architecture: 6 conv + 5 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 46d74a68 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7126, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7222, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 1: loss=0.7201, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7560, acc=71.72% (best=71.72%)\n",
      "          Fold 1 Epoch 1: loss=0.7198, acc=51.95% (best=51.95%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 68.20%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 4 Epoch 30: loss=0.1968, acc=69.14% (best=70.31%)\n",
      "          Fold 3 Epoch 30: loss=0.1454, acc=76.64% (best=78.28%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 78.28%\n",
      "          Fold 4: Early stopping at epoch 54\n",
      "      â†’ Fold 4 completed: 73.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 46d74a68:\n",
      "        Fold accuracies: ['68.20%', '65.16%', '78.28%', '73.67%', '56.72%']\n",
      "        Average fitness: 68.41% Â± 7.38%\n",
      "        Best fold: Fold 3 with 78.28%\n",
      "      Fitness obtained: 68.41% | Best in generation: 73.66% | Global best: 74.00%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 274bb062)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 274bb062 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6955, acc=58.36% (best=58.36%)\n",
      "          Fold 1 Epoch 1: loss=0.6674, acc=72.66% (best=72.66%)\n",
      "          Fold 4 Epoch 1: loss=0.7018, acc=58.20% (best=58.20%)\n",
      "          Fold 2 Epoch 1: loss=0.6865, acc=64.22% (best=64.22%)\n",
      "          Fold 3 Epoch 1: loss=0.7009, acc=56.80% (best=56.80%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 79.53%\n",
      "          Fold 5: Early stopping at epoch 18          Fold 4: Early stopping at epoch 18\n",
      "\n",
      "      â†’ Fold 4 completed: 69.84%\n",
      "      â†’ Fold 5 completed: 69.69%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 80.94%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 274bb062:\n",
      "        Fold accuracies: ['80.94%', '70.39%', '79.53%', '69.84%', '69.69%']\n",
      "        Average fitness: 74.08% Â± 5.05%\n",
      "        Best fold: Fold 1 with 80.94%\n",
      "      New best fitness in this generation: 74.08%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 74.08% > 74.00%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen2_id2b677fbd_fitness74.00.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen3_id274bb062_fitness74.08.pth\n",
      "        Fitness: 74.08%, ID: 274bb062, Gen: 3\n",
      "      Fitness obtained: 74.08% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 634f5938)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 634f5938 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6012, acc=55.47% (best=55.47%)\n",
      "          Fold 2 Epoch 1: loss=0.5584, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.4870, acc=51.64% (best=51.64%)\n",
      "          Fold 3 Epoch 1: loss=0.6036, acc=53.28% (best=53.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6310, acc=49.61% (best=49.61%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 61.72%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 59.38%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 70.70%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 59.45%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 634f5938:\n",
      "        Fold accuracies: ['64.84%', '59.38%', '70.70%', '59.45%', '61.72%']\n",
      "        Average fitness: 63.22% Â± 4.24%\n",
      "        Best fold: Fold 3 with 70.70%\n",
      "      Fitness obtained: 63.22% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 6b00e6bd)\n",
      "      Architecture: 11 conv + 3 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 6b00e6bd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6838, acc=64.77% (best=64.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6507, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6727, acc=38.36% (best=38.36%)\n",
      "          Fold 1 Epoch 1: loss=0.5307, acc=55.00% (best=55.00%)\n",
      "          Fold 5 Epoch 1: loss=0.6314, acc=40.62% (best=40.62%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 76.64%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 71.72%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 66.09%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 55.23%\n",
      "          Fold 4 Epoch 30: loss=0.0981, acc=56.64% (best=69.06%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 69.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6b00e6bd:\n",
      "        Fold accuracies: ['71.72%', '66.09%', '76.64%', '69.06%', '55.23%']\n",
      "        Average fitness: 67.75% Â± 7.15%\n",
      "        Best fold: Fold 3 with 76.64%\n",
      "      Fitness obtained: 67.75% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 2207cbfc)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 2207cbfc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5719, acc=48.28% (best=48.28%)\n",
      "          Fold 2 Epoch 1: loss=0.5735, acc=48.91% (best=48.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6006, acc=44.22% (best=44.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6069, acc=72.50% (best=72.50%)\n",
      "          Fold 1 Epoch 1: loss=0.4683, acc=60.08% (best=60.08%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 79.22%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 73.05%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 61.95%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 65.16%\n",
      "          Fold 4 Epoch 30: loss=0.1022, acc=66.48% (best=70.94%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 70.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2207cbfc:\n",
      "        Fold accuracies: ['65.16%', '79.22%', '73.05%', '70.94%', '61.95%']\n",
      "        Average fitness: 70.06% Â± 6.06%\n",
      "        Best fold: Fold 2 with 79.22%\n",
      "      Fitness obtained: 70.06% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: cc549c8c)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model cc549c8c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.3285, acc=48.98% (best=48.98%)\n",
      "          Fold 5 Epoch 1: loss=0.4681, acc=59.14% (best=59.14%)\n",
      "          Fold 3 Epoch 1: loss=0.4312, acc=51.17% (best=51.17%)\n",
      "          Fold 4 Epoch 1: loss=0.5534, acc=47.42% (best=47.42%)\n",
      "          Fold 2 Epoch 1: loss=0.5182, acc=68.98% (best=68.98%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.98%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.09%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 72.50%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 66.17%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 62.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc549c8c:\n",
      "        Fold accuracies: ['66.17%', '68.98%', '66.09%', '62.58%', '72.50%']\n",
      "        Average fitness: 67.27% Â± 3.31%\n",
      "        Best fold: Fold 5 with 72.50%\n",
      "      Fitness obtained: 67.27% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 1a8e52c5)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 1a8e52c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=2.0609, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=1.8421, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=1.7826, acc=73.59% (best=73.59%)\n",
      "          Fold 5 Epoch 1: loss=2.2604, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 1: loss=1.7740, acc=34.77% (best=34.77%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.59%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.86%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 66.56%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 68.98%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1a8e52c5:\n",
      "        Fold accuracies: ['68.98%', '74.84%', '73.59%', '66.56%', '65.86%']\n",
      "        Average fitness: 69.97% Â± 3.64%\n",
      "        Best fold: Fold 2 with 74.84%\n",
      "      Fitness obtained: 69.97% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: db98f258)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model db98f258 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for db98f258:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 5f56ddd0)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 5f56ddd0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.3201, acc=54.45% (best=54.45%)\n",
      "          Fold 4 Epoch 1: loss=0.4945, acc=58.05% (best=58.05%)\n",
      "          Fold 5 Epoch 1: loss=0.4478, acc=55.47% (best=55.47%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.47%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 72.34%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5f56ddd0:\n",
      "        Fold accuracies: ['72.34%', '0.00%', '0.00%', '71.17%', '55.47%']\n",
      "        Average fitness: 39.80% Â± 33.04%\n",
      "        Best fold: Fold 1 with 72.34%\n",
      "      Fitness obtained: 39.80% | Best in generation: 74.08% | Global best: 74.08%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 3 STATISTICS:\n",
      "   Maximum fitness: 74.08%\n",
      "   Average fitness: 56.83%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 23.61%\n",
      "   Best individual: 274bb062 with 74.08%\n",
      "   Global best individual: 274bb062 with 74.08%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=23.61)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 274bb062 (fitness: 74.08%)\n",
      "   Elite 2: a11f019e (fitness: 73.66%)\n",
      "   Elite 3: 1dc0009e (fitness: 73.11%)\n",
      "   Elite 4: 1d33bd50 (fitness: 71.59%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 4\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 4)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 274bb062)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 274bb062 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7165, acc=48.20% (best=48.20%)\n",
      "          Fold 2 Epoch 1: loss=0.7638, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6970, acc=64.61% (best=64.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6989, acc=46.88% (best=46.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6655, acc=64.84% (best=64.84%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 66.41%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 62.27%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 52.19%\n",
      "          Fold 4 Epoch 30: loss=0.5395, acc=70.23% (best=70.39%)\n",
      "          Fold 5 Epoch 30: loss=0.4555, acc=71.48% (best=72.73%)\n",
      "          Fold 5: Early stopping at epoch 46\n",
      "      â†’ Fold 5 completed: 74.69%\n",
      "          Fold 4: Early stopping at epoch 50\n",
      "      â†’ Fold 4 completed: 71.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 274bb062:\n",
      "        Fold accuracies: ['66.41%', '52.19%', '62.27%', '71.80%', '74.69%']\n",
      "        Average fitness: 65.47% Â± 7.91%\n",
      "        Best fold: Fold 5 with 74.69%\n",
      "      New best fitness in this generation: 65.47%!\n",
      "      Fitness obtained: 65.47% | Best in generation: 65.47% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: a11f019e)\n",
      "      Architecture: 6 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model a11f019e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5555, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 1: loss=0.4874, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 1: loss=0.5466, acc=79.14% (best=79.14%)\n",
      "          Fold 5 Epoch 1: loss=0.5030, acc=61.88% (best=61.88%)\n",
      "          Fold 1 Epoch 1: loss=0.3790, acc=70.55% (best=70.55%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.16%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.41%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 72.03%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 62.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a11f019e:\n",
      "        Fold accuracies: ['72.03%', '62.42%', '81.41%', '60.16%', '61.88%']\n",
      "        Average fitness: 67.58% Â± 8.07%\n",
      "        Best fold: Fold 3 with 81.41%\n",
      "      New best fitness in this generation: 67.58%!\n",
      "      Fitness obtained: 67.58% | Best in generation: 67.58% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 1dc0009e)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1dc0009e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6084, acc=50.31% (best=50.31%)\n",
      "          Fold 2 Epoch 1: loss=0.5637, acc=57.11% (best=57.11%)\n",
      "          Fold 5 Epoch 1: loss=0.5694, acc=55.39% (best=55.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6500, acc=64.92% (best=64.92%)\n",
      "          Fold 1 Epoch 1: loss=0.4750, acc=68.36% (best=68.36%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.92%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 73.36%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 75.86%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 64.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1dc0009e:\n",
      "        Fold accuracies: ['68.36%', '73.36%', '75.86%', '64.92%', '64.30%']\n",
      "        Average fitness: 69.36% Â± 4.57%\n",
      "        Best fold: Fold 3 with 75.86%\n",
      "      New best fitness in this generation: 69.36%!\n",
      "      Fitness obtained: 69.36% | Best in generation: 69.36% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1d33bd50)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 1d33bd50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5827, acc=47.81% (best=47.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6109, acc=63.83% (best=63.83%)\n",
      "          Fold 3 Epoch 1: loss=0.5886, acc=58.67% (best=58.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6402, acc=62.19% (best=62.19%)\n",
      "          Fold 1 Epoch 1: loss=0.4539, acc=73.75% (best=73.75%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 65.08%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 77.73%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 73.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d33bd50:\n",
      "        Fold accuracies: ['73.75%', '73.83%', '65.08%', '77.73%', '65.39%']\n",
      "        Average fitness: 71.16% Â± 5.05%\n",
      "        Best fold: Fold 4 with 77.73%\n",
      "      New best fitness in this generation: 71.16%!\n",
      "      Fitness obtained: 71.16% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 90d5c73b)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 90d5c73b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5327, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.5594, acc=63.83% (best=63.83%)\n",
      "          Fold 5 Epoch 1: loss=0.4982, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 1: loss=0.5253, acc=52.19% (best=52.19%)\n",
      "          Fold 1 Epoch 1: loss=0.3811, acc=58.98% (best=58.98%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.83%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 64.77%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 73.05%\n",
      "          Fold 3 Epoch 30: loss=0.0804, acc=59.84% (best=72.27%)\n",
      "          Fold 3: Early stopping at epoch 45\n",
      "      â†’ Fold 3 completed: 72.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 90d5c73b:\n",
      "        Fold accuracies: ['73.05%', '64.77%', '72.42%', '73.83%', '66.56%']\n",
      "        Average fitness: 70.12% Â± 3.71%\n",
      "        Best fold: Fold 4 with 73.83%\n",
      "      Fitness obtained: 70.12% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: ffe9bf0d)\n",
      "      Architecture: 8 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model ffe9bf0d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6333, acc=59.84% (best=59.84%)\n",
      "          Fold 5 Epoch 1: loss=0.6533, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6557, acc=45.55% (best=45.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6439, acc=61.80% (best=61.80%)\n",
      "          Fold 2 Epoch 1: loss=0.6637, acc=56.17% (best=56.17%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.80%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 76.09%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.78%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 55.94%\n",
      "          Fold 2 Epoch 30: loss=0.1495, acc=66.88% (best=73.67%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 73.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ffe9bf0d:\n",
      "        Fold accuracies: ['76.09%', '73.67%', '65.78%', '61.80%', '55.94%']\n",
      "        Average fitness: 66.66% Â± 7.45%\n",
      "        Best fold: Fold 1 with 76.09%\n",
      "      Fitness obtained: 66.66% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 678da4cf)\n",
      "      Architecture: 6 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 678da4cf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4783, acc=75.08% (best=75.08%)\n",
      "          Fold 3 Epoch 1: loss=0.5370, acc=89.69% (best=89.69%)\n",
      "          Fold 5 Epoch 1: loss=0.4758, acc=64.30% (best=64.30%)\n",
      "          Fold 2 Epoch 1: loss=0.4606, acc=56.72% (best=56.72%)\n",
      "          Fold 4 Epoch 1: loss=0.5529, acc=44.22% (best=44.22%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 89.69%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.30%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 77.58%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 58.44%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 53.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 678da4cf:\n",
      "        Fold accuracies: ['77.58%', '58.44%', '89.69%', '53.83%', '64.30%']\n",
      "        Average fitness: 68.77% Â± 13.15%\n",
      "        Best fold: Fold 3 with 89.69%\n",
      "      Fitness obtained: 68.77% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 911e2e21)\n",
      "      Architecture: 11 conv + 7 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 911e2e21 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6943, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6876, acc=53.83% (best=53.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6996, acc=59.92% (best=59.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6993, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6865, acc=50.39% (best=50.39%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 53.83%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 69.77%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 61.64%\n",
      "          Fold 4 Epoch 30: loss=0.2914, acc=70.08% (best=80.39%)\n",
      "          Fold 4: Early stopping at epoch 38\n",
      "      â†’ Fold 4 completed: 80.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 911e2e21:\n",
      "        Fold accuracies: ['69.77%', '61.64%', '53.83%', '80.39%', '63.12%']\n",
      "        Average fitness: 65.75% Â± 8.90%\n",
      "        Best fold: Fold 4 with 80.39%\n",
      "      Fitness obtained: 65.75% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: e948bee1)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e948bee1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6703, acc=68.05% (best=68.05%)\n",
      "          Fold 5 Epoch 1: loss=0.6968, acc=52.58% (best=52.58%)\n",
      "          Fold 3 Epoch 1: loss=0.7049, acc=51.25% (best=51.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6966, acc=61.88% (best=61.88%)\n",
      "          Fold 2 Epoch 1: loss=0.7087, acc=40.47% (best=40.47%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.95%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 58.91%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 74.14%\n",
      "          Fold 3 Epoch 30: loss=0.4275, acc=69.14% (best=72.27%)\n",
      "          Fold 3: Early stopping at epoch 33\n",
      "      â†’ Fold 3 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e948bee1:\n",
      "        Fold accuracies: ['71.95%', '50.08%', '72.27%', '74.14%', '58.91%']\n",
      "        Average fitness: 65.47% Â± 9.42%\n",
      "        Best fold: Fold 4 with 74.14%\n",
      "      Fitness obtained: 65.47% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 675f7968)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 675f7968 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5876, acc=71.41% (best=71.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6088, acc=70.94% (best=70.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6323, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6242, acc=50.23% (best=50.23%)\n",
      "          Fold 1 Epoch 1: loss=0.4735, acc=42.11% (best=42.11%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 71.41%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.94%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 59.69%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 71.41%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 70.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 675f7968:\n",
      "        Fold accuracies: ['70.86%', '70.94%', '71.41%', '71.41%', '59.69%']\n",
      "        Average fitness: 68.86% Â± 4.59%\n",
      "        Best fold: Fold 3 with 71.41%\n",
      "      Fitness obtained: 68.86% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: efadacdc)\n",
      "      Architecture: 1 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model efadacdc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.2010, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.1965, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 1: loss=0.0533, acc=51.95% (best=51.95%)\n",
      "          Fold 5 Epoch 1: loss=0.1735, acc=51.80% (best=51.80%)\n",
      "          Fold 4 Epoch 1: loss=0.1903, acc=49.69% (best=49.69%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 63.28%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 52.03%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 59.30%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 61.95%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 57.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for efadacdc:\n",
      "        Fold accuracies: ['61.95%', '63.28%', '59.30%', '57.19%', '52.03%']\n",
      "        Average fitness: 58.75% Â± 3.97%\n",
      "        Best fold: Fold 2 with 63.28%\n",
      "      Fitness obtained: 58.75% | Best in generation: 71.16% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 5bb7d0cf)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 5bb7d0cf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=4.8598, acc=68.67% (best=68.67%)\n",
      "          Fold 2 Epoch 1: loss=3.0164, acc=46.80% (best=46.80%)\n",
      "          Fold 3 Epoch 1: loss=3.2766, acc=51.17% (best=51.17%)\n",
      "          Fold 5 Epoch 1: loss=4.0315, acc=65.55% (best=65.55%)\n",
      "          Fold 1 Epoch 1: loss=3.0465, acc=66.88% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.67%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 83.75%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 78.67%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 2 Epoch 30: loss=0.1384, acc=64.38% (best=71.33%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 71.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5bb7d0cf:\n",
      "        Fold accuracies: ['78.67%', '71.33%', '83.75%', '68.67%', '66.17%']\n",
      "        Average fitness: 73.72% Â± 6.53%\n",
      "        Best fold: Fold 3 with 83.75%\n",
      "      New best fitness in this generation: 73.72%!\n",
      "      Fitness obtained: 73.72% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 7303fdba)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 7303fdba with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6332, acc=55.08% (best=55.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6135, acc=86.25% (best=86.25%)\n",
      "          Fold 2 Epoch 1: loss=0.6536, acc=66.56% (best=66.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6473, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.5407, acc=75.94% (best=75.94%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.94%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.25%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 65.16%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 67.97%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7303fdba:\n",
      "        Fold accuracies: ['75.94%', '67.97%', '86.25%', '65.16%', '60.23%']\n",
      "        Average fitness: 71.11% Â± 9.12%\n",
      "        Best fold: Fold 3 with 86.25%\n",
      "      Fitness obtained: 71.11% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 2e2ea48d)\n",
      "      Architecture: 6 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 2e2ea48d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.5712, acc=64.45% (best=64.45%)\n",
      "          Fold 2 Epoch 1: loss=0.5350, acc=55.86% (best=55.86%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.67%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 60.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2e2ea48d:\n",
      "        Fold accuracies: ['0.00%', '60.08%', '0.00%', '73.67%', '0.00%']\n",
      "        Average fitness: 26.75% Â± 33.04%\n",
      "        Best fold: Fold 4 with 73.67%\n",
      "      Fitness obtained: 26.75% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 55b8c555)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 55b8c555 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.9645, acc=59.06% (best=59.06%)\n",
      "          Fold 5 Epoch 1: loss=1.1035, acc=51.88% (best=51.88%)\n",
      "          Fold 2 Epoch 1: loss=1.2510, acc=73.28% (best=73.28%)\n",
      "          Fold 3 Epoch 1: loss=1.0094, acc=54.38% (best=54.38%)\n",
      "          Fold 1 Epoch 1: loss=1.0025, acc=57.73% (best=57.73%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.28%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 68.59%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 81.17%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 64.38%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 70.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 55b8c555:\n",
      "        Fold accuracies: ['70.23%', '73.28%', '81.17%', '64.38%', '68.59%']\n",
      "        Average fitness: 71.53% Â± 5.61%\n",
      "        Best fold: Fold 3 with 81.17%\n",
      "      Fitness obtained: 71.53% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: cac35aab)\n",
      "      Architecture: 6 conv + 3 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model cac35aab with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.1089, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 1: loss=0.2718, acc=51.41% (best=51.41%)\n",
      "          Fold 3 Epoch 1: loss=0.2802, acc=60.94% (best=60.94%)\n",
      "          Fold 4 Epoch 1: loss=0.2923, acc=56.17% (best=56.17%)\n",
      "          Fold 2 Epoch 1: loss=0.3667, acc=52.42% (best=52.42%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 69.61%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 74.45%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 66.25%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 64.38%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 67.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cac35aab:\n",
      "        Fold accuracies: ['74.45%', '64.38%', '69.61%', '66.25%', '67.50%']\n",
      "        Average fitness: 68.44% Â± 3.46%\n",
      "        Best fold: Fold 1 with 74.45%\n",
      "      Fitness obtained: 68.44% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: e9c4b5e0)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model e9c4b5e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5665, acc=76.17% (best=76.17%)\n",
      "          Fold 5 Epoch 1: loss=0.4992, acc=56.25% (best=56.25%)\n",
      "          Fold 2 Epoch 1: loss=0.5290, acc=58.52% (best=58.52%)\n",
      "          Fold 3 Epoch 1: loss=0.5093, acc=52.50% (best=52.50%)\n",
      "          Fold 1 Epoch 1: loss=0.3212, acc=51.09% (best=51.09%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 76.17%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.30%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 74.06%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 70.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e9c4b5e0:\n",
      "        Fold accuracies: ['70.00%', '74.06%', '64.06%', '76.17%', '59.30%']\n",
      "        Average fitness: 68.72% Â± 6.26%\n",
      "        Best fold: Fold 4 with 76.17%\n",
      "      Fitness obtained: 68.72% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: d8fdec77)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model d8fdec77 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.5443, acc=66.95% (best=66.95%)\n",
      "          Fold 2 Epoch 1: loss=0.5674, acc=68.98% (best=68.98%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 69.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d8fdec77:\n",
      "        Fold accuracies: ['0.00%', '69.30%', '67.58%', '0.00%', '0.00%']\n",
      "        Average fitness: 27.38% Â± 33.53%\n",
      "        Best fold: Fold 2 with 69.30%\n",
      "      Fitness obtained: 27.38% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 6532fd60)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 6532fd60 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=2.7323, acc=51.95% (best=51.95%)\n",
      "          Fold 4 Epoch 1: loss=2.4295, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=2.5298, acc=46.72% (best=46.72%)\n",
      "          Fold 1 Epoch 1: loss=2.2933, acc=57.27% (best=57.27%)\n",
      "          Fold 5 Epoch 1: loss=1.4377, acc=50.70% (best=50.70%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 67.58%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 75.86%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 68.28%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 71.17%\n",
      "          Fold 4 Epoch 30: loss=0.1206, acc=60.39% (best=65.39%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6532fd60:\n",
      "        Fold accuracies: ['68.28%', '67.58%', '75.86%', '65.39%', '71.17%']\n",
      "        Average fitness: 69.66% Â± 3.61%\n",
      "        Best fold: Fold 3 with 75.86%\n",
      "      Fitness obtained: 69.66% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: a2b01a02)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model a2b01a02 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5397, acc=46.56% (best=46.56%)\n",
      "          Fold 3 Epoch 1: loss=0.4866, acc=80.78% (best=80.78%)\n",
      "          Fold 1 Epoch 1: loss=0.2999, acc=56.48% (best=56.48%)\n",
      "          Fold 4 Epoch 1: loss=0.5175, acc=65.39% (best=65.39%)\n",
      "          Fold 2 Epoch 1: loss=0.5452, acc=49.92% (best=49.92%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.78%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 74.53%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 66.64%\n",
      "          Fold 4 Epoch 30: loss=0.0726, acc=69.38% (best=70.39%)\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 73.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a2b01a02:\n",
      "        Fold accuracies: ['74.53%', '66.64%', '80.78%', '73.83%', '61.48%']\n",
      "        Average fitness: 71.45% Â± 6.70%\n",
      "        Best fold: Fold 3 with 80.78%\n",
      "      Fitness obtained: 71.45% | Best in generation: 73.72% | Global best: 74.08%\n",
      "\n",
      "GENERATION 4 STATISTICS:\n",
      "   Maximum fitness: 73.72%\n",
      "   Average fitness: 64.33%\n",
      "   Minimum fitness: 26.75%\n",
      "   Standard deviation: 12.80%\n",
      "   Best individual: 5bb7d0cf with 73.72%\n",
      "   Global best individual: 274bb062 with 74.08%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "\n",
      "ðŸ“‰ Stagnation detected in last 3 generations (all within 0.36%)\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=12.80)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 5bb7d0cf (fitness: 73.72%)\n",
      "   Elite 2: 55b8c555 (fitness: 71.53%)\n",
      "   Elite 3: a2b01a02 (fitness: 71.45%)\n",
      "   Elite 4: 1d33bd50 (fitness: 71.16%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "ðŸ“‰ Stagnation detected in last 3 generations (all within 0.36%)\n",
      "\n",
      "================================================================================\n",
      "GENERATION 5\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 5)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 5bb7d0cf)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 5bb7d0cf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=3.5398, acc=64.14% (best=64.14%)\n",
      "          Fold 5 Epoch 1: loss=3.3010, acc=51.41% (best=51.41%)\n",
      "          Fold 4 Epoch 1: loss=4.5471, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=3.6244, acc=71.64% (best=71.64%)\n",
      "          Fold 1 Epoch 1: loss=3.6766, acc=49.61% (best=49.61%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 59.38%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 74.22%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 67.42%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5bb7d0cf:\n",
      "        Fold accuracies: ['70.08%', '67.42%', '74.22%', '73.28%', '59.38%']\n",
      "        Average fitness: 68.88% Â± 5.33%\n",
      "        Best fold: Fold 3 with 74.22%\n",
      "      New best fitness in this generation: 68.88%!\n",
      "      Fitness obtained: 68.88% | Best in generation: 68.88% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 55b8c555)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 55b8c555 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=1.2927, acc=54.38% (best=54.38%)\n",
      "          Fold 5 Epoch 1: loss=1.0416, acc=57.11% (best=57.11%)\n",
      "          Fold 4 Epoch 1: loss=1.1391, acc=55.86% (best=55.86%)\n",
      "          Fold 1 Epoch 1: loss=1.0900, acc=51.64% (best=51.64%)\n",
      "          Fold 2 Epoch 1: loss=0.9966, acc=58.67% (best=58.67%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.27%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 66.33%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 71.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 55b8c555:\n",
      "        Fold accuracies: ['64.84%', '71.02%', '82.27%', '66.33%', '67.42%']\n",
      "        Average fitness: 70.38% Â± 6.28%\n",
      "        Best fold: Fold 3 with 82.27%\n",
      "      New best fitness in this generation: 70.38%!\n",
      "      Fitness obtained: 70.38% | Best in generation: 70.38% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: a2b01a02)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model a2b01a02 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5104, acc=60.70% (best=60.70%)\n",
      "          Fold 5 Epoch 1: loss=0.4640, acc=60.86% (best=60.86%)\n",
      "          Fold 2 Epoch 1: loss=0.4641, acc=41.64% (best=41.64%)\n",
      "          Fold 3 Epoch 1: loss=0.4687, acc=83.44% (best=83.44%)\n",
      "          Fold 1 Epoch 1: loss=0.2790, acc=60.23% (best=60.23%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 68.59%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 83.91%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 69.69%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 71.88%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 62.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a2b01a02:\n",
      "        Fold accuracies: ['68.59%', '62.19%', '83.91%', '71.88%', '69.69%']\n",
      "        Average fitness: 71.25% Â± 7.10%\n",
      "        Best fold: Fold 3 with 83.91%\n",
      "      New best fitness in this generation: 71.25%!\n",
      "      Fitness obtained: 71.25% | Best in generation: 71.25% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1d33bd50)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 1d33bd50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6357, acc=25.94% (best=25.94%)\n",
      "          Fold 1 Epoch 1: loss=0.4661, acc=55.08% (best=55.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6152, acc=69.22% (best=69.22%)\n",
      "          Fold 5 Epoch 1: loss=0.6354, acc=58.44% (best=58.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6142, acc=77.19% (best=77.19%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 77.19%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.25%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 68.67%\n",
      "          Fold 3 Epoch 30: loss=0.1021, acc=65.08% (best=76.33%)\n",
      "          Fold 5 Epoch 30: loss=0.1155, acc=61.25% (best=62.27%)\n",
      "          Fold 3: Early stopping at epoch 32\n",
      "      â†’ Fold 3 completed: 76.33%\n",
      "          Fold 5: Early stopping at epoch 43\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d33bd50:\n",
      "        Fold accuracies: ['68.67%', '77.19%', '76.33%', '66.25%', '64.77%']\n",
      "        Average fitness: 70.64% Â± 5.16%\n",
      "        Best fold: Fold 2 with 77.19%\n",
      "      Fitness obtained: 70.64% | Best in generation: 71.25% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 2cae6cae)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 2cae6cae with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5196, acc=68.28% (best=68.28%)\n",
      "          Fold 5 Epoch 1: loss=0.5134, acc=57.50% (best=57.50%)\n",
      "          Fold 2 Epoch 1: loss=0.5353, acc=37.27% (best=37.27%)\n",
      "          Fold 4 Epoch 1: loss=0.5587, acc=35.94% (best=35.94%)\n",
      "          Fold 1 Epoch 1: loss=0.4102, acc=49.84% (best=49.84%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 77.42%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 75.78%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 66.17%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 67.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2cae6cae:\n",
      "        Fold accuracies: ['67.89%', '77.42%', '75.78%', '66.17%', '65.39%']\n",
      "        Average fitness: 70.53% Â± 5.05%\n",
      "        Best fold: Fold 2 with 77.42%\n",
      "      Fitness obtained: 70.53% | Best in generation: 71.25% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: b2a74b3f)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model b2a74b3f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.7343, acc=43.44% (best=43.44%)\n",
      "          Fold 5 Epoch 1: loss=0.8065, acc=56.33% (best=56.33%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b2a74b3f:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '65.23%', '56.72%']\n",
      "        Average fitness: 24.39% Â± 29.99%\n",
      "        Best fold: Fold 4 with 65.23%\n",
      "      Fitness obtained: 24.39% | Best in generation: 71.25% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 88c9bf7c)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 88c9bf7c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6170, acc=47.89% (best=47.89%)\n",
      "          Fold 1 Epoch 1: loss=0.5182, acc=62.34% (best=62.34%)\n",
      "          Fold 3 Epoch 1: loss=0.6244, acc=58.52% (best=58.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6203, acc=63.44% (best=63.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6207, acc=65.70% (best=65.70%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.70%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 72.27%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 88c9bf7c:\n",
      "        Fold accuracies: ['76.41%', '65.70%', '75.23%', '72.27%', '61.25%']\n",
      "        Average fitness: 70.17% Â± 5.80%\n",
      "        Best fold: Fold 1 with 76.41%\n",
      "      Fitness obtained: 70.17% | Best in generation: 71.25% | Global best: 74.08%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: cc04ff86)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cc04ff86 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6153, acc=78.28% (best=78.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6390, acc=63.91% (best=63.91%)\n",
      "          Fold 5 Epoch 1: loss=0.6226, acc=66.64% (best=66.64%)\n",
      "          Fold 1 Epoch 1: loss=0.5498, acc=77.03% (best=77.03%)\n",
      "          Fold 2 Epoch 1: loss=0.6250, acc=71.88% (best=71.88%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.64%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.88%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 78.75%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc04ff86:\n",
      "        Fold accuracies: ['78.75%', '71.88%', '81.88%', '77.42%', '66.64%']\n",
      "        Average fitness: 75.31% Â± 5.41%\n",
      "        Best fold: Fold 3 with 81.88%\n",
      "      New best fitness in this generation: 75.31%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 75.31% > 74.08%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen3_id274bb062_fitness74.08.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen5_idcc04ff86_fitness75.31.pth\n",
      "        Fitness: 75.31%, ID: cc04ff86, Gen: 5\n",
      "      Fitness obtained: 75.31% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 979b44b2)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 979b44b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6173, acc=49.53% (best=49.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6305, acc=46.72% (best=46.72%)\n",
      "          Fold 1 Epoch 1: loss=0.5348, acc=71.56% (best=71.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6050, acc=72.34% (best=72.34%)\n",
      "          Fold 3 Epoch 1: loss=0.5918, acc=51.41% (best=51.41%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 72.34%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 79.06%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 62.11%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 77.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 979b44b2:\n",
      "        Fold accuracies: ['77.97%', '72.34%', '79.06%', '62.11%', '66.17%']\n",
      "        Average fitness: 71.53% Â± 6.58%\n",
      "        Best fold: Fold 3 with 79.06%\n",
      "      Fitness obtained: 71.53% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: d67f50a2)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d67f50a2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5829, acc=61.09% (best=61.09%)\n",
      "          Fold 5 Epoch 1: loss=0.6216, acc=62.58% (best=62.58%)\n",
      "          Fold 3 Epoch 1: loss=0.5958, acc=73.67% (best=73.67%)\n",
      "          Fold 1 Epoch 1: loss=0.5920, acc=54.77% (best=54.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6172, acc=68.91% (best=68.91%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.67%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 74.45%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d67f50a2:\n",
      "        Fold accuracies: ['74.45%', '68.91%', '73.67%', '63.83%', '66.88%']\n",
      "        Average fitness: 69.55% Â± 4.03%\n",
      "        Best fold: Fold 1 with 74.45%\n",
      "      Fitness obtained: 69.55% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: af257c77)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model af257c77 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5298, acc=44.06% (best=44.06%)\n",
      "          Fold 5 Epoch 1: loss=0.5127, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 1: loss=0.4704, acc=62.66% (best=62.66%)\n",
      "          Fold 3 Epoch 1: loss=0.5106, acc=67.81% (best=67.81%)\n",
      "          Fold 1 Epoch 1: loss=0.3277, acc=75.62% (best=75.62%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.62%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 77.11%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 4 Epoch 30: loss=0.0730, acc=71.41% (best=75.39%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 75.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for af257c77:\n",
      "        Fold accuracies: ['75.62%', '68.91%', '77.11%', '75.39%', '62.03%']\n",
      "        Average fitness: 71.81% Â± 5.65%\n",
      "        Best fold: Fold 3 with 77.11%\n",
      "      Fitness obtained: 71.81% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 66fefec6)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 66fefec6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5150, acc=64.53% (best=64.53%)\n",
      "          Fold 3 Epoch 1: loss=0.5023, acc=66.88% (best=66.88%)\n",
      "          Fold 5 Epoch 1: loss=0.4598, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 1: loss=0.4450, acc=73.83% (best=73.83%)\n",
      "          Fold 4 Epoch 1: loss=0.5741, acc=49.30% (best=49.30%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.83%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 64.61%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 71.72%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 71.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 66fefec6:\n",
      "        Fold accuracies: ['73.83%', '64.61%', '71.95%', '71.72%', '62.19%']\n",
      "        Average fitness: 68.86% Â± 4.58%\n",
      "        Best fold: Fold 1 with 73.83%\n",
      "      Fitness obtained: 68.86% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 8528505c)\n",
      "      Architecture: 5 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 8528505c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.2409, acc=68.44% (best=68.44%)\n",
      "          Fold 1 Epoch 1: loss=0.1343, acc=65.31% (best=65.31%)\n",
      "          Fold 2 Epoch 1: loss=0.2944, acc=62.81% (best=62.81%)\n",
      "          Fold 4 Epoch 1: loss=0.2936, acc=61.56% (best=61.56%)\n",
      "          Fold 5 Epoch 1: loss=0.2980, acc=59.69% (best=59.69%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.28%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.36%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 69.53%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 71.25%\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 73.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8528505c:\n",
      "        Fold accuracies: ['73.59%', '68.36%', '71.25%', '63.28%', '69.53%']\n",
      "        Average fitness: 69.20% Â± 3.45%\n",
      "        Best fold: Fold 1 with 73.59%\n",
      "      Fitness obtained: 69.20% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: c6313d70)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model c6313d70 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6108, acc=65.00% (best=65.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6260, acc=62.50% (best=62.50%)\n",
      "          Fold 4 Epoch 1: loss=0.5993, acc=71.48% (best=71.48%)\n",
      "          Fold 1 Epoch 1: loss=0.4290, acc=56.17% (best=56.17%)\n",
      "          Fold 3 Epoch 1: loss=0.5859, acc=37.58% (best=37.58%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.08%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 72.27%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 72.03%\n",
      "          Fold 2 Epoch 30: loss=0.0865, acc=50.39% (best=68.67%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c6313d70:\n",
      "        Fold accuracies: ['72.27%', '68.67%', '72.03%', '71.48%', '65.08%']\n",
      "        Average fitness: 69.91% Â± 2.74%\n",
      "        Best fold: Fold 1 with 72.27%\n",
      "      Fitness obtained: 69.91% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: d736b764)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model d736b764 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5107, acc=55.00% (best=55.00%)\n",
      "          Fold 4 Epoch 1: loss=0.5289, acc=54.38% (best=54.38%)\n",
      "          Fold 5 Epoch 1: loss=0.4973, acc=47.19% (best=47.19%)\n",
      "          Fold 2 Epoch 1: loss=0.5114, acc=51.64% (best=51.64%)\n",
      "          Fold 1 Epoch 1: loss=0.3496, acc=65.31% (best=65.31%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 78.44%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 71.02%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 71.64%\n",
      "          Fold 5 Epoch 30: loss=0.0790, acc=60.55% (best=62.34%)\n",
      "          Fold 4 Epoch 30: loss=0.0931, acc=56.33% (best=61.25%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "          Fold 5: Early stopping at epoch 44\n",
      "      â†’ Fold 5 completed: 64.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d736b764:\n",
      "        Fold accuracies: ['71.02%', '71.64%', '78.44%', '61.25%', '64.30%']\n",
      "        Average fitness: 69.33% Â± 6.03%\n",
      "        Best fold: Fold 3 with 78.44%\n",
      "      Fitness obtained: 69.33% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 310a8423)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 310a8423 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=1.7502, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=2.5452, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=1.7193, acc=52.42% (best=52.42%)\n",
      "          Fold 1 Epoch 1: loss=1.4474, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=2.0622, acc=54.06% (best=54.06%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 52.42%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 73.83%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 67.50%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 81.48%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 310a8423:\n",
      "        Fold accuracies: ['67.50%', '73.83%', '81.48%', '69.38%', '52.42%']\n",
      "        Average fitness: 68.92% Â± 9.55%\n",
      "        Best fold: Fold 3 with 81.48%\n",
      "      Fitness obtained: 68.92% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 7114a256)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 7114a256 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7136, acc=47.97% (best=47.97%)\n",
      "          Fold 2 Epoch 1: loss=0.7157, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.7199, acc=46.02% (best=46.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7189, acc=51.56% (best=51.56%)\n",
      "          Fold 1 Epoch 1: loss=0.7222, acc=55.23% (best=55.23%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 51.56%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 74.38%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.67%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 49.45%\n",
      "          Fold 3 Epoch 30: loss=0.5602, acc=68.36% (best=70.62%)\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 70.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7114a256:\n",
      "        Fold accuracies: ['74.38%', '63.67%', '70.62%', '49.45%', '51.56%']\n",
      "        Average fitness: 61.94% Â± 9.97%\n",
      "        Best fold: Fold 1 with 74.38%\n",
      "      Fitness obtained: 61.94% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 7e75759a)\n",
      "      Architecture: 11 conv + 5 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 7e75759a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6851, acc=48.44% (best=48.44%)\n",
      "          Fold 3 Epoch 1: loss=0.6634, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 1: loss=0.6217, acc=68.44% (best=68.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6832, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.5990, acc=72.89% (best=72.89%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.44%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.89%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 60.08%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 87.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7e75759a:\n",
      "        Fold accuracies: ['72.89%', '68.44%', '87.03%', '60.08%', '61.64%']\n",
      "        Average fitness: 70.02% Â± 9.69%\n",
      "        Best fold: Fold 3 with 87.03%\n",
      "      Fitness obtained: 70.02% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 244338f7)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 244338f7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=3.3304, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=3.1408, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 1: loss=4.6629, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=4.0154, acc=52.97% (best=52.97%)\n",
      "          Fold 1 Epoch 1: loss=5.2666, acc=48.75% (best=48.75%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 71.41%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 76.56%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 79.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 244338f7:\n",
      "        Fold accuracies: ['79.69%', '71.95%', '76.56%', '71.41%', '61.88%']\n",
      "        Average fitness: 72.30% Â± 6.04%\n",
      "        Best fold: Fold 1 with 79.69%\n",
      "      Fitness obtained: 72.30% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 21d0c85e)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 21d0c85e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=3.8702, acc=60.39% (best=60.39%)\n",
      "          Fold 4 Epoch 1: loss=5.0756, acc=56.64% (best=56.64%)\n",
      "          Fold 2 Epoch 1: loss=4.8122, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=5.0284, acc=59.06% (best=59.06%)\n",
      "          Fold 3 Epoch 1: loss=4.1668, acc=75.08% (best=75.08%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 75.08%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 73.12%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 4 Epoch 30: loss=0.1181, acc=52.66% (best=68.05%)\n",
      "          Fold 4: Early stopping at epoch 30\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 21d0c85e:\n",
      "        Fold accuracies: ['73.12%', '65.86%', '75.08%', '68.05%', '60.39%']\n",
      "        Average fitness: 68.50% Â± 5.25%\n",
      "        Best fold: Fold 3 with 75.08%\n",
      "      Fitness obtained: 68.50% | Best in generation: 75.31% | Global best: 75.31%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 5 STATISTICS:\n",
      "   Maximum fitness: 75.31%\n",
      "   Average fitness: 67.67%\n",
      "   Minimum fitness: 24.39%\n",
      "   Standard deviation: 10.21%\n",
      "   Best individual: cc04ff86 with 75.31%\n",
      "   Global best individual: cc04ff86 with 75.31%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.31% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=10.21)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: cc04ff86 (fitness: 75.31%)\n",
      "   Elite 2: 244338f7 (fitness: 72.30%)\n",
      "   Elite 3: af257c77 (fitness: 71.81%)\n",
      "   Elite 4: 979b44b2 (fitness: 71.53%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 6\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 6)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: cc04ff86)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cc04ff86 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6183, acc=61.56% (best=61.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6260, acc=55.55% (best=55.55%)\n",
      "          Fold 3 Epoch 1: loss=0.6307, acc=76.88% (best=76.88%)\n",
      "          Fold 1 Epoch 1: loss=0.5909, acc=72.81% (best=72.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6533, acc=65.78% (best=65.78%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.56%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.09%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 81.33%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 74.30%\n",
      "          Fold 2 Epoch 30: loss=0.1612, acc=68.59% (best=72.19%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 72.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc04ff86:\n",
      "        Fold accuracies: ['81.33%', '72.19%', '81.09%', '74.30%', '61.56%']\n",
      "        Average fitness: 74.09% Â± 7.24%\n",
      "        Best fold: Fold 1 with 81.33%\n",
      "      New best fitness in this generation: 74.09%!\n",
      "      Fitness obtained: 74.09% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 244338f7)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 244338f7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=3.6442, acc=43.52% (best=43.52%)\n",
      "          Fold 5 Epoch 1: loss=3.5614, acc=60.08% (best=60.08%)\n",
      "          Fold 2 Epoch 1: loss=2.8271, acc=60.23% (best=60.23%)\n",
      "          Fold 3 Epoch 1: loss=4.6825, acc=55.70% (best=55.70%)\n",
      "          Fold 1 Epoch 1: loss=4.2648, acc=52.27% (best=52.27%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 76.02%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 66.88%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 68.05%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 244338f7:\n",
      "        Fold accuracies: ['76.02%', '66.88%', '68.05%', '67.11%', '62.66%']\n",
      "        Average fitness: 68.14% Â± 4.35%\n",
      "        Best fold: Fold 1 with 76.02%\n",
      "      Fitness obtained: 68.14% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: af257c77)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model af257c77 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4533, acc=43.52% (best=43.52%)\n",
      "          Fold 5 Epoch 1: loss=0.4740, acc=40.86% (best=40.86%)\n",
      "          Fold 4 Epoch 1: loss=0.5454, acc=43.98% (best=43.98%)\n",
      "          Fold 3 Epoch 1: loss=0.5155, acc=53.75% (best=53.75%)\n",
      "          Fold 1 Epoch 1: loss=0.3486, acc=69.92% (best=69.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 69.92%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 52.50%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 70.78%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for af257c77:\n",
      "        Fold accuracies: ['69.92%', '70.39%', '70.78%', '70.70%', '52.50%']\n",
      "        Average fitness: 66.86% Â± 7.19%\n",
      "        Best fold: Fold 3 with 70.78%\n",
      "      Fitness obtained: 66.86% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 979b44b2)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 979b44b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5748, acc=34.30% (best=34.30%)\n",
      "          Fold 2 Epoch 1: loss=0.5774, acc=63.05% (best=63.05%)\n",
      "          Fold 5 Epoch 1: loss=0.5855, acc=60.00% (best=60.00%)\n",
      "          Fold 1 Epoch 1: loss=0.5117, acc=63.36% (best=63.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6503, acc=43.44% (best=43.44%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 72.27%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 60.39%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 73.28%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 979b44b2:\n",
      "        Fold accuracies: ['73.28%', '72.27%', '75.23%', '60.39%', '62.81%']\n",
      "        Average fitness: 68.80% Â± 6.00%\n",
      "        Best fold: Fold 3 with 75.23%\n",
      "      Fitness obtained: 68.80% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 47f8f641)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 47f8f641 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 47f8f641:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 660f7479)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 660f7479 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5974, acc=84.06% (best=84.06%)\n",
      "          Fold 5 Epoch 1: loss=0.5944, acc=60.55% (best=60.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6174, acc=62.89% (best=62.89%)\n",
      "          Fold 2 Epoch 1: loss=0.5934, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=0.5030, acc=55.16% (best=55.16%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 84.06%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 74.69%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 66.80%\n",
      "          Fold 2 Epoch 30: loss=0.1224, acc=61.25% (best=77.19%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 77.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 660f7479:\n",
      "        Fold accuracies: ['74.69%', '77.19%', '84.06%', '65.94%', '66.80%']\n",
      "        Average fitness: 73.73% Â± 6.76%\n",
      "        Best fold: Fold 3 with 84.06%\n",
      "      Fitness obtained: 73.73% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 35b9c032)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 35b9c032 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6146, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.5944, acc=51.56% (best=51.56%)\n",
      "          Fold 5 Epoch 1: loss=0.6023, acc=62.19% (best=62.19%)\n",
      "          Fold 4 Epoch 1: loss=0.6096, acc=47.11% (best=47.11%)\n",
      "          Fold 1 Epoch 1: loss=0.4949, acc=63.05% (best=63.05%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 79.06%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 77.50%\n",
      "          Fold 4 Epoch 30: loss=0.0914, acc=49.69% (best=67.89%)\n",
      "          Fold 2 Epoch 30: loss=0.0969, acc=56.09% (best=66.48%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 67.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 35b9c032:\n",
      "        Fold accuracies: ['77.50%', '66.48%', '79.06%', '67.89%', '62.19%']\n",
      "        Average fitness: 70.62% Â± 6.55%\n",
      "        Best fold: Fold 3 with 79.06%\n",
      "      Fitness obtained: 70.62% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 9b59c8df)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 9b59c8df with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6135, acc=63.12% (best=63.12%)\n",
      "          Fold 2 Epoch 1: loss=0.5359, acc=68.91% (best=68.91%)\n",
      "          Fold 1 Epoch 1: loss=0.3578, acc=50.94% (best=50.94%)\n",
      "          Fold 3 Epoch 1: loss=0.5486, acc=44.69% (best=44.69%)\n",
      "          Fold 4 Epoch 1: loss=0.5543, acc=49.30% (best=49.30%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 67.58%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 77.81%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 74.61%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 74.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9b59c8df:\n",
      "        Fold accuracies: ['77.81%', '68.91%', '74.69%', '74.61%', '67.58%']\n",
      "        Average fitness: 72.72% Â± 3.86%\n",
      "        Best fold: Fold 1 with 77.81%\n",
      "      Fitness obtained: 72.72% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 816e2636)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 816e2636 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5584, acc=51.72% (best=51.72%)\n",
      "          Fold 5 Epoch 1: loss=0.5376, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.5806, acc=50.31% (best=50.31%)\n",
      "          Fold 4 Epoch 1: loss=0.5554, acc=62.19% (best=62.19%)\n",
      "          Fold 1 Epoch 1: loss=0.4365, acc=57.42% (best=57.42%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 77.42%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 76.48%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 74.77%\n",
      "          Fold 5 Epoch 30: loss=0.0770, acc=56.25% (best=61.02%)\n",
      "          Fold 5: Early stopping at epoch 35\n",
      "      â†’ Fold 5 completed: 61.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 816e2636:\n",
      "        Fold accuracies: ['76.48%', '74.77%', '77.42%', '73.36%', '61.02%']\n",
      "        Average fitness: 72.61% Â± 5.96%\n",
      "        Best fold: Fold 3 with 77.42%\n",
      "      Fitness obtained: 72.61% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: a09c4080)\n",
      "      Architecture: 9 conv + 4 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model a09c4080 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5709, acc=62.89% (best=62.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5673, acc=63.20% (best=63.20%)\n",
      "          Fold 2 Epoch 1: loss=0.5844, acc=52.66% (best=52.66%)\n",
      "          Fold 1 Epoch 1: loss=0.4297, acc=60.94% (best=60.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6232, acc=36.72% (best=36.72%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 52.66%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 72.27%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 70.08%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 67.73%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 80.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a09c4080:\n",
      "        Fold accuracies: ['80.08%', '52.66%', '72.27%', '70.08%', '67.73%']\n",
      "        Average fitness: 68.56% Â± 8.97%\n",
      "        Best fold: Fold 1 with 80.08%\n",
      "      Fitness obtained: 68.56% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: c3b3f805)\n",
      "      Architecture: 11 conv + 10 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model c3b3f805 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6479, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6367, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6904, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7269, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.5724, acc=50.39% (best=50.39%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 83.91%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.20%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.16%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 70.47%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 76.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c3b3f805:\n",
      "        Fold accuracies: ['76.09%', '70.47%', '83.91%', '68.20%', '65.16%']\n",
      "        Average fitness: 72.77% Â± 6.62%\n",
      "        Best fold: Fold 3 with 83.91%\n",
      "      Fitness obtained: 72.77% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 5760fd1d)\n",
      "      Architecture: 11 conv + 9 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 5760fd1d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7129, acc=46.48% (best=46.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6933, acc=51.17% (best=51.17%)\n",
      "          Fold 4 Epoch 1: loss=0.7175, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.7466, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7052, acc=49.61% (best=49.61%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 71.80%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 75.86%\n",
      "          Fold 1 Epoch 30: loss=0.0087, acc=68.59% (best=78.44%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 78.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5760fd1d:\n",
      "        Fold accuracies: ['78.44%', '70.16%', '75.86%', '71.80%', '60.62%']\n",
      "        Average fitness: 71.38% Â± 6.12%\n",
      "        Best fold: Fold 1 with 78.44%\n",
      "      Fitness obtained: 71.38% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: d6dd2db2)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d6dd2db2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5708, acc=54.69% (best=54.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6058, acc=42.03% (best=42.03%)\n",
      "          Fold 3 Epoch 1: loss=0.5863, acc=67.58% (best=67.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6054, acc=51.48% (best=51.48%)\n",
      "          Fold 5 Epoch 1: loss=0.6331, acc=53.12% (best=53.12%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.59%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 74.92%\n",
      "          Fold 2 Epoch 30: loss=0.1468, acc=59.53% (best=70.47%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 70.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d6dd2db2:\n",
      "        Fold accuracies: ['71.88%', '70.47%', '74.92%', '69.30%', '53.59%']\n",
      "        Average fitness: 68.03% Â± 7.46%\n",
      "        Best fold: Fold 3 with 74.92%\n",
      "      Fitness obtained: 68.03% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: a06d9d03)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model a06d9d03 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.5501, acc=57.73% (best=57.73%)\n",
      "          Fold 1 Epoch 1: loss=0.3967, acc=51.48% (best=51.48%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.73%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 81.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a06d9d03:\n",
      "        Fold accuracies: ['81.09%', '0.00%', '0.00%', '0.00%', '57.73%']\n",
      "        Average fitness: 27.77% Â± 34.80%\n",
      "        Best fold: Fold 1 with 81.09%\n",
      "      Fitness obtained: 27.77% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 289e89c9)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 289e89c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6266, acc=53.05% (best=53.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6968, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.7063, acc=48.59% (best=48.59%)\n",
      "          Fold 5 Epoch 1: loss=0.6769, acc=53.12% (best=53.12%)\n",
      "          Fold 3 Epoch 1: loss=0.6769, acc=54.69% (best=54.69%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 53.12%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 73.83%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 72.81%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 78.52%\n",
      "          Fold 4 Epoch 30: loss=0.0975, acc=54.77% (best=67.66%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 67.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 289e89c9:\n",
      "        Fold accuracies: ['78.52%', '73.83%', '72.81%', '67.66%', '53.12%']\n",
      "        Average fitness: 69.19% Â± 8.74%\n",
      "        Best fold: Fold 1 with 78.52%\n",
      "      Fitness obtained: 69.19% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 37bc4d60)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 37bc4d60 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5356, acc=51.88% (best=51.88%)          Fold 3 Epoch 1: loss=0.5860, acc=44.22% (best=44.22%)\n",
      "\n",
      "          Fold 2 Epoch 1: loss=0.4843, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6216, acc=49.84% (best=49.84%)\n",
      "          Fold 1 Epoch 1: loss=0.4887, acc=61.72% (best=61.72%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.75%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 74.45%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 65.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 37bc4d60:\n",
      "        Fold accuracies: ['74.45%', '66.41%', '79.69%', '65.55%', '58.75%']\n",
      "        Average fitness: 68.97% Â± 7.32%\n",
      "        Best fold: Fold 3 with 79.69%\n",
      "      Fitness obtained: 68.97% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 87ea86bb)\n",
      "      Architecture: 11 conv + 5 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 87ea86bb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6160, acc=42.11% (best=42.11%)\n",
      "          Fold 5 Epoch 1: loss=0.5745, acc=51.56% (best=51.56%)\n",
      "          Fold 1 Epoch 1: loss=0.4952, acc=64.30% (best=64.30%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 74.69%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 3 Epoch 30: loss=0.0856, acc=72.34% (best=80.31%)\n",
      "          Fold 3: Early stopping at epoch 33\n",
      "      â†’ Fold 3 completed: 80.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 87ea86bb:\n",
      "        Fold accuracies: ['74.69%', '0.00%', '80.31%', '0.00%', '61.25%']\n",
      "        Average fitness: 43.25% Â± 35.85%\n",
      "        Best fold: Fold 3 with 80.31%\n",
      "      Fitness obtained: 43.25% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 87cf3153)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 87cf3153 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6270, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6139, acc=68.98% (best=68.98%)\n",
      "          Fold 1 Epoch 1: loss=0.5934, acc=65.16% (best=65.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6114, acc=49.30% (best=49.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6142, acc=54.45% (best=54.45%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 72.11%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.42%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 72.19%\n",
      "          Fold 4 Epoch 30: loss=0.1129, acc=57.11% (best=75.78%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 75.78%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 76.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 87cf3153:\n",
      "        Fold accuracies: ['72.11%', '76.33%', '72.19%', '75.78%', '57.42%']\n",
      "        Average fitness: 70.77% Â± 6.90%\n",
      "        Best fold: Fold 2 with 76.33%\n",
      "      Fitness obtained: 70.77% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 665de27f)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 665de27f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=5.0467, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=3.3691, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=3.3833, acc=51.17% (best=51.17%)\n",
      "          Fold 5 Epoch 1: loss=4.0471, acc=54.38% (best=54.38%)\n",
      "          Fold 2 Epoch 1: loss=4.7724, acc=62.81% (best=62.81%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 62.81%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 69.92%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 72.34%\n",
      "          Fold 4 Epoch 30: loss=0.1232, acc=59.45% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 665de27f:\n",
      "        Fold accuracies: ['69.92%', '62.81%', '72.34%', '67.34%', '62.03%']\n",
      "        Average fitness: 66.89% Â± 3.98%\n",
      "        Best fold: Fold 3 with 72.34%\n",
      "      Fitness obtained: 66.89% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: a0b25eec)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model a0b25eec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6078, acc=68.75% (best=68.75%)\n",
      "          Fold 3 Epoch 1: loss=0.5757, acc=72.19% (best=72.19%)\n",
      "          Fold 2 Epoch 1: loss=0.5923, acc=53.91% (best=53.91%)\n",
      "          Fold 5 Epoch 1: loss=0.5768, acc=57.97% (best=57.97%)\n",
      "          Fold 1 Epoch 1: loss=0.4414, acc=62.89% (best=62.89%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.89%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.75%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.97%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 79.84%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 58.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a0b25eec:\n",
      "        Fold accuracies: ['62.89%', '58.36%', '79.84%', '68.75%', '57.97%']\n",
      "        Average fitness: 65.56% Â± 8.13%\n",
      "        Best fold: Fold 3 with 79.84%\n",
      "      Fitness obtained: 65.56% | Best in generation: 74.09% | Global best: 75.31%\n",
      "\n",
      "GENERATION 6 STATISTICS:\n",
      "   Maximum fitness: 74.09%\n",
      "   Average fitness: 63.04%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 18.08%\n",
      "   Best individual: cc04ff86 with 74.09%\n",
      "   Global best individual: cc04ff86 with 75.31%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=18.08)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: cc04ff86 (fitness: 74.09%)\n",
      "   Elite 2: 660f7479 (fitness: 73.73%)\n",
      "   Elite 3: c3b3f805 (fitness: 72.77%)\n",
      "   Elite 4: 9b59c8df (fitness: 72.72%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 7\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 7)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: cc04ff86)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cc04ff86 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6019, acc=60.94% (best=60.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6402, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6350, acc=86.56% (best=86.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5565, acc=64.53% (best=64.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6183, acc=62.73% (best=62.73%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 89.30%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 69.77%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 80.94%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 2 Epoch 30: loss=0.1429, acc=71.02% (best=71.02%)\n",
      "          Fold 2: Early stopping at epoch 51\n",
      "      â†’ Fold 2 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc04ff86:\n",
      "        Fold accuracies: ['80.94%', '77.42%', '89.30%', '69.77%', '61.25%']\n",
      "        Average fitness: 75.73% Â± 9.58%\n",
      "        Best fold: Fold 3 with 89.30%\n",
      "      New best fitness in this generation: 75.73%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 75.73% > 75.31%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen5_idcc04ff86_fitness75.31.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen7_idcc04ff86_fitness75.73.pth\n",
      "        Fitness: 75.73%, ID: cc04ff86, Gen: 7\n",
      "      Fitness obtained: 75.73% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 660f7479)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 660f7479 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6237, acc=65.00% (best=65.00%)\n",
      "          Fold 5 Epoch 1: loss=0.6218, acc=56.41% (best=56.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6085, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 1: loss=0.6175, acc=60.78% (best=60.78%)\n",
      "          Fold 1 Epoch 1: loss=0.4893, acc=76.95% (best=76.95%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 70.86%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 78.75%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 82.34%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 660f7479:\n",
      "        Fold accuracies: ['78.75%', '66.72%', '82.34%', '70.47%', '70.86%']\n",
      "        Average fitness: 73.83% Â± 5.79%\n",
      "        Best fold: Fold 3 with 82.34%\n",
      "      Fitness obtained: 73.83% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: c3b3f805)\n",
      "      Architecture: 11 conv + 10 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model c3b3f805 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6643, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.6857, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 1: loss=0.6267, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6495, acc=62.50% (best=62.50%)\n",
      "          Fold 1 Epoch 1: loss=0.5770, acc=50.39% (best=50.39%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 71.41%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 81.02%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 61.72%\n",
      "          Fold 1 Epoch 30: loss=0.0306, acc=68.28% (best=74.84%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c3b3f805:\n",
      "        Fold accuracies: ['74.84%', '73.75%', '81.02%', '61.72%', '71.41%']\n",
      "        Average fitness: 72.55% Â± 6.28%\n",
      "        Best fold: Fold 3 with 81.02%\n",
      "      Fitness obtained: 72.55% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 9b59c8df)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 9b59c8df with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5391, acc=66.02% (best=66.02%)\n",
      "          Fold 1 Epoch 1: loss=0.3822, acc=63.36% (best=63.36%)\n",
      "          Fold 2 Epoch 1: loss=0.4952, acc=55.70% (best=55.70%)\n",
      "          Fold 3 Epoch 1: loss=0.5769, acc=72.66% (best=72.66%)\n",
      "          Fold 5 Epoch 1: loss=0.5417, acc=53.28% (best=53.28%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 67.89%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 64.45%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 71.95%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 72.66%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 67.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9b59c8df:\n",
      "        Fold accuracies: ['71.95%', '64.45%', '72.66%', '67.89%', '67.66%']\n",
      "        Average fitness: 68.92% Â± 3.03%\n",
      "        Best fold: Fold 3 with 72.66%\n",
      "      Fitness obtained: 68.92% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 085b2071)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 085b2071 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=1.2846, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 1: loss=0.9082, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 1: loss=1.3660, acc=61.33% (best=61.33%)\n",
      "          Fold 5 Epoch 1: loss=1.2078, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 1: loss=1.2520, acc=71.41% (best=71.41%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.41%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 76.72%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 59.84%\n",
      "          Fold 3 Epoch 30: loss=0.1263, acc=61.33% (best=70.08%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 70.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 085b2071:\n",
      "        Fold accuracies: ['76.72%', '71.41%', '70.08%', '70.31%', '59.84%']\n",
      "        Average fitness: 69.67% Â± 5.47%\n",
      "        Best fold: Fold 1 with 76.72%\n",
      "      Fitness obtained: 69.67% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: bd62434a)\n",
      "      Architecture: 11 conv + 10 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model bd62434a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6620, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7177, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7066, acc=53.05% (best=53.05%)\n",
      "          Fold 5 Epoch 1: loss=0.7302, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6026, acc=56.02% (best=56.02%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 77.27%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.12%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 74.77%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 69.84%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd62434a:\n",
      "        Fold accuracies: ['64.69%', '74.77%', '77.27%', '69.84%', '68.12%']\n",
      "        Average fitness: 70.94% Â± 4.54%\n",
      "        Best fold: Fold 3 with 77.27%\n",
      "      Fitness obtained: 70.94% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 05e83c13)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 05e83c13 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7190, acc=86.80% (best=86.80%)\n",
      "          Fold 4 Epoch 1: loss=0.7110, acc=65.16% (best=65.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6589, acc=69.45% (best=69.45%)\n",
      "          Fold 1 Epoch 1: loss=0.5524, acc=70.62% (best=70.62%)\n",
      "          Fold 5 Epoch 1: loss=0.6850, acc=57.89% (best=57.89%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.80%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 69.45%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 5 Epoch 30: loss=0.0862, acc=60.70% (best=68.12%)\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 68.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 05e83c13:\n",
      "        Fold accuracies: ['76.41%', '69.45%', '86.80%', '71.25%', '68.12%']\n",
      "        Average fitness: 74.41% Â± 6.80%\n",
      "        Best fold: Fold 3 with 86.80%\n",
      "      Fitness obtained: 74.41% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: d9291c72)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model d9291c72 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6227, acc=82.73% (best=82.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6574, acc=64.14% (best=64.14%)\n",
      "          Fold 4 Epoch 1: loss=0.7069, acc=52.66% (best=52.66%)\n",
      "          Fold 5 Epoch 1: loss=0.6549, acc=53.12% (best=53.12%)\n",
      "          Fold 2 Epoch 1: loss=0.6509, acc=71.88% (best=71.88%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 82.73%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.25%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "          Fold 5 Epoch 30: loss=0.1414, acc=60.62% (best=69.14%)\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 69.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d9291c72:\n",
      "        Fold accuracies: ['82.73%', '71.88%', '66.25%', '70.31%', '69.14%']\n",
      "        Average fitness: 72.06% Â± 5.64%\n",
      "        Best fold: Fold 1 with 82.73%\n",
      "      Fitness obtained: 72.06% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 4c9b0611)\n",
      "      Architecture: 4 conv + 10 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 4c9b0611 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.3785, acc=64.92% (best=64.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6061, acc=56.56% (best=56.56%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 72.97%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 69.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4c9b0611:\n",
      "        Fold accuracies: ['72.97%', '69.53%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 28.50% Â± 34.92%\n",
      "        Best fold: Fold 1 with 72.97%\n",
      "      Fitness obtained: 28.50% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: cdbd632f)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model cdbd632f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6107, acc=57.89% (best=57.89%)\n",
      "          Fold 3 Epoch 1: loss=0.6258, acc=57.34% (best=57.34%)\n",
      "          Fold 2 Epoch 1: loss=0.5876, acc=48.36% (best=48.36%)\n",
      "          Fold 5 Epoch 1: loss=0.5600, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.4594, acc=52.89% (best=52.89%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 67.58%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 80.39%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 4 Epoch 30: loss=0.0856, acc=65.70% (best=77.11%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 77.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cdbd632f:\n",
      "        Fold accuracies: ['80.39%', '67.58%', '79.77%', '77.11%', '58.98%']\n",
      "        Average fitness: 72.77% Â± 8.28%\n",
      "        Best fold: Fold 1 with 80.39%\n",
      "      Fitness obtained: 72.77% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 364a0900)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 364a0900 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6329, acc=63.36% (best=63.36%)\n",
      "          Fold 2 Epoch 1: loss=0.6042, acc=53.59% (best=53.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6323, acc=64.38% (best=64.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6366, acc=59.69% (best=59.69%)\n",
      "          Fold 1 Epoch 1: loss=0.5061, acc=73.05% (best=73.05%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.66%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 80.08%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 64.30%\n",
      "          Fold 2 Epoch 30: loss=0.1441, acc=61.72% (best=69.84%)\n",
      "          Fold 4 Epoch 30: loss=0.1432, acc=75.08% (best=75.31%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 75.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 364a0900:\n",
      "        Fold accuracies: ['80.08%', '69.84%', '64.30%', '75.31%', '67.66%']\n",
      "        Average fitness: 71.44% Â± 5.61%\n",
      "        Best fold: Fold 1 with 80.08%\n",
      "      Fitness obtained: 71.44% | Best in generation: 75.73% | Global best: 75.73%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6400, acc=67.19% (best=67.19%)\n",
      "          Fold 1 Epoch 1: loss=0.5516, acc=86.88% (best=86.88%)\n",
      "          Fold 5 Epoch 1: loss=0.6533, acc=65.94% (best=65.94%)\n",
      "          Fold 3 Epoch 1: loss=0.6284, acc=83.75% (best=83.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6499, acc=63.83% (best=63.83%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 86.88%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 83.75%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.19%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 69.06%\n",
      "          Fold 4 Epoch 30: loss=0.1492, acc=72.11% (best=76.17%)\n",
      "          Fold 4: Early stopping at epoch 30\n",
      "      â†’ Fold 4 completed: 76.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['86.88%', '67.19%', '83.75%', '76.17%', '69.06%']\n",
      "        Average fitness: 76.61% Â± 7.78%\n",
      "        Best fold: Fold 1 with 86.88%\n",
      "      New best fitness in this generation: 76.61%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 76.61% > 75.73%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen7_idcc04ff86_fitness75.73.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen7_id1e909e9b_fitness76.61.pth\n",
      "        Fitness: 76.61%, ID: 1e909e9b, Gen: 7\n",
      "      Fitness obtained: 76.61% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 4838ffd1)\n",
      "      Architecture: 11 conv + 10 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 4838ffd1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7137, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 1: loss=0.7020, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6699, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6712, acc=55.47% (best=55.47%)\n",
      "          Fold 1 Epoch 1: loss=0.5486, acc=50.39% (best=50.39%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.98%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 73.44%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 76.48%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 78.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4838ffd1:\n",
      "        Fold accuracies: ['76.48%', '73.44%', '78.28%', '68.98%', '65.47%']\n",
      "        Average fitness: 72.53% Â± 4.73%\n",
      "        Best fold: Fold 3 with 78.28%\n",
      "      Fitness obtained: 72.53% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: ca2f8658)\n",
      "      Architecture: 11 conv + 10 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model ca2f8658 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6930, acc=64.53% (best=64.53%)\n",
      "          Fold 5 Epoch 1: loss=0.6154, acc=46.17% (best=46.17%)\n",
      "          Fold 1 Epoch 1: loss=0.5686, acc=63.75% (best=63.75%)\n",
      "          Fold 2 Epoch 1: loss=0.6338, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.6980, acc=59.69% (best=59.69%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 80.00%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 76.56%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 64.14%\n",
      "          Fold 4 Epoch 30: loss=0.0983, acc=68.83% (best=76.95%)\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 76.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ca2f8658:\n",
      "        Fold accuracies: ['76.56%', '68.83%', '80.00%', '76.95%', '64.14%']\n",
      "        Average fitness: 73.30% Â± 5.88%\n",
      "        Best fold: Fold 3 with 80.00%\n",
      "      Fitness obtained: 73.30% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: b53e4974)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model b53e4974 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5579, acc=46.64% (best=46.64%)\n",
      "          Fold 5 Epoch 1: loss=0.5666, acc=43.67% (best=43.67%)\n",
      "          Fold 3 Epoch 1: loss=0.5281, acc=49.06% (best=49.06%)\n",
      "          Fold 2 Epoch 1: loss=0.5235, acc=34.84% (best=34.84%)\n",
      "          Fold 1 Epoch 1: loss=0.5470, acc=48.05% (best=48.05%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 62.89%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 76.48%\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 73.98%\n",
      "          Fold 4 Epoch 30: loss=0.0720, acc=53.52% (best=63.67%)\n",
      "          Fold 2 Epoch 30: loss=0.0711, acc=64.92% (best=72.66%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 72.66%\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b53e4974:\n",
      "        Fold accuracies: ['76.48%', '72.66%', '73.98%', '65.39%', '62.89%']\n",
      "        Average fitness: 70.28% Â± 5.22%\n",
      "        Best fold: Fold 1 with 76.48%\n",
      "      Fitness obtained: 70.28% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 32322db1)\n",
      "      Architecture: 11 conv + 6 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 32322db1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6118, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 1: loss=0.5497, acc=76.64% (best=76.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6252, acc=41.95% (best=41.95%)\n",
      "          Fold 3 Epoch 1: loss=0.6858, acc=47.19% (best=47.19%)\n",
      "          Fold 1 Epoch 1: loss=0.4459, acc=47.58% (best=47.58%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 76.64%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 71.25%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 80.86%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 70.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 32322db1:\n",
      "        Fold accuracies: ['71.25%', '76.64%', '80.86%', '70.94%', '64.06%']\n",
      "        Average fitness: 72.75% Â± 5.69%\n",
      "        Best fold: Fold 3 with 80.86%\n",
      "      Fitness obtained: 72.75% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: b9a3f0f1)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model b9a3f0f1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6413, acc=80.78% (best=80.78%)\n",
      "          Fold 4 Epoch 1: loss=0.7055, acc=56.41% (best=56.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6940, acc=62.97% (best=62.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6878, acc=51.88% (best=51.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7118, acc=58.52% (best=58.52%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 84.45%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 82.50%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 75.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b9a3f0f1:\n",
      "        Fold accuracies: ['84.45%', '73.75%', '82.50%', '75.47%', '65.62%']\n",
      "        Average fitness: 76.36% Â± 6.72%\n",
      "        Best fold: Fold 1 with 84.45%\n",
      "      Fitness obtained: 76.36% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 5ab0a455)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 5ab0a455 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5935, acc=71.02% (best=71.02%)\n",
      "          Fold 1 Epoch 1: loss=0.4662, acc=67.42% (best=67.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6216, acc=59.30% (best=59.30%)\n",
      "          Fold 5 Epoch 1: loss=0.5767, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 1: loss=0.5955, acc=74.14% (best=74.14%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 80.47%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 74.30%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 70.31%\n",
      "          Fold 4 Epoch 30: loss=0.0737, acc=69.61% (best=78.83%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 78.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5ab0a455:\n",
      "        Fold accuracies: ['74.30%', '70.31%', '80.47%', '78.83%', '62.03%']\n",
      "        Average fitness: 73.19% Â± 6.62%\n",
      "        Best fold: Fold 3 with 80.47%\n",
      "      Fitness obtained: 73.19% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 49c9215e)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 49c9215e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5673, acc=60.86% (best=60.86%)\n",
      "          Fold 5 Epoch 1: loss=0.5475, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 1: loss=0.5550, acc=62.89% (best=62.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5633, acc=65.94% (best=65.94%)\n",
      "          Fold 1 Epoch 1: loss=0.3878, acc=52.19% (best=52.19%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.86%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 68.75%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 67.58%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 71.09%\n",
      "          Fold 1 Epoch 30: loss=0.0102, acc=63.28% (best=75.23%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 49c9215e:\n",
      "        Fold accuracies: ['75.23%', '67.58%', '68.75%', '60.86%', '71.09%']\n",
      "        Average fitness: 68.70% Â± 4.72%\n",
      "        Best fold: Fold 1 with 75.23%\n",
      "      Fitness obtained: 68.70% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: d4f075b1)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model d4f075b1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.4674, acc=53.98% (best=53.98%)\n",
      "          Fold 2 Epoch 1: loss=0.5184, acc=55.31% (best=55.31%)\n",
      "          Fold 4 Epoch 1: loss=0.5150, acc=55.08% (best=55.08%)\n",
      "          Fold 3 Epoch 1: loss=0.5379, acc=58.91% (best=58.91%)\n",
      "          Fold 1 Epoch 1: loss=0.3107, acc=60.39% (best=60.39%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.78%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 70.39%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 66.17%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d4f075b1:\n",
      "        Fold accuracies: ['70.39%', '71.95%', '66.17%', '69.84%', '60.78%']\n",
      "        Average fitness: 67.83% Â± 4.00%\n",
      "        Best fold: Fold 2 with 71.95%\n",
      "      Fitness obtained: 67.83% | Best in generation: 76.61% | Global best: 76.61%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 7 STATISTICS:\n",
      "   Maximum fitness: 76.61%\n",
      "   Average fitness: 70.12%\n",
      "   Minimum fitness: 28.50%\n",
      "   Standard deviation: 9.84%\n",
      "   Best individual: 1e909e9b with 76.61%\n",
      "   Global best individual: 1e909e9b with 76.61%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.30% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=9.84)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1e909e9b (fitness: 76.61%)\n",
      "   Elite 2: b9a3f0f1 (fitness: 76.36%)\n",
      "   Elite 3: cc04ff86 (fitness: 75.73%)\n",
      "   Elite 4: 05e83c13 (fitness: 74.41%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 8\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 8)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5856, acc=68.98% (best=68.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6443, acc=81.41% (best=81.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6579, acc=62.03% (best=62.03%)\n",
      "          Fold 4 Epoch 1: loss=0.6444, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6476, acc=63.98% (best=63.98%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 93.83%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 70.47%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 81.88%\n",
      "          Fold 4 Epoch 30: loss=0.1513, acc=74.53% (best=77.03%)\n",
      "          Fold 4: Early stopping at epoch 37\n",
      "      â†’ Fold 4 completed: 77.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['81.88%', '70.47%', '93.83%', '77.03%', '68.75%']\n",
      "        Average fitness: 78.39% Â± 9.03%\n",
      "        Best fold: Fold 3 with 93.83%\n",
      "      New best fitness in this generation: 78.39%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 78.39% > 76.61%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen7_id1e909e9b_fitness76.61.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen8_id1e909e9b_fitness78.39.pth\n",
      "        Fitness: 78.39%, ID: 1e909e9b, Gen: 8\n",
      "      Fitness obtained: 78.39% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b9a3f0f1)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model b9a3f0f1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6768, acc=44.06% (best=44.06%)\n",
      "          Fold 3 Epoch 1: loss=0.6767, acc=57.81% (best=57.81%)\n",
      "          Fold 5 Epoch 1: loss=0.6973, acc=65.16% (best=65.16%)\n",
      "          Fold 1 Epoch 1: loss=0.6651, acc=53.83% (best=53.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7378, acc=54.53% (best=54.53%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 73.36%\n",
      "          Fold 1 Epoch 30: loss=0.0443, acc=80.16% (best=82.66%)\n",
      "          Fold 3 Epoch 30: loss=0.2461, acc=77.89% (best=82.27%)\n",
      "          Fold 4 Epoch 30: loss=0.2530, acc=68.44% (best=75.00%)\n",
      "          Fold 2 Epoch 30: loss=0.2513, acc=67.58% (best=68.52%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 75.00%\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 82.27%\n",
      "          Fold 1: Early stopping at epoch 46\n",
      "      â†’ Fold 1 completed: 84.84%\n",
      "          Fold 2: Early stopping at epoch 46\n",
      "      â†’ Fold 2 completed: 75.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b9a3f0f1:\n",
      "        Fold accuracies: ['84.84%', '75.39%', '82.27%', '75.00%', '73.36%']\n",
      "        Average fitness: 78.17% Â± 4.52%\n",
      "        Best fold: Fold 1 with 84.84%\n",
      "      Fitness obtained: 78.17% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: cc04ff86)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cc04ff86 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6243, acc=65.70% (best=65.70%)\n",
      "          Fold 4 Epoch 1: loss=0.6434, acc=51.41% (best=51.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6193, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5624, acc=78.28% (best=78.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6223, acc=83.67% (best=83.67%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.28%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.36%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 84.84%\n",
      "          Fold 4: Early stopping at epoch 29\n",
      "      â†’ Fold 4 completed: 76.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc04ff86:\n",
      "        Fold accuracies: ['78.28%', '66.25%', '84.84%', '76.48%', '63.36%']\n",
      "        Average fitness: 73.84% Â± 7.94%\n",
      "        Best fold: Fold 3 with 84.84%\n",
      "      Fitness obtained: 73.84% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 05e83c13)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 05e83c13 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6740, acc=54.92% (best=54.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6951, acc=60.78% (best=60.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6971, acc=65.39% (best=65.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7230, acc=77.73% (best=77.73%)\n",
      "          Fold 1 Epoch 1: loss=0.5562, acc=58.12% (best=58.12%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 81.25%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 74.92%\n",
      "          Fold 2 Epoch 30: loss=0.1072, acc=70.62% (best=75.55%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 73.20%\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 75.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 05e83c13:\n",
      "        Fold accuracies: ['73.20%', '75.55%', '81.25%', '74.92%', '61.88%']\n",
      "        Average fitness: 73.36% Â± 6.35%\n",
      "        Best fold: Fold 3 with 81.25%\n",
      "      Fitness obtained: 73.36% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 33bb127b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 33bb127b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6331, acc=61.33% (best=61.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6331, acc=66.41% (best=66.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6463, acc=82.03% (best=82.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6142, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5780, acc=76.17% (best=76.17%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 82.03%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 82.03%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 4 Epoch 30: loss=0.1360, acc=73.59% (best=75.39%)\n",
      "          Fold 4: Early stopping at epoch 30\n",
      "      â†’ Fold 4 completed: 75.39%\n",
      "          Fold 2 Epoch 30: loss=0.1457, acc=70.23% (best=74.84%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 33bb127b:\n",
      "        Fold accuracies: ['82.03%', '74.84%', '82.03%', '75.39%', '65.47%']\n",
      "        Average fitness: 75.95% Â± 6.09%\n",
      "        Best fold: Fold 3 with 82.03%\n",
      "      Fitness obtained: 75.95% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: dd69baae)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model dd69baae with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6887, acc=58.83% (best=58.83%)\n",
      "          Fold 3 Epoch 1: loss=0.7013, acc=76.25% (best=76.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6955, acc=48.91% (best=48.91%)\n",
      "          Fold 5 Epoch 1: loss=0.7350, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6943, acc=52.11% (best=52.11%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 77.97%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 79.53%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 51.88%\n",
      "          Fold 2 Epoch 30: loss=0.2426, acc=66.09% (best=69.61%)\n",
      "          Fold 5 Epoch 30: loss=0.2141, acc=53.28% (best=62.58%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dd69baae:\n",
      "        Fold accuracies: ['77.97%', '69.61%', '79.53%', '51.88%', '62.58%']\n",
      "        Average fitness: 68.31% Â± 10.24%\n",
      "        Best fold: Fold 3 with 79.53%\n",
      "      Fitness obtained: 68.31% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 544ca502)\n",
      "      Architecture: 11 conv + 10 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 544ca502 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7833, acc=37.19% (best=37.19%)\n",
      "          Fold 4 Epoch 1: loss=0.7908, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 1: loss=0.6852, acc=69.69% (best=69.69%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 65.78%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 66.56%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 75.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 544ca502:\n",
      "        Fold accuracies: ['75.70%', '65.78%', '0.00%', '66.56%', '0.00%']\n",
      "        Average fitness: 41.61% Â± 34.15%\n",
      "        Best fold: Fold 1 with 75.70%\n",
      "      Fitness obtained: 41.61% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: dccab5ce)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model dccab5ce with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5948, acc=48.28% (best=48.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6425, acc=38.12% (best=38.12%)\n",
      "          Fold 1 Epoch 1: loss=0.5021, acc=83.44% (best=83.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6877, acc=71.33% (best=71.33%)\n",
      "          Fold 5 Epoch 1: loss=0.6150, acc=48.44% (best=48.44%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 83.44%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 71.33%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.69%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 78.36%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 74.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dccab5ce:\n",
      "        Fold accuracies: ['83.44%', '78.36%', '74.22%', '71.33%', '69.69%']\n",
      "        Average fitness: 75.41% Â± 4.98%\n",
      "        Best fold: Fold 1 with 83.44%\n",
      "      Fitness obtained: 75.41% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 194e910d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 194e910d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6294, acc=55.94% (best=55.94%)\n",
      "          Fold 1 Epoch 1: loss=0.5325, acc=74.06% (best=74.06%)\n",
      "          Fold 5 Epoch 1: loss=0.6173, acc=54.84% (best=54.84%)\n",
      "          Fold 3 Epoch 1: loss=0.6280, acc=79.84% (best=79.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6444, acc=52.34% (best=52.34%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.84%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 74.53%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 71.41%\n",
      "          Fold 5 Epoch 30: loss=0.1297, acc=52.11% (best=62.50%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "          Fold 4 Epoch 30: loss=0.1389, acc=71.09% (best=77.73%)\n",
      "          Fold 4: Early stopping at epoch 39\n",
      "      â†’ Fold 4 completed: 77.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 194e910d:\n",
      "        Fold accuracies: ['74.53%', '71.41%', '79.84%', '77.73%', '62.50%']\n",
      "        Average fitness: 73.20% Â± 6.07%\n",
      "        Best fold: Fold 3 with 79.84%\n",
      "      Fitness obtained: 73.20% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 0e405658)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0e405658 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5984, acc=77.19% (best=77.19%)\n",
      "          Fold 4 Epoch 1: loss=0.6622, acc=66.95% (best=66.95%)\n",
      "          Fold 3 Epoch 1: loss=0.6474, acc=82.97% (best=82.97%)\n",
      "          Fold 2 Epoch 1: loss=0.6412, acc=68.83% (best=68.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6525, acc=69.92% (best=69.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 69.92%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 84.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0e405658:\n",
      "        Fold accuracies: ['77.19%', '68.83%', '84.45%', '69.38%', '69.92%']\n",
      "        Average fitness: 73.95% Â± 6.07%\n",
      "        Best fold: Fold 3 with 84.45%\n",
      "      Fitness obtained: 73.95% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: c99a3a88)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c99a3a88 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.7195, acc=61.17% (best=61.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7280, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7185, acc=48.83% (best=48.83%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.17%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c99a3a88:\n",
      "        Fold accuracies: ['50.39%', '0.00%', '48.83%', '61.17%', '0.00%']\n",
      "        Average fitness: 32.08% Â± 26.53%\n",
      "        Best fold: Fold 4 with 61.17%\n",
      "      Fitness obtained: 32.08% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 137bb2f5)\n",
      "      Architecture: 2 conv + 2 fc, opt=sgd, lr=0.001\n",
      "      Training/Evaluating model 137bb2f5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.3064, acc=50.94% (best=50.94%)\n",
      "          Fold 4 Epoch 1: loss=0.3208, acc=52.27% (best=52.27%)\n",
      "          Fold 2 Epoch 1: loss=0.3455, acc=53.20% (best=53.20%)\n",
      "          Fold 1 Epoch 1: loss=0.2416, acc=64.45% (best=64.45%)\n",
      "          Fold 3 Epoch 1: loss=0.3225, acc=74.92% (best=74.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.45%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 75.86%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 60.31%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 56.80%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 137bb2f5:\n",
      "        Fold accuracies: ['64.45%', '60.31%', '75.86%', '56.80%', '60.39%']\n",
      "        Average fitness: 63.56% Â± 6.61%\n",
      "        Best fold: Fold 3 with 75.86%\n",
      "      Fitness obtained: 63.56% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: e322ab28)\n",
      "      Architecture: 11 conv + 6 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model e322ab28 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.5555, acc=53.98% (best=53.98%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 57.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e322ab28:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '57.97%']\n",
      "        Average fitness: 11.59% Â± 23.19%\n",
      "        Best fold: Fold 5 with 57.97%\n",
      "      Fitness obtained: 11.59% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 13449ff0)\n",
      "      Architecture: 11 conv + 10 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 13449ff0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6803, acc=69.30% (best=69.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6901, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6256, acc=68.67% (best=68.67%)\n",
      "          Fold 3 Epoch 1: loss=0.6729, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.5925, acc=50.39% (best=50.39%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 66.80%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 69.77%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 71.95%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.17%\n",
      "          Fold 3 Epoch 30: loss=0.0891, acc=61.64% (best=80.78%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 80.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 13449ff0:\n",
      "        Fold accuracies: ['76.17%', '69.77%', '80.78%', '71.95%', '66.80%']\n",
      "        Average fitness: 73.09% Â± 4.91%\n",
      "        Best fold: Fold 3 with 80.78%\n",
      "      Fitness obtained: 73.09% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: cfb42a64)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model cfb42a64 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6854, acc=71.48% (best=71.48%)\n",
      "          Fold 5 Epoch 1: loss=0.5952, acc=65.70% (best=65.70%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 75.23%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 71.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cfb42a64:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '75.23%', '71.95%']\n",
      "        Average fitness: 29.44% Â± 36.07%\n",
      "        Best fold: Fold 4 with 75.23%\n",
      "      Fitness obtained: 29.44% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 046930ec)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 046930ec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6669, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6710, acc=55.39% (best=55.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6751, acc=55.00% (best=55.00%)\n",
      "          Fold 3 Epoch 1: loss=0.6709, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6649, acc=56.56% (best=56.56%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 55.00%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.28%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 75.08%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 67.19%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 046930ec:\n",
      "        Fold accuracies: ['67.19%', '70.55%', '75.08%', '55.00%', '58.28%']\n",
      "        Average fitness: 65.22% Â± 7.51%\n",
      "        Best fold: Fold 3 with 75.08%\n",
      "      Fitness obtained: 65.22% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: f9fae4a4)\n",
      "      Architecture: 9 conv + 9 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model f9fae4a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6334, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6637, acc=52.58% (best=52.58%)\n",
      "          Fold 3 Epoch 1: loss=0.6881, acc=67.42% (best=67.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6793, acc=56.33% (best=56.33%)\n",
      "          Fold 1 Epoch 1: loss=0.5632, acc=57.27% (best=57.27%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 69.77%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 71.64%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 80.94%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 69.92%\n",
      "          Fold 1 Epoch 30: loss=0.0231, acc=68.67% (best=74.22%)\n",
      "          Fold 1: Early stopping at epoch 55\n",
      "      â†’ Fold 1 completed: 79.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f9fae4a4:\n",
      "        Fold accuracies: ['79.22%', '71.64%', '80.94%', '69.92%', '69.77%']\n",
      "        Average fitness: 74.30% Â± 4.80%\n",
      "        Best fold: Fold 3 with 80.94%\n",
      "      Fitness obtained: 74.30% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 6f5333a5)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 6f5333a5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 6f5333a5:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4ce6ea9a)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4ce6ea9a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6269, acc=60.86% (best=60.86%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4ce6ea9a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '60.86%']\n",
      "        Average fitness: 12.17% Â± 24.34%\n",
      "        Best fold: Fold 5 with 60.86%\n",
      "      Fitness obtained: 12.17% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 0bb6453d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0bb6453d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=54.14% (best=54.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6962, acc=44.69% (best=44.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6942, acc=48.75% (best=48.75%)\n",
      "          Fold 2 Epoch 1: loss=0.7106, acc=52.50% (best=52.50%)\n",
      "          Fold 1 Epoch 1: loss=0.6902, acc=47.66% (best=47.66%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 68.44%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 49.53%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 78.52%\n",
      "          Fold 5 Epoch 30: loss=0.1854, acc=58.91% (best=67.27%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0bb6453d:\n",
      "        Fold accuracies: ['76.41%', '78.52%', '68.44%', '49.53%', '67.27%']\n",
      "        Average fitness: 68.03% Â± 10.23%\n",
      "        Best fold: Fold 2 with 78.52%\n",
      "      Fitness obtained: 68.03% | Best in generation: 78.39% | Global best: 78.39%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 8 STATISTICS:\n",
      "   Maximum fitness: 78.39%\n",
      "   Average fitness: 57.08%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 25.06%\n",
      "   Best individual: 1e909e9b with 78.39%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.78% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=25.06)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1e909e9b (fitness: 78.39%)\n",
      "   Elite 2: b9a3f0f1 (fitness: 78.17%)\n",
      "   Elite 3: 33bb127b (fitness: 75.95%)\n",
      "   Elite 4: dccab5ce (fitness: 75.41%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 9\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 9)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6370, acc=62.81% (best=62.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6596, acc=60.78% (best=60.78%)\n",
      "          Fold 3 Epoch 1: loss=0.6359, acc=80.23% (best=80.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6355, acc=67.42% (best=67.42%)\n",
      "          Fold 1 Epoch 1: loss=0.5664, acc=77.66% (best=77.66%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 80.78%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.97%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 69.61%\n",
      "          Fold 4 Epoch 30: loss=0.1474, acc=70.08% (best=71.72%)\n",
      "          Fold 2 Epoch 30: loss=0.1612, acc=66.95% (best=68.20%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 71.72%\n",
      "          Fold 2: Early stopping at epoch 59\n",
      "      â†’ Fold 2 completed: 73.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['82.97%', '73.44%', '80.78%', '71.72%', '69.61%']\n",
      "        Average fitness: 75.70% Â± 5.23%\n",
      "        Best fold: Fold 1 with 82.97%\n",
      "      New best fitness in this generation: 75.70%!\n",
      "      Fitness obtained: 75.70% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b9a3f0f1)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model b9a3f0f1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6746, acc=51.48% (best=51.48%)\n",
      "          Fold 1 Epoch 1: loss=0.6565, acc=53.05% (best=53.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6887, acc=51.64% (best=51.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6955, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6816, acc=47.97% (best=47.97%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 58.36%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 77.42%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 53.59%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 77.81%\n",
      "          Fold 5 Epoch 30: loss=0.2111, acc=68.52% (best=73.52%)\n",
      "          Fold 5: Early stopping at epoch 37\n",
      "      â†’ Fold 5 completed: 73.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b9a3f0f1:\n",
      "        Fold accuracies: ['58.36%', '53.59%', '77.42%', '77.81%', '73.52%']\n",
      "        Average fitness: 68.14% Â± 10.16%\n",
      "        Best fold: Fold 4 with 77.81%\n",
      "      Fitness obtained: 68.14% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 33bb127b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 33bb127b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6266, acc=83.75% (best=83.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6388, acc=46.88% (best=46.88%)\n",
      "          Fold 1 Epoch 1: loss=0.5570, acc=64.45% (best=64.45%)\n",
      "          Fold 2 Epoch 1: loss=0.6566, acc=54.06% (best=54.06%)\n",
      "          Fold 5 Epoch 1: loss=0.6274, acc=64.69% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 87.34%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 76.64%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 79.77%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 60.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 33bb127b:\n",
      "        Fold accuracies: ['79.77%', '60.31%', '87.34%', '76.64%', '64.69%']\n",
      "        Average fitness: 73.75% Â± 9.92%\n",
      "        Best fold: Fold 3 with 87.34%\n",
      "      Fitness obtained: 73.75% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: dccab5ce)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model dccab5ce with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7009, acc=39.84% (best=39.84%)\n",
      "          Fold 1 Epoch 1: loss=0.5175, acc=51.33% (best=51.33%)\n",
      "          Fold 5 Epoch 1: loss=0.5775, acc=64.92% (best=64.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6685, acc=55.94% (best=55.94%)\n",
      "          Fold 2 Epoch 1: loss=0.5885, acc=48.91% (best=48.91%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.92%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 81.02%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 69.77%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 73.59%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 81.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dccab5ce:\n",
      "        Fold accuracies: ['81.02%', '69.77%', '81.02%', '73.59%', '64.92%']\n",
      "        Average fitness: 74.06% Â± 6.31%\n",
      "        Best fold: Fold 1 with 81.02%\n",
      "      Fitness obtained: 74.06% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 1a53b58f)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1a53b58f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7126, acc=67.50% (best=67.50%)\n",
      "          Fold 3 Epoch 1: loss=0.6417, acc=73.05% (best=73.05%)\n",
      "          Fold 1 Epoch 1: loss=0.5725, acc=67.50% (best=67.50%)\n",
      "          Fold 4 Epoch 1: loss=0.6948, acc=52.89% (best=52.89%)\n",
      "          Fold 5 Epoch 1: loss=0.6350, acc=55.70% (best=55.70%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 83.28%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.80%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 73.28%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 70.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1a53b58f:\n",
      "        Fold accuracies: ['71.80%', '73.28%', '83.28%', '70.23%', '66.17%']\n",
      "        Average fitness: 72.95% Â± 5.68%\n",
      "        Best fold: Fold 3 with 83.28%\n",
      "      Fitness obtained: 72.95% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 9aa07ba3)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9aa07ba3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6915, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 1: loss=0.6959, acc=53.44% (best=53.44%)\n",
      "          Fold 3 Epoch 1: loss=0.6674, acc=76.33% (best=76.33%)\n",
      "          Fold 1 Epoch 1: loss=0.6323, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6835, acc=62.27% (best=62.27%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 68.59%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 83.59%\n",
      "          Fold 1 Epoch 30: loss=0.0202, acc=56.33% (best=59.22%)\n",
      "          Fold 2 Epoch 30: loss=0.1607, acc=68.59% (best=71.88%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 59.22%\n",
      "          Fold 4 Epoch 30: loss=0.1554, acc=75.47% (best=82.34%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 82.34%\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 71.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9aa07ba3:\n",
      "        Fold accuracies: ['59.22%', '71.88%', '83.59%', '82.34%', '68.59%']\n",
      "        Average fitness: 73.12% Â± 9.06%\n",
      "        Best fold: Fold 3 with 83.59%\n",
      "      Fitness obtained: 73.12% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: c0e915cc)\n",
      "      Architecture: 9 conv + 9 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model c0e915cc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6714, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6594, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.7043, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.6585, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6286, acc=50.39% (best=50.39%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 55.94%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 71.41%\n",
      "          Fold 5 Epoch 30: loss=0.1331, acc=54.84% (best=59.84%)\n",
      "          Fold 4 Epoch 30: loss=0.1655, acc=65.31% (best=65.31%)\n",
      "          Fold 5: Early stopping at epoch 36\n",
      "      â†’ Fold 5 completed: 59.84%\n",
      "          Fold 4: Early stopping at epoch 40\n",
      "      â†’ Fold 4 completed: 65.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c0e915cc:\n",
      "        Fold accuracies: ['50.39%', '71.41%', '55.94%', '65.31%', '59.84%']\n",
      "        Average fitness: 60.58% Â± 7.29%\n",
      "        Best fold: Fold 2 with 71.41%\n",
      "      Fitness obtained: 60.58% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: e46cc80d)\n",
      "      Architecture: 7 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model e46cc80d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.3470, acc=52.03% (best=52.03%)\n",
      "          Fold 2 Epoch 1: loss=0.3530, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.3157, acc=60.62% (best=60.62%)\n",
      "          Fold 1 Epoch 1: loss=0.1760, acc=67.73% (best=67.73%)\n",
      "          Fold 3 Epoch 1: loss=0.3364, acc=67.50% (best=67.50%)\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 61.33%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.02%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 67.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e46cc80d:\n",
      "        Fold accuracies: ['76.02%', '61.33%', '0.00%', '0.00%', '67.50%']\n",
      "        Average fitness: 40.97% Â± 33.77%\n",
      "        Best fold: Fold 1 with 76.02%\n",
      "      Fitness obtained: 40.97% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 64f96212)\n",
      "      Architecture: 9 conv + 9 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 64f96212 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 247, in step\n",
      "    adam(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 949, in adam\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 773, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 247, in step\n",
      "    adam(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 949, in adam\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 773, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 232, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 247, in step\n",
      "    adam(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 949, in adam\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 773, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 232, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 64f96212:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 884e12e9)\n",
      "      Architecture: 11 conv + 10 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 884e12e9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6983, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.7217, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 1: loss=0.7257, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6735, acc=50.39% (best=50.39%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 884e12e9:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '49.61%', '49.53%']\n",
      "        Average fitness: 49.69% Â± 0.53%\n",
      "        Best fold: Fold 1 with 50.39%\n",
      "      Fitness obtained: 49.69% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 8e639332)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8e639332 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.7140, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7185, acc=48.83% (best=48.83%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8e639332:\n",
      "        Fold accuracies: ['50.39%', '0.00%', '48.83%', '0.00%', '0.00%']\n",
      "        Average fitness: 19.84% Â± 24.31%\n",
      "        Best fold: Fold 1 with 50.39%\n",
      "      Fitness obtained: 19.84% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 929c1574)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 929c1574 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.5257, acc=57.34% (best=57.34%)\n",
      "          Fold 4 Epoch 1: loss=0.5641, acc=69.77% (best=69.77%)\n",
      "          Fold 3 Epoch 1: loss=0.5493, acc=87.27% (best=87.27%)\n",
      "          Fold 1 Epoch 1: loss=0.4055, acc=76.56% (best=76.56%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 75.08%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 929c1574:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '75.08%', '61.80%']\n",
      "        Average fitness: 27.38% Â± 33.79%\n",
      "        Best fold: Fold 4 with 75.08%\n",
      "      Fitness obtained: 27.38% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 318d1b22)\n",
      "      Architecture: 11 conv + 6 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 318d1b22 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6616, acc=61.17% (best=61.17%)\n",
      "          Fold 2 Epoch 1: loss=0.6417, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 1: loss=0.4405, acc=35.62% (best=35.62%)\n",
      "          Fold 4 Epoch 1: loss=0.6872, acc=59.53% (best=59.53%)\n",
      "          Fold 5 Epoch 1: loss=0.6414, acc=62.50% (best=62.50%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 75.47%\n",
      "          Fold 1 Epoch 30: loss=0.0128, acc=66.25% (best=79.53%)\n",
      "          Fold 4 Epoch 30: loss=0.0808, acc=70.08% (best=77.73%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 79.53%\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 77.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 318d1b22:\n",
      "        Fold accuracies: ['79.53%', '70.23%', '75.47%', '77.73%', '62.50%']\n",
      "        Average fitness: 73.09% Â± 6.15%\n",
      "        Best fold: Fold 1 with 79.53%\n",
      "      Fitness obtained: 73.09% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: d093c7ca)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d093c7ca with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6760, acc=70.08% (best=70.08%)\n",
      "          Fold 2 Epoch 1: loss=0.7262, acc=65.23% (best=65.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6850, acc=61.41% (best=61.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6704, acc=62.34% (best=62.34%)\n",
      "          Fold 1 Epoch 1: loss=0.6903, acc=70.08% (best=70.08%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 70.08%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 75.86%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 72.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d093c7ca:\n",
      "        Fold accuracies: ['71.48%', '72.66%', '70.08%', '75.86%', '65.94%']\n",
      "        Average fitness: 71.20% Â± 3.25%\n",
      "        Best fold: Fold 4 with 75.86%\n",
      "      Fitness obtained: 71.20% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 7ee2c418)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 7ee2c418 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4369, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.5354, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.4585, acc=64.53% (best=64.53%)\n",
      "          Fold 4 Epoch 1: loss=0.5590, acc=46.48% (best=46.48%)\n",
      "          Fold 5 Epoch 1: loss=0.4976, acc=58.52% (best=58.52%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 57.89%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 78.12%\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7ee2c418:\n",
      "        Fold accuracies: ['57.89%', '78.12%', '69.84%', '67.58%', '68.75%']\n",
      "        Average fitness: 68.44% Â± 6.45%\n",
      "        Best fold: Fold 2 with 78.12%\n",
      "      Fitness obtained: 68.44% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 79d7e06f)\n",
      "      Architecture: 5 conv + 9 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 79d7e06f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6960, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7078, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7139, acc=49.53% (best=49.53%)\n",
      "          Fold 4 Epoch 1: loss=0.7204, acc=48.05% (best=48.05%)\n",
      "          Fold 1 Epoch 1: loss=0.6928, acc=50.39% (best=50.39%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 79d7e06f:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '49.61%', '49.53%']\n",
      "        Average fitness: 49.69% Â± 0.53%\n",
      "        Best fold: Fold 1 with 50.39%\n",
      "      Fitness obtained: 49.69% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 333c8ac5)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 333c8ac5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 333c8ac5:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: f0d79aa7)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f0d79aa7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f0d79aa7:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4e04ea9d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4e04ea9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7096, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7002, acc=44.61% (best=44.61%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 66.33%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 80.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4e04ea9d:\n",
      "        Fold accuracies: ['66.33%', '0.00%', '80.16%', '0.00%', '0.00%']\n",
      "        Average fitness: 29.30% Â± 36.15%\n",
      "        Best fold: Fold 3 with 80.16%\n",
      "      Fitness obtained: 29.30% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 69188162)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 69188162 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6978, acc=48.05% (best=48.05%)\n",
      "          Fold 4 Epoch 1: loss=0.7006, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7073, acc=47.97% (best=47.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6979, acc=47.81% (best=47.81%)\n",
      "          Fold 2 Epoch 1: loss=0.7070, acc=50.08% (best=50.08%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 67.89%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 75.78%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 69.53%\n",
      "          Fold 4 Epoch 30: loss=0.2955, acc=55.39% (best=65.94%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 69188162:\n",
      "        Fold accuracies: ['69.53%', '67.89%', '75.78%', '65.94%', '64.69%']\n",
      "        Average fitness: 68.77% Â± 3.88%\n",
      "        Best fold: Fold 3 with 75.78%\n",
      "      Fitness obtained: 68.77% | Best in generation: 75.70% | Global best: 78.39%\n",
      "\n",
      "GENERATION 9 STATISTICS:\n",
      "   Maximum fitness: 75.70%\n",
      "   Average fitness: 49.83%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 26.84%\n",
      "   Best individual: 1e909e9b with 75.70%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=26.84)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1e909e9b (fitness: 75.70%)\n",
      "   Elite 2: dccab5ce (fitness: 74.06%)\n",
      "   Elite 3: 33bb127b (fitness: 73.75%)\n",
      "   Elite 4: 9aa07ba3 (fitness: 73.12%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 10\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 10)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6452, acc=53.20% (best=53.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6514, acc=67.11% (best=67.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6436, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.5685, acc=77.03% (best=77.03%)\n",
      "          Fold 3 Epoch 1: loss=0.6274, acc=82.81% (best=82.81%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 85.31%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 78.44%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 67.50%\n",
      "          Fold 4 Epoch 30: loss=0.1483, acc=64.77% (best=77.03%)\n",
      "          Fold 2 Epoch 30: loss=0.1558, acc=65.55% (best=69.06%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 69.06%\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 77.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['78.44%', '69.06%', '85.31%', '77.03%', '67.50%']\n",
      "        Average fitness: 75.47% Â± 6.52%\n",
      "        Best fold: Fold 3 with 85.31%\n",
      "      New best fitness in this generation: 75.47%!\n",
      "      Fitness obtained: 75.47% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: dccab5ce)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model dccab5ce with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5844, acc=56.09% (best=56.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6043, acc=53.20% (best=53.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6571, acc=61.48% (best=61.48%)\n",
      "          Fold 1 Epoch 1: loss=0.5740, acc=61.48% (best=61.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6485, acc=45.00% (best=45.00%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.14%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 73.12%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.42%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 72.97%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 78.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dccab5ce:\n",
      "        Fold accuracies: ['73.12%', '72.97%', '82.42%', '78.59%', '59.14%']\n",
      "        Average fitness: 73.25% Â± 7.90%\n",
      "        Best fold: Fold 3 with 82.42%\n",
      "      Fitness obtained: 73.25% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 33bb127b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 33bb127b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6115, acc=64.92% (best=64.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6360, acc=61.88% (best=61.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6225, acc=69.30% (best=69.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6362, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.5366, acc=68.28% (best=68.28%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 70.00%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 70.08%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 84.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 33bb127b:\n",
      "        Fold accuracies: ['77.19%', '70.08%', '84.14%', '67.97%', '70.00%']\n",
      "        Average fitness: 73.88% Â± 6.01%\n",
      "        Best fold: Fold 3 with 84.14%\n",
      "      Fitness obtained: 73.88% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 9aa07ba3)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9aa07ba3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6669, acc=64.53% (best=64.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6728, acc=65.86% (best=65.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7085, acc=75.39% (best=75.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6794, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.6287, acc=78.20% (best=78.20%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.39%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 82.58%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 71.25%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 85.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9aa07ba3:\n",
      "        Fold accuracies: ['82.58%', '71.25%', '85.16%', '60.39%', '66.48%']\n",
      "        Average fitness: 73.17% Â± 9.42%\n",
      "        Best fold: Fold 3 with 85.16%\n",
      "      Fitness obtained: 73.17% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 283240ad)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 283240ad with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5647, acc=72.89% (best=72.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5788, acc=66.41% (best=66.41%)\n",
      "          Fold 2 Epoch 1: loss=0.5914, acc=59.84% (best=59.84%)\n",
      "          Fold 1 Epoch 1: loss=0.4846, acc=65.47% (best=65.47%)\n",
      "          Fold 5 Epoch 1: loss=0.6006, acc=55.47% (best=55.47%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 72.89%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 74.61%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 71.80%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 283240ad:\n",
      "        Fold accuracies: ['71.80%', '73.28%', '74.61%', '72.89%', '65.47%']\n",
      "        Average fitness: 71.61% Â± 3.20%\n",
      "        Best fold: Fold 3 with 74.61%\n",
      "      Fitness obtained: 71.61% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 749843e0)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 749843e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6628, acc=82.03% (best=82.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6020, acc=68.52% (best=68.52%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 82.03%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 72.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 749843e0:\n",
      "        Fold accuracies: ['72.66%', '0.00%', '82.03%', '0.00%', '0.00%']\n",
      "        Average fitness: 30.94% Â± 38.01%\n",
      "        Best fold: Fold 3 with 82.03%\n",
      "      Fitness obtained: 30.94% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: dd47d257)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model dd47d257 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6934, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6745, acc=56.17% (best=56.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6799, acc=64.92% (best=64.92%)\n",
      "          Fold 1 Epoch 1: loss=0.6420, acc=73.36% (best=73.36%)\n",
      "          Fold 5 Epoch 1: loss=0.6839, acc=52.03% (best=52.03%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.36%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 50.47%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 76.64%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 82.27%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 67.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dd47d257:\n",
      "        Fold accuracies: ['73.36%', '82.27%', '76.64%', '50.47%', '67.97%']\n",
      "        Average fitness: 70.14% Â± 10.87%\n",
      "        Best fold: Fold 2 with 82.27%\n",
      "      Fitness obtained: 70.14% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: d10efd83)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model d10efd83 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=8.5417, acc=50.55% (best=50.55%)\n",
      "          Fold 1 Epoch 1: loss=10.3181, acc=48.36% (best=48.36%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 72.66%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 70.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d10efd83:\n",
      "        Fold accuracies: ['70.23%', '72.66%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 28.58% Â± 35.01%\n",
      "        Best fold: Fold 2 with 72.66%\n",
      "      Fitness obtained: 28.58% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: c21912c5)\n",
      "      Architecture: 11 conv + 10 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c21912c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6376, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.7244, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7063, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6953, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6623, acc=69.53% (best=69.53%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.00%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.25%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 74.45%\n",
      "          Fold 2 Epoch 30: loss=0.1330, acc=58.75% (best=75.23%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c21912c5:\n",
      "        Fold accuracies: ['71.25%', '75.23%', '74.45%', '65.00%', '62.27%']\n",
      "        Average fitness: 69.64% Â± 5.16%\n",
      "        Best fold: Fold 2 with 75.23%\n",
      "      Fitness obtained: 69.64% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 2169740e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 2169740e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.3311, acc=76.33% (best=76.33%)\n",
      "          Fold 2 Epoch 1: loss=0.4752, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.4434, acc=45.47% (best=45.47%)\n",
      "          Fold 3 Epoch 1: loss=0.4126, acc=84.38% (best=84.38%)\n",
      "          Fold 5 Epoch 1: loss=0.4395, acc=54.92% (best=54.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.33%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 84.38%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 72.50%\n",
      "          Fold 4 Epoch 30: loss=0.0728, acc=74.45% (best=74.45%)\n",
      "          Fold 4: Early stopping at epoch 40\n",
      "      â†’ Fold 4 completed: 74.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2169740e:\n",
      "        Fold accuracies: ['76.33%', '72.50%', '84.38%', '74.45%', '62.81%']\n",
      "        Average fitness: 74.09% Â± 6.94%\n",
      "        Best fold: Fold 3 with 84.38%\n",
      "      Fitness obtained: 74.09% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: cc0771db)\n",
      "      Architecture: 11 conv + 9 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model cc0771db with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7002, acc=49.53% (best=49.53%)          Fold 4 Epoch 1: loss=0.7126, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6557, acc=50.39% (best=50.39%)\n",
      "\n",
      "          Fold 2 Epoch 1: loss=0.7044, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7075, acc=48.83% (best=48.83%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cc0771db:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '49.61%', '49.53%']\n",
      "        Average fitness: 49.69% Â± 0.53%\n",
      "        Best fold: Fold 1 with 50.39%\n",
      "      Fitness obtained: 49.69% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 5d833bf2)\n",
      "      Architecture: 9 conv + 6 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 5d833bf2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6766, acc=50.86% (best=50.86%)\n",
      "          Fold 1 Epoch 1: loss=0.5588, acc=71.25% (best=71.25%)\n",
      "          Fold 5 Epoch 1: loss=0.6550, acc=68.12% (best=68.12%)\n",
      "          Fold 2 Epoch 1: loss=0.6954, acc=65.00% (best=65.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6569, acc=60.78% (best=60.78%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 68.12%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 72.03%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 73.20%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 72.89%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 76.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5d833bf2:\n",
      "        Fold accuracies: ['72.03%', '73.20%', '72.89%', '76.02%', '68.12%']\n",
      "        Average fitness: 72.45% Â± 2.54%\n",
      "        Best fold: Fold 4 with 76.02%\n",
      "      Fitness obtained: 72.45% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 277af83f)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 277af83f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6826, acc=74.30% (best=74.30%)\n",
      "          Fold 4 Epoch 1: loss=0.7175, acc=57.89% (best=57.89%)\n",
      "          Fold 2 Epoch 1: loss=0.6991, acc=58.05% (best=58.05%)\n",
      "          Fold 5 Epoch 1: loss=0.6779, acc=61.02% (best=61.02%)\n",
      "          Fold 1 Epoch 1: loss=0.6641, acc=77.97% (best=77.97%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 87.50%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 68.05%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 75.31%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 73.67%\n",
      "          Fold 2 Epoch 30: loss=0.1619, acc=64.53% (best=71.88%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 71.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 277af83f:\n",
      "        Fold accuracies: ['87.50%', '71.88%', '75.31%', '73.67%', '68.05%']\n",
      "        Average fitness: 75.28% Â± 6.57%\n",
      "        Best fold: Fold 1 with 87.50%\n",
      "      Fitness obtained: 75.28% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 8a003f19)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 8a003f19 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6813, acc=53.05% (best=53.05%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 64.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8a003f19:\n",
      "        Fold accuracies: ['0.00%', '64.61%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 12.92% Â± 25.84%\n",
      "        Best fold: Fold 2 with 64.61%\n",
      "      Fitness obtained: 12.92% | Best in generation: 75.47% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: b65993e8)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b65993e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5899, acc=77.03% (best=77.03%)\n",
      "          Fold 2 Epoch 1: loss=0.6483, acc=57.81% (best=57.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6612, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.6706, acc=66.64% (best=66.64%)\n",
      "          Fold 3 Epoch 1: loss=0.6439, acc=74.61% (best=74.61%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.03%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.25%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 69.45%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 72.34%\n",
      "          Fold 2 Epoch 30: loss=0.1466, acc=74.92% (best=79.69%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 79.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b65993e8:\n",
      "        Fold accuracies: ['77.03%', '79.69%', '81.25%', '72.34%', '69.45%']\n",
      "        Average fitness: 75.95% Â± 4.44%\n",
      "        Best fold: Fold 3 with 81.25%\n",
      "      New best fitness in this generation: 75.95%!\n",
      "      Fitness obtained: 75.95% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 86fd7566)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 86fd7566 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6905, acc=77.97% (best=77.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6858, acc=54.30% (best=54.30%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 79.38%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 82.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 86fd7566:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '79.38%', '82.97%', '0.00%']\n",
      "        Average fitness: 32.47% Â± 39.78%\n",
      "        Best fold: Fold 4 with 82.97%\n",
      "      Fitness obtained: 32.47% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 17b579be)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 17b579be with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7157, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 1: loss=0.7016, acc=46.41% (best=46.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6902, acc=46.88% (best=46.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7088, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6859, acc=63.28% (best=63.28%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 46.41%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 72.89%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 60.70%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 80.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17b579be:\n",
      "        Fold accuracies: ['60.70%', '46.41%', '80.94%', '72.89%', '61.25%']\n",
      "        Average fitness: 64.44% Â± 11.77%\n",
      "        Best fold: Fold 3 with 80.94%\n",
      "      Fitness obtained: 64.44% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: e93eda82)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model e93eda82 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.4016, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.3578, acc=54.38% (best=54.38%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 62.27%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 66.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e93eda82:\n",
      "        Fold accuracies: ['0.00%', '62.27%', '0.00%', '66.95%', '0.00%']\n",
      "        Average fitness: 25.84% Â± 31.69%\n",
      "        Best fold: Fold 4 with 66.95%\n",
      "      Fitness obtained: 25.84% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: cfc603d1)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model cfc603d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6287, acc=57.34% (best=57.34%)\n",
      "          Fold 3 Epoch 1: loss=0.6489, acc=78.28% (best=78.28%)\n",
      "          Fold 2 Epoch 1: loss=0.6142, acc=60.00% (best=60.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6495, acc=63.91% (best=63.91%)\n",
      "          Fold 1 Epoch 1: loss=0.5867, acc=75.23% (best=75.23%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.23%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 74.38%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 81.88%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 69.92%\n",
      "          Fold 2 Epoch 30: loss=0.1372, acc=62.27% (best=67.81%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cfc603d1:\n",
      "        Fold accuracies: ['75.23%', '67.81%', '81.88%', '74.38%', '69.92%']\n",
      "        Average fitness: 73.84% Â± 4.87%\n",
      "        Best fold: Fold 3 with 81.88%\n",
      "      Fitness obtained: 73.84% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 130e6a5e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 130e6a5e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6272, acc=52.89% (best=52.89%)\n",
      "          Fold 1 Epoch 1: loss=0.5845, acc=69.22% (best=69.22%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 70.86%\n",
      "          Fold 2 Epoch 30: loss=0.1511, acc=69.53% (best=74.77%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 130e6a5e:\n",
      "        Fold accuracies: ['70.86%', '74.77%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 29.12% Â± 35.69%\n",
      "        Best fold: Fold 2 with 74.77%\n",
      "      Fitness obtained: 29.12% | Best in generation: 75.95% | Global best: 78.39%\n",
      "\n",
      "GENERATION 10 STATISTICS:\n",
      "   Maximum fitness: 75.95%\n",
      "   Average fitness: 57.64%\n",
      "   Minimum fitness: 12.92%\n",
      "   Standard deviation: 21.31%\n",
      "   Best individual: b65993e8 with 75.95%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=21.31)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: b65993e8 (fitness: 75.95%)\n",
      "   Elite 2: 1e909e9b (fitness: 75.47%)\n",
      "   Elite 3: 277af83f (fitness: 75.28%)\n",
      "   Elite 4: 2169740e (fitness: 74.09%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 11\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 11)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: b65993e8)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b65993e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6767, acc=61.33% (best=61.33%)\n",
      "          Fold 5 Epoch 1: loss=0.6851, acc=67.03% (best=67.03%)\n",
      "          Fold 2 Epoch 1: loss=0.6650, acc=64.30% (best=64.30%)\n",
      "          Fold 3 Epoch 1: loss=0.6519, acc=73.44% (best=73.44%)\n",
      "          Fold 1 Epoch 1: loss=0.6077, acc=75.00% (best=75.00%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 76.80%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 79.92%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.48%\n",
      "          Fold 2 Epoch 30: loss=0.1615, acc=71.56% (best=75.47%)\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 75.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b65993e8:\n",
      "        Fold accuracies: ['76.48%', '75.47%', '76.80%', '79.92%', '67.03%']\n",
      "        Average fitness: 75.14% Â± 4.32%\n",
      "        Best fold: Fold 4 with 79.92%\n",
      "      New best fitness in this generation: 75.14%!\n",
      "      Fitness obtained: 75.14% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6437, acc=79.38% (best=79.38%)\n",
      "          Fold 5 Epoch 1: loss=0.6528, acc=57.50% (best=57.50%)\n",
      "          Fold 4 Epoch 1: loss=0.6509, acc=58.05% (best=58.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6373, acc=53.98% (best=53.98%)\n",
      "          Fold 1 Epoch 1: loss=0.5750, acc=73.59% (best=73.59%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.59%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 91.64%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.19%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 63.75%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['73.59%', '63.75%', '91.64%', '77.42%', '67.19%']\n",
      "        Average fitness: 74.72% Â± 9.72%\n",
      "        Best fold: Fold 3 with 91.64%\n",
      "      Fitness obtained: 74.72% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 277af83f)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 277af83f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6936, acc=68.52% (best=68.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6361, acc=75.16% (best=75.16%)\n",
      "          Fold 3 Epoch 1: loss=0.6831, acc=78.52% (best=78.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6746, acc=63.98% (best=63.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7295, acc=63.36% (best=63.36%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.16%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.36%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 87.89%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 78.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 277af83f:\n",
      "        Fold accuracies: ['75.16%', '68.75%', '87.89%', '78.28%', '63.36%']\n",
      "        Average fitness: 74.69% Â± 8.38%\n",
      "        Best fold: Fold 3 with 87.89%\n",
      "      Fitness obtained: 74.69% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 2169740e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 2169740e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.4354, acc=57.19% (best=57.19%)\n",
      "          Fold 4 Epoch 1: loss=0.4584, acc=45.23% (best=45.23%)\n",
      "          Fold 2 Epoch 1: loss=0.4424, acc=30.94% (best=30.94%)\n",
      "          Fold 1 Epoch 1: loss=0.3140, acc=59.61% (best=59.61%)\n",
      "          Fold 5 Epoch 1: loss=0.4977, acc=52.11% (best=52.11%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 70.94%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 65.31%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 86.56%\n",
      "          Fold 4 Epoch 30: loss=0.0719, acc=73.28% (best=73.28%)\n",
      "          Fold 1 Epoch 30: loss=0.0021, acc=73.52% (best=78.75%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 78.75%\n",
      "          Fold 4: Early stopping at epoch 40\n",
      "      â†’ Fold 4 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2169740e:\n",
      "        Fold accuracies: ['78.75%', '65.31%', '86.56%', '73.28%', '70.94%']\n",
      "        Average fitness: 74.97% Â± 7.23%\n",
      "        Best fold: Fold 3 with 86.56%\n",
      "      Fitness obtained: 74.97% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: b2fb6677)\n",
      "      Architecture: 9 conv + 6 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model b2fb6677 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6401, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6800, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.4810, acc=58.75% (best=58.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6502, acc=46.33% (best=46.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6596, acc=50.55% (best=50.55%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 71.25%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 64.38%\n",
      "          Fold 4 Epoch 30: loss=0.0944, acc=67.50% (best=74.30%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 74.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b2fb6677:\n",
      "        Fold accuracies: ['64.38%', '70.16%', '71.25%', '74.30%', '62.66%']\n",
      "        Average fitness: 68.55% Â± 4.36%\n",
      "        Best fold: Fold 4 with 74.30%\n",
      "      Fitness obtained: 68.55% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 806b623f)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 806b623f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6066, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.5551, acc=53.36% (best=53.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6608, acc=50.62% (best=50.62%)\n",
      "          Fold 5 Epoch 1: loss=0.5552, acc=48.91% (best=48.91%)\n",
      "          Fold 1 Epoch 1: loss=0.4537, acc=71.64% (best=71.64%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.88%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 71.41%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 75.94%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 806b623f:\n",
      "        Fold accuracies: ['71.88%', '65.39%', '75.94%', '71.41%', '62.19%']\n",
      "        Average fitness: 69.36% Â± 4.92%\n",
      "        Best fold: Fold 3 with 75.94%\n",
      "      Fitness obtained: 69.36% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 47bc3df7)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 47bc3df7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6928, acc=44.92% (best=44.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6686, acc=47.81% (best=47.81%)\n",
      "          Fold 5 Epoch 1: loss=0.6859, acc=54.77% (best=54.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6895, acc=64.84% (best=64.84%)\n",
      "          Fold 1 Epoch 1: loss=0.6635, acc=47.27% (best=47.27%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 64.84%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 54.30%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 49.69%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 63.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 47bc3df7:\n",
      "        Fold accuracies: ['65.00%', '64.84%', '54.30%', '49.69%', '63.28%']\n",
      "        Average fitness: 59.42% Â± 6.27%\n",
      "        Best fold: Fold 1 with 65.00%\n",
      "      Fitness obtained: 59.42% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 732d6650)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 732d6650 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=43.67% (best=43.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7800, acc=47.58% (best=47.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6916, acc=68.75% (best=68.75%)\n",
      "          Fold 1 Epoch 1: loss=0.7014, acc=64.14% (best=64.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6919, acc=50.55% (best=50.55%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.20%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 58.52%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 70.47%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 78.28%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 76.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 732d6650:\n",
      "        Fold accuracies: ['76.33%', '78.28%', '70.47%', '58.52%', '58.20%']\n",
      "        Average fitness: 68.36% Â± 8.56%\n",
      "        Best fold: Fold 2 with 78.28%\n",
      "      Fitness obtained: 68.36% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: e5b3572a)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e5b3572a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6161, acc=63.52% (best=63.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6282, acc=55.16% (best=55.16%)\n",
      "          Fold 3 Epoch 1: loss=0.6222, acc=53.59% (best=53.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6316, acc=50.70% (best=50.70%)\n",
      "          Fold 1 Epoch 1: loss=0.5504, acc=69.30% (best=69.30%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 76.48%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 67.81%\n",
      "          Fold 5 Epoch 30: loss=0.1548, acc=49.38% (best=60.86%)\n",
      "          Fold 2 Epoch 30: loss=0.1682, acc=73.98% (best=76.64%)\n",
      "          Fold 3 Epoch 30: loss=0.1938, acc=57.03% (best=58.91%)\n",
      "          Fold 5: Early stopping at epoch 35\n",
      "      â†’ Fold 5 completed: 60.86%\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 76.64%\n",
      "          Fold 3: Early stopping at epoch 50\n",
      "      â†’ Fold 3 completed: 76.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e5b3572a:\n",
      "        Fold accuracies: ['76.48%', '76.64%', '76.64%', '67.81%', '60.86%']\n",
      "        Average fitness: 71.69% Â± 6.39%\n",
      "        Best fold: Fold 2 with 76.64%\n",
      "      Fitness obtained: 71.69% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: bbf737fc)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model bbf737fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.7086, acc=57.42% (best=57.42%)\n",
      "          Fold 3 Epoch 1: loss=0.7040, acc=74.84% (best=74.84%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.92%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 76.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bbf737fc:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '76.48%', '0.00%', '69.92%']\n",
      "        Average fitness: 29.28% Â± 35.92%\n",
      "        Best fold: Fold 3 with 76.48%\n",
      "      Fitness obtained: 29.28% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 83e7c020)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 83e7c020 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5938, acc=77.03% (best=77.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6006, acc=73.52% (best=73.52%)\n",
      "          Fold 2 Epoch 1: loss=0.5972, acc=52.97% (best=52.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6032, acc=58.91% (best=58.91%)\n",
      "          Fold 1 Epoch 1: loss=0.4974, acc=74.38% (best=74.38%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 73.52%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 80.39%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 78.44%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 2 Epoch 30: loss=0.1410, acc=61.02% (best=65.70%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 83e7c020:\n",
      "        Fold accuracies: ['80.39%', '65.70%', '78.44%', '72.42%', '73.52%']\n",
      "        Average fitness: 74.09% Â± 5.14%\n",
      "        Best fold: Fold 1 with 80.39%\n",
      "      Fitness obtained: 74.09% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 3c0a4f9c)\n",
      "      Architecture: 9 conv + 6 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 3c0a4f9c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7128, acc=56.09% (best=56.09%)\n",
      "          Fold 3 Epoch 1: loss=0.8063, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7167, acc=62.58% (best=62.58%)\n",
      "          Fold 2 Epoch 1: loss=0.7114, acc=63.83% (best=63.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6898, acc=65.31% (best=65.31%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.97%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.59%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 65.23%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 87.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3c0a4f9c:\n",
      "        Fold accuracies: ['65.31%', '65.23%', '87.58%', '68.59%', '62.97%']\n",
      "        Average fitness: 69.94% Â± 9.00%\n",
      "        Best fold: Fold 3 with 87.58%\n",
      "      Fitness obtained: 69.94% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 61497e6b)\n",
      "      Architecture: 3 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 61497e6b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 167, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 123, in _init_group\n",
      "    state[\"square_avg\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 177, in step\n",
      "    rmsprop(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 522, in rmsprop\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 445, in _multi_tensor_rmsprop\n",
      "    avg = torch._foreach_sqrt(grouped_square_avgs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 167, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 123, in _init_group\n",
      "    state[\"square_avg\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 177, in step\n",
      "    rmsprop(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 522, in rmsprop\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 445, in _multi_tensor_rmsprop\n",
      "    avg = torch._foreach_sqrt(grouped_square_avgs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 167, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 123, in _init_group\n",
      "    state[\"square_avg\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 61497e6b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: f1b68e60)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model f1b68e60 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6792, acc=68.75% (best=68.75%)\n",
      "          Fold 2 Epoch 1: loss=0.6337, acc=53.36% (best=53.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6623, acc=46.33% (best=46.33%)\n",
      "          Fold 5 Epoch 1: loss=0.6801, acc=44.38% (best=44.38%)\n",
      "          Fold 1 Epoch 1: loss=0.5564, acc=65.16% (best=65.16%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 87.27%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 81.33%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 71.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f1b68e60:\n",
      "        Fold accuracies: ['81.33%', '68.52%', '87.27%', '71.09%', '59.92%']\n",
      "        Average fitness: 73.62% Â± 9.65%\n",
      "        Best fold: Fold 3 with 87.27%\n",
      "      Fitness obtained: 73.62% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 0f73a0b2)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0f73a0b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6262, acc=61.17% (best=61.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6326, acc=58.05% (best=58.05%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 76.80%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 62.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0f73a0b2:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '76.80%', '0.00%', '62.11%']\n",
      "        Average fitness: 27.78% Â± 34.34%\n",
      "        Best fold: Fold 3 with 76.80%\n",
      "      Fitness obtained: 27.78% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: b07d1794)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model b07d1794 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.3643, acc=70.39% (best=70.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6005, acc=62.19% (best=62.19%)\n",
      "          Fold 3 Epoch 1: loss=0.4844, acc=71.41% (best=71.41%)\n",
      "          Fold 5 Epoch 1: loss=0.4820, acc=54.14% (best=54.14%)\n",
      "          Fold 4 Epoch 1: loss=0.5597, acc=67.27% (best=67.27%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 71.41%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.19%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 66.88%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 65.31%\n",
      "          Fold 4 Epoch 30: loss=0.0736, acc=68.75% (best=77.19%)\n",
      "          Fold 4: Early stopping at epoch 44\n",
      "      â†’ Fold 4 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b07d1794:\n",
      "        Fold accuracies: ['82.19%', '66.88%', '71.41%', '77.42%', '65.31%']\n",
      "        Average fitness: 72.64% Â± 6.36%\n",
      "        Best fold: Fold 1 with 82.19%\n",
      "      Fitness obtained: 72.64% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: fb6931c1)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model fb6931c1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.5494, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 1: loss=0.6065, acc=53.36% (best=53.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6322, acc=66.72% (best=66.72%)\n",
      "          Fold 1 Epoch 1: loss=0.5084, acc=52.34% (best=52.34%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 68.12%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 72.19%\n",
      "          Fold 1 Epoch 30: loss=0.0408, acc=49.61% (best=79.69%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 79.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fb6931c1:\n",
      "        Fold accuracies: ['79.69%', '0.00%', '72.19%', '68.12%', '57.89%']\n",
      "        Average fitness: 55.58% Â± 28.67%\n",
      "        Best fold: Fold 1 with 79.69%\n",
      "      Fitness obtained: 55.58% | Best in generation: 75.14% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 10f194d4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10f194d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6746, acc=74.77% (best=74.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6904, acc=58.91% (best=58.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6718, acc=66.95% (best=66.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7001, acc=56.88% (best=56.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6428, acc=71.09% (best=71.09%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.95%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.30%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.95%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 73.67%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 79.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10f194d4:\n",
      "        Fold accuracies: ['79.30%', '66.95%', '86.95%', '73.67%', '69.30%']\n",
      "        Average fitness: 75.23% Â± 7.21%\n",
      "        Best fold: Fold 3 with 86.95%\n",
      "      New best fitness in this generation: 75.23%!\n",
      "      Fitness obtained: 75.23% | Best in generation: 75.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 1af889d3)\n",
      "      Architecture: 1 conv + 2 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 1af889d3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.2978, acc=65.94% (best=65.94%)\n",
      "          Fold 3 Epoch 1: loss=0.2714, acc=79.14% (best=79.14%)\n",
      "          Fold 4 Epoch 1: loss=0.3106, acc=57.19% (best=57.19%)\n",
      "          Fold 1 Epoch 1: loss=0.1715, acc=60.39% (best=60.39%)\n",
      "          Fold 5 Epoch 1: loss=0.2547, acc=49.84% (best=49.84%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.94%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.14%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 58.44%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 55.47%\n",
      "          Fold 1 Epoch 30: loss=0.0001, acc=67.73% (best=69.30%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 69.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1af889d3:\n",
      "        Fold accuracies: ['69.30%', '65.94%', '79.14%', '58.44%', '55.47%']\n",
      "        Average fitness: 65.66% Â± 8.38%\n",
      "        Best fold: Fold 3 with 79.14%\n",
      "      Fitness obtained: 65.66% | Best in generation: 75.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 349f4124)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 349f4124 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6374, acc=76.17% (best=76.17%)\n",
      "          Fold 2 Epoch 1: loss=0.6226, acc=70.78% (best=70.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6106, acc=60.78% (best=60.78%)\n",
      "          Fold 5 Epoch 1: loss=0.5915, acc=60.78% (best=60.78%)\n",
      "          Fold 1 Epoch 1: loss=0.5147, acc=65.94% (best=65.94%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 76.17%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.78%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 78.12%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 74.38%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 63.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 349f4124:\n",
      "        Fold accuracies: ['74.38%', '70.78%', '76.17%', '78.12%', '63.67%']\n",
      "        Average fitness: 72.62% Â± 5.09%\n",
      "        Best fold: Fold 4 with 78.12%\n",
      "      Fitness obtained: 72.62% | Best in generation: 75.23% | Global best: 78.39%\n",
      "\n",
      "GENERATION 11 STATISTICS:\n",
      "   Maximum fitness: 75.23%\n",
      "   Average fitness: 62.67%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 19.72%\n",
      "   Best individual: 10f194d4 with 75.23%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 6/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=19.72)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 10f194d4 (fitness: 75.23%)\n",
      "   Elite 2: b65993e8 (fitness: 75.14%)\n",
      "   Elite 3: 2169740e (fitness: 74.97%)\n",
      "   Elite 4: 1e909e9b (fitness: 74.72%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 7/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 12\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 12)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 10f194d4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10f194d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6516, acc=78.44% (best=78.44%)\n",
      "          Fold 4 Epoch 1: loss=0.7259, acc=66.33% (best=66.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6733, acc=76.56% (best=76.56%)\n",
      "          Fold 5 Epoch 1: loss=0.6810, acc=63.20% (best=63.20%)\n",
      "          Fold 2 Epoch 1: loss=0.6648, acc=60.08% (best=60.08%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.44%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 66.41%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.72%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 76.80%\n",
      "          Fold 2 Epoch 30: loss=0.1641, acc=72.03% (best=72.73%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 72.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10f194d4:\n",
      "        Fold accuracies: ['78.44%', '72.73%', '86.72%', '76.80%', '66.41%']\n",
      "        Average fitness: 76.22% Â± 6.69%\n",
      "        Best fold: Fold 3 with 86.72%\n",
      "      New best fitness in this generation: 76.22%!\n",
      "      Fitness obtained: 76.22% | Best in generation: 76.22% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b65993e8)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b65993e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6639, acc=65.78% (best=65.78%)\n",
      "          Fold 3 Epoch 1: loss=0.6398, acc=75.23% (best=75.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6691, acc=74.84% (best=74.84%)\n",
      "          Fold 1 Epoch 1: loss=0.5909, acc=75.00% (best=75.00%)\n",
      "          Fold 5 Epoch 1: loss=0.6698, acc=46.25% (best=46.25%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.00%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 53.28%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 82.42%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 79.53%\n",
      "          Fold 2 Epoch 30: loss=0.1586, acc=69.22% (best=71.33%)\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 71.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b65993e8:\n",
      "        Fold accuracies: ['75.00%', '71.33%', '79.53%', '82.42%', '53.28%']\n",
      "        Average fitness: 72.31% Â± 10.24%\n",
      "        Best fold: Fold 4 with 82.42%\n",
      "      Fitness obtained: 72.31% | Best in generation: 76.22% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 2169740e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 2169740e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.4576, acc=48.20% (best=48.20%)\n",
      "          Fold 5 Epoch 1: loss=0.4037, acc=63.05% (best=63.05%)\n",
      "          Fold 3 Epoch 1: loss=0.4461, acc=74.30% (best=74.30%)\n",
      "          Fold 1 Epoch 1: loss=0.2977, acc=70.62% (best=70.62%)\n",
      "          Fold 2 Epoch 1: loss=0.4571, acc=41.72% (best=41.72%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.62%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 76.02%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2169740e:\n",
      "        Fold accuracies: ['70.62%', '70.39%', '76.02%', '67.19%', '66.56%']\n",
      "        Average fitness: 70.16% Â± 3.36%\n",
      "        Best fold: Fold 3 with 76.02%\n",
      "      Fitness obtained: 70.16% | Best in generation: 76.22% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6485, acc=74.30% (best=74.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6576, acc=69.38% (best=69.38%)\n",
      "          Fold 2 Epoch 1: loss=0.6470, acc=56.80% (best=56.80%)\n",
      "          Fold 1 Epoch 1: loss=0.5556, acc=73.44% (best=73.44%)\n",
      "          Fold 3 Epoch 1: loss=0.6252, acc=85.62% (best=85.62%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 74.30%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 85.62%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 76.95%\n",
      "          Fold 2 Epoch 30: loss=0.1553, acc=74.30% (best=76.80%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 76.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['77.11%', '76.80%', '85.62%', '76.95%', '74.30%']\n",
      "        Average fitness: 78.16% Â± 3.87%\n",
      "        Best fold: Fold 3 with 85.62%\n",
      "      New best fitness in this generation: 78.16%!\n",
      "      Fitness obtained: 78.16% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 006f9b50)\n",
      "      Architecture: 9 conv + 9 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 006f9b50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7334, acc=51.72% (best=51.72%)\n",
      "          Fold 3 Epoch 1: loss=0.7266, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7174, acc=53.52% (best=53.52%)\n",
      "          Fold 2 Epoch 1: loss=0.7541, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7173, acc=50.39% (best=50.39%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 53.52%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 61.02%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 66.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 006f9b50:\n",
      "        Fold accuracies: ['66.41%', '50.08%', '48.83%', '61.02%', '53.52%']\n",
      "        Average fitness: 55.97% Â± 6.72%\n",
      "        Best fold: Fold 1 with 66.41%\n",
      "      Fitness obtained: 55.97% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 64dcff76)\n",
      "      Architecture: 11 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 64dcff76 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7115, acc=64.22% (best=64.22%)\n",
      "          Fold 4 Epoch 1: loss=0.7381, acc=44.53% (best=44.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7441, acc=59.30% (best=59.30%)\n",
      "          Fold 2 Epoch 1: loss=0.7239, acc=38.91% (best=38.91%)\n",
      "          Fold 1 Epoch 1: loss=0.7125, acc=61.88% (best=61.88%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.30%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 66.88%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 65.94%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 51.02%\n",
      "          Fold 4 Epoch 30: loss=0.6706, acc=56.95% (best=58.59%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 58.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 64dcff76:\n",
      "        Fold accuracies: ['65.94%', '51.02%', '66.88%', '58.59%', '59.30%']\n",
      "        Average fitness: 60.34% Â± 5.75%\n",
      "        Best fold: Fold 3 with 66.88%\n",
      "      Fitness obtained: 60.34% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 9a21518d)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 9a21518d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6642, acc=63.83% (best=63.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6664, acc=65.00% (best=65.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6595, acc=71.56% (best=71.56%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.56%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 68.75%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 74.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9a21518d:\n",
      "        Fold accuracies: ['0.00%', '71.56%', '68.75%', '74.69%', '0.00%']\n",
      "        Average fitness: 43.00% Â± 35.16%\n",
      "        Best fold: Fold 4 with 74.69%\n",
      "      Fitness obtained: 43.00% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: bfcc4e14)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model bfcc4e14 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6123, acc=64.53% (best=64.53%)\n",
      "          Fold 5 Epoch 1: loss=0.6270, acc=60.00% (best=60.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6437, acc=48.52% (best=48.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6287, acc=67.42% (best=67.42%)\n",
      "          Fold 1 Epoch 1: loss=0.5415, acc=72.81% (best=72.81%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.81%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 67.03%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 67.03%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bfcc4e14:\n",
      "        Fold accuracies: ['72.81%', '71.88%', '67.03%', '67.03%', '63.05%']\n",
      "        Average fitness: 68.36% Â± 3.58%\n",
      "        Best fold: Fold 1 with 72.81%\n",
      "      Fitness obtained: 68.36% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: d091e2b2)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d091e2b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6498, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6682, acc=68.83% (best=68.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6415, acc=80.31% (best=80.31%)\n",
      "          Fold 5 Epoch 1: loss=0.6413, acc=58.36% (best=58.36%)\n",
      "          Fold 1 Epoch 1: loss=0.5767, acc=84.61% (best=84.61%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 61.48%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 84.61%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.31%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 67.34%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d091e2b2:\n",
      "        Fold accuracies: ['84.61%', '61.48%', '80.31%', '69.38%', '67.34%']\n",
      "        Average fitness: 72.62% Â± 8.55%\n",
      "        Best fold: Fold 1 with 84.61%\n",
      "      Fitness obtained: 72.62% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 19335c57)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 19335c57 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5989, acc=67.89% (best=67.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5811, acc=85.55% (best=85.55%)\n",
      "          Fold 2 Epoch 1: loss=0.5938, acc=44.14% (best=44.14%)\n",
      "          Fold 5 Epoch 1: loss=0.5899, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.5096, acc=70.55% (best=70.55%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 91.88%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 73.52%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 68.05%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.25%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 74.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19335c57:\n",
      "        Fold accuracies: ['76.25%', '74.92%', '91.88%', '73.52%', '68.05%']\n",
      "        Average fitness: 76.92% Â± 7.98%\n",
      "        Best fold: Fold 3 with 91.88%\n",
      "      Fitness obtained: 76.92% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: c31b5a21)\n",
      "      Architecture: 1 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model c31b5a21 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.2588, acc=67.97% (best=67.97%)\n",
      "          Fold 2 Epoch 1: loss=0.2633, acc=48.12% (best=48.12%)\n",
      "          Fold 5 Epoch 1: loss=0.2298, acc=58.98% (best=58.98%)\n",
      "          Fold 1 Epoch 1: loss=0.1090, acc=64.92% (best=64.92%)\n",
      "          Fold 4 Epoch 1: loss=0.2527, acc=53.67% (best=53.67%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 82.19%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 73.44%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 60.00%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c31b5a21:\n",
      "        Fold accuracies: ['73.44%', '68.83%', '82.19%', '60.00%', '58.98%']\n",
      "        Average fitness: 68.69% Â± 8.65%\n",
      "        Best fold: Fold 3 with 82.19%\n",
      "      Fitness obtained: 68.69% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 986761ba)\n",
      "      Architecture: 9 conv + 5 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 986761ba with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5585, acc=70.00% (best=70.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6338, acc=66.41% (best=66.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6498, acc=56.25% (best=56.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6588, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6495, acc=53.44% (best=53.44%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.00%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 79.45%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 66.88%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 67.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 986761ba:\n",
      "        Fold accuracies: ['70.00%', '66.88%', '79.45%', '67.73%', '67.03%']\n",
      "        Average fitness: 70.22% Â± 4.75%\n",
      "        Best fold: Fold 3 with 79.45%\n",
      "      Fitness obtained: 70.22% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: b352660a)\n",
      "      Architecture: 11 conv + 10 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model b352660a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6448, acc=46.33% (best=46.33%)\n",
      "          Fold 2 Epoch 1: loss=0.6614, acc=51.25% (best=51.25%)\n",
      "          Fold 5 Epoch 1: loss=0.6605, acc=59.92% (best=59.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6752, acc=66.41% (best=66.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6117, acc=61.56% (best=61.56%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 69.14%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.34%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.19%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 73.67%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 79.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b352660a:\n",
      "        Fold accuracies: ['73.67%', '69.14%', '79.30%', '67.34%', '67.19%']\n",
      "        Average fitness: 71.33% Â± 4.62%\n",
      "        Best fold: Fold 3 with 79.30%\n",
      "      Fitness obtained: 71.33% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: c44aa8e8)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model c44aa8e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6049, acc=39.45% (best=39.45%)\n",
      "          Fold 1 Epoch 1: loss=0.4875, acc=60.08% (best=60.08%)\n",
      "          Fold 5 Epoch 1: loss=0.5548, acc=43.75% (best=43.75%)\n",
      "          Fold 2 Epoch 1: loss=0.5891, acc=73.05% (best=73.05%)\n",
      "          Fold 3 Epoch 1: loss=0.6033, acc=75.47% (best=75.47%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.05%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 76.25%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 79.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c44aa8e8:\n",
      "        Fold accuracies: ['67.11%', '73.05%', '76.25%', '79.45%', '67.42%']\n",
      "        Average fitness: 72.66% Â± 4.85%\n",
      "        Best fold: Fold 4 with 79.45%\n",
      "      Fitness obtained: 72.66% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 52be3eb4)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 52be3eb4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5924, acc=51.25% (best=51.25%)\n",
      "          Fold 1 Epoch 1: loss=0.4710, acc=51.33% (best=51.33%)\n",
      "          Fold 5 Epoch 1: loss=0.5480, acc=40.55% (best=40.55%)\n",
      "          Fold 3 Epoch 1: loss=0.5654, acc=68.12% (best=68.12%)\n",
      "          Fold 2 Epoch 1: loss=0.5594, acc=68.59% (best=68.59%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 70.08%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 80.62%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 73.98%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 74.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 52be3eb4:\n",
      "        Fold accuracies: ['74.61%', '73.98%', '70.08%', '80.62%', '63.75%']\n",
      "        Average fitness: 72.61% Â± 5.57%\n",
      "        Best fold: Fold 4 with 80.62%\n",
      "      Fitness obtained: 72.61% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 3533f2b5)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 3533f2b5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7051, acc=51.72% (best=51.72%)          Fold 5 Epoch 1: loss=0.7053, acc=58.67% (best=58.67%)\n",
      "\n",
      "          Fold 3 Epoch 1: loss=0.7094, acc=63.05% (best=63.05%)\n",
      "          Fold 1 Epoch 1: loss=0.6471, acc=68.36% (best=68.36%)\n",
      "          Fold 2 Epoch 1: loss=0.7028, acc=49.92% (best=49.92%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 69.06%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.62%\n",
      "          Fold 2 Epoch 30: loss=0.2598, acc=63.98% (best=69.45%)\n",
      "          Fold 3 Epoch 30: loss=0.2470, acc=75.23% (best=78.83%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 69.45%\n",
      "          Fold 3: Early stopping at epoch 37\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3533f2b5:\n",
      "        Fold accuracies: ['69.06%', '69.45%', '78.83%', '60.62%', '67.27%']\n",
      "        Average fitness: 69.05% Â± 5.83%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 69.05% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 90a79f4c)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 90a79f4c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.2583, acc=67.66% (best=67.66%)\n",
      "          Fold 2 Epoch 1: loss=0.4039, acc=59.30% (best=59.30%)\n",
      "          Fold 3 Epoch 1: loss=0.4278, acc=66.48% (best=66.48%)\n",
      "          Fold 4 Epoch 1: loss=0.4248, acc=68.91% (best=68.91%)\n",
      "          Fold 5 Epoch 1: loss=0.4291, acc=63.12% (best=63.12%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 67.89%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 79.22%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 75.55%\n",
      "          Fold 1 Epoch 30: loss=0.0006, acc=65.23% (best=74.77%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 90a79f4c:\n",
      "        Fold accuracies: ['74.77%', '67.89%', '75.55%', '79.22%', '65.62%']\n",
      "        Average fitness: 72.61% Â± 5.06%\n",
      "        Best fold: Fold 4 with 79.22%\n",
      "      Fitness obtained: 72.61% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: a17ccd05)\n",
      "      Architecture: 9 conv + 6 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model a17ccd05 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7125, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.7139, acc=47.27% (best=47.27%)\n",
      "          Fold 5 Epoch 1: loss=0.7248, acc=53.05% (best=53.05%)\n",
      "          Fold 1 Epoch 1: loss=0.7209, acc=57.73% (best=57.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7173, acc=54.14% (best=54.14%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 77.73%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 59.45%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 82.81%\n",
      "          Fold 2 Epoch 30: loss=0.3532, acc=73.20% (best=75.23%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a17ccd05:\n",
      "        Fold accuracies: ['77.73%', '75.23%', '82.81%', '59.45%', '63.44%']\n",
      "        Average fitness: 71.73% Â± 8.84%\n",
      "        Best fold: Fold 3 with 82.81%\n",
      "      Fitness obtained: 71.73% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 9987fdaa)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 9987fdaa with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.4225, acc=62.97% (best=62.97%)\n",
      "          Fold 2 Epoch 1: loss=0.4988, acc=46.25% (best=46.25%)\n",
      "          Fold 4 Epoch 1: loss=0.4685, acc=44.14% (best=44.14%)\n",
      "          Fold 3 Epoch 1: loss=0.4664, acc=70.16% (best=70.16%)\n",
      "          Fold 1 Epoch 1: loss=0.3347, acc=61.25% (best=61.25%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 72.89%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 71.88%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 72.50%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 74.53%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9987fdaa:\n",
      "        Fold accuracies: ['72.50%', '74.53%', '72.89%', '67.11%', '71.88%']\n",
      "        Average fitness: 71.78% Â± 2.50%\n",
      "        Best fold: Fold 2 with 74.53%\n",
      "      Fitness obtained: 71.78% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: e419afc7)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model e419afc7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.3952, acc=41.17% (best=41.17%)\n",
      "          Fold 1 Epoch 1: loss=0.2683, acc=69.69% (best=69.69%)\n",
      "          Fold 3 Epoch 1: loss=0.4320, acc=72.81% (best=72.81%)\n",
      "          Fold 5 Epoch 1: loss=0.4199, acc=63.83% (best=63.83%)\n",
      "          Fold 2 Epoch 1: loss=0.4314, acc=60.62% (best=60.62%)\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 75.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e419afc7:\n",
      "        Fold accuracies: ['0.00%', '75.16%', '0.00%', '70.47%', '0.00%']\n",
      "        Average fitness: 29.12% Â± 35.70%\n",
      "        Best fold: Fold 2 with 75.16%\n",
      "      Fitness obtained: 29.12% | Best in generation: 78.16% | Global best: 78.39%\n",
      "\n",
      "GENERATION 12 STATISTICS:\n",
      "   Maximum fitness: 78.16%\n",
      "   Average fitness: 67.19%\n",
      "   Minimum fitness: 29.12%\n",
      "   Standard deviation: 11.69%\n",
      "   Best individual: 1e909e9b with 78.16%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 8/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=11.69)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1e909e9b (fitness: 78.16%)\n",
      "   Elite 2: 19335c57 (fitness: 76.92%)\n",
      "   Elite 3: 10f194d4 (fitness: 76.22%)\n",
      "   Elite 4: c44aa8e8 (fitness: 72.66%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 9/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 13\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 13)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6482, acc=85.00% (best=85.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6373, acc=60.16% (best=60.16%)\n",
      "          Fold 5 Epoch 1: loss=0.6241, acc=62.66% (best=62.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6488, acc=60.55% (best=60.55%)\n",
      "          Fold 1 Epoch 1: loss=0.5924, acc=72.58% (best=72.58%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 85.00%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 77.34%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 85.39%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['85.39%', '68.44%', '85.00%', '77.34%', '65.00%']\n",
      "        Average fitness: 76.23% Â± 8.35%\n",
      "        Best fold: Fold 1 with 85.39%\n",
      "      New best fitness in this generation: 76.23%!\n",
      "      Fitness obtained: 76.23% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 19335c57)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 19335c57 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5945, acc=61.41% (best=61.41%)\n",
      "          Fold 4 Epoch 1: loss=0.6151, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.4817, acc=68.44% (best=68.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6183, acc=59.30% (best=59.30%)\n",
      "          Fold 3 Epoch 1: loss=0.5864, acc=70.47% (best=70.47%)\n",
      "          Fold 5: Early stopping at epoch 11          Fold 1: Early stopping at epoch 11\n",
      "\n",
      "      â†’ Fold 1 completed: 68.44%\n",
      "      â†’ Fold 5 completed: 61.41%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 73.91%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 64.77%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 70.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19335c57:\n",
      "        Fold accuracies: ['68.44%', '70.62%', '73.91%', '64.77%', '61.41%']\n",
      "        Average fitness: 67.83% Â± 4.38%\n",
      "        Best fold: Fold 3 with 73.91%\n",
      "      Fitness obtained: 67.83% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 10f194d4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10f194d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6639, acc=76.41% (best=76.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6959, acc=65.23% (best=65.23%)\n",
      "          Fold 4 Epoch 1: loss=0.7016, acc=66.41% (best=66.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6745, acc=67.19% (best=67.19%)\n",
      "          Fold 3 Epoch 1: loss=0.6769, acc=65.08% (best=65.08%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.19%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 83.91%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 75.86%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "          Fold 4 Epoch 30: loss=0.1603, acc=67.66% (best=74.69%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 74.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10f194d4:\n",
      "        Fold accuracies: ['83.91%', '68.52%', '75.86%', '74.69%', '67.19%']\n",
      "        Average fitness: 74.03% Â± 5.98%\n",
      "        Best fold: Fold 1 with 83.91%\n",
      "      Fitness obtained: 74.03% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: c44aa8e8)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model c44aa8e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6177, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 1: loss=0.6008, acc=44.53% (best=44.53%)\n",
      "          Fold 1 Epoch 1: loss=0.4303, acc=63.75% (best=63.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6330, acc=50.94% (best=50.94%)\n",
      "          Fold 5 Epoch 1: loss=0.5468, acc=58.83% (best=58.83%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 75.08%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 78.20%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 70.62%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 76.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c44aa8e8:\n",
      "        Fold accuracies: ['70.62%', '75.08%', '78.20%', '76.02%', '62.81%']\n",
      "        Average fitness: 72.55% Â± 5.46%\n",
      "        Best fold: Fold 3 with 78.20%\n",
      "      Fitness obtained: 72.55% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 10bb5993)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 10bb5993 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.3699, acc=68.67% (best=68.67%)\n",
      "          Fold 4 Epoch 1: loss=0.5640, acc=48.20% (best=48.20%)\n",
      "          Fold 3 Epoch 1: loss=0.5706, acc=78.44% (best=78.44%)\n",
      "          Fold 2 Epoch 1: loss=0.5898, acc=75.31% (best=75.31%)\n",
      "          Fold 5 Epoch 1: loss=0.5221, acc=64.69% (best=64.69%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 75.31%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 82.19%\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 4 Epoch 30: loss=0.0771, acc=72.66% (best=72.66%)\n",
      "          Fold 4: Early stopping at epoch 44\n",
      "      â†’ Fold 4 completed: 73.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10bb5993:\n",
      "        Fold accuracies: ['76.41%', '75.31%', '82.19%', '73.67%', '64.69%']\n",
      "        Average fitness: 74.45% Â± 5.66%\n",
      "        Best fold: Fold 3 with 82.19%\n",
      "      Fitness obtained: 74.45% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: e469c488)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e469c488 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6161, acc=60.70% (best=60.70%)\n",
      "          Fold 4 Epoch 1: loss=0.6361, acc=67.11% (best=67.11%)\n",
      "          Fold 1 Epoch 1: loss=0.5011, acc=62.73% (best=62.73%)\n",
      "          Fold 5 Epoch 1: loss=0.5932, acc=39.84% (best=39.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6167, acc=52.11% (best=52.11%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 70.70%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.73%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 77.03%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e469c488:\n",
      "        Fold accuracies: ['70.70%', '70.23%', '64.06%', '77.03%', '57.73%']\n",
      "        Average fitness: 67.95% Â± 6.55%\n",
      "        Best fold: Fold 4 with 77.03%\n",
      "      Fitness obtained: 67.95% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: c29dcdff)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model c29dcdff with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6741, acc=71.25% (best=71.25%)\n",
      "          Fold 2 Epoch 1: loss=0.6545, acc=67.34% (best=67.34%)\n",
      "          Fold 4 Epoch 1: loss=0.6632, acc=67.66% (best=67.66%)\n",
      "          Fold 3 Epoch 1: loss=0.6677, acc=70.23% (best=70.23%)\n",
      "          Fold 1 Epoch 1: loss=0.6297, acc=70.23% (best=70.23%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.66%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 70.23%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 71.25%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c29dcdff:\n",
      "        Fold accuracies: ['75.78%', '70.39%', '70.23%', '67.66%', '71.25%']\n",
      "        Average fitness: 71.06% Â± 2.65%\n",
      "        Best fold: Fold 1 with 75.78%\n",
      "      Fitness obtained: 71.06% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: ec32c66b)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model ec32c66b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4104, acc=55.47% (best=55.47%)\n",
      "          Fold 5 Epoch 1: loss=0.5435, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 1: loss=0.5576, acc=55.00% (best=55.00%)\n",
      "          Fold 3 Epoch 1: loss=0.5229, acc=78.44% (best=78.44%)\n",
      "          Fold 4 Epoch 1: loss=0.5573, acc=64.69% (best=64.69%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.44%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 74.84%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 76.41%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 69.06%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 77.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ec32c66b:\n",
      "        Fold accuracies: ['74.84%', '76.41%', '78.44%', '77.58%', '69.06%']\n",
      "        Average fitness: 75.27% Â± 3.33%\n",
      "        Best fold: Fold 3 with 78.44%\n",
      "      Fitness obtained: 75.27% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 1d0013a3)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1d0013a3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5433, acc=43.52% (best=43.52%)          Fold 2 Epoch 1: loss=0.5772, acc=57.03% (best=57.03%)\n",
      "\n",
      "          Fold 5 Epoch 1: loss=0.5161, acc=54.30% (best=54.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6072, acc=47.66% (best=47.66%)\n",
      "          Fold 1 Epoch 1: loss=0.3821, acc=48.52% (best=48.52%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 73.52%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "          Fold 3 Epoch 30: loss=0.0761, acc=64.45% (best=71.33%)\n",
      "          Fold 4 Epoch 30: loss=0.0733, acc=67.19% (best=70.70%)\n",
      "          Fold 2 Epoch 30: loss=0.0905, acc=56.41% (best=66.41%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 3: Early stopping at epoch 34\n",
      "      â†’ Fold 3 completed: 71.33%\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d0013a3:\n",
      "        Fold accuracies: ['73.52%', '66.41%', '71.33%', '70.70%', '62.58%']\n",
      "        Average fitness: 68.91% Â± 3.91%\n",
      "        Best fold: Fold 1 with 73.52%\n",
      "      Fitness obtained: 68.91% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 43306be8)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 43306be8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5671, acc=75.16% (best=75.16%)\n",
      "          Fold 4 Epoch 1: loss=0.5808, acc=72.34% (best=72.34%)\n",
      "          Fold 2 Epoch 1: loss=0.6405, acc=53.59% (best=53.59%)\n",
      "          Fold 5 Epoch 1: loss=0.5301, acc=51.41% (best=51.41%)\n",
      "          Fold 1 Epoch 1: loss=0.4518, acc=57.97% (best=57.97%)\n",
      "          Fold 3: Early stopping at epoch 11          Fold 4: Early stopping at epoch 11\n",
      "\n",
      "      â†’ Fold 4 completed: 72.34%\n",
      "      â†’ Fold 3 completed: 75.16%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 59.06%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 74.30%\n",
      "          Fold 2 Epoch 30: loss=0.0695, acc=58.36% (best=69.84%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 43306be8:\n",
      "        Fold accuracies: ['74.30%', '69.84%', '75.16%', '72.34%', '59.06%']\n",
      "        Average fitness: 70.14% Â± 5.83%\n",
      "        Best fold: Fold 3 with 75.16%\n",
      "      Fitness obtained: 70.14% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 7aeb372b)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 7aeb372b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5870, acc=47.27% (best=47.27%)\n",
      "          Fold 1 Epoch 1: loss=0.5021, acc=67.66% (best=67.66%)\n",
      "          Fold 3 Epoch 1: loss=0.5738, acc=68.28% (best=68.28%)\n",
      "          Fold 2 Epoch 1: loss=0.6282, acc=67.34% (best=67.34%)\n",
      "          Fold 4 Epoch 1: loss=0.6079, acc=51.56% (best=51.56%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.83%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 76.95%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 60.00%\n",
      "          Fold 5 Epoch 30: loss=0.0824, acc=46.64% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 44\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7aeb372b:\n",
      "        Fold accuracies: ['78.83%', '67.34%', '76.95%', '60.00%', '63.44%']\n",
      "        Average fitness: 69.31% Â± 7.40%\n",
      "        Best fold: Fold 1 with 78.83%\n",
      "      Fitness obtained: 69.31% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: e27dd4e5)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e27dd4e5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6527, acc=65.47% (best=65.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6461, acc=74.69% (best=74.69%)\n",
      "          Fold 5 Epoch 1: loss=0.6651, acc=60.78% (best=60.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6256, acc=67.34% (best=67.34%)\n",
      "          Fold 2 Epoch 1: loss=0.6228, acc=66.88% (best=66.88%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 67.34%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 74.69%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.97%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 72.19%\n",
      "          Fold 2 Epoch 30: loss=0.1944, acc=68.75% (best=71.88%)\n",
      "          Fold 2: Early stopping at epoch 50\n",
      "      â†’ Fold 2 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e27dd4e5:\n",
      "        Fold accuracies: ['67.34%', '72.27%', '74.69%', '72.19%', '62.97%']\n",
      "        Average fitness: 69.89% Â± 4.20%\n",
      "        Best fold: Fold 3 with 74.69%\n",
      "      Fitness obtained: 69.89% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 1cefe821)\n",
      "      Architecture: 9 conv + 6 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 1cefe821 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7141, acc=45.23% (best=45.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=64.92% (best=64.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7177, acc=49.38% (best=49.38%)\n",
      "          Fold 2 Epoch 1: loss=0.7402, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7421, acc=49.61% (best=49.61%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 73.05%\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 77.89%\n",
      "          Fold 2 Epoch 30: loss=0.2846, acc=69.92% (best=70.00%)\n",
      "          Fold 2: Early stopping at epoch 44\n",
      "      â†’ Fold 2 completed: 71.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1cefe821:\n",
      "        Fold accuracies: ['73.75%', '71.48%', '77.89%', '69.61%', '73.05%']\n",
      "        Average fitness: 73.16% Â± 2.76%\n",
      "        Best fold: Fold 3 with 77.89%\n",
      "      Fitness obtained: 73.16% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 4c382754)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 4c382754 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5849, acc=60.47% (best=60.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6152, acc=67.97% (best=67.97%)\n",
      "          Fold 4 Epoch 1: loss=0.5941, acc=49.14% (best=49.14%)\n",
      "          Fold 3 Epoch 1: loss=0.5810, acc=57.97% (best=57.97%)\n",
      "          Fold 1 Epoch 1: loss=0.5254, acc=70.08% (best=70.08%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 67.73%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 71.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4c382754:\n",
      "        Fold accuracies: ['70.08%', '68.91%', '78.83%', '67.73%', '71.25%']\n",
      "        Average fitness: 71.36% Â± 3.91%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 71.36% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 5555da59)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 5555da59 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=3.9858, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=3.2141, acc=59.69% (best=59.69%)\n",
      "          Fold 5 Epoch 1: loss=3.7257, acc=52.58% (best=52.58%)\n",
      "          Fold 1 Epoch 1: loss=3.5953, acc=37.50% (best=37.50%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 59.69%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 67.97%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 68.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5555da59:\n",
      "        Fold accuracies: ['67.97%', '68.12%', '0.00%', '59.69%', '66.56%']\n",
      "        Average fitness: 52.47% Â± 26.42%\n",
      "        Best fold: Fold 2 with 68.12%\n",
      "      Fitness obtained: 52.47% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 83a67716)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 83a67716 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6278, acc=78.28% (best=78.28%)\n",
      "          Fold 5 Epoch 1: loss=0.6291, acc=54.61% (best=54.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6478, acc=44.22% (best=44.22%)\n",
      "          Fold 2 Epoch 1: loss=0.6188, acc=62.89% (best=62.89%)\n",
      "          Fold 1 Epoch 1: loss=0.5524, acc=74.92% (best=74.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.92%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.34%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 73.83%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 83a67716:\n",
      "        Fold accuracies: ['74.92%', '66.48%', '82.34%', '73.83%', '65.16%']\n",
      "        Average fitness: 72.55% Â± 6.24%\n",
      "        Best fold: Fold 3 with 82.34%\n",
      "      Fitness obtained: 72.55% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 4ee3e2cc)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 4ee3e2cc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5485, acc=70.31% (best=70.31%)\n",
      "          Fold 2 Epoch 1: loss=0.5911, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=0.5845, acc=65.70% (best=65.70%)\n",
      "          Fold 4 Epoch 1: loss=0.6162, acc=57.50% (best=57.50%)\n",
      "          Fold 5 Epoch 1: loss=0.5369, acc=55.23% (best=55.23%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 80.86%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 70.00%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 78.52%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 57.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4ee3e2cc:\n",
      "        Fold accuracies: ['80.86%', '68.20%', '78.52%', '70.00%', '57.11%']\n",
      "        Average fitness: 70.94% Â± 8.43%\n",
      "        Best fold: Fold 1 with 80.86%\n",
      "      Fitness obtained: 70.94% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 1732ec34)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1732ec34 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5565, acc=57.27% (best=57.27%)\n",
      "          Fold 5 Epoch 1: loss=0.5174, acc=45.08% (best=45.08%)\n",
      "          Fold 3 Epoch 1: loss=0.5415, acc=70.16% (best=70.16%)\n",
      "          Fold 4 Epoch 1: loss=0.5370, acc=47.66% (best=47.66%)\n",
      "          Fold 1 Epoch 1: loss=0.4570, acc=62.27% (best=62.27%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 71.56%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 72.89%\n",
      "          Fold 5 Epoch 30: loss=0.0872, acc=60.00% (best=65.94%)\n",
      "          Fold 4 Epoch 30: loss=0.0746, acc=58.83% (best=67.50%)\n",
      "          Fold 4: Early stopping at epoch 30\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1732ec34:\n",
      "        Fold accuracies: ['72.89%', '71.56%', '70.16%', '67.50%', '65.94%']\n",
      "        Average fitness: 69.61% Â± 2.56%\n",
      "        Best fold: Fold 1 with 72.89%\n",
      "      Fitness obtained: 69.61% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 0b8993f2)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0b8993f2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7067, acc=44.06% (best=44.06%)\n",
      "          Fold 2 Epoch 1: loss=0.7041, acc=71.25% (best=71.25%)\n",
      "          Fold 3 Epoch 1: loss=0.7365, acc=45.39% (best=45.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6929, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6738, acc=42.81% (best=42.81%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 45.39%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 83.83%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 77.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0b8993f2:\n",
      "        Fold accuracies: ['75.78%', '83.83%', '77.03%', '49.61%', '45.39%']\n",
      "        Average fitness: 66.33% Â± 15.67%\n",
      "        Best fold: Fold 2 with 83.83%\n",
      "      Fitness obtained: 66.33% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 855449e9)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 855449e9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6077, acc=58.75% (best=58.75%)          Fold 4 Epoch 1: loss=0.6196, acc=54.84% (best=54.84%)\n",
      "\n",
      "          Fold 3 Epoch 1: loss=0.6055, acc=80.23% (best=80.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6502, acc=67.34% (best=67.34%)\n",
      "          Fold 1 Epoch 1: loss=0.5689, acc=69.61% (best=69.61%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.12%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 80.86%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 65.78%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 72.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 855449e9:\n",
      "        Fold accuracies: ['78.12%', '67.34%', '80.86%', '72.58%', '65.78%']\n",
      "        Average fitness: 72.94% Â± 5.87%\n",
      "        Best fold: Fold 3 with 80.86%\n",
      "      Fitness obtained: 72.94% | Best in generation: 76.23% | Global best: 78.39%\n",
      "\n",
      "GENERATION 13 STATISTICS:\n",
      "   Maximum fitness: 76.23%\n",
      "   Average fitness: 70.35%\n",
      "   Minimum fitness: 52.47%\n",
      "   Standard deviation: 4.83%\n",
      "   Best individual: 1e909e9b with 76.23%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 10/20\n",
      "Adaptive mutation rate updated to 0.2567 (std_fitness=4.83)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1e909e9b (fitness: 76.23%)\n",
      "   Elite 2: ec32c66b (fitness: 75.27%)\n",
      "   Elite 3: 10bb5993 (fitness: 74.45%)\n",
      "   Elite 4: 10f194d4 (fitness: 74.03%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 11/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 14\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 14)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1e909e9b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e909e9b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6384, acc=62.42% (best=62.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6230, acc=59.30% (best=59.30%)\n",
      "          Fold 3 Epoch 1: loss=0.6286, acc=58.12% (best=58.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6341, acc=72.27% (best=72.27%)\n",
      "          Fold 1 Epoch 1: loss=0.5958, acc=70.39% (best=70.39%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 74.38%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 69.38%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 74.53%\n",
      "          Fold 2 Epoch 30: loss=0.1548, acc=67.34% (best=67.58%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e909e9b:\n",
      "        Fold accuracies: ['74.38%', '67.58%', '69.38%', '74.53%', '65.00%']\n",
      "        Average fitness: 70.17% Â± 3.76%\n",
      "        Best fold: Fold 4 with 74.53%\n",
      "      New best fitness in this generation: 70.17%!\n",
      "      Fitness obtained: 70.17% | Best in generation: 70.17% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: ec32c66b)\n",
      "      Architecture: 11 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model ec32c66b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5640, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 1: loss=0.5279, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 1: loss=0.5898, acc=53.67% (best=53.67%)\n",
      "          Fold 1 Epoch 1: loss=0.4572, acc=63.05% (best=63.05%)\n",
      "          Fold 4 Epoch 1: loss=0.5465, acc=48.20% (best=48.20%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 82.73%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 72.66%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 71.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ec32c66b:\n",
      "        Fold accuracies: ['68.36%', '71.56%', '82.73%', '72.66%', '66.56%']\n",
      "        Average fitness: 72.38% Â± 5.62%\n",
      "        Best fold: Fold 3 with 82.73%\n",
      "      New best fitness in this generation: 72.38%!\n",
      "      Fitness obtained: 72.38% | Best in generation: 72.38% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 10bb5993)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 10bb5993 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5776, acc=55.55% (best=55.55%)\n",
      "          Fold 1 Epoch 1: loss=0.4042, acc=63.36% (best=63.36%)\n",
      "          Fold 5 Epoch 1: loss=0.4986, acc=55.47% (best=55.47%)\n",
      "          Fold 3 Epoch 1: loss=0.5401, acc=54.69% (best=54.69%)\n",
      "          Fold 4 Epoch 1: loss=0.5280, acc=59.53% (best=59.53%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 67.50%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 70.08%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 65.47%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 68.59%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10bb5993:\n",
      "        Fold accuracies: ['68.59%', '70.08%', '67.50%', '65.47%', '60.31%']\n",
      "        Average fitness: 66.39% Â± 3.39%\n",
      "        Best fold: Fold 2 with 70.08%\n",
      "      Fitness obtained: 66.39% | Best in generation: 72.38% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 10f194d4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10f194d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6896, acc=75.62% (best=75.62%)\n",
      "          Fold 2 Epoch 1: loss=0.6802, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6841, acc=67.03% (best=67.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6508, acc=80.31% (best=80.31%)\n",
      "          Fold 5 Epoch 1: loss=0.7601, acc=60.16% (best=60.16%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 80.31%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 91.25%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.20%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 63.67%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10f194d4:\n",
      "        Fold accuracies: ['80.31%', '69.22%', '91.25%', '73.20%', '63.67%']\n",
      "        Average fitness: 75.53% Â± 9.55%\n",
      "        Best fold: Fold 3 with 91.25%\n",
      "      New best fitness in this generation: 75.53%!\n",
      "      Fitness obtained: 75.53% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: dd39e18d)\n",
      "      Architecture: 9 conv + 10 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model dd39e18d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dd39e18d:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: db88f2c1)\n",
      "      Architecture: 11 conv + 3 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model db88f2c1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=10.9502, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 1: loss=7.1610, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=7.3032, acc=56.72% (best=56.72%)\n",
      "          Fold 3 Epoch 1: loss=6.1120, acc=69.30% (best=69.30%)\n",
      "          Fold 1 Epoch 1: loss=4.6280, acc=48.44% (best=48.44%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 63.36%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 73.52%\n",
      "          Fold 3 Epoch 30: loss=0.1173, acc=72.19% (best=76.72%)\n",
      "          Fold 3: Early stopping at epoch 39\n",
      "      â†’ Fold 3 completed: 76.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for db88f2c1:\n",
      "        Fold accuracies: ['63.36%', '73.52%', '76.72%', '71.25%', '68.36%']\n",
      "        Average fitness: 70.64% Â± 4.56%\n",
      "        Best fold: Fold 3 with 76.72%\n",
      "      Fitness obtained: 70.64% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 8785f55d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8785f55d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6660, acc=77.66% (best=77.66%)\n",
      "          Fold 4 Epoch 1: loss=0.7034, acc=41.33% (best=41.33%)\n",
      "          Fold 5 Epoch 1: loss=0.6919, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6985, acc=61.48% (best=61.48%)\n",
      "          Fold 1 Epoch 1: loss=0.6709, acc=53.91% (best=53.91%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.22%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.98%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 57.27%\n",
      "      â†’ Fold 4 completed: 74.14%\n",
      "          Fold 1 Epoch 30: loss=0.0285, acc=53.36% (best=76.95%)\n",
      "          Fold 1: Early stopping at epoch 37\n",
      "      â†’ Fold 1 completed: 76.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8785f55d:\n",
      "        Fold accuracies: ['76.95%', '68.98%', '79.22%', '74.14%', '57.27%']\n",
      "        Average fitness: 71.31% Â± 7.81%\n",
      "        Best fold: Fold 3 with 79.22%\n",
      "      Fitness obtained: 71.31% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 90490dcd)\n",
      "      Architecture: 9 conv + 5 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 90490dcd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6950, acc=68.36% (best=68.36%)\n",
      "          Fold 2 Epoch 1: loss=0.7000, acc=70.31% (best=70.31%)\n",
      "          Fold 1 Epoch 1: loss=0.6821, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6893, acc=63.28% (best=63.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6974, acc=57.42% (best=57.42%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.31%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 71.64%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 79.30%\n",
      "          Fold 1 Epoch 30: loss=0.0106, acc=81.09% (best=81.09%)\n",
      "          Fold 1: Early stopping at epoch 45\n",
      "      â†’ Fold 1 completed: 82.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 90490dcd:\n",
      "        Fold accuracies: ['82.34%', '70.31%', '79.30%', '71.64%', '63.98%']\n",
      "        Average fitness: 73.52% Â± 6.57%\n",
      "        Best fold: Fold 1 with 82.34%\n",
      "      Fitness obtained: 73.52% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 0d9e9289)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0d9e9289 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6234, acc=65.08% (best=65.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6517, acc=56.09% (best=56.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6486, acc=84.38% (best=84.38%)\n",
      "          Fold 4 Epoch 1: loss=0.6401, acc=62.42% (best=62.42%)\n",
      "          Fold 1 Epoch 1: loss=0.5719, acc=70.55% (best=70.55%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.08%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.20%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 93.52%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 82.73%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 75.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0d9e9289:\n",
      "        Fold accuracies: ['82.73%', '65.08%', '93.52%', '75.62%', '58.20%']\n",
      "        Average fitness: 75.03% Â± 12.52%\n",
      "        Best fold: Fold 3 with 93.52%\n",
      "      Fitness obtained: 75.03% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 741176ac)\n",
      "      Architecture: 9 conv + 1 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 741176ac with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 741176ac:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 2d3d9a7b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 2d3d9a7b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6244, acc=59.06% (best=59.06%)\n",
      "          Fold 3 Epoch 1: loss=0.5803, acc=67.50% (best=67.50%)\n",
      "          Fold 5 Epoch 1: loss=0.5407, acc=46.95% (best=46.95%)\n",
      "          Fold 1 Epoch 1: loss=0.4108, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 1: loss=0.5993, acc=42.50% (best=42.50%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 59.53%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 77.73%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 73.83%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 78.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2d3d9a7b:\n",
      "        Fold accuracies: ['78.44%', '66.25%', '73.83%', '77.73%', '59.53%']\n",
      "        Average fitness: 71.16% Â± 7.25%\n",
      "        Best fold: Fold 1 with 78.44%\n",
      "      Fitness obtained: 71.16% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: db27a5a6)\n",
      "      Architecture: 9 conv + 6 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model db27a5a6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7212, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7204, acc=57.34% (best=57.34%)\n",
      "          Fold 1 Epoch 1: loss=0.7139, acc=47.19% (best=47.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7182, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 1: loss=0.7197, acc=58.59% (best=58.59%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 57.34%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.70%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 58.59%\n",
      "          Fold 1 Epoch 30: loss=0.2180, acc=62.34% (best=67.03%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 67.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for db27a5a6:\n",
      "        Fold accuracies: ['67.03%', '58.59%', '57.34%', '49.61%', '55.70%']\n",
      "        Average fitness: 57.66% Â± 5.61%\n",
      "        Best fold: Fold 1 with 67.03%\n",
      "      Fitness obtained: 57.66% | Best in generation: 75.53% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: faf10540)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model faf10540 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6805, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6188, acc=84.92% (best=84.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6809, acc=74.45% (best=74.45%)\n",
      "          Fold 5 Epoch 1: loss=0.7266, acc=56.33% (best=56.33%)\n",
      "          Fold 2 Epoch 1: loss=0.6627, acc=62.58% (best=62.58%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 84.92%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.14%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.08%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 71.88%\n",
      "          Fold 4 Epoch 30: loss=0.1649, acc=79.06% (best=79.06%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 79.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for faf10540:\n",
      "        Fold accuracies: ['84.92%', '70.08%', '79.14%', '79.06%', '71.88%']\n",
      "        Average fitness: 77.02% Â± 5.40%\n",
      "        Best fold: Fold 1 with 84.92%\n",
      "      New best fitness in this generation: 77.02%!\n",
      "      Fitness obtained: 77.02% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: f86825e7)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model f86825e7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5880, acc=67.11% (best=67.11%)\n",
      "          Fold 5 Epoch 1: loss=0.6285, acc=76.41% (best=76.41%)\n",
      "          Fold 4 Epoch 1: loss=0.5644, acc=67.58% (best=67.58%)\n",
      "          Fold 3 Epoch 1: loss=0.5994, acc=68.83% (best=68.83%)\n",
      "          Fold 1 Epoch 1: loss=0.4780, acc=73.44% (best=73.44%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.44%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 76.41%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 81.95%\n",
      "          Fold 4 Epoch 30: loss=0.0786, acc=73.44% (best=76.02%)\n",
      "          Fold 4: Early stopping at epoch 39\n",
      "      â†’ Fold 4 completed: 76.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f86825e7:\n",
      "        Fold accuracies: ['73.44%', '67.11%', '81.95%', '76.02%', '76.41%']\n",
      "        Average fitness: 74.98% Â± 4.82%\n",
      "        Best fold: Fold 3 with 81.95%\n",
      "      Fitness obtained: 74.98% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 1aec6068)\n",
      "      Architecture: 9 conv + 6 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 1aec6068 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4315, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6182, acc=55.94% (best=55.94%)\n",
      "          Fold 5 Epoch 1: loss=0.5459, acc=38.91% (best=38.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6332, acc=63.12% (best=63.12%)\n",
      "          Fold 3 Epoch 1: loss=0.5818, acc=82.27% (best=82.27%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 67.89%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 82.27%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 66.80%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 4 Epoch 30: loss=0.0786, acc=61.88% (best=67.34%)\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1aec6068:\n",
      "        Fold accuracies: ['67.89%', '71.95%', '82.27%', '67.58%', '66.80%']\n",
      "        Average fitness: 71.30% Â± 5.77%\n",
      "        Best fold: Fold 3 with 82.27%\n",
      "      Fitness obtained: 71.30% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 735b7dd9)\n",
      "      Architecture: 9 conv + 7 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 735b7dd9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7164, acc=50.08% (best=50.08%)          Fold 3 Epoch 1: loss=0.7575, acc=48.83% (best=48.83%)\n",
      "\n",
      "          Fold 4 Epoch 1: loss=0.7250, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7164, acc=50.47% (best=50.47%)\n",
      "          Fold 1 Epoch 1: loss=0.7205, acc=49.61% (best=49.61%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 62.19%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 51.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 735b7dd9:\n",
      "        Fold accuracies: ['62.19%', '50.08%', '48.83%', '49.61%', '51.64%']\n",
      "        Average fitness: 52.47% Â± 4.95%\n",
      "        Best fold: Fold 1 with 62.19%\n",
      "      Fitness obtained: 52.47% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 3e01264a)\n",
      "      Architecture: 9 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 3e01264a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.7333, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 1: loss=0.7649, acc=48.83% (best=48.83%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3e01264a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '48.83%', '0.00%', '49.53%']\n",
      "        Average fitness: 19.67% Â± 24.09%\n",
      "        Best fold: Fold 5 with 49.53%\n",
      "      Fitness obtained: 19.67% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 53489f61)\n",
      "      Architecture: 5 conv + 2 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 53489f61 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.2277, acc=60.00% (best=60.00%)\n",
      "          Fold 3 Epoch 1: loss=0.2032, acc=68.44% (best=68.44%)\n",
      "          Fold 2 Epoch 1: loss=0.2218, acc=66.33% (best=66.33%)\n",
      "          Fold 1 Epoch 1: loss=0.0988, acc=42.89% (best=42.89%)\n",
      "          Fold 4 Epoch 1: loss=0.2210, acc=57.19% (best=57.19%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.33%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 57.19%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 65.78%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 71.88%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 72.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 53489f61:\n",
      "        Fold accuracies: ['65.78%', '66.33%', '71.88%', '57.19%', '72.89%']\n",
      "        Average fitness: 66.81% Â± 5.59%\n",
      "        Best fold: Fold 5 with 72.89%\n",
      "      Fitness obtained: 66.81% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 819984c9)\n",
      "      Architecture: 9 conv + 6 fc, opt=sgd, lr=0.01\n",
      "      Training/Evaluating model 819984c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7056, acc=41.33% (best=41.33%)\n",
      "          Fold 4 Epoch 1: loss=0.7020, acc=72.73% (best=72.73%)\n",
      "          Fold 5 Epoch 1: loss=0.6966, acc=62.34% (best=62.34%)\n",
      "          Fold 3 Epoch 1: loss=0.6962, acc=71.88% (best=71.88%)\n",
      "          Fold 1 Epoch 1: loss=0.7005, acc=64.92% (best=64.92%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 72.73%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.34%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 72.66%\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 75.16%\n",
      "          Fold 2 Epoch 30: loss=0.1223, acc=54.14% (best=70.31%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 70.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 819984c9:\n",
      "        Fold accuracies: ['72.66%', '70.31%', '75.16%', '72.73%', '62.34%']\n",
      "        Average fitness: 70.64% Â± 4.42%\n",
      "        Best fold: Fold 3 with 75.16%\n",
      "      Fitness obtained: 70.64% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 269df888)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 269df888 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6929, acc=59.77% (best=59.77%)          Fold 5 Epoch 1: loss=0.6904, acc=69.69% (best=69.69%)\n",
      "\n",
      "          Fold 1 Epoch 1: loss=0.6743, acc=63.05% (best=63.05%)\n",
      "          Fold 4 Epoch 1: loss=0.6920, acc=70.23% (best=70.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6907, acc=74.69% (best=74.69%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 74.69%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 59.77%\n",
      "      â†’ Fold 5 completed: 69.69%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.23%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 269df888:\n",
      "        Fold accuracies: ['77.19%', '59.77%', '74.69%', '70.23%', '69.69%']\n",
      "        Average fitness: 70.31% Â± 5.97%\n",
      "        Best fold: Fold 1 with 77.19%\n",
      "      Fitness obtained: 70.31% | Best in generation: 77.02% | Global best: 78.39%\n",
      "\n",
      "GENERATION 14 STATISTICS:\n",
      "   Maximum fitness: 77.02%\n",
      "   Average fitness: 60.35%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 23.57%\n",
      "   Best individual: faf10540 with 77.02%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 12/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=23.57)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: faf10540 (fitness: 77.02%)\n",
      "   Elite 2: 10f194d4 (fitness: 75.53%)\n",
      "   Elite 3: 0d9e9289 (fitness: 75.03%)\n",
      "   Elite 4: f86825e7 (fitness: 74.98%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 13/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 15\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 15)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: faf10540)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model faf10540 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6404, acc=78.36% (best=78.36%)          Fold 3 Epoch 1: loss=0.6660, acc=69.06% (best=69.06%)\n",
      "\n",
      "          Fold 2 Epoch 1: loss=0.6814, acc=52.66% (best=52.66%)\n",
      "          Fold 5 Epoch 1: loss=0.6785, acc=59.77% (best=59.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6749, acc=49.30% (best=49.30%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.11%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 65.62%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 73.52%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 83.83%\n",
      "          Fold 4 Epoch 30: loss=0.1605, acc=69.77% (best=74.61%)\n",
      "          Fold 4: Early stopping at epoch 52\n",
      "      â†’ Fold 4 completed: 76.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for faf10540:\n",
      "        Fold accuracies: ['83.83%', '65.62%', '82.11%', '76.33%', '73.52%']\n",
      "        Average fitness: 76.28% Â± 6.51%\n",
      "        Best fold: Fold 1 with 83.83%\n",
      "      New best fitness in this generation: 76.28%!\n",
      "      Fitness obtained: 76.28% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 10f194d4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10f194d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6767, acc=74.84% (best=74.84%)\n",
      "          Fold 5 Epoch 1: loss=0.6726, acc=66.33% (best=66.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6829, acc=57.81% (best=57.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6952, acc=69.45% (best=69.45%)\n",
      "          Fold 1 Epoch 1: loss=0.6785, acc=72.42% (best=72.42%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.42%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.66%\n",
      "          Fold 3: Early stopping at epoch 14          Fold 2: Early stopping at epoch 14\n",
      "\n",
      "      â†’ Fold 3 completed: 90.55%\n",
      "      â†’ Fold 2 completed: 69.53%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10f194d4:\n",
      "        Fold accuracies: ['72.42%', '69.53%', '90.55%', '72.27%', '67.66%']\n",
      "        Average fitness: 74.48% Â± 8.23%\n",
      "        Best fold: Fold 3 with 90.55%\n",
      "      Fitness obtained: 74.48% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 0d9e9289)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 0d9e9289 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6174, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6465, acc=65.08% (best=65.08%)\n",
      "          Fold 2 Epoch 1: loss=0.6288, acc=67.42% (best=67.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6420, acc=77.58% (best=77.58%)\n",
      "          Fold 1 Epoch 1: loss=0.5681, acc=75.39% (best=75.39%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.39%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.67%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 77.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0d9e9289:\n",
      "        Fold accuracies: ['75.39%', '68.67%', '77.58%', '77.81%', '56.88%']\n",
      "        Average fitness: 71.27% Â± 7.92%\n",
      "        Best fold: Fold 4 with 77.81%\n",
      "      Fitness obtained: 71.27% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: f86825e7)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model f86825e7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5806, acc=59.45% (best=59.45%)\n",
      "          Fold 3 Epoch 1: loss=0.5998, acc=79.77% (best=79.77%)\n",
      "          Fold 4 Epoch 1: loss=0.5708, acc=58.12% (best=58.12%)\n",
      "          Fold 2 Epoch 1: loss=0.6104, acc=72.81% (best=72.81%)\n",
      "          Fold 1 Epoch 1: loss=0.4618, acc=70.31% (best=70.31%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 59.30%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 74.53%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 74.06%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 61.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f86825e7:\n",
      "        Fold accuracies: ['74.53%', '74.06%', '79.77%', '59.30%', '61.17%']\n",
      "        Average fitness: 69.77% Â± 8.06%\n",
      "        Best fold: Fold 3 with 79.77%\n",
      "      Fitness obtained: 69.77% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 11e3ee89)\n",
      "      Architecture: 9 conv + 6 fc, opt=sgd, lr=0.001\n",
      "      Training/Evaluating model 11e3ee89 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7199, acc=60.55% (best=60.55%)\n",
      "          Fold 2 Epoch 1: loss=0.7109, acc=46.33% (best=46.33%)\n",
      "          Fold 5 Epoch 1: loss=0.7208, acc=58.67% (best=58.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7142, acc=53.67% (best=53.67%)\n",
      "          Fold 1 Epoch 1: loss=0.7146, acc=48.83% (best=48.83%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 53.67%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 72.03%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 76.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 11e3ee89:\n",
      "        Fold accuracies: ['72.03%', '50.08%', '53.67%', '76.41%', '58.67%']\n",
      "        Average fitness: 62.17% Â± 10.30%\n",
      "        Best fold: Fold 4 with 76.41%\n",
      "      Fitness obtained: 62.17% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 6a8e7bdd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 6a8e7bdd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=1.1287, acc=55.08% (best=55.08%)\n",
      "          Fold 1 Epoch 1: loss=0.8796, acc=67.89% (best=67.89%)\n",
      "          Fold 2 Epoch 1: loss=1.4453, acc=30.70% (best=30.70%)\n",
      "          Fold 4 Epoch 1: loss=1.1849, acc=42.19% (best=42.19%)\n",
      "          Fold 3 Epoch 1: loss=1.2093, acc=51.33% (best=51.33%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 69.06%\n",
      "          Fold 4 Epoch 30: loss=0.0774, acc=49.06% (best=73.52%)\n",
      "          Fold 5 Epoch 30: loss=0.0738, acc=51.72% (best=64.22%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 73.52%\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 64.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6a8e7bdd:\n",
      "        Fold accuracies: ['68.36%', '68.75%', '69.06%', '73.52%', '64.22%']\n",
      "        Average fitness: 68.78% Â± 2.95%\n",
      "        Best fold: Fold 4 with 73.52%\n",
      "      Fitness obtained: 68.78% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: e9d1a1b3)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e9d1a1b3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6385, acc=80.00% (best=80.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6279, acc=69.45% (best=69.45%)\n",
      "          Fold 1 Epoch 1: loss=0.5330, acc=70.78% (best=70.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6303, acc=60.62% (best=60.62%)\n",
      "          Fold 5 Epoch 1: loss=0.6602, acc=53.52% (best=53.52%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.00%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 73.67%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e9d1a1b3:\n",
      "        Fold accuracies: ['73.67%', '71.17%', '80.00%', '63.52%', '63.12%']\n",
      "        Average fitness: 70.30% Â± 6.38%\n",
      "        Best fold: Fold 3 with 80.00%\n",
      "      Fitness obtained: 70.30% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 65e58c38)\n",
      "      Architecture: 9 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 65e58c38 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7167, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.7230, acc=47.58% (best=47.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7110, acc=47.81% (best=47.81%)\n",
      "          Fold 3 Epoch 1: loss=0.7169, acc=55.08% (best=55.08%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 62.34%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 58.59%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 65e58c38:\n",
      "        Fold accuracies: ['0.00%', '70.39%', '62.34%', '74.84%', '58.59%']\n",
      "        Average fitness: 53.23% Â± 27.23%\n",
      "        Best fold: Fold 4 with 74.84%\n",
      "      Fitness obtained: 53.23% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 596e0cb7)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 596e0cb7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6878, acc=74.38% (best=74.38%)\n",
      "          Fold 1 Epoch 1: loss=0.5295, acc=78.44% (best=78.44%)\n",
      "          Fold 5 Epoch 1: loss=0.6193, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 1: loss=0.6186, acc=65.16% (best=65.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6373, acc=65.55% (best=65.55%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.52%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 74.38%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 77.42%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 2 Epoch 30: loss=0.1549, acc=61.88% (best=71.33%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 71.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 596e0cb7:\n",
      "        Fold accuracies: ['78.52%', '71.33%', '74.38%', '77.42%', '66.88%']\n",
      "        Average fitness: 73.70% Â± 4.24%\n",
      "        Best fold: Fold 1 with 78.52%\n",
      "      Fitness obtained: 73.70% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 404250d8)\n",
      "      Architecture: 9 conv + 10 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 404250d8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7234, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.7285, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7965, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.7368, acc=49.92% (best=49.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7392, acc=48.05% (best=48.05%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.92%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 57.89%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 56.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 404250d8:\n",
      "        Fold accuracies: ['57.89%', '49.92%', '48.83%', '50.39%', '56.80%']\n",
      "        Average fitness: 52.77% Â± 3.79%\n",
      "        Best fold: Fold 1 with 57.89%\n",
      "      Fitness obtained: 52.77% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 08afde9c)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 08afde9c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6525, acc=69.45% (best=69.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6475, acc=60.55% (best=60.55%)\n",
      "          Fold 1 Epoch 1: loss=0.5913, acc=75.00% (best=75.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6371, acc=54.38% (best=54.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6420, acc=84.61% (best=84.61%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.08%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 79.61%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 88.28%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 08afde9c:\n",
      "        Fold accuracies: ['79.61%', '67.34%', '88.28%', '72.42%', '65.08%']\n",
      "        Average fitness: 74.55% Â± 8.49%\n",
      "        Best fold: Fold 3 with 88.28%\n",
      "      Fitness obtained: 74.55% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 8971bc4b)\n",
      "      Architecture: 9 conv + 1 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8971bc4b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 329, in forward\n",
      "    return torch.sigmoid(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6934, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6850, acc=51.72% (best=51.72%)\n",
      "          Fold 2 Epoch 1: loss=0.6947, acc=56.72% (best=56.72%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 51.80%\n",
      "      â†’ Fold 3 completed: 85.31%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 77.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8971bc4b:\n",
      "        Fold accuracies: ['0.00%', '77.34%', '85.31%', '0.00%', '51.80%']\n",
      "        Average fitness: 42.89% Â± 36.73%\n",
      "        Best fold: Fold 3 with 85.31%\n",
      "      Fitness obtained: 42.89% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 47b54572)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 47b54572 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4145, acc=62.19% (best=62.19%)\n",
      "          Fold 4 Epoch 1: loss=0.4753, acc=56.88% (best=56.88%)\n",
      "          Fold 3 Epoch 1: loss=0.5199, acc=69.45% (best=69.45%)\n",
      "          Fold 2 Epoch 1: loss=0.5391, acc=33.05% (best=33.05%)\n",
      "          Fold 5 Epoch 1: loss=0.4911, acc=49.69% (best=49.69%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 64.30%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 76.33%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 71.72%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 74.92%\n",
      "          Fold 5 Epoch 30: loss=0.0726, acc=48.59% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 36\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 47b54572:\n",
      "        Fold accuracies: ['76.33%', '71.72%', '74.92%', '64.30%', '64.69%']\n",
      "        Average fitness: 70.39% Â± 5.04%\n",
      "        Best fold: Fold 1 with 76.33%\n",
      "      Fitness obtained: 70.39% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 791f2412)\n",
      "      Architecture: 9 conv + 6 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 791f2412 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7122, acc=73.59% (best=73.59%)\n",
      "          Fold 4 Epoch 1: loss=0.7086, acc=49.38% (best=49.38%)\n",
      "          Fold 5 Epoch 1: loss=0.7246, acc=41.80% (best=41.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7159, acc=53.28% (best=53.28%)\n",
      "          Fold 1 Epoch 1: loss=0.7306, acc=49.61% (best=49.61%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 74.22%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 63.59%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 70.55%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 69.92%\n",
      "          Fold 5 Epoch 30: loss=0.2419, acc=61.09% (best=62.73%)\n",
      "          Fold 5: Early stopping at epoch 56\n",
      "      â†’ Fold 5 completed: 69.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 791f2412:\n",
      "        Fold accuracies: ['63.59%', '74.22%', '69.92%', '70.55%', '69.77%']\n",
      "        Average fitness: 69.61% Â± 3.42%\n",
      "        Best fold: Fold 2 with 74.22%\n",
      "      Fitness obtained: 69.61% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 5a8ed3e0)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5a8ed3e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5484, acc=73.28% (best=73.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6085, acc=72.50% (best=72.50%)\n",
      "          Fold 4 Epoch 1: loss=0.6568, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6578, acc=64.06% (best=64.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6209, acc=52.03% (best=52.03%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.28%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 73.44%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 70.08%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 72.97%\n",
      "          Fold 2 Epoch 30: loss=0.1698, acc=55.00% (best=62.19%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 62.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5a8ed3e0:\n",
      "        Fold accuracies: ['73.28%', '62.19%', '73.44%', '72.97%', '70.08%']\n",
      "        Average fitness: 70.39% Â± 4.28%\n",
      "        Best fold: Fold 3 with 73.44%\n",
      "      Fitness obtained: 70.39% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 9196168d)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 9196168d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5414, acc=44.14% (best=44.14%)\n",
      "          Fold 2 Epoch 1: loss=0.4917, acc=69.53% (best=69.53%)\n",
      "          Fold 1 Epoch 1: loss=0.3650, acc=82.66% (best=82.66%)\n",
      "          Fold 3 Epoch 1: loss=0.4638, acc=75.86% (best=75.86%)\n",
      "          Fold 5 Epoch 1: loss=0.5360, acc=48.98% (best=48.98%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 75.39%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 84.53%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9196168d:\n",
      "        Fold accuracies: ['84.53%', '75.39%', '77.58%', '68.91%', '68.67%']\n",
      "        Average fitness: 75.02% Â± 5.91%\n",
      "        Best fold: Fold 1 with 84.53%\n",
      "      Fitness obtained: 75.02% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: a7beac41)\n",
      "      Architecture: 9 conv + 6 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model a7beac41 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6003, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 1: loss=0.6339, acc=38.52% (best=38.52%)\n",
      "          Fold 2 Epoch 1: loss=0.5592, acc=40.62% (best=40.62%)\n",
      "          Fold 5 Epoch 1: loss=0.5470, acc=57.73% (best=57.73%)\n",
      "          Fold 1 Epoch 1: loss=0.5765, acc=63.36% (best=63.36%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 74.22%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 69.61%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 68.36%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a7beac41:\n",
      "        Fold accuracies: ['69.61%', '65.16%', '68.36%', '74.22%', '60.39%']\n",
      "        Average fitness: 67.55% Â± 4.61%\n",
      "        Best fold: Fold 4 with 74.22%\n",
      "      Fitness obtained: 67.55% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 99d663b0)\n",
      "      Architecture: 9 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 99d663b0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 99d663b0:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 10c5b636)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10c5b636 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6971, acc=63.75% (best=63.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6957, acc=54.69% (best=54.69%)\n",
      "          Fold 5 Epoch 1: loss=0.6757, acc=64.06% (best=64.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6705, acc=53.52% (best=53.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6131, acc=76.41% (best=76.41%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.64%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 79.69%\n",
      "          Fold 2 Epoch 30: loss=0.1575, acc=68.12% (best=71.80%)\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 71.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10c5b636:\n",
      "        Fold accuracies: ['76.41%', '71.80%', '86.64%', '79.69%', '66.88%']\n",
      "        Average fitness: 76.28% Â± 6.75%\n",
      "        Best fold: Fold 3 with 86.64%\n",
      "      Fitness obtained: 76.28% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: b62a3bf4)\n",
      "      Architecture: 7 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model b62a3bf4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7068, acc=57.03% (best=57.03%)\n",
      "          Fold 2 Epoch 1: loss=0.7152, acc=53.20% (best=53.20%)\n",
      "          Fold 4 Epoch 1: loss=0.7014, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.6999, acc=48.36% (best=48.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7073, acc=46.95% (best=46.95%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 73.52%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.00%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 75.08%\n",
      "          Fold 2 Epoch 30: loss=0.2107, acc=73.28% (best=78.83%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 78.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b62a3bf4:\n",
      "        Fold accuracies: ['70.08%', '78.83%', '73.52%', '75.08%', '60.00%']\n",
      "        Average fitness: 71.50% Â± 6.40%\n",
      "        Best fold: Fold 2 with 78.83%\n",
      "      Fitness obtained: 71.50% | Best in generation: 76.28% | Global best: 78.39%\n",
      "\n",
      "GENERATION 15 STATISTICS:\n",
      "   Maximum fitness: 76.28%\n",
      "   Average fitness: 64.55%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 17.10%\n",
      "   Best individual: faf10540 with 76.28%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 14/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=17.10)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: faf10540 (fitness: 76.28%)\n",
      "   Elite 2: 10c5b636 (fitness: 76.28%)\n",
      "   Elite 3: 9196168d (fitness: 75.02%)\n",
      "   Elite 4: 08afde9c (fitness: 74.55%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 15/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 16\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 16)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: faf10540)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model faf10540 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6817, acc=62.34% (best=62.34%)\n",
      "          Fold 2 Epoch 1: loss=0.6911, acc=64.14% (best=64.14%)\n",
      "          Fold 5 Epoch 1: loss=0.6558, acc=63.59% (best=63.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6160, acc=84.22% (best=84.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6662, acc=78.75% (best=78.75%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 84.22%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.75%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 64.14%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for faf10540:\n",
      "        Fold accuracies: ['84.22%', '64.14%', '78.75%', '67.11%', '68.75%']\n",
      "        Average fitness: 72.59% Â± 7.61%\n",
      "        Best fold: Fold 1 with 84.22%\n",
      "      New best fitness in this generation: 72.59%!\n",
      "      Fitness obtained: 72.59% | Best in generation: 72.59% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 10c5b636)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 10c5b636 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6902, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6768, acc=64.30% (best=64.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6655, acc=69.61% (best=69.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6384, acc=74.61% (best=74.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6856, acc=71.48% (best=71.48%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 69.61%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 75.94%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.72%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10c5b636:\n",
      "        Fold accuracies: ['75.94%', '66.41%', '86.72%', '63.20%', '69.61%']\n",
      "        Average fitness: 72.38% Â± 8.32%\n",
      "        Best fold: Fold 3 with 86.72%\n",
      "      Fitness obtained: 72.38% | Best in generation: 72.59% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 9196168d)\n",
      "      Architecture: 11 conv + 2 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 9196168d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.2752, acc=66.88% (best=66.88%)\n",
      "          Fold 4 Epoch 1: loss=0.5477, acc=59.45% (best=59.45%)\n",
      "          Fold 3 Epoch 1: loss=0.4268, acc=73.20% (best=73.20%)\n",
      "          Fold 2 Epoch 1: loss=0.4847, acc=46.17% (best=46.17%)\n",
      "          Fold 5 Epoch 1: loss=0.4431, acc=47.81% (best=47.81%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 83.20%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 78.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9196168d:\n",
      "        Fold accuracies: ['83.20%', '73.75%', '78.44%', '69.30%', '64.53%']\n",
      "        Average fitness: 73.84% Â± 6.57%\n",
      "        Best fold: Fold 1 with 83.20%\n",
      "      New best fitness in this generation: 73.84%!\n",
      "      Fitness obtained: 73.84% | Best in generation: 73.84% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 08afde9c)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 08afde9c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6578, acc=78.52% (best=78.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6560, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 1: loss=0.6347, acc=68.12% (best=68.12%)\n",
      "          Fold 5 Epoch 1: loss=0.6463, acc=65.31% (best=65.31%)\n",
      "          Fold 1 Epoch 1: loss=0.5768, acc=78.12% (best=78.12%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.12%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.12%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 69.14%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 93.28%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 08afde9c:\n",
      "        Fold accuracies: ['78.12%', '68.12%', '93.28%', '74.77%', '69.14%']\n",
      "        Average fitness: 76.69% Â± 9.07%\n",
      "        Best fold: Fold 3 with 93.28%\n",
      "      New best fitness in this generation: 76.69%!\n",
      "      Fitness obtained: 76.69% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: c6912c03)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c6912c03 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6230, acc=58.20% (best=58.20%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 67.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c6912c03:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '67.89%']\n",
      "        Average fitness: 13.58% Â± 27.16%\n",
      "        Best fold: Fold 5 with 67.89%\n",
      "      Fitness obtained: 13.58% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: c4db3987)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c4db3987 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5462, acc=59.92% (best=59.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6310, acc=64.06% (best=64.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6504, acc=68.12% (best=68.12%)\n",
      "          Fold 5 Epoch 1: loss=0.6265, acc=50.16% (best=50.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6226, acc=70.62% (best=70.62%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.92%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.12%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.62%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c4db3987:\n",
      "        Fold accuracies: ['59.92%', '70.62%', '64.06%', '68.12%', '53.20%']\n",
      "        Average fitness: 63.19% Â± 6.18%\n",
      "        Best fold: Fold 2 with 70.62%\n",
      "      Fitness obtained: 63.19% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: f6efd8f7)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model f6efd8f7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6867, acc=74.30% (best=74.30%)\n",
      "          Fold 4 Epoch 1: loss=0.7026, acc=59.30% (best=59.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6946, acc=62.73% (best=62.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7136, acc=65.62% (best=65.62%)\n",
      "          Fold 1 Epoch 1: loss=0.6906, acc=59.53% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 74.30%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.78%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 83.59%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 75.94%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 72.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f6efd8f7:\n",
      "        Fold accuracies: ['75.94%', '74.30%', '83.59%', '65.78%', '72.42%']\n",
      "        Average fitness: 74.41% Â± 5.75%\n",
      "        Best fold: Fold 3 with 83.59%\n",
      "      Fitness obtained: 74.41% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: f2028be5)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f2028be5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5768, acc=54.92% (best=54.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6446, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 1: loss=0.6523, acc=53.12% (best=53.12%)\n",
      "          Fold 3 Epoch 1: loss=0.6486, acc=56.02% (best=56.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6541, acc=51.56% (best=51.56%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 55.70%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 79.84%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 76.17%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 65.78%\n",
      "          Fold 4 Epoch 30: loss=0.1647, acc=72.34% (best=76.33%)\n",
      "          Fold 4: Early stopping at epoch 35\n",
      "      â†’ Fold 4 completed: 76.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f2028be5:\n",
      "        Fold accuracies: ['76.17%', '55.70%', '79.84%', '76.33%', '65.78%']\n",
      "        Average fitness: 70.77% Â± 8.88%\n",
      "        Best fold: Fold 3 with 79.84%\n",
      "      Fitness obtained: 70.77% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 5bad4b6c)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 5bad4b6c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6508, acc=86.48% (best=86.48%)\n",
      "          Fold 5 Epoch 1: loss=0.6468, acc=67.11% (best=67.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6687, acc=61.02% (best=61.02%)\n",
      "          Fold 4 Epoch 1: loss=0.6589, acc=66.80% (best=66.80%)\n",
      "          Fold 1 Epoch 1: loss=0.5981, acc=77.11% (best=77.11%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.80%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.48%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 82.89%\n",
      "          Fold 2 Epoch 30: loss=0.1499, acc=73.75% (best=75.08%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 75.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5bad4b6c:\n",
      "        Fold accuracies: ['82.89%', '75.08%', '86.48%', '66.80%', '67.42%']\n",
      "        Average fitness: 75.73% Â± 7.95%\n",
      "        Best fold: Fold 3 with 86.48%\n",
      "      Fitness obtained: 75.73% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: cdbb9d1b)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model cdbb9d1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6887, acc=70.00% (best=70.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6911, acc=63.91% (best=63.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6889, acc=69.30% (best=69.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6810, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6332, acc=71.33% (best=71.33%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 70.00%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 69.30%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 68.59%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 75.00%\n",
      "          Fold 4 Epoch 30: loss=0.1857, acc=71.95% (best=75.94%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 75.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cdbb9d1b:\n",
      "        Fold accuracies: ['75.00%', '68.59%', '69.30%', '75.94%', '70.00%']\n",
      "        Average fitness: 71.77% Â± 3.07%\n",
      "        Best fold: Fold 4 with 75.94%\n",
      "      Fitness obtained: 71.77% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 2f0d899f)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 2f0d899f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.5781, acc=61.95% (best=61.95%)\n",
      "          Fold 4 Epoch 1: loss=0.5954, acc=47.89% (best=47.89%)\n",
      "          Fold 1 Epoch 1: loss=0.3737, acc=53.83% (best=53.83%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 70.16%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2f0d899f:\n",
      "        Fold accuracies: ['75.78%', '0.00%', '72.27%', '70.16%', '0.00%']\n",
      "        Average fitness: 43.64% Â± 35.68%\n",
      "        Best fold: Fold 1 with 75.78%\n",
      "      Fitness obtained: 43.64% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: bdca290e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model bdca290e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6649, acc=62.58% (best=62.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6953, acc=52.66% (best=52.66%)\n",
      "          Fold 3 Epoch 1: loss=0.6584, acc=67.19% (best=67.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6356, acc=69.45% (best=69.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6723, acc=68.12% (best=68.12%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 82.03%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 62.66%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 85.70%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 74.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bdca290e:\n",
      "        Fold accuracies: ['85.70%', '62.66%', '82.03%', '74.30%', '67.42%']\n",
      "        Average fitness: 74.42% Â± 8.63%\n",
      "        Best fold: Fold 1 with 85.70%\n",
      "      Fitness obtained: 74.42% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 65df4c19)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 65df4c19 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6351, acc=55.16% (best=55.16%)\n",
      "          Fold 1 Epoch 1: loss=0.4869, acc=66.41% (best=66.41%)\n",
      "          Fold 3 Epoch 1: loss=0.5992, acc=85.31% (best=85.31%)\n",
      "          Fold 2 Epoch 1: loss=0.6072, acc=55.31% (best=55.31%)\n",
      "          Fold 5 Epoch 1: loss=0.6179, acc=62.66% (best=62.66%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 85.31%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.27%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 72.66%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 63.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 65df4c19:\n",
      "        Fold accuracies: ['72.66%', '63.75%', '85.31%', '62.27%', '62.66%']\n",
      "        Average fitness: 69.33% Â± 8.86%\n",
      "        Best fold: Fold 3 with 85.31%\n",
      "      Fitness obtained: 69.33% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: ddc8d735)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model ddc8d735 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7117, acc=68.52% (best=68.52%)          Fold 5 Epoch 1: loss=0.6970, acc=63.67% (best=63.67%)\n",
      "          Fold 1 Epoch 1: loss=0.6878, acc=61.64% (best=61.64%)\n",
      "\n",
      "          Fold 4 Epoch 1: loss=0.6958, acc=65.23% (best=65.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6987, acc=57.11% (best=57.11%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 85.78%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ddc8d735:\n",
      "        Fold accuracies: ['75.78%', '65.16%', '85.78%', '70.70%', '67.19%']\n",
      "        Average fitness: 72.92% Â± 7.37%\n",
      "        Best fold: Fold 3 with 85.78%\n",
      "      Fitness obtained: 72.92% | Best in generation: 76.69% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 68b150fd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 68b150fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6297, acc=58.12% (best=58.12%)\n",
      "          Fold 3 Epoch 1: loss=0.6237, acc=88.67% (best=88.67%)\n",
      "          Fold 1 Epoch 1: loss=0.6163, acc=71.80% (best=71.80%)\n",
      "          Fold 4 Epoch 1: loss=0.6467, acc=54.92% (best=54.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6413, acc=64.45% (best=64.45%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 88.75%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 85.70%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 71.72%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 2 Epoch 30: loss=0.1581, acc=65.23% (best=71.95%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 68b150fd:\n",
      "        Fold accuracies: ['85.70%', '71.95%', '88.75%', '71.72%', '65.47%']\n",
      "        Average fitness: 76.72% Â± 8.94%\n",
      "        Best fold: Fold 3 with 88.75%\n",
      "      New best fitness in this generation: 76.72%!\n",
      "      Fitness obtained: 76.72% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: c0082812)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c0082812 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6349, acc=51.56% (best=51.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6282, acc=52.58% (best=52.58%)\n",
      "          Fold 3 Epoch 1: loss=0.6323, acc=75.16% (best=75.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6436, acc=65.86% (best=65.86%)\n",
      "          Fold 1 Epoch 1: loss=0.5610, acc=79.30% (best=79.30%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 79.30%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 64.22%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 82.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c0082812:\n",
      "        Fold accuracies: ['79.30%', '64.22%', '82.89%', '65.86%', '63.44%']\n",
      "        Average fitness: 71.14% Â± 8.24%\n",
      "        Best fold: Fold 3 with 82.89%\n",
      "      Fitness obtained: 71.14% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 275f7b79)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 275f7b79 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6859, acc=52.42% (best=52.42%)\n",
      "          Fold 5 Epoch 1: loss=0.6567, acc=58.05% (best=58.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6690, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6075, acc=81.41% (best=81.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6730, acc=85.70% (best=85.70%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 85.70%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 63.20%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.14%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 82.03%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 73.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 275f7b79:\n",
      "        Fold accuracies: ['82.03%', '63.20%', '85.70%', '73.98%', '69.14%']\n",
      "        Average fitness: 74.81% Â± 8.23%\n",
      "        Best fold: Fold 3 with 85.70%\n",
      "      Fitness obtained: 74.81% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 6a7f5ef8)\n",
      "      Architecture: 9 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 6a7f5ef8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6863, acc=62.66% (best=62.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6803, acc=40.31% (best=40.31%)\n",
      "          Fold 3 Epoch 1: loss=0.6806, acc=68.28% (best=68.28%)\n",
      "          Fold 2 Epoch 1: loss=0.6693, acc=62.81% (best=62.81%)\n",
      "          Fold 1 Epoch 1: loss=0.6265, acc=73.75% (best=73.75%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 67.97%\n",
      "          Fold 3 Epoch 30: loss=0.1596, acc=79.84% (best=81.56%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 81.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6a7f5ef8:\n",
      "        Fold accuracies: ['73.75%', '67.97%', '81.56%', '66.88%', '69.84%']\n",
      "        Average fitness: 72.00% Â± 5.32%\n",
      "        Best fold: Fold 3 with 81.56%\n",
      "      Fitness obtained: 72.00% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: a997118c)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model a997118c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6963, acc=58.67% (best=58.67%)\n",
      "          Fold 2 Epoch 1: loss=0.6956, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6991, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6972, acc=50.47% (best=50.47%)\n",
      "          Fold 1 Epoch 1: loss=0.6694, acc=73.44% (best=73.44%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 73.98%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 85.86%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 69.22%\n",
      "          Fold 2 Epoch 30: loss=0.1816, acc=72.81% (best=74.61%)\n",
      "          Fold 2: Early stopping at epoch 50\n",
      "      â†’ Fold 2 completed: 77.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a997118c:\n",
      "        Fold accuracies: ['73.98%', '77.73%', '85.86%', '66.88%', '69.22%']\n",
      "        Average fitness: 74.73% Â± 6.72%\n",
      "        Best fold: Fold 3 with 85.86%\n",
      "      Fitness obtained: 74.73% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 39537cbb)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 39537cbb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5613, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 1: loss=0.5743, acc=56.48% (best=56.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6291, acc=61.33% (best=61.33%)\n",
      "          Fold 1 Epoch 1: loss=0.4580, acc=63.44% (best=63.44%)\n",
      "          Fold 3 Epoch 1: loss=0.5819, acc=55.16% (best=55.16%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 63.44%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 69.77%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 63.52%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 74.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 39537cbb:\n",
      "        Fold accuracies: ['63.44%', '69.77%', '63.59%', '74.38%', '63.52%']\n",
      "        Average fitness: 66.94% Â± 4.44%\n",
      "        Best fold: Fold 4 with 74.38%\n",
      "      Fitness obtained: 66.94% | Best in generation: 76.72% | Global best: 78.39%\n",
      "\n",
      "GENERATION 16 STATISTICS:\n",
      "   Maximum fitness: 76.72%\n",
      "   Average fitness: 68.08%\n",
      "   Minimum fitness: 13.58%\n",
      "   Standard deviation: 14.34%\n",
      "   Best individual: 68b150fd with 76.72%\n",
      "   Global best individual: 1e909e9b with 78.39%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 16/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=14.34)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 68b150fd (fitness: 76.72%)\n",
      "   Elite 2: 08afde9c (fitness: 76.69%)\n",
      "   Elite 3: 5bad4b6c (fitness: 75.73%)\n",
      "   Elite 4: 275f7b79 (fitness: 74.81%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 17/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 17\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 17)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 68b150fd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 68b150fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6292, acc=70.23% (best=70.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6280, acc=62.66% (best=62.66%)\n",
      "          Fold 2 Epoch 1: loss=0.6168, acc=69.92% (best=69.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6206, acc=88.67% (best=88.67%)\n",
      "          Fold 1 Epoch 1: loss=0.5624, acc=75.39% (best=75.39%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.39%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 89.53%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 76.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 68b150fd:\n",
      "        Fold accuracies: ['75.39%', '71.95%', '89.53%', '76.25%', '62.66%']\n",
      "        Average fitness: 75.16% Â± 8.65%\n",
      "        Best fold: Fold 3 with 89.53%\n",
      "      New best fitness in this generation: 75.16%!\n",
      "      Fitness obtained: 75.16% | Best in generation: 75.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 08afde9c)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 08afde9c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6376, acc=67.42% (best=67.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6470, acc=83.67% (best=83.67%)\n",
      "          Fold 5 Epoch 1: loss=0.6433, acc=66.33% (best=66.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6687, acc=71.17% (best=71.17%)\n",
      "          Fold 1 Epoch 1: loss=0.6075, acc=66.72% (best=66.72%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.59%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 86.09%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 71.95%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 74.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 08afde9c:\n",
      "        Fold accuracies: ['74.22%', '68.59%', '86.09%', '71.95%', '67.11%']\n",
      "        Average fitness: 73.59% Â± 6.73%\n",
      "        Best fold: Fold 3 with 86.09%\n",
      "      Fitness obtained: 73.59% | Best in generation: 75.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 5bad4b6c)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 5bad4b6c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6814, acc=67.11% (best=67.11%)\n",
      "          Fold 3 Epoch 1: loss=0.6572, acc=73.20% (best=73.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6636, acc=65.47% (best=65.47%)\n",
      "          Fold 1 Epoch 1: loss=0.6024, acc=70.94% (best=70.94%)\n",
      "          Fold 5 Epoch 1: loss=0.6609, acc=50.31% (best=50.31%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 72.03%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 83.98%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 70.55%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 68.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5bad4b6c:\n",
      "        Fold accuracies: ['72.03%', '70.16%', '83.98%', '68.98%', '70.55%']\n",
      "        Average fitness: 73.14% Â± 5.51%\n",
      "        Best fold: Fold 3 with 83.98%\n",
      "      Fitness obtained: 73.14% | Best in generation: 75.16% | Global best: 78.39%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 275f7b79)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 275f7b79 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6570, acc=66.64% (best=66.64%)\n",
      "          Fold 3 Epoch 1: loss=0.6476, acc=87.89% (best=87.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6697, acc=53.52% (best=53.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6674, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.6575, acc=75.70% (best=75.70%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.91%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 94.45%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.89%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 4 Epoch 30: loss=0.1353, acc=74.61% (best=82.03%)\n",
      "          Fold 4: Early stopping at epoch 53\n",
      "      â†’ Fold 4 completed: 83.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 275f7b79:\n",
      "        Fold accuracies: ['82.89%', '65.86%', '94.45%', '83.91%', '68.91%']\n",
      "        Average fitness: 79.20% Â± 10.51%\n",
      "        Best fold: Fold 3 with 94.45%\n",
      "      New best fitness in this generation: 79.20%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 79.20% > 78.39%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen8_id1e909e9b_fitness78.39.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen17_id275f7b79_fitness79.20.pth\n",
      "        Fitness: 79.20%, ID: 275f7b79, Gen: 17\n",
      "      Fitness obtained: 79.20% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: eb440e5e)\n",
      "      Architecture: 11 conv + 7 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model eb440e5e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6180, acc=48.67% (best=48.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6255, acc=81.80% (best=81.80%)\n",
      "          Fold 1 Epoch 1: loss=0.5707, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6330, acc=37.89% (best=37.89%)\n",
      "          Fold 3 Epoch 1: loss=0.6696, acc=65.23% (best=65.23%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 81.80%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 65.08%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 84.84%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 84.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eb440e5e:\n",
      "        Fold accuracies: ['84.84%', '65.08%', '84.61%', '81.80%', '67.11%']\n",
      "        Average fitness: 76.69% Â± 8.74%\n",
      "        Best fold: Fold 1 with 84.84%\n",
      "      Fitness obtained: 76.69% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 028daab5)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 028daab5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6489, acc=64.14% (best=64.14%)\n",
      "          Fold 5 Epoch 1: loss=0.6540, acc=59.30% (best=59.30%)\n",
      "          Fold 1 Epoch 1: loss=0.6524, acc=67.66% (best=67.66%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 71.48%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 75.08%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 77.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 028daab5:\n",
      "        Fold accuracies: ['77.81%', '75.08%', '0.00%', '0.00%', '71.48%']\n",
      "        Average fitness: 44.88% Â± 36.70%\n",
      "        Best fold: Fold 1 with 77.81%\n",
      "      Fitness obtained: 44.88% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 3686204e)\n",
      "      Architecture: 7 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 3686204e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5977, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 1: loss=0.6048, acc=56.56% (best=56.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5382, acc=69.06% (best=69.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6134, acc=58.28% (best=58.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6111, acc=74.45% (best=74.45%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 78.98%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 73.59%\n",
      "          Fold 2 Epoch 30: loss=0.0917, acc=65.47% (best=67.11%)\n",
      "          Fold 4 Epoch 30: loss=0.0899, acc=67.58% (best=71.02%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "          Fold 4: Early stopping at epoch 38\n",
      "      â†’ Fold 4 completed: 71.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3686204e:\n",
      "        Fold accuracies: ['73.59%', '67.11%', '78.98%', '71.02%', '63.83%']\n",
      "        Average fitness: 70.91% Â± 5.23%\n",
      "        Best fold: Fold 3 with 78.98%\n",
      "      Fitness obtained: 70.91% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: da7659a9)\n",
      "      Architecture: 2 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model da7659a9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.3549, acc=70.62% (best=70.62%)\n",
      "          Fold 4 Epoch 1: loss=0.3604, acc=56.33% (best=56.33%)\n",
      "          Fold 2 Epoch 1: loss=0.3695, acc=66.72% (best=66.72%)\n",
      "          Fold 5 Epoch 1: loss=0.3440, acc=56.25% (best=56.25%)\n",
      "          Fold 1 Epoch 1: loss=0.3221, acc=62.27% (best=62.27%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 58.83%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 70.31%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 72.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for da7659a9:\n",
      "        Fold accuracies: ['70.31%', '66.72%', '72.19%', '58.83%', '60.31%']\n",
      "        Average fitness: 65.67% Â± 5.30%\n",
      "        Best fold: Fold 3 with 72.19%\n",
      "      Fitness obtained: 65.67% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: c82fda95)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model c82fda95 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6794, acc=62.11% (best=62.11%)\n",
      "          Fold 4 Epoch 1: loss=0.7059, acc=57.50% (best=57.50%)\n",
      "          Fold 2 Epoch 1: loss=0.6832, acc=65.16% (best=65.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7663, acc=73.36% (best=73.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7098, acc=59.92% (best=59.92%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 70.70%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.08%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 91.72%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 81.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c82fda95:\n",
      "        Fold accuracies: ['91.72%', '65.16%', '81.64%', '65.08%', '70.70%']\n",
      "        Average fitness: 74.86% Â± 10.37%\n",
      "        Best fold: Fold 1 with 91.72%\n",
      "      Fitness obtained: 74.86% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 451997c5)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 451997c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6381, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 1: loss=0.4818, acc=74.06% (best=74.06%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.06%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 451997c5:\n",
      "        Fold accuracies: ['74.06%', '69.61%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 28.73% Â± 35.22%\n",
      "        Best fold: Fold 1 with 74.06%\n",
      "      Fitness obtained: 28.73% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 7219cd5d)\n",
      "      Architecture: 7 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 7219cd5d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.4811, acc=54.30% (best=54.30%)\n",
      "          Fold 1 Epoch 1: loss=0.4421, acc=64.14% (best=64.14%)\n",
      "          Fold 5 Epoch 1: loss=0.4816, acc=54.53% (best=54.53%)\n",
      "          Fold 2 Epoch 1: loss=0.5111, acc=54.77% (best=54.77%)\n",
      "          Fold 4 Epoch 1: loss=0.5238, acc=72.42% (best=72.42%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.64%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 70.55%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 77.73%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 77.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7219cd5d:\n",
      "        Fold accuracies: ['71.64%', '77.73%', '70.55%', '72.42%', '77.03%']\n",
      "        Average fitness: 73.88% Â± 2.93%\n",
      "        Best fold: Fold 2 with 77.73%\n",
      "      Fitness obtained: 73.88% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 2b6037c5)\n",
      "      Architecture: 9 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 2b6037c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7209, acc=73.91% (best=73.91%)\n",
      "          Fold 5 Epoch 1: loss=0.7196, acc=46.72% (best=46.72%)\n",
      "          Fold 3 Epoch 1: loss=0.7168, acc=48.05% (best=48.05%)\n",
      "          Fold 2 Epoch 1: loss=0.7210, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7179, acc=50.39% (best=50.39%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 73.91%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 73.44%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 64.61%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 66.80%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 87.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2b6037c5:\n",
      "        Fold accuracies: ['73.44%', '66.80%', '87.27%', '73.91%', '64.61%']\n",
      "        Average fitness: 73.20% Â± 7.91%\n",
      "        Best fold: Fold 3 with 87.27%\n",
      "      Fitness obtained: 73.20% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 0303ff0f)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 0303ff0f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5752, acc=66.09% (best=66.09%)\n",
      "          Fold 5 Epoch 1: loss=0.4894, acc=53.12% (best=53.12%)\n",
      "          Fold 3 Epoch 1: loss=0.5292, acc=59.14% (best=59.14%)\n",
      "          Fold 2 Epoch 1: loss=0.5401, acc=73.59% (best=73.59%)\n",
      "          Fold 1 Epoch 1: loss=0.4641, acc=49.84% (best=49.84%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 81.80%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 70.55%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 74.30%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0303ff0f:\n",
      "        Fold accuracies: ['74.30%', '81.80%', '77.42%', '70.55%', '67.27%']\n",
      "        Average fitness: 74.27% Â± 5.09%\n",
      "        Best fold: Fold 2 with 81.80%\n",
      "      Fitness obtained: 74.27% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 7546e659)\n",
      "      Architecture: 2 conv + 1 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 7546e659 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.2884, acc=51.33% (best=51.33%)\n",
      "          Fold 5 Epoch 1: loss=0.2315, acc=57.50% (best=57.50%)\n",
      "          Fold 3 Epoch 1: loss=0.2227, acc=76.02% (best=76.02%)\n",
      "          Fold 2 Epoch 1: loss=0.2781, acc=64.45% (best=64.45%)\n",
      "          Fold 1 Epoch 1: loss=0.1384, acc=72.11% (best=72.11%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.50%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 76.02%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.11%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 65.23%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 54.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7546e659:\n",
      "        Fold accuracies: ['72.11%', '65.23%', '76.02%', '54.92%', '57.50%']\n",
      "        Average fitness: 65.16% Â± 8.12%\n",
      "        Best fold: Fold 3 with 76.02%\n",
      "      Fitness obtained: 65.16% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 17b69912)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 17b69912 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6463, acc=82.58% (best=82.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6360, acc=62.66% (best=62.66%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 84.22%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17b69912:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '84.22%', '74.77%', '0.00%']\n",
      "        Average fitness: 31.80% Â± 39.06%\n",
      "        Best fold: Fold 3 with 84.22%\n",
      "      Fitness obtained: 31.80% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 2b8b105d)\n",
      "      Architecture: 9 conv + 6 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2b8b105d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7101, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7146, acc=48.98% (best=48.98%)\n",
      "          Fold 3 Epoch 1: loss=0.7074, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7138, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7160, acc=50.39% (best=50.39%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 64.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2b8b105d:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '50.39%', '64.14%']\n",
      "        Average fitness: 52.77% Â± 5.72%\n",
      "        Best fold: Fold 5 with 64.14%\n",
      "      Fitness obtained: 52.77% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: cca209e0)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cca209e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5968, acc=53.59% (best=53.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6026, acc=60.16% (best=60.16%)\n",
      "          Fold 3 Epoch 1: loss=0.5970, acc=78.59% (best=78.59%)\n",
      "          Fold 5 Epoch 1: loss=0.6029, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.4853, acc=58.91% (best=58.91%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.59%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 73.67%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 60.39%\n",
      "          Fold 5 Epoch 30: loss=0.1293, acc=63.52% (best=70.39%)\n",
      "          Fold 4 Epoch 30: loss=0.1366, acc=57.81% (best=72.81%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 72.81%\n",
      "      â†’ Fold 5 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cca209e0:\n",
      "        Fold accuracies: ['73.67%', '60.39%', '78.59%', '72.81%', '70.39%']\n",
      "        Average fitness: 71.17% Â± 6.01%\n",
      "        Best fold: Fold 3 with 78.59%\n",
      "      Fitness obtained: 71.17% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: f37d8370)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model f37d8370 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7259, acc=67.27% (best=67.27%)\n",
      "          Fold 5 Epoch 1: loss=0.6950, acc=66.17% (best=66.17%)\n",
      "          Fold 4 Epoch 1: loss=0.7088, acc=64.53% (best=64.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7749, acc=68.67% (best=68.67%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 84.77%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.47%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f37d8370:\n",
      "        Fold accuracies: ['75.47%', '0.00%', '84.77%', '72.42%', '66.17%']\n",
      "        Average fitness: 59.77% Â± 30.48%\n",
      "        Best fold: Fold 3 with 84.77%\n",
      "      Fitness obtained: 59.77% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 480d5328)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 480d5328 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6498, acc=82.42% (best=82.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6549, acc=74.84% (best=74.84%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 83.52%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 81.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 480d5328:\n",
      "        Fold accuracies: ['81.80%', '0.00%', '83.52%', '0.00%', '0.00%']\n",
      "        Average fitness: 33.06% Â± 40.50%\n",
      "        Best fold: Fold 3 with 83.52%\n",
      "      Fitness obtained: 33.06% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 6feea895)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 6feea895 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6421, acc=59.53% (best=59.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6239, acc=64.22% (best=64.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5932, acc=85.62% (best=85.62%)\n",
      "          Fold 5 Epoch 1: loss=0.6476, acc=55.23% (best=55.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6247, acc=76.48% (best=76.48%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 85.62%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 74.45%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 84.84%\n",
      "          Fold 2 Epoch 30: loss=0.1421, acc=73.44% (best=74.45%)\n",
      "          Fold 5 Epoch 30: loss=0.1578, acc=60.47% (best=67.58%)\n",
      "          Fold 5: Early stopping at epoch 34\n",
      "      â†’ Fold 5 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 45\n",
      "      â†’ Fold 2 completed: 76.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6feea895:\n",
      "        Fold accuracies: ['85.62%', '76.72%', '84.84%', '74.45%', '67.58%']\n",
      "        Average fitness: 77.84% Â± 6.75%\n",
      "        Best fold: Fold 1 with 85.62%\n",
      "      Fitness obtained: 77.84% | Best in generation: 79.20% | Global best: 79.20%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 17 STATISTICS:\n",
      "   Maximum fitness: 79.20%\n",
      "   Average fitness: 63.79%\n",
      "   Minimum fitness: 28.73%\n",
      "   Standard deviation: 16.03%\n",
      "   Best individual: 275f7b79 with 79.20%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "ðŸ”„ Improvement detected: 0.81% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=16.03)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 275f7b79 (fitness: 79.20%)\n",
      "   Elite 2: 6feea895 (fitness: 77.84%)\n",
      "   Elite 3: eb440e5e (fitness: 76.69%)\n",
      "   Elite 4: 68b150fd (fitness: 75.16%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 18\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 18)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 275f7b79)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 275f7b79 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6671, acc=50.78% (best=50.78%)\n",
      "          Fold 2 Epoch 1: loss=0.6446, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 1: loss=0.6587, acc=76.80% (best=76.80%)\n",
      "          Fold 5 Epoch 1: loss=0.6556, acc=62.97% (best=62.97%)\n",
      "          Fold 1 Epoch 1: loss=0.6021, acc=75.00% (best=75.00%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 68.91%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 85.16%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 77.66%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 80.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 275f7b79:\n",
      "        Fold accuracies: ['80.16%', '68.52%', '85.16%', '77.66%', '68.91%']\n",
      "        Average fitness: 76.08% Â± 6.48%\n",
      "        Best fold: Fold 3 with 85.16%\n",
      "      New best fitness in this generation: 76.08%!\n",
      "      Fitness obtained: 76.08% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 6feea895)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 6feea895 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6493, acc=77.58% (best=77.58%)\n",
      "          Fold 5 Epoch 1: loss=0.6590, acc=65.78% (best=65.78%)\n",
      "          Fold 2 Epoch 1: loss=0.6533, acc=48.91% (best=48.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6377, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5613, acc=67.34% (best=67.34%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 77.66%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 74.14%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 64.30%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6feea895:\n",
      "        Fold accuracies: ['74.14%', '64.30%', '77.58%', '77.66%', '68.36%']\n",
      "        Average fitness: 72.41% Â± 5.28%\n",
      "        Best fold: Fold 4 with 77.66%\n",
      "      Fitness obtained: 72.41% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: eb440e5e)\n",
      "      Architecture: 11 conv + 7 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model eb440e5e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6404, acc=66.64% (best=66.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6754, acc=63.12% (best=63.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6472, acc=75.78% (best=75.78%)\n",
      "          Fold 3 Epoch 1: loss=0.6733, acc=70.86% (best=70.86%)\n",
      "          Fold 1 Epoch 1: loss=0.6450, acc=61.09% (best=61.09%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 75.78%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 78.20%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 80.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eb440e5e:\n",
      "        Fold accuracies: ['67.58%', '78.20%', '80.70%', '75.78%', '63.12%']\n",
      "        Average fitness: 73.08% Â± 6.65%\n",
      "        Best fold: Fold 3 with 80.70%\n",
      "      Fitness obtained: 73.08% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 68b150fd)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 68b150fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6424, acc=67.66% (best=67.66%)          Fold 2 Epoch 1: loss=0.6328, acc=65.00% (best=65.00%)\n",
      "\n",
      "          Fold 5 Epoch 1: loss=0.6714, acc=61.64% (best=61.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6414, acc=62.73% (best=62.73%)\n",
      "          Fold 1 Epoch 1: loss=0.5592, acc=78.67% (best=78.67%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.67%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 72.50%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 72.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 68b150fd:\n",
      "        Fold accuracies: ['78.67%', '65.00%', '72.50%', '72.50%', '62.81%']\n",
      "        Average fitness: 70.30% Â± 5.73%\n",
      "        Best fold: Fold 1 with 78.67%\n",
      "      Fitness obtained: 70.30% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 33a21c36)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 33a21c36 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6704, acc=68.52% (best=68.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6439, acc=55.78% (best=55.78%)\n",
      "          Fold 2 Epoch 1: loss=0.6568, acc=59.69% (best=59.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6776, acc=71.17% (best=71.17%)\n",
      "          Fold 1 Epoch 1: loss=0.6333, acc=71.88% (best=71.88%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.52%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 77.81%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 74.61%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 65.86%\n",
      "          Fold 2 Epoch 30: loss=0.1658, acc=66.95% (best=68.52%)\n",
      "          Fold 2: Early stopping at epoch 50\n",
      "      â†’ Fold 2 completed: 72.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 33a21c36:\n",
      "        Fold accuracies: ['77.81%', '72.19%', '74.61%', '68.52%', '65.86%']\n",
      "        Average fitness: 71.80% Â± 4.25%\n",
      "        Best fold: Fold 1 with 77.81%\n",
      "      Fitness obtained: 71.80% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 781fb585)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 781fb585 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6644, acc=76.48% (best=76.48%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 76.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 781fb585:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '76.48%', '0.00%', '0.00%']\n",
      "        Average fitness: 15.30% Â± 30.59%\n",
      "        Best fold: Fold 3 with 76.48%\n",
      "      Fitness obtained: 15.30% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 69e86422)\n",
      "      Architecture: 7 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 69e86422 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.3707, acc=62.11% (best=62.11%)\n",
      "          Fold 5 Epoch 1: loss=0.4156, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.3118, acc=68.75% (best=68.75%)\n",
      "          Fold 2 Epoch 1: loss=0.4811, acc=55.62% (best=55.62%)\n",
      "          Fold 4 Epoch 1: loss=0.4712, acc=61.41% (best=61.41%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.75%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 71.95%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 72.89%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 70.47%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 63.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 69e86422:\n",
      "        Fold accuracies: ['68.75%', '70.47%', '71.95%', '72.89%', '63.05%']\n",
      "        Average fitness: 69.42% Â± 3.48%\n",
      "        Best fold: Fold 4 with 72.89%\n",
      "      Fitness obtained: 69.42% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 262c63a1)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 262c63a1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6798, acc=64.06% (best=64.06%)\n",
      "          Fold 3 Epoch 1: loss=0.6845, acc=75.55% (best=75.55%)\n",
      "          Fold 5 Epoch 1: loss=0.6389, acc=57.19% (best=57.19%)\n",
      "          Fold 4 Epoch 1: loss=0.6850, acc=51.09% (best=51.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6908, acc=68.98% (best=68.98%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 64.06%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.34%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 80.78%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 262c63a1:\n",
      "        Fold accuracies: ['71.56%', '64.06%', '80.78%', '63.44%', '62.34%']\n",
      "        Average fitness: 68.44% Â± 6.98%\n",
      "        Best fold: Fold 3 with 80.78%\n",
      "      Fitness obtained: 68.44% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 5f52070b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 5f52070b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4027, acc=53.12% (best=53.12%)\n",
      "          Fold 5 Epoch 1: loss=0.5090, acc=62.19% (best=62.19%)\n",
      "          Fold 4 Epoch 1: loss=0.4994, acc=57.89% (best=57.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5254, acc=54.30% (best=54.30%)\n",
      "          Fold 2 Epoch 1: loss=0.5529, acc=64.14% (best=64.14%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 77.89%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 81.88%\n",
      "          Fold 4 Epoch 30: loss=0.0718, acc=57.89% (best=68.44%)\n",
      "          Fold 2 Epoch 30: loss=0.0737, acc=53.52% (best=72.50%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 72.50%\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5f52070b:\n",
      "        Fold accuracies: ['81.88%', '72.50%', '77.89%', '68.44%', '62.19%']\n",
      "        Average fitness: 72.58% Â± 6.92%\n",
      "        Best fold: Fold 1 with 81.88%\n",
      "      Fitness obtained: 72.58% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 0f175044)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 0f175044 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7090, acc=75.23% (best=75.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6757, acc=56.95% (best=56.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6691, acc=64.38% (best=64.38%)\n",
      "          Fold 1 Epoch 1: loss=0.6080, acc=73.59% (best=73.59%)\n",
      "          Fold 5 Epoch 1: loss=0.6758, acc=63.59% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 78.75%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 65.23%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 75.86%\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 78.28%\n",
      "          Fold 2 Epoch 30: loss=0.1735, acc=69.77% (best=77.27%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 77.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0f175044:\n",
      "        Fold accuracies: ['78.28%', '77.27%', '78.75%', '75.86%', '65.23%']\n",
      "        Average fitness: 75.08% Â± 5.02%\n",
      "        Best fold: Fold 3 with 78.75%\n",
      "      Fitness obtained: 75.08% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: db6b453a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model db6b453a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5808, acc=76.41% (best=76.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6558, acc=79.14% (best=79.14%)\n",
      "          Fold 2 Epoch 1: loss=0.6451, acc=62.42% (best=62.42%)\n",
      "          Fold 5 Epoch 1: loss=0.6505, acc=62.97% (best=62.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6714, acc=58.36% (best=58.36%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.14%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 61.80%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 67.66%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 74.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for db6b453a:\n",
      "        Fold accuracies: ['76.41%', '74.30%', '79.14%', '61.80%', '67.66%']\n",
      "        Average fitness: 71.86% Â± 6.30%\n",
      "        Best fold: Fold 3 with 79.14%\n",
      "      Fitness obtained: 71.86% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: d2b19408)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d2b19408 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5119, acc=63.75% (best=63.75%)\n",
      "          Fold 3 Epoch 1: loss=0.5141, acc=75.31% (best=75.31%)\n",
      "          Fold 5 Epoch 1: loss=0.4642, acc=46.41% (best=46.41%)\n",
      "          Fold 1 Epoch 1: loss=0.3897, acc=48.36% (best=48.36%)\n",
      "          Fold 4 Epoch 1: loss=0.5541, acc=51.17% (best=51.17%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.27%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 70.62%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 63.36%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 82.50%\n",
      "          Fold 4 Epoch 30: loss=0.0735, acc=64.92% (best=73.36%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d2b19408:\n",
      "        Fold accuracies: ['63.36%', '70.62%', '82.50%', '73.36%', '57.27%']\n",
      "        Average fitness: 69.42% Â± 8.63%\n",
      "        Best fold: Fold 3 with 82.50%\n",
      "      Fitness obtained: 69.42% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 8ca920b9)\n",
      "      Architecture: 9 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 8ca920b9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7272, acc=43.36% (best=43.36%)\n",
      "          Fold 4 Epoch 1: loss=0.7671, acc=52.34% (best=52.34%)\n",
      "          Fold 3 Epoch 1: loss=0.7486, acc=36.09% (best=36.09%)\n",
      "          Fold 5 Epoch 1: loss=0.7328, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=0.7500, acc=50.31% (best=50.31%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 53.52%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 61.17%\n",
      "          Fold 1 Epoch 30: loss=0.6584, acc=69.22% (best=75.16%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 75.16%\n",
      "          Fold 5 Epoch 30: loss=0.6813, acc=52.73% (best=59.84%)\n",
      "          Fold 3 Epoch 30: loss=0.6958, acc=59.22% (best=62.11%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 59.84%\n",
      "          Fold 3 Epoch 60: loss=0.6690, acc=69.38% (best=69.61%)\n",
      "          Fold 3: Early stopping at epoch 71\n",
      "      â†’ Fold 3 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8ca920b9:\n",
      "        Fold accuracies: ['75.16%', '61.17%', '71.17%', '53.52%', '59.84%']\n",
      "        Average fitness: 64.17% Â± 7.89%\n",
      "        Best fold: Fold 1 with 75.16%\n",
      "      Fitness obtained: 64.17% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 92c01080)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 92c01080 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6715, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6659, acc=79.14% (best=79.14%)\n",
      "          Fold 2 Epoch 1: loss=0.6574, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6877, acc=48.36% (best=48.36%)\n",
      "          Fold 1 Epoch 1: loss=0.6264, acc=76.17% (best=76.17%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.14%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 78.05%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 70.08%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 61.33%\n",
      "          Fold 4 Epoch 30: loss=0.1662, acc=65.78% (best=72.73%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 72.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 92c01080:\n",
      "        Fold accuracies: ['78.05%', '61.33%', '79.14%', '72.73%', '70.08%']\n",
      "        Average fitness: 72.27% Â± 6.41%\n",
      "        Best fold: Fold 3 with 79.14%\n",
      "      Fitness obtained: 72.27% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: f2a70bfc)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f2a70bfc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for f2a70bfc:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: a374cabe)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model a374cabe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7091, acc=63.59% (best=63.59%)          Fold 3 Epoch 1: loss=0.7236, acc=52.81% (best=52.81%)\n",
      "\n",
      "          Fold 5 Epoch 1: loss=0.7034, acc=62.03% (best=62.03%)\n",
      "          Fold 4 Epoch 1: loss=0.6800, acc=55.94% (best=55.94%)\n",
      "          Fold 1 Epoch 1: loss=0.6667, acc=69.92% (best=69.92%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 76.33%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 65.16%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 74.92%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 84.69%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a374cabe:\n",
      "        Fold accuracies: ['76.33%', '74.92%', '84.69%', '69.30%', '65.16%']\n",
      "        Average fitness: 74.08% Â± 6.65%\n",
      "        Best fold: Fold 3 with 84.69%\n",
      "      Fitness obtained: 74.08% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 29eb0d2a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 29eb0d2a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6508, acc=79.77% (best=79.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6539, acc=66.25% (best=66.25%)\n",
      "          Fold 1 Epoch 1: loss=0.6073, acc=72.89% (best=72.89%)\n",
      "          Fold 5 Epoch 1: loss=0.6476, acc=60.62% (best=60.62%)\n",
      "          Fold 2 Epoch 1: loss=0.6463, acc=56.41% (best=56.41%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.89%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 78.83%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "          Fold 2 Epoch 30: loss=0.1471, acc=70.00% (best=70.70%)\n",
      "          Fold 2: Early stopping at epoch 49\n",
      "      â†’ Fold 2 completed: 72.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 29eb0d2a:\n",
      "        Fold accuracies: ['72.89%', '72.03%', '79.77%', '78.83%', '69.84%']\n",
      "        Average fitness: 74.67% Â± 3.92%\n",
      "        Best fold: Fold 3 with 79.77%\n",
      "      Fitness obtained: 74.67% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 15ed59ab)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 15ed59ab with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6541, acc=65.47% (best=65.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6282, acc=64.38% (best=64.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6395, acc=74.84% (best=74.84%)\n",
      "          Fold 1 Epoch 1: loss=0.5504, acc=70.47% (best=70.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6175, acc=53.20% (best=53.20%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.47%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 91.80%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 69.92%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 72.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15ed59ab:\n",
      "        Fold accuracies: ['70.47%', '67.34%', '91.80%', '72.66%', '69.92%']\n",
      "        Average fitness: 74.44% Â± 8.84%\n",
      "        Best fold: Fold 3 with 91.80%\n",
      "      Fitness obtained: 74.44% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 84d74ba1)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 84d74ba1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.5807, acc=57.97% (best=57.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6235, acc=66.09% (best=66.09%)\n",
      "          Fold 1 Epoch 1: loss=0.5400, acc=66.02% (best=66.02%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 80.94%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 84d74ba1:\n",
      "        Fold accuracies: ['74.77%', '0.00%', '0.00%', '80.94%', '65.62%']\n",
      "        Average fitness: 44.27% Â± 36.47%\n",
      "        Best fold: Fold 4 with 80.94%\n",
      "      Fitness obtained: 44.27% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 474370ed)\n",
      "      Architecture: 7 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 474370ed with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6731, acc=61.33% (best=61.33%)\n",
      "          Fold 2 Epoch 1: loss=0.6654, acc=63.98% (best=63.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6823, acc=78.98% (best=78.98%)\n",
      "          Fold 5 Epoch 1: loss=0.6951, acc=62.03% (best=62.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6510, acc=76.02% (best=76.02%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.11%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 79.84%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 76.64%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 75.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 474370ed:\n",
      "        Fold accuracies: ['76.64%', '65.16%', '79.84%', '75.78%', '62.11%']\n",
      "        Average fitness: 71.91% Â± 6.96%\n",
      "        Best fold: Fold 3 with 79.84%\n",
      "      Fitness obtained: 71.91% | Best in generation: 76.08% | Global best: 79.20%\n",
      "\n",
      "GENERATION 18 STATISTICS:\n",
      "   Maximum fitness: 76.08%\n",
      "   Average fitness: 64.08%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 20.06%\n",
      "   Best individual: 275f7b79 with 76.08%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=20.06)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 275f7b79 (fitness: 76.08%)\n",
      "   Elite 2: 0f175044 (fitness: 75.08%)\n",
      "   Elite 3: 29eb0d2a (fitness: 74.67%)\n",
      "   Elite 4: 15ed59ab (fitness: 74.44%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 19\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 19)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 275f7b79)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 275f7b79 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6384, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6632, acc=60.08% (best=60.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6651, acc=79.92% (best=79.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6558, acc=57.66% (best=57.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6112, acc=79.38% (best=79.38%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 79.38%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 85.55%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.67%\n",
      "          Fold 4 Epoch 30: loss=0.1450, acc=78.67% (best=80.31%)\n",
      "          Fold 2 Epoch 30: loss=0.1391, acc=62.81% (best=69.84%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 80.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 275f7b79:\n",
      "        Fold accuracies: ['79.38%', '69.84%', '85.55%', '80.31%', '63.67%']\n",
      "        Average fitness: 75.75% Â± 7.88%\n",
      "        Best fold: Fold 3 with 85.55%\n",
      "      New best fitness in this generation: 75.75%!\n",
      "      Fitness obtained: 75.75% | Best in generation: 75.75% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 0f175044)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 0f175044 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6755, acc=56.25% (best=56.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6969, acc=85.16% (best=85.16%)\n",
      "          Fold 5 Epoch 1: loss=0.6694, acc=68.98% (best=68.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6828, acc=64.92% (best=64.92%)\n",
      "          Fold 1 Epoch 1: loss=0.6719, acc=76.88% (best=76.88%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 68.98%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 93.12%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 81.56%\n",
      "          Fold 1 Epoch 30: loss=0.0328, acc=76.80% (best=82.11%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 82.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0f175044:\n",
      "        Fold accuracies: ['82.11%', '67.34%', '93.12%', '81.56%', '68.98%']\n",
      "        Average fitness: 78.62% Â± 9.50%\n",
      "        Best fold: Fold 3 with 93.12%\n",
      "      New best fitness in this generation: 78.62%!\n",
      "      Fitness obtained: 78.62% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 29eb0d2a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 29eb0d2a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6512, acc=82.11% (best=82.11%)\n",
      "          Fold 5 Epoch 1: loss=0.6384, acc=61.56% (best=61.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6490, acc=66.25% (best=66.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6565, acc=58.28% (best=58.28%)\n",
      "          Fold 1 Epoch 1: loss=0.5826, acc=80.31% (best=80.31%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 80.31%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 82.11%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.86%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 29eb0d2a:\n",
      "        Fold accuracies: ['80.31%', '70.86%', '82.11%', '68.91%', '68.75%']\n",
      "        Average fitness: 74.19% Â± 5.81%\n",
      "        Best fold: Fold 3 with 82.11%\n",
      "      Fitness obtained: 74.19% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 15ed59ab)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 15ed59ab with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6244, acc=51.88% (best=51.88%)\n",
      "          Fold 2 Epoch 1: loss=0.6095, acc=44.53% (best=44.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6325, acc=59.61% (best=59.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6227, acc=74.53% (best=74.53%)\n",
      "          Fold 1 Epoch 1: loss=0.5368, acc=74.61% (best=74.61%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 82.19%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 75.31%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 58.98%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 66.33%\n",
      "          Fold 1 Epoch 30: loss=0.0065, acc=76.95% (best=82.34%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 82.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15ed59ab:\n",
      "        Fold accuracies: ['82.34%', '58.98%', '82.19%', '75.31%', '66.33%']\n",
      "        Average fitness: 73.03% Â± 9.14%\n",
      "        Best fold: Fold 1 with 82.34%\n",
      "      Fitness obtained: 73.03% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: ad32241e)\n",
      "      Architecture: 9 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model ad32241e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7123, acc=65.39% (best=65.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7222, acc=54.06% (best=54.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7307, acc=35.94% (best=35.94%)\n",
      "          Fold 4 Epoch 1: loss=0.7333, acc=43.44% (best=43.44%)\n",
      "          Fold 5 Epoch 1: loss=0.8011, acc=51.02% (best=51.02%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 51.64%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 69.38%\n",
      "          Fold 1 Epoch 30: loss=0.6658, acc=71.72% (best=73.28%)\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 66.25%\n",
      "          Fold 3 Epoch 30: loss=0.6990, acc=60.00% (best=60.94%)\n",
      "          Fold 1 Epoch 60: loss=0.6339, acc=79.22% (best=81.17%)\n",
      "          Fold 3 Epoch 60: loss=0.6753, acc=61.88% (best=65.94%)\n",
      "          Fold 3: Early stopping at epoch 65\n",
      "      â†’ Fold 3 completed: 65.94%\n",
      "          Fold 1: Early stopping at epoch 71\n",
      "      â†’ Fold 1 completed: 85.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ad32241e:\n",
      "        Fold accuracies: ['85.08%', '69.38%', '65.94%', '66.25%', '51.64%']\n",
      "        Average fitness: 67.66% Â± 10.66%\n",
      "        Best fold: Fold 1 with 85.08%\n",
      "      Fitness obtained: 67.66% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 73144237)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 73144237 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6710, acc=70.47% (best=70.47%)\n",
      "          Fold 4 Epoch 1: loss=0.7040, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6885, acc=57.73% (best=57.73%)\n",
      "          Fold 2 Epoch 1: loss=0.6746, acc=70.70% (best=70.70%)\n",
      "          Fold 1 Epoch 1: loss=0.6497, acc=71.64% (best=71.64%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 76.02%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 72.34%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 80.47%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 73.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 73144237:\n",
      "        Fold accuracies: ['76.02%', '72.34%', '80.47%', '73.12%', '73.59%']\n",
      "        Average fitness: 75.11% Â± 2.95%\n",
      "        Best fold: Fold 3 with 80.47%\n",
      "      Fitness obtained: 75.11% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: a01496f9)\n",
      "      Architecture: 9 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model a01496f9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7030, acc=51.25% (best=51.25%)\n",
      "          Fold 4 Epoch 1: loss=0.7126, acc=54.92% (best=54.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7141, acc=71.33% (best=71.33%)\n",
      "          Fold 5 Epoch 1: loss=0.7173, acc=61.25% (best=61.25%)\n",
      "          Fold 2 Epoch 1: loss=0.7091, acc=62.50% (best=62.50%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 83.59%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 79.14%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 71.88%\n",
      "          Fold 5 Epoch 30: loss=0.2225, acc=55.47% (best=65.86%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 65.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a01496f9:\n",
      "        Fold accuracies: ['83.59%', '68.83%', '79.14%', '71.88%', '65.86%']\n",
      "        Average fitness: 73.86% Â± 6.57%\n",
      "        Best fold: Fold 1 with 83.59%\n",
      "      Fitness obtained: 73.86% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: b80e7757)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b80e7757 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6802, acc=59.38% (best=59.38%)\n",
      "          Fold 4 Epoch 1: loss=0.6905, acc=62.19% (best=62.19%)\n",
      "          Fold 2 Epoch 1: loss=0.6968, acc=45.86% (best=45.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7048, acc=60.70% (best=60.70%)\n",
      "          Fold 1 Epoch 1: loss=0.7251, acc=44.84% (best=44.84%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 77.34%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 64.84%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 84.77%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 4: Early stopping at epoch 29\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b80e7757:\n",
      "        Fold accuracies: ['77.34%', '64.84%', '84.77%', '71.17%', '63.75%']\n",
      "        Average fitness: 72.38% Â± 7.88%\n",
      "        Best fold: Fold 3 with 84.77%\n",
      "      Fitness obtained: 72.38% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 9fdc0c87)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 9fdc0c87 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.4848, acc=82.73% (best=82.73%)\n",
      "          Fold 5 Epoch 1: loss=0.4523, acc=47.89% (best=47.89%)\n",
      "          Fold 1 Epoch 1: loss=0.2848, acc=68.28% (best=68.28%)\n",
      "          Fold 2 Epoch 1: loss=0.4953, acc=60.86% (best=60.86%)\n",
      "          Fold 4 Epoch 1: loss=0.4963, acc=74.06% (best=74.06%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 82.73%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.53%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 69.06%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 75.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fdc0c87:\n",
      "        Fold accuracies: ['77.11%', '69.06%', '82.73%', '75.86%', '59.53%']\n",
      "        Average fitness: 72.86% Â± 7.96%\n",
      "        Best fold: Fold 3 with 82.73%\n",
      "      Fitness obtained: 72.86% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 4edf27e0)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4edf27e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6275, acc=88.05% (best=88.05%)\n",
      "          Fold 2 Epoch 1: loss=0.5737, acc=58.91% (best=58.91%)\n",
      "          Fold 1 Epoch 1: loss=0.5187, acc=65.08% (best=65.08%)\n",
      "          Fold 4 Epoch 1: loss=0.6124, acc=65.31% (best=65.31%)\n",
      "          Fold 5 Epoch 1: loss=0.5871, acc=62.03% (best=62.03%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 89.69%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 78.44%\n",
      "          Fold 2 Epoch 30: loss=0.1303, acc=64.77% (best=71.95%)\n",
      "          Fold 1 Epoch 30: loss=0.0127, acc=77.97% (best=79.22%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 79.22%\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4edf27e0:\n",
      "        Fold accuracies: ['79.22%', '71.95%', '89.69%', '78.44%', '64.77%']\n",
      "        Average fitness: 76.81% Â± 8.28%\n",
      "        Best fold: Fold 3 with 89.69%\n",
      "      Fitness obtained: 76.81% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: af6c6a9d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model af6c6a9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6573, acc=55.47% (best=55.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6561, acc=45.94% (best=45.94%)\n",
      "          Fold 3 Epoch 1: loss=0.6337, acc=39.92% (best=39.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6222, acc=56.56% (best=56.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5328, acc=71.17% (best=71.17%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 71.17%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 70.70%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 79.84%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 4 Epoch 30: loss=0.1592, acc=65.47% (best=73.12%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for af6c6a9d:\n",
      "        Fold accuracies: ['71.17%', '68.91%', '79.84%', '73.12%', '70.70%']\n",
      "        Average fitness: 72.75% Â± 3.79%\n",
      "        Best fold: Fold 3 with 79.84%\n",
      "      Fitness obtained: 72.75% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 198cfb76)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 198cfb76 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6021, acc=53.20% (best=53.20%)\n",
      "          Fold 1 Epoch 1: loss=0.5630, acc=80.62% (best=80.62%)\n",
      "          Fold 3 Epoch 1: loss=0.6109, acc=67.89% (best=67.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6341, acc=63.91% (best=63.91%)\n",
      "          Fold 5 Epoch 1: loss=0.6126, acc=51.56% (best=51.56%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 72.81%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 87.89%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 68.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 198cfb76:\n",
      "        Fold accuracies: ['87.89%', '68.28%', '72.81%', '68.83%', '66.88%']\n",
      "        Average fitness: 72.94% Â± 7.73%\n",
      "        Best fold: Fold 1 with 87.89%\n",
      "      Fitness obtained: 72.94% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 71b1a810)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 71b1a810 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4023, acc=64.77% (best=64.77%)\n",
      "          Fold 3 Epoch 1: loss=0.4938, acc=55.47% (best=55.47%)\n",
      "          Fold 2 Epoch 1: loss=0.5156, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 1: loss=0.5309, acc=56.41% (best=56.41%)\n",
      "          Fold 5 Epoch 1: loss=0.4728, acc=57.03% (best=57.03%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 71.56%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 75.47%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 67.03%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 59.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 71b1a810:\n",
      "        Fold accuracies: ['67.03%', '75.47%', '70.16%', '71.56%', '59.77%']\n",
      "        Average fitness: 68.80% Â± 5.27%\n",
      "        Best fold: Fold 2 with 75.47%\n",
      "      Fitness obtained: 68.80% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 4c7ef8e3)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 4c7ef8e3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6359, acc=84.06% (best=84.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6293, acc=59.14% (best=59.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6583, acc=68.59% (best=68.59%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 74.06%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 86.56%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 70.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4c7ef8e3:\n",
      "        Fold accuracies: ['0.00%', '70.70%', '86.56%', '74.06%', '0.00%']\n",
      "        Average fitness: 46.27% Â± 38.14%\n",
      "        Best fold: Fold 3 with 86.56%\n",
      "      Fitness obtained: 46.27% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 50031305)\n",
      "      Architecture: 11 conv + 7 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 50031305 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.5908, acc=62.97% (best=62.97%)\n",
      "          Fold 1 Epoch 1: loss=0.5438, acc=64.77% (best=64.77%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 68.91%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 66.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 50031305:\n",
      "        Fold accuracies: ['68.91%', '0.00%', '0.00%', '0.00%', '66.64%']\n",
      "        Average fitness: 27.11% Â± 33.21%\n",
      "        Best fold: Fold 1 with 68.91%\n",
      "      Fitness obtained: 27.11% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: f3d93678)\n",
      "      Architecture: 11 conv + 7 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model f3d93678 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7188, acc=80.70% (best=80.70%)\n",
      "          Fold 2 Epoch 1: loss=0.6930, acc=42.19% (best=42.19%)\n",
      "          Fold 1 Epoch 1: loss=0.5697, acc=71.09% (best=71.09%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.70%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.12%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 74.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f3d93678:\n",
      "        Fold accuracies: ['78.12%', '74.53%', '80.70%', '0.00%', '0.00%']\n",
      "        Average fitness: 46.67% Â± 38.16%\n",
      "        Best fold: Fold 3 with 80.70%\n",
      "      Fitness obtained: 46.67% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 927c919f)\n",
      "      Architecture: 9 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 927c919f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7010, acc=65.31% (best=65.31%)\n",
      "          Fold 2 Epoch 1: loss=0.6830, acc=66.64% (best=66.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6918, acc=59.53% (best=59.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6766, acc=65.00% (best=65.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7071, acc=62.19% (best=62.19%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 80.00%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 75.00%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 85.62%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 75.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 927c919f:\n",
      "        Fold accuracies: ['80.00%', '75.00%', '85.62%', '75.47%', '63.20%']\n",
      "        Average fitness: 75.86% Â± 7.40%\n",
      "        Best fold: Fold 3 with 85.62%\n",
      "      Fitness obtained: 75.86% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 97eade09)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 97eade09 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6333, acc=50.86% (best=50.86%)\n",
      "          Fold 3 Epoch 1: loss=0.6164, acc=79.77% (best=79.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6068, acc=62.66% (best=62.66%)\n",
      "          Fold 1 Epoch 1: loss=0.5196, acc=61.02% (best=61.02%)\n",
      "          Fold 2 Epoch 1: loss=0.5920, acc=51.17% (best=51.17%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 64.14%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 72.34%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 71.41%\n",
      "          Fold 1 Epoch 30: loss=0.0042, acc=73.67% (best=79.61%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 79.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 97eade09:\n",
      "        Fold accuracies: ['79.61%', '71.41%', '79.77%', '72.34%', '64.14%']\n",
      "        Average fitness: 73.45% Â± 5.83%\n",
      "        Best fold: Fold 3 with 79.77%\n",
      "      Fitness obtained: 73.45% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4e51f170)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4e51f170 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6013, acc=80.62% (best=80.62%)\n",
      "          Fold 2 Epoch 1: loss=0.5799, acc=42.89% (best=42.89%)\n",
      "          Fold 5 Epoch 1: loss=0.6072, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 1: loss=0.5900, acc=55.62% (best=55.62%)\n",
      "          Fold 1 Epoch 1: loss=0.5270, acc=67.81% (best=67.81%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.62%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 67.81%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 58.44%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 60.47%\n",
      "          Fold 4 Epoch 30: loss=0.0962, acc=65.31% (best=68.91%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4e51f170:\n",
      "        Fold accuracies: ['67.81%', '58.44%', '80.62%', '68.91%', '60.47%']\n",
      "        Average fitness: 67.25% Â± 7.82%\n",
      "        Best fold: Fold 3 with 80.62%\n",
      "      Fitness obtained: 67.25% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 02c48d8e)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 02c48d8e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5013, acc=78.67% (best=78.67%)\n",
      "          Fold 4 Epoch 1: loss=0.3941, acc=69.84% (best=69.84%)\n",
      "          Fold 2 Epoch 1: loss=0.4673, acc=66.64% (best=66.64%)\n",
      "          Fold 1 Epoch 1: loss=0.2800, acc=68.44% (best=68.44%)\n",
      "          Fold 5 Epoch 1: loss=0.4710, acc=46.48% (best=46.48%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.64%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.44%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 89.77%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 02c48d8e:\n",
      "        Fold accuracies: ['68.44%', '66.64%', '89.77%', '77.42%', '61.48%']\n",
      "        Average fitness: 72.75% Â± 9.94%\n",
      "        Best fold: Fold 3 with 89.77%\n",
      "      Fitness obtained: 72.75% | Best in generation: 78.62% | Global best: 79.20%\n",
      "\n",
      "GENERATION 19 STATISTICS:\n",
      "   Maximum fitness: 78.62%\n",
      "   Average fitness: 68.21%\n",
      "   Minimum fitness: 27.11%\n",
      "   Standard deviation: 12.65%\n",
      "   Best individual: 0f175044 with 78.62%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=12.65)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 0f175044 (fitness: 78.62%)\n",
      "   Elite 2: 4edf27e0 (fitness: 76.81%)\n",
      "   Elite 3: 927c919f (fitness: 75.86%)\n",
      "   Elite 4: 275f7b79 (fitness: 75.75%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 20\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 20)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 0f175044)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 0f175044 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6761, acc=82.03% (best=82.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6943, acc=48.44% (best=48.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6845, acc=62.97% (best=62.97%)\n",
      "          Fold 2 Epoch 1: loss=0.6678, acc=62.66% (best=62.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6198, acc=80.94% (best=80.94%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 80.94%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 90.00%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 76.17%\n",
      "          Fold 4 Epoch 30: loss=0.1895, acc=73.44% (best=76.48%)\n",
      "          Fold 4: Early stopping at epoch 50\n",
      "      â†’ Fold 4 completed: 78.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0f175044:\n",
      "        Fold accuracies: ['80.94%', '76.17%', '90.00%', '78.52%', '63.83%']\n",
      "        Average fitness: 77.89% Â± 8.45%\n",
      "        Best fold: Fold 3 with 90.00%\n",
      "      New best fitness in this generation: 77.89%!\n",
      "      Fitness obtained: 77.89% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 4edf27e0)\n",
      "      Architecture: 8 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4edf27e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6147, acc=80.08% (best=80.08%)\n",
      "          Fold 1 Epoch 1: loss=0.4999, acc=65.16% (best=65.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6222, acc=61.56% (best=61.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6073, acc=63.59% (best=63.59%)\n",
      "          Fold 5 Epoch 1: loss=0.6153, acc=56.41% (best=56.41%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 80.08%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 70.86%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 72.11%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4edf27e0:\n",
      "        Fold accuracies: ['70.86%', '65.39%', '80.08%', '72.11%', '68.83%']\n",
      "        Average fitness: 71.45% Â± 4.87%\n",
      "        Best fold: Fold 3 with 80.08%\n",
      "      Fitness obtained: 71.45% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 927c919f)\n",
      "      Architecture: 9 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 927c919f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7048, acc=64.69% (best=64.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6926, acc=62.34% (best=62.34%)\n",
      "          Fold 1 Epoch 1: loss=0.6732, acc=77.58% (best=77.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6893, acc=56.17% (best=56.17%)\n",
      "          Fold 5 Epoch 1: loss=0.7125, acc=59.30% (best=59.30%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 80.23%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 61.95%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 83.52%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 74.92%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 927c919f:\n",
      "        Fold accuracies: ['80.23%', '73.75%', '83.52%', '74.92%', '61.95%']\n",
      "        Average fitness: 74.88% Â± 7.37%\n",
      "        Best fold: Fold 3 with 83.52%\n",
      "      Fitness obtained: 74.88% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 275f7b79)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 275f7b79 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6640, acc=81.72% (best=81.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6688, acc=70.00% (best=70.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6368, acc=53.91% (best=53.91%)\n",
      "          Fold 5 Epoch 1: loss=0.6526, acc=56.80% (best=56.80%)\n",
      "          Fold 1 Epoch 1: loss=0.6211, acc=78.28% (best=78.28%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.28%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 81.72%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 75.08%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 2 Epoch 30: loss=0.1401, acc=68.75% (best=71.64%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 71.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 275f7b79:\n",
      "        Fold accuracies: ['78.28%', '71.64%', '81.72%', '75.08%', '62.19%']\n",
      "        Average fitness: 73.78% Â± 6.69%\n",
      "        Best fold: Fold 3 with 81.72%\n",
      "      Fitness obtained: 73.78% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 9214e5b9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 9214e5b9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.4835, acc=56.41% (best=56.41%)\n",
      "          Fold 3 Epoch 1: loss=0.4121, acc=50.94% (best=50.94%)\n",
      "          Fold 5 Epoch 1: loss=0.4323, acc=58.12% (best=58.12%)\n",
      "          Fold 1 Epoch 1: loss=0.2224, acc=48.75% (best=48.75%)\n",
      "          Fold 2 Epoch 1: loss=0.4602, acc=47.58% (best=47.58%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "      â†’ Fold 3 completed: 66.80%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 80.08%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 75.23%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 72.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9214e5b9:\n",
      "        Fold accuracies: ['80.08%', '72.34%', '66.80%', '75.23%', '64.06%']\n",
      "        Average fitness: 71.70% Â± 5.75%\n",
      "        Best fold: Fold 1 with 80.08%\n",
      "      Fitness obtained: 71.70% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 51fce61b)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 51fce61b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7139, acc=65.23% (best=65.23%)\n",
      "          Fold 4 Epoch 1: loss=0.7124, acc=52.66% (best=52.66%)\n",
      "          Fold 3 Epoch 1: loss=0.7060, acc=75.31% (best=75.31%)\n",
      "          Fold 5 Epoch 1: loss=0.6858, acc=46.09% (best=46.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6950, acc=51.25% (best=51.25%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 52.89%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 80.78%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 72.97%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 50.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 51fce61b:\n",
      "        Fold accuracies: ['72.97%', '68.75%', '80.78%', '52.89%', '50.94%']\n",
      "        Average fitness: 65.27% Â± 11.58%\n",
      "        Best fold: Fold 3 with 80.78%\n",
      "      Fitness obtained: 65.27% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 73c2ffe5)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 73c2ffe5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6328, acc=59.69% (best=59.69%)\n",
      "          Fold 5 Epoch 1: loss=0.6331, acc=61.80% (best=61.80%)\n",
      "          Fold 1 Epoch 1: loss=0.5287, acc=76.25% (best=76.25%)\n",
      "          Fold 2 Epoch 1: loss=0.6169, acc=52.73% (best=52.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6227, acc=79.77% (best=79.77%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.25%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.98%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 76.33%\n",
      "          Fold 2 Epoch 30: loss=0.1387, acc=66.25% (best=67.42%)\n",
      "          Fold 2: Early stopping at epoch 42\n",
      "      â†’ Fold 2 completed: 68.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 73c2ffe5:\n",
      "        Fold accuracies: ['76.25%', '68.12%', '79.77%', '76.33%', '68.98%']\n",
      "        Average fitness: 73.89% Â± 4.55%\n",
      "        Best fold: Fold 3 with 79.77%\n",
      "      Fitness obtained: 73.89% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: b3f10d0c)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b3f10d0c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6921, acc=57.27% (best=57.27%)\n",
      "          Fold 4 Epoch 1: loss=0.6860, acc=52.11% (best=52.11%)\n",
      "          Fold 2 Epoch 1: loss=0.7418, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7345, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6916, acc=59.84% (best=59.84%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 78.36%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 70.55%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 51.17%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 66.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b3f10d0c:\n",
      "        Fold accuracies: ['78.36%', '56.09%', '70.55%', '66.48%', '51.17%']\n",
      "        Average fitness: 64.53% Â± 9.81%\n",
      "        Best fold: Fold 1 with 78.36%\n",
      "      Fitness obtained: 64.53% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 3753069b)\n",
      "      Architecture: 1 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 3753069b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.4951, acc=52.89% (best=52.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5122, acc=71.17% (best=71.17%)\n",
      "          Fold 2 Epoch 1: loss=0.5656, acc=69.84% (best=69.84%)\n",
      "          Fold 5 Epoch 1: loss=0.4985, acc=53.75% (best=53.75%)\n",
      "          Fold 1 Epoch 1: loss=0.4570, acc=55.08% (best=55.08%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 71.17%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.94%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 60.00%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 60.00%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3753069b:\n",
      "        Fold accuracies: ['60.00%', '70.94%', '71.17%', '60.00%', '60.78%']\n",
      "        Average fitness: 64.58% Â± 5.30%\n",
      "        Best fold: Fold 3 with 71.17%\n",
      "      Fitness obtained: 64.58% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: a8cd2af1)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model a8cd2af1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6645, acc=68.75% (best=68.75%)\n",
      "          Fold 2 Epoch 1: loss=0.6854, acc=60.23% (best=60.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6913, acc=50.62% (best=50.62%)\n",
      "          Fold 5 Epoch 1: loss=0.7511, acc=53.05% (best=53.05%)\n",
      "          Fold 1 Epoch 1: loss=0.6702, acc=66.88% (best=66.88%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 72.81%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 78.59%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 64.22%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 67.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a8cd2af1:\n",
      "        Fold accuracies: ['78.59%', '64.22%', '72.81%', '72.42%', '67.73%']\n",
      "        Average fitness: 71.16% Â± 4.89%\n",
      "        Best fold: Fold 1 with 78.59%\n",
      "      Fitness obtained: 71.16% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: e7451d27)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e7451d27 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6485, acc=46.17% (best=46.17%)\n",
      "          Fold 5 Epoch 1: loss=0.6277, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 1: loss=0.5996, acc=60.86% (best=60.86%)\n",
      "          Fold 3 Epoch 1: loss=0.6296, acc=79.53% (best=79.53%)\n",
      "          Fold 1 Epoch 1: loss=0.5115, acc=70.86% (best=70.86%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.86%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 84.77%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 64.38%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 64.92%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 75.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e7451d27:\n",
      "        Fold accuracies: ['70.86%', '75.16%', '84.77%', '64.38%', '64.92%']\n",
      "        Average fitness: 72.02% Â± 7.52%\n",
      "        Best fold: Fold 3 with 84.77%\n",
      "      Fitness obtained: 72.02% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 8c5f55c9)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8c5f55c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6867, acc=65.62% (best=65.62%)\n",
      "          Fold 3 Epoch 1: loss=0.6712, acc=74.92% (best=74.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6783, acc=61.09% (best=61.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6487, acc=67.50% (best=67.50%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.52%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 65.70%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 78.12%\n",
      "          Fold 1 Epoch 30: loss=0.0100, acc=78.75% (best=81.64%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 81.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8c5f55c9:\n",
      "        Fold accuracies: ['81.64%', '0.00%', '78.12%', '68.52%', '65.70%']\n",
      "        Average fitness: 58.80% Â± 29.98%\n",
      "        Best fold: Fold 1 with 81.64%\n",
      "      Fitness obtained: 58.80% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 4db70fd5)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 4db70fd5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5925, acc=70.94% (best=70.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6655, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6592, acc=64.22% (best=64.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6713, acc=72.97% (best=72.97%)\n",
      "          Fold 2 Epoch 1: loss=0.6447, acc=62.89% (best=62.89%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 75.39%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 79.14%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4db70fd5:\n",
      "        Fold accuracies: ['75.78%', '68.83%', '75.39%', '79.14%', '68.75%']\n",
      "        Average fitness: 73.58% Â± 4.12%\n",
      "        Best fold: Fold 4 with 79.14%\n",
      "      Fitness obtained: 73.58% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: da9d357a)\n",
      "      Architecture: 3 conv + 1 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model da9d357a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.1837, acc=60.55% (best=60.55%)\n",
      "          Fold 3 Epoch 1: loss=0.2092, acc=64.45% (best=64.45%)\n",
      "          Fold 1 Epoch 1: loss=0.1039, acc=49.61% (best=49.61%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for da9d357a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '75.23%', '0.00%', '0.00%']\n",
      "        Average fitness: 15.05% Â± 30.09%\n",
      "        Best fold: Fold 3 with 75.23%\n",
      "      Fitness obtained: 15.05% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 33108271)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 33108271 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7189, acc=42.58% (best=42.58%)\n",
      "          Fold 2 Epoch 1: loss=0.7187, acc=57.27% (best=57.27%)\n",
      "          Fold 4 Epoch 1: loss=0.7057, acc=43.98% (best=43.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7221, acc=45.16% (best=45.16%)\n",
      "          Fold 1 Epoch 1: loss=0.7392, acc=43.83% (best=43.83%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 57.27%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 47.97%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 81.88%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.16%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 66.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 33108271:\n",
      "        Fold accuracies: ['81.88%', '57.27%', '66.72%', '47.97%', '60.16%']\n",
      "        Average fitness: 62.80% Â± 11.29%\n",
      "        Best fold: Fold 1 with 81.88%\n",
      "      Fitness obtained: 62.80% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 882a98ff)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 882a98ff with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6975, acc=70.47% (best=70.47%)          Fold 1 Epoch 1: loss=0.6871, acc=63.52% (best=63.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6725, acc=47.66% (best=47.66%)\n",
      "\n",
      "          Fold 2 Epoch 1: loss=0.6894, acc=59.53% (best=59.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6939, acc=56.02% (best=56.02%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 68.28%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 86.41%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 86.41%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 56.25%\n",
      "          Fold 2 Epoch 30: loss=0.1986, acc=68.20% (best=76.41%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 76.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 882a98ff:\n",
      "        Fold accuracies: ['86.41%', '76.41%', '86.41%', '68.28%', '56.25%']\n",
      "        Average fitness: 74.75% Â± 11.48%\n",
      "        Best fold: Fold 1 with 86.41%\n",
      "      Fitness obtained: 74.75% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 84d440a3)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 84d440a3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6754, acc=62.42% (best=62.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6932, acc=55.00% (best=55.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6148, acc=77.73% (best=77.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6970, acc=80.86% (best=80.86%)\n",
      "          Fold 5 Epoch 1: loss=0.6775, acc=65.00% (best=65.00%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.73%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 84.92%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 71.95%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 63.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 84d440a3:\n",
      "        Fold accuracies: ['77.73%', '63.67%', '84.92%', '71.95%', '65.00%']\n",
      "        Average fitness: 72.66% Â± 7.95%\n",
      "        Best fold: Fold 3 with 84.92%\n",
      "      Fitness obtained: 72.66% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: be520c9e)\n",
      "      Architecture: 9 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model be520c9e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7294, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.7183, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7305, acc=73.67% (best=73.67%)\n",
      "          Fold 1 Epoch 1: loss=0.7308, acc=48.05% (best=48.05%)\n",
      "          Fold 5 Epoch 1: loss=0.7169, acc=51.17% (best=51.17%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.67%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 62.89%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 66.80%\n",
      "          Fold 4: Early stopping at epoch 29\n",
      "      â†’ Fold 4 completed: 61.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for be520c9e:\n",
      "        Fold accuracies: ['68.36%', '66.80%', '73.67%', '61.41%', '62.89%']\n",
      "        Average fitness: 66.62% Â± 4.33%\n",
      "        Best fold: Fold 3 with 73.67%\n",
      "      Fitness obtained: 66.62% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 8a0449c4)\n",
      "      Architecture: 9 conv + 7 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 8a0449c4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7211, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 1: loss=0.7172, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.7187, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7220, acc=52.97% (best=52.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7129, acc=49.53% (best=49.53%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 52.97%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 49.53%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8a0449c4:\n",
      "        Fold accuracies: ['52.97%', '50.08%', '48.83%', '49.61%', '49.53%']\n",
      "        Average fitness: 50.20% Â± 1.44%\n",
      "        Best fold: Fold 1 with 52.97%\n",
      "      Fitness obtained: 50.20% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: f0d6623b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f0d6623b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7077, acc=48.28% (best=48.28%)\n",
      "          Fold 2 Epoch 1: loss=0.7067, acc=51.56% (best=51.56%)\n",
      "          Fold 3 Epoch 1: loss=0.7116, acc=56.33% (best=56.33%)\n",
      "          Fold 5 Epoch 1: loss=0.7383, acc=42.42% (best=42.42%)\n",
      "          Fold 1 Epoch 1: loss=0.7291, acc=47.66% (best=47.66%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 60.70%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 61.17%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 54.77%\n",
      "          Fold 1 Epoch 30: loss=0.1104, acc=74.45% (best=78.44%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 78.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f0d6623b:\n",
      "        Fold accuracies: ['78.44%', '61.17%', '60.70%', '50.39%', '54.77%']\n",
      "        Average fitness: 61.09% Â± 9.55%\n",
      "        Best fold: Fold 1 with 78.44%\n",
      "      Fitness obtained: 61.09% | Best in generation: 77.89% | Global best: 79.20%\n",
      "\n",
      "GENERATION 20 STATISTICS:\n",
      "   Maximum fitness: 77.89%\n",
      "   Average fitness: 65.83%\n",
      "   Minimum fitness: 15.05%\n",
      "   Standard deviation: 13.38%\n",
      "   Best individual: 0f175044 with 77.89%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 6/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=13.38)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 0f175044 (fitness: 77.89%)\n",
      "   Elite 2: 927c919f (fitness: 74.88%)\n",
      "   Elite 3: 882a98ff (fitness: 74.75%)\n",
      "   Elite 4: 73c2ffe5 (fitness: 73.89%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 7/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 21\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 21)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 0f175044)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 0f175044 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6648, acc=76.72% (best=76.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6806, acc=59.92% (best=59.92%)\n",
      "          Fold 5 Epoch 1: loss=0.6494, acc=70.16% (best=70.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6739, acc=73.59% (best=73.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6490, acc=67.34% (best=67.34%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.59%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 70.16%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 84.06%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.58%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 63.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0f175044:\n",
      "        Fold accuracies: ['82.58%', '73.59%', '84.06%', '63.05%', '70.16%']\n",
      "        Average fitness: 74.69% Â± 7.84%\n",
      "        Best fold: Fold 3 with 84.06%\n",
      "      New best fitness in this generation: 74.69%!\n",
      "      Fitness obtained: 74.69% | Best in generation: 74.69% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 927c919f)\n",
      "      Architecture: 9 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 927c919f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7080, acc=72.03% (best=72.03%)\n",
      "          Fold 3 Epoch 1: loss=0.6843, acc=68.59% (best=68.59%)\n",
      "          Fold 4 Epoch 1: loss=0.7120, acc=63.52% (best=63.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6918, acc=66.02% (best=66.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6876, acc=51.72% (best=51.72%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 75.86%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 72.34%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 73.83%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 74.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 927c919f:\n",
      "        Fold accuracies: ['75.86%', '72.34%', '74.38%', '73.83%', '66.56%']\n",
      "        Average fitness: 72.59% Â± 3.22%\n",
      "        Best fold: Fold 1 with 75.86%\n",
      "      Fitness obtained: 72.59% | Best in generation: 74.69% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 882a98ff)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 882a98ff with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7160, acc=62.42% (best=62.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6833, acc=62.97% (best=62.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6893, acc=56.02% (best=56.02%)\n",
      "          Fold 2 Epoch 1: loss=0.6813, acc=52.66% (best=52.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6999, acc=61.72% (best=61.72%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 69.84%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 74.06%\n",
      "          Fold 2 Epoch 30: loss=0.2109, acc=65.78% (best=67.42%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 67.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 882a98ff:\n",
      "        Fold accuracies: ['69.84%', '67.42%', '74.06%', '62.97%', '67.42%']\n",
      "        Average fitness: 68.34% Â± 3.62%\n",
      "        Best fold: Fold 3 with 74.06%\n",
      "      Fitness obtained: 68.34% | Best in generation: 74.69% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 73c2ffe5)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 73c2ffe5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6172, acc=73.91% (best=73.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6383, acc=68.44% (best=68.44%)\n",
      "          Fold 5 Epoch 1: loss=0.6219, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5545, acc=76.56% (best=76.56%)\n",
      "          Fold 3 Epoch 1: loss=0.6118, acc=75.94% (best=75.94%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.91%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.56%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.50%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 74.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 73c2ffe5:\n",
      "        Fold accuracies: ['76.56%', '73.91%', '82.50%', '74.84%', '61.64%']\n",
      "        Average fitness: 73.89% Â± 6.82%\n",
      "        Best fold: Fold 3 with 82.50%\n",
      "      Fitness obtained: 73.89% | Best in generation: 74.69% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 9be22a3d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 9be22a3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6832, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 1: loss=0.6464, acc=64.14% (best=64.14%)\n",
      "          Fold 1 Epoch 1: loss=0.5756, acc=75.55% (best=75.55%)\n",
      "          Fold 3 Epoch 1: loss=0.6434, acc=73.98% (best=73.98%)\n",
      "          Fold 5 Epoch 1: loss=0.6437, acc=76.17% (best=76.17%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 76.17%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 82.11%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 80.47%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 58.75%\n",
      "          Fold 2 Epoch 30: loss=0.1964, acc=73.67% (best=80.47%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 80.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9be22a3d:\n",
      "        Fold accuracies: ['82.11%', '80.47%', '80.47%', '58.75%', '76.17%']\n",
      "        Average fitness: 75.59% Â± 8.65%\n",
      "        Best fold: Fold 1 with 82.11%\n",
      "      New best fitness in this generation: 75.59%!\n",
      "      Fitness obtained: 75.59% | Best in generation: 75.59% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: e3f1180e)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model e3f1180e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6555, acc=64.77% (best=64.77%)\n",
      "          Fold 1 Epoch 1: loss=0.6023, acc=70.70% (best=70.70%)\n",
      "          Fold 5 Epoch 1: loss=0.6523, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 1: loss=0.6530, acc=88.36% (best=88.36%)\n",
      "          Fold 2 Epoch 1: loss=0.6479, acc=60.55% (best=60.55%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 88.36%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 76.41%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 78.83%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 69.22%\n",
      "          Fold 5 Epoch 30: loss=0.1242, acc=67.03% (best=68.75%)\n",
      "          Fold 5: Early stopping at epoch 33\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e3f1180e:\n",
      "        Fold accuracies: ['78.83%', '69.22%', '88.36%', '76.41%', '68.75%']\n",
      "        Average fitness: 76.31% Â± 7.20%\n",
      "        Best fold: Fold 3 with 88.36%\n",
      "      New best fitness in this generation: 76.31%!\n",
      "      Fitness obtained: 76.31% | Best in generation: 76.31% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: cda09c18)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model cda09c18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7025, acc=64.92% (best=64.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6901, acc=62.97% (best=62.97%)\n",
      "          Fold 4 Epoch 1: loss=0.7014, acc=53.67% (best=53.67%)\n",
      "          Fold 5 Epoch 1: loss=0.6883, acc=62.11% (best=62.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6817, acc=75.86% (best=75.86%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 70.39%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 90.39%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 78.36%\n",
      "          Fold 4 Epoch 30: loss=0.1803, acc=63.05% (best=73.44%)\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 73.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cda09c18:\n",
      "        Fold accuracies: ['78.36%', '70.55%', '90.39%', '73.44%', '70.39%']\n",
      "        Average fitness: 76.62% Â± 7.46%\n",
      "        Best fold: Fold 3 with 90.39%\n",
      "      New best fitness in this generation: 76.62%!\n",
      "      Fitness obtained: 76.62% | Best in generation: 76.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 5345472b)\n",
      "      Architecture: 9 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 5345472b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6522, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6777, acc=68.67% (best=68.67%)\n",
      "          Fold 1 Epoch 1: loss=0.6121, acc=71.95% (best=71.95%)\n",
      "          Fold 3 Epoch 1: loss=0.6547, acc=71.56% (best=71.56%)\n",
      "          Fold 5 Epoch 1: loss=0.6741, acc=58.20% (best=58.20%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 76.48%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 73.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5345472b:\n",
      "        Fold accuracies: ['73.75%', '73.20%', '76.48%', '68.83%', '63.75%']\n",
      "        Average fitness: 71.20% Â± 4.46%\n",
      "        Best fold: Fold 3 with 76.48%\n",
      "      Fitness obtained: 71.20% | Best in generation: 76.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 976b7314)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 976b7314 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5002, acc=63.91% (best=63.91%)\n",
      "          Fold 4 Epoch 1: loss=0.5778, acc=67.66% (best=67.66%)\n",
      "          Fold 2 Epoch 1: loss=0.5952, acc=66.17% (best=66.17%)\n",
      "          Fold 5 Epoch 1: loss=0.5350, acc=44.38% (best=44.38%)\n",
      "          Fold 3 Epoch 1: loss=0.5938, acc=59.14% (best=59.14%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.66%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 55.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 976b7314:\n",
      "        Fold accuracies: ['73.75%', '66.25%', '71.48%', '67.66%', '55.55%']\n",
      "        Average fitness: 66.94% Â± 6.29%\n",
      "        Best fold: Fold 1 with 73.75%\n",
      "      Fitness obtained: 66.94% | Best in generation: 76.62% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: bcfe8f47)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model bcfe8f47 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6525, acc=64.22% (best=64.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5783, acc=83.67% (best=83.67%)\n",
      "          Fold 2 Epoch 1: loss=0.6226, acc=69.45% (best=69.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6609, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6557, acc=88.83% (best=88.83%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 83.67%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 69.45%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 88.83%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 70.23%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 76.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bcfe8f47:\n",
      "        Fold accuracies: ['83.67%', '69.45%', '88.83%', '76.72%', '70.23%']\n",
      "        Average fitness: 77.78% Â± 7.54%\n",
      "        Best fold: Fold 3 with 88.83%\n",
      "      New best fitness in this generation: 77.78%!\n",
      "      Fitness obtained: 77.78% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: ca215506)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ca215506 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[120], expected input with shape [*, 120], but got input of size[1, 120, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for ca215506:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 34cdcc7f)\n",
      "      Architecture: 10 conv + 10 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 34cdcc7f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7163, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7178, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7235, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7243, acc=50.47% (best=50.47%)\n",
      "          Fold 1 Epoch 1: loss=0.7242, acc=49.61% (best=49.61%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.83%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 50.70%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 54.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 34cdcc7f:\n",
      "        Fold accuracies: ['50.39%', '50.08%', '48.83%', '54.69%', '50.70%']\n",
      "        Average fitness: 50.94% Â± 1.98%\n",
      "        Best fold: Fold 4 with 54.69%\n",
      "      Fitness obtained: 50.94% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: e9de8060)\n",
      "      Architecture: 9 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model e9de8060 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7411, acc=53.44% (best=53.44%)\n",
      "          Fold 1 Epoch 1: loss=0.6596, acc=40.00% (best=40.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7382, acc=52.27% (best=52.27%)\n",
      "          Fold 2 Epoch 1: loss=0.7122, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 1: loss=0.7737, acc=55.39% (best=55.39%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 64.84%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 71.95%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e9de8060:\n",
      "        Fold accuracies: ['71.56%', '71.95%', '64.84%', '70.31%', '63.12%']\n",
      "        Average fitness: 68.36% Â± 3.65%\n",
      "        Best fold: Fold 2 with 71.95%\n",
      "      Fitness obtained: 68.36% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: d2516bd2)\n",
      "      Architecture: 9 conv + 10 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model d2516bd2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7203, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 1: loss=0.7184, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.7427, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7230, acc=50.39% (best=50.39%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 71.95%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 53.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d2516bd2:\n",
      "        Fold accuracies: ['50.39%', '53.67%', '71.95%', '50.39%', '0.00%']\n",
      "        Average fitness: 45.28% Â± 24.02%\n",
      "        Best fold: Fold 3 with 71.95%\n",
      "      Fitness obtained: 45.28% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: e96e4170)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model e96e4170 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6329, acc=59.92% (best=59.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6633, acc=72.97% (best=72.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6730, acc=60.55% (best=60.55%)\n",
      "          Fold 5 Epoch 1: loss=0.6482, acc=57.50% (best=57.50%)\n",
      "          Fold 1 Epoch 1: loss=0.6268, acc=74.22% (best=74.22%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.50%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 74.30%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 76.09%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 73.59%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e96e4170:\n",
      "        Fold accuracies: ['76.41%', '76.09%', '74.30%', '73.59%', '57.50%']\n",
      "        Average fitness: 71.58% Â± 7.12%\n",
      "        Best fold: Fold 1 with 76.41%\n",
      "      Fitness obtained: 71.58% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 730f4ace)\n",
      "      Architecture: 2 conv + 2 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 730f4ace with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.2121, acc=56.56% (best=56.56%)\n",
      "          Fold 4 Epoch 1: loss=0.2439, acc=62.19% (best=62.19%)\n",
      "          Fold 5 Epoch 1: loss=0.2041, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.2252, acc=54.53% (best=54.53%)\n",
      "          Fold 1 Epoch 1: loss=0.1278, acc=67.66% (best=67.66%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.19%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 67.66%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 63.05%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 62.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 730f4ace:\n",
      "        Fold accuracies: ['67.66%', '62.19%', '67.58%', '62.19%', '63.05%']\n",
      "        Average fitness: 64.53% Â± 2.54%\n",
      "        Best fold: Fold 1 with 67.66%\n",
      "      Fitness obtained: 64.53% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: c1035f60)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model c1035f60 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7093, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7136, acc=57.34% (best=57.34%)\n",
      "          Fold 3 Epoch 1: loss=0.6994, acc=56.80% (best=56.80%)\n",
      "          Fold 4 Epoch 1: loss=0.7035, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.6921, acc=61.64% (best=61.64%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 72.11%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 71.25%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 72.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c1035f60:\n",
      "        Fold accuracies: ['71.48%', '71.25%', '72.11%', '72.89%', '67.03%']\n",
      "        Average fitness: 70.95% Â± 2.04%\n",
      "        Best fold: Fold 4 with 72.89%\n",
      "      Fitness obtained: 70.95% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 4ffd7b99)\n",
      "      Architecture: 10 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 4ffd7b99 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6855, acc=55.78% (best=55.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6742, acc=74.22% (best=74.22%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.73%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 72.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4ffd7b99:\n",
      "        Fold accuracies: ['82.73%', '0.00%', '0.00%', '0.00%', '72.03%']\n",
      "        Average fitness: 30.95% Â± 38.06%\n",
      "        Best fold: Fold 1 with 82.73%\n",
      "      Fitness obtained: 30.95% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 31b1debe)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 31b1debe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.4662, acc=48.05% (best=48.05%)\n",
      "          Fold 5 Epoch 1: loss=0.5888, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6680, acc=50.31% (best=50.31%)\n",
      "          Fold 3 Epoch 1: loss=0.6354, acc=57.81% (best=57.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6002, acc=50.08% (best=50.08%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 72.81%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 74.30%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 60.78%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 1 Epoch 30: loss=0.0129, acc=50.39% (best=68.05%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 68.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 31b1debe:\n",
      "        Fold accuracies: ['68.05%', '74.30%', '72.81%', '60.78%', '65.62%']\n",
      "        Average fitness: 68.31% Â± 4.90%\n",
      "        Best fold: Fold 2 with 74.30%\n",
      "      Fitness obtained: 68.31% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: eabdd68e)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model eabdd68e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6364, acc=63.52% (best=63.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6008, acc=57.81% (best=57.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6201, acc=79.45% (best=79.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6238, acc=60.47% (best=60.47%)\n",
      "          Fold 1 Epoch 1: loss=0.5207, acc=74.06% (best=74.06%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.45%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 73.98%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 71.56%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 82.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eabdd68e:\n",
      "        Fold accuracies: ['82.42%', '71.56%', '79.45%', '73.98%', '68.36%']\n",
      "        Average fitness: 75.16% Â± 5.13%\n",
      "        Best fold: Fold 1 with 82.42%\n",
      "      Fitness obtained: 75.16% | Best in generation: 77.78% | Global best: 79.20%\n",
      "\n",
      "GENERATION 21 STATISTICS:\n",
      "   Maximum fitness: 77.78%\n",
      "   Average fitness: 64.00%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 18.68%\n",
      "   Best individual: bcfe8f47 with 77.78%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 8/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=18.68)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: bcfe8f47 (fitness: 77.78%)\n",
      "   Elite 2: cda09c18 (fitness: 76.62%)\n",
      "   Elite 3: e3f1180e (fitness: 76.31%)\n",
      "   Elite 4: 9be22a3d (fitness: 75.59%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 9/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 22\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 22)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: bcfe8f47)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model bcfe8f47 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6462, acc=71.33% (best=71.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6517, acc=80.08% (best=80.08%)\n",
      "          Fold 4 Epoch 1: loss=0.6401, acc=66.09% (best=66.09%)\n",
      "          Fold 1 Epoch 1: loss=0.5544, acc=74.61% (best=74.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6452, acc=71.17% (best=71.17%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.09%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 71.33%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.61%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 80.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bcfe8f47:\n",
      "        Fold accuracies: ['74.61%', '71.17%', '80.94%', '66.09%', '71.33%']\n",
      "        Average fitness: 72.83% Â± 4.88%\n",
      "        Best fold: Fold 3 with 80.94%\n",
      "      New best fitness in this generation: 72.83%!\n",
      "      Fitness obtained: 72.83% | Best in generation: 72.83% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: cda09c18)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model cda09c18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6990, acc=52.50% (best=52.50%)\n",
      "          Fold 1 Epoch 1: loss=0.6876, acc=58.52% (best=58.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6896, acc=69.38% (best=69.38%)\n",
      "          Fold 5 Epoch 1: loss=0.7059, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6843, acc=66.41% (best=66.41%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 88.98%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 69.45%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 85.31%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "          Fold 4: Early stopping at epoch 29\n",
      "      â†’ Fold 4 completed: 75.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cda09c18:\n",
      "        Fold accuracies: ['85.31%', '70.39%', '88.98%', '75.08%', '69.45%']\n",
      "        Average fitness: 77.84% Â± 7.92%\n",
      "        Best fold: Fold 3 with 88.98%\n",
      "      New best fitness in this generation: 77.84%!\n",
      "      Fitness obtained: 77.84% | Best in generation: 77.84% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: e3f1180e)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model e3f1180e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6468, acc=66.72% (best=66.72%)          Fold 2 Epoch 1: loss=0.6428, acc=67.34% (best=67.34%)\n",
      "          Fold 1 Epoch 1: loss=0.6012, acc=81.33% (best=81.33%)\n",
      "\n",
      "          Fold 4 Epoch 1: loss=0.6619, acc=69.30% (best=69.30%)\n",
      "          Fold 3 Epoch 1: loss=0.6567, acc=90.62% (best=90.62%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 81.33%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.72%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 90.62%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 75.62%\n",
      "          Fold 2 Epoch 30: loss=0.1332, acc=73.28% (best=77.03%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 77.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e3f1180e:\n",
      "        Fold accuracies: ['81.33%', '77.03%', '90.62%', '75.62%', '66.72%']\n",
      "        Average fitness: 78.27% Â± 7.80%\n",
      "        Best fold: Fold 3 with 90.62%\n",
      "      New best fitness in this generation: 78.27%!\n",
      "      Fitness obtained: 78.27% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 9be22a3d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 9be22a3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6309, acc=66.41% (best=66.41%)\n",
      "          Fold 1 Epoch 1: loss=0.5637, acc=77.81% (best=77.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6585, acc=76.64% (best=76.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6356, acc=64.38% (best=64.38%)\n",
      "          Fold 4 Epoch 1: loss=0.6561, acc=65.31% (best=65.31%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.81%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 85.47%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "          Fold 4 Epoch 30: loss=0.1920, acc=65.70% (best=73.20%)\n",
      "          Fold 4: Early stopping at epoch 37\n",
      "      â†’ Fold 4 completed: 73.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9be22a3d:\n",
      "        Fold accuracies: ['77.81%', '66.41%', '85.47%', '73.20%', '65.39%']\n",
      "        Average fitness: 73.66% Â± 7.46%\n",
      "        Best fold: Fold 3 with 85.47%\n",
      "      Fitness obtained: 73.66% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: c0040e02)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c0040e02 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6512, acc=69.22% (best=69.22%)\n",
      "          Fold 1 Epoch 1: loss=0.5525, acc=71.33% (best=71.33%)\n",
      "          Fold 2 Epoch 1: loss=0.6321, acc=73.67% (best=73.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6612, acc=69.30% (best=69.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6675, acc=69.61% (best=69.61%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.67%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 71.48%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 72.03%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 74.84%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 77.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c0040e02:\n",
      "        Fold accuracies: ['74.84%', '73.67%', '77.97%', '71.48%', '72.03%']\n",
      "        Average fitness: 74.00% Â± 2.31%\n",
      "        Best fold: Fold 3 with 77.97%\n",
      "      Fitness obtained: 74.00% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 7a89b1b9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 7a89b1b9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6561, acc=65.55% (best=65.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6578, acc=59.14% (best=59.14%)\n",
      "          Fold 5 Epoch 1: loss=0.6564, acc=61.33% (best=61.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6557, acc=78.52% (best=78.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6014, acc=80.47% (best=80.47%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 80.47%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 77.42%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 72.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7a89b1b9:\n",
      "        Fold accuracies: ['80.47%', '77.42%', '79.69%', '72.97%', '68.75%']\n",
      "        Average fitness: 75.86% Â± 4.41%\n",
      "        Best fold: Fold 1 with 80.47%\n",
      "      Fitness obtained: 75.86% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 104d3bc9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 104d3bc9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6409, acc=67.66% (best=67.66%)\n",
      "          Fold 4 Epoch 1: loss=0.7739, acc=63.91% (best=63.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6780, acc=57.27% (best=57.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6641, acc=71.25% (best=71.25%)\n",
      "          Fold 5 Epoch 1: loss=0.6922, acc=58.28% (best=58.28%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 76.41%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 80.23%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 71.80%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 75.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 104d3bc9:\n",
      "        Fold accuracies: ['80.23%', '71.80%', '76.41%', '75.08%', '61.48%']\n",
      "        Average fitness: 73.00% Â± 6.36%\n",
      "        Best fold: Fold 1 with 80.23%\n",
      "      Fitness obtained: 73.00% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 1bb4b8e9)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1bb4b8e9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6595, acc=63.98% (best=63.98%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1bb4b8e9:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '63.98%']\n",
      "        Average fitness: 12.80% Â± 25.59%\n",
      "        Best fold: Fold 5 with 63.98%\n",
      "      Fitness obtained: 12.80% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 8ad81743)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 8ad81743 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6745, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 1: loss=0.6542, acc=65.39% (best=65.39%)\n",
      "          Fold 3 Epoch 1: loss=0.6599, acc=66.48% (best=66.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6456, acc=54.84% (best=54.84%)\n",
      "          Fold 1 Epoch 1: loss=0.6012, acc=69.61% (best=69.61%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 56.56%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 84.30%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.80%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8ad81743:\n",
      "        Fold accuracies: ['84.30%', '56.56%', '86.80%', '69.61%', '65.47%']\n",
      "        Average fitness: 72.55% Â± 11.45%\n",
      "        Best fold: Fold 3 with 86.80%\n",
      "      Fitness obtained: 72.55% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 2e5c5de6)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2e5c5de6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6582, acc=59.77% (best=59.77%)\n",
      "          Fold 1 Epoch 1: loss=0.6059, acc=56.80% (best=56.80%)\n",
      "          Fold 2 Epoch 1: loss=0.6662, acc=63.91% (best=63.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6420, acc=69.92% (best=69.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6520, acc=69.84% (best=69.84%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 78.12%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 78.98%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 78.59%\n",
      "          Fold 5 Epoch 30: loss=0.1845, acc=68.83% (best=70.55%)\n",
      "          Fold 5: Early stopping at epoch 36\n",
      "      â†’ Fold 5 completed: 70.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2e5c5de6:\n",
      "        Fold accuracies: ['78.98%', '68.20%', '78.12%', '78.59%', '70.55%']\n",
      "        Average fitness: 74.89% Â± 4.57%\n",
      "        Best fold: Fold 1 with 78.98%\n",
      "      Fitness obtained: 74.89% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 19f9bc4b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 19f9bc4b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6325, acc=51.25% (best=51.25%)\n",
      "          Fold 1 Epoch 1: loss=0.5839, acc=81.56% (best=81.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6544, acc=63.75% (best=63.75%)\n",
      "          Fold 3 Epoch 1: loss=0.6241, acc=76.88% (best=76.88%)\n",
      "          Fold 5 Epoch 1: loss=0.6584, acc=61.25% (best=61.25%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 81.56%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.98%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 78.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19f9bc4b:\n",
      "        Fold accuracies: ['81.56%', '68.83%', '78.20%', '68.98%', '65.47%']\n",
      "        Average fitness: 72.61% Â± 6.16%\n",
      "        Best fold: Fold 1 with 81.56%\n",
      "      Fitness obtained: 72.61% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 165a304a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 165a304a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6205, acc=78.05% (best=78.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6665, acc=56.17% (best=56.17%)\n",
      "          Fold 4 Epoch 1: loss=0.6669, acc=58.91% (best=58.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6741, acc=73.28% (best=73.28%)\n",
      "          Fold 5 Epoch 1: loss=0.6776, acc=67.81% (best=67.81%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.05%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.81%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 79.06%\n",
      "          Fold 2 Epoch 30: loss=0.1389, acc=53.67% (best=63.59%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 165a304a:\n",
      "        Fold accuracies: ['78.05%', '63.59%', '79.06%', '67.50%', '67.81%']\n",
      "        Average fitness: 71.20% Â± 6.19%\n",
      "        Best fold: Fold 3 with 79.06%\n",
      "      Fitness obtained: 71.20% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 982d2e17)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 982d2e17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6528, acc=68.52% (best=68.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6281, acc=56.17% (best=56.17%)\n",
      "          Fold 4 Epoch 1: loss=0.6580, acc=53.59% (best=53.59%)\n",
      "          Fold 3 Epoch 1: loss=0.6256, acc=85.70% (best=85.70%)\n",
      "          Fold 1 Epoch 1: loss=0.5668, acc=66.48% (best=66.48%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.45%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 91.17%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 73.75%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 76.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 982d2e17:\n",
      "        Fold accuracies: ['73.75%', '67.11%', '91.17%', '76.48%', '69.45%']\n",
      "        Average fitness: 75.59% Â± 8.44%\n",
      "        Best fold: Fold 3 with 91.17%\n",
      "      Fitness obtained: 75.59% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 633ac31a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 633ac31a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6530, acc=75.23% (best=75.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6552, acc=55.39% (best=55.39%)\n",
      "          Fold 1 Epoch 1: loss=0.6035, acc=76.64% (best=76.64%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.64%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 86.80%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 633ac31a:\n",
      "        Fold accuracies: ['76.64%', '0.00%', '86.80%', '63.20%', '0.00%']\n",
      "        Average fitness: 45.33% Â± 37.76%\n",
      "        Best fold: Fold 3 with 86.80%\n",
      "      Fitness obtained: 45.33% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 1666b31b)\n",
      "      Architecture: 10 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 1666b31b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7165, acc=51.80% (best=51.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7386, acc=43.36% (best=43.36%)\n",
      "          Fold 4 Epoch 1: loss=0.7090, acc=53.12% (best=53.12%)\n",
      "          Fold 2 Epoch 1: loss=0.7237, acc=51.33% (best=51.33%)\n",
      "          Fold 1 Epoch 1: loss=0.7341, acc=60.47% (best=60.47%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 59.92%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "          Fold 3 Epoch 30: loss=0.6901, acc=72.89% (best=74.30%)\n",
      "          Fold 5 Epoch 30: loss=0.7085, acc=51.80% (best=55.86%)\n",
      "          Fold 3: Early stopping at epoch 35\n",
      "      â†’ Fold 3 completed: 74.30%\n",
      "          Fold 5: Early stopping at epoch 35\n",
      "      â†’ Fold 5 completed: 55.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1666b31b:\n",
      "        Fold accuracies: ['65.00%', '70.39%', '74.30%', '59.92%', '55.86%']\n",
      "        Average fitness: 65.09% Â± 6.71%\n",
      "        Best fold: Fold 3 with 74.30%\n",
      "      Fitness obtained: 65.09% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 7ba6b840)\n",
      "      Architecture: 3 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 7ba6b840 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 237, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 181, in _init_group\n",
      "    state[\"exp_avg_sq\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 237, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 181, in _init_group\n",
      "    state[\"exp_avg_sq\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 237, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 177, in _init_group\n",
      "    state[\"exp_avg\"] = torch.zeros_like(\n",
      "                       ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.2150, acc=60.78% (best=60.78%)\n",
      "          Fold 2 Epoch 1: loss=0.2875, acc=55.47% (best=55.47%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 63.36%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7ba6b840:\n",
      "        Fold accuracies: ['0.00%', '59.61%', '63.36%', '0.00%', '0.00%']\n",
      "        Average fitness: 24.59% Â± 30.14%\n",
      "        Best fold: Fold 3 with 63.36%\n",
      "      Fitness obtained: 24.59% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 4c3a9a90)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 4c3a9a90 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6730, acc=68.83% (best=68.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6751, acc=47.42% (best=47.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6815, acc=67.50% (best=67.50%)\n",
      "          Fold 4 Epoch 1: loss=0.7012, acc=63.52% (best=63.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6652, acc=67.66% (best=67.66%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 68.83%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 70.16%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 69.14%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 70.16%\n",
      "          Fold 5 Epoch 30: loss=0.1699, acc=62.73% (best=65.70%)\n",
      "          Fold 5: Early stopping at epoch 36\n",
      "      â†’ Fold 5 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4c3a9a90:\n",
      "        Fold accuracies: ['70.16%', '69.14%', '68.83%', '70.16%', '65.70%']\n",
      "        Average fitness: 68.80% Â± 1.64%\n",
      "        Best fold: Fold 1 with 70.16%\n",
      "      Fitness obtained: 68.80% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 6b2587c8)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 6b2587c8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.5836, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 1: loss=0.5694, acc=55.55% (best=55.55%)\n",
      "          Fold 4 Epoch 1: loss=0.5771, acc=56.72% (best=56.72%)\n",
      "          Fold 3 Epoch 1: loss=0.5394, acc=84.38% (best=84.38%)\n",
      "          Fold 1 Epoch 1: loss=0.3984, acc=75.78% (best=75.78%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 84.38%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 79.61%\n",
      "          Fold 5 Epoch 30: loss=0.0823, acc=55.39% (best=64.38%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 64.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6b2587c8:\n",
      "        Fold accuracies: ['79.61%', '69.61%', '84.38%', '62.97%', '64.38%']\n",
      "        Average fitness: 72.19% Â± 8.44%\n",
      "        Best fold: Fold 3 with 84.38%\n",
      "      Fitness obtained: 72.19% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 79ad4327)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 79ad4327 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.6932, acc=65.47% (best=65.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6901, acc=55.86% (best=55.86%)\n",
      "          Fold 2 Epoch 1: loss=0.6868, acc=62.03% (best=62.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6574, acc=76.88% (best=76.88%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 65.47%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 75.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 79ad4327:\n",
      "        Fold accuracies: ['77.11%', '75.70%', '0.00%', '67.97%', '65.47%']\n",
      "        Average fitness: 57.25% Â± 28.97%\n",
      "        Best fold: Fold 1 with 77.11%\n",
      "      Fitness obtained: 57.25% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: b12f27f2)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b12f27f2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6698, acc=53.28% (best=53.28%)\n",
      "          Fold 5 Epoch 1: loss=0.6441, acc=69.84% (best=69.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6411, acc=64.22% (best=64.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6012, acc=74.06% (best=74.06%)\n",
      "          Fold 3 Epoch 1: loss=0.6494, acc=77.11% (best=77.11%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.06%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 64.22%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 72.11%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 85.00%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b12f27f2:\n",
      "        Fold accuracies: ['74.06%', '64.22%', '85.00%', '67.58%', '72.11%']\n",
      "        Average fitness: 72.59% Â± 7.09%\n",
      "        Best fold: Fold 3 with 85.00%\n",
      "      Fitness obtained: 72.59% | Best in generation: 78.27% | Global best: 79.20%\n",
      "\n",
      "GENERATION 22 STATISTICS:\n",
      "   Maximum fitness: 78.27%\n",
      "   Average fitness: 65.55%\n",
      "   Minimum fitness: 12.80%\n",
      "   Standard deviation: 17.36%\n",
      "   Best individual: e3f1180e with 78.27%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 10/20\n",
      "\n",
      "ðŸ“‰ Stagnation detected in last 3 generations (all within 0.48%)\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=17.36)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: e3f1180e (fitness: 78.27%)\n",
      "   Elite 2: cda09c18 (fitness: 77.84%)\n",
      "   Elite 3: 7a89b1b9 (fitness: 75.86%)\n",
      "   Elite 4: 982d2e17 (fitness: 75.59%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 11/20\n",
      "\n",
      "ðŸ“‰ Stagnation detected in last 3 generations (all within 0.48%)\n",
      "\n",
      "================================================================================\n",
      "GENERATION 23\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 23)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: e3f1180e)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model e3f1180e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6576, acc=62.42% (best=62.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6633, acc=66.25% (best=66.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6600, acc=81.25% (best=81.25%)\n",
      "          Fold 5 Epoch 1: loss=0.6495, acc=64.30% (best=64.30%)\n",
      "          Fold 1 Epoch 1: loss=0.6270, acc=74.53% (best=74.53%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.30%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 74.53%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 82.11%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 75.47%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 62.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e3f1180e:\n",
      "        Fold accuracies: ['74.53%', '62.73%', '82.11%', '75.47%', '64.30%']\n",
      "        Average fitness: 71.83% Â± 7.29%\n",
      "        Best fold: Fold 3 with 82.11%\n",
      "      New best fitness in this generation: 71.83%!\n",
      "      Fitness obtained: 71.83% | Best in generation: 71.83% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: cda09c18)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model cda09c18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6558, acc=68.36% (best=68.36%)\n",
      "          Fold 4 Epoch 1: loss=0.7021, acc=63.83% (best=63.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6873, acc=69.92% (best=69.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6997, acc=66.41% (best=66.41%)\n",
      "          Fold 5 Epoch 1: loss=0.6862, acc=73.12% (best=73.12%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 68.36%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 73.12%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 78.98%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 78.20%\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 76.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cda09c18:\n",
      "        Fold accuracies: ['68.36%', '76.25%', '78.98%', '78.20%', '73.12%']\n",
      "        Average fitness: 74.98% Â± 3.88%\n",
      "        Best fold: Fold 3 with 78.98%\n",
      "      New best fitness in this generation: 74.98%!\n",
      "      Fitness obtained: 74.98% | Best in generation: 74.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 7a89b1b9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 7a89b1b9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6124, acc=77.34% (best=77.34%)\n",
      "          Fold 3 Epoch 1: loss=0.6980, acc=71.95% (best=71.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6846, acc=59.45% (best=59.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6856, acc=68.91% (best=68.91%)\n",
      "          Fold 5 Epoch 1: loss=0.6566, acc=58.52% (best=58.52%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.34%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 60.78%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 82.11%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 73.44%\n",
      "          Fold 2 Epoch 30: loss=0.1620, acc=61.33% (best=69.77%)\n",
      "          Fold 2: Early stopping at epoch 56\n",
      "      â†’ Fold 2 completed: 72.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7a89b1b9:\n",
      "        Fold accuracies: ['77.34%', '72.03%', '82.11%', '73.44%', '60.78%']\n",
      "        Average fitness: 73.14% Â± 7.10%\n",
      "        Best fold: Fold 3 with 82.11%\n",
      "      Fitness obtained: 73.14% | Best in generation: 74.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 982d2e17)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 982d2e17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5812, acc=79.77% (best=79.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6264, acc=57.19% (best=57.19%)\n",
      "          Fold 2 Epoch 1: loss=0.6161, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6475, acc=84.61% (best=84.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6599, acc=73.05% (best=73.05%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 79.77%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 73.05%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 89.38%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 65.23%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 70.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 982d2e17:\n",
      "        Fold accuracies: ['79.77%', '70.62%', '89.38%', '73.05%', '65.23%']\n",
      "        Average fitness: 75.61% Â± 8.32%\n",
      "        Best fold: Fold 3 with 89.38%\n",
      "      New best fitness in this generation: 75.61%!\n",
      "      Fitness obtained: 75.61% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: b818078d)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b818078d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6372, acc=77.66% (best=77.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6815, acc=65.08% (best=65.08%)\n",
      "          Fold 2 Epoch 1: loss=0.6734, acc=69.84% (best=69.84%)\n",
      "          Fold 5 Epoch 1: loss=0.6871, acc=66.56% (best=66.56%)\n",
      "          Fold 3 Epoch 1: loss=0.6611, acc=79.53% (best=79.53%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 77.81%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.53%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.44%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 72.89%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 76.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b818078d:\n",
      "        Fold accuracies: ['77.81%', '72.89%', '79.53%', '76.88%', '68.44%']\n",
      "        Average fitness: 75.11% Â± 3.99%\n",
      "        Best fold: Fold 3 with 79.53%\n",
      "      Fitness obtained: 75.11% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 3feb8f99)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 3feb8f99 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.3990, acc=52.03% (best=52.03%)\n",
      "          Fold 2 Epoch 1: loss=0.5401, acc=46.25% (best=46.25%)\n",
      "          Fold 4 Epoch 1: loss=0.5739, acc=71.64% (best=71.64%)\n",
      "          Fold 3 Epoch 1: loss=0.5444, acc=56.48% (best=56.48%)\n",
      "          Fold 5 Epoch 1: loss=0.5249, acc=62.58% (best=62.58%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 71.64%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 71.88%\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 80.00%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "          Fold 1 Epoch 30: loss=0.0007, acc=62.81% (best=69.22%)\n",
      "          Fold 1: Early stopping at epoch 39\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3feb8f99:\n",
      "        Fold accuracies: ['69.22%', '69.61%', '80.00%', '71.64%', '71.88%']\n",
      "        Average fitness: 72.47% Â± 3.91%\n",
      "        Best fold: Fold 3 with 80.00%\n",
      "      Fitness obtained: 72.47% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 79b596c9)\n",
      "      Architecture: 10 conv + 2 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 79b596c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.2484, acc=69.69% (best=69.69%)\n",
      "          Fold 4 Epoch 1: loss=0.4817, acc=45.31% (best=45.31%)\n",
      "          Fold 3 Epoch 1: loss=0.4292, acc=78.91% (best=78.91%)\n",
      "          Fold 2 Epoch 1: loss=0.4510, acc=54.53% (best=54.53%)\n",
      "          Fold 5 Epoch 1: loss=0.4570, acc=53.36% (best=53.36%)\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch.       ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 79b596c9:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 77f2b212)\n",
      "      Architecture: 9 conv + 3 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 77f2b212 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.7544, acc=51.17% (best=51.17%)\n",
      "          Fold 5 Epoch 1: loss=0.7263, acc=43.05% (best=43.05%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 53.36%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 49.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 77f2b212:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '53.36%', '0.00%', '49.69%']\n",
      "        Average fitness: 20.61% Â± 25.27%\n",
      "        Best fold: Fold 3 with 53.36%\n",
      "      Fitness obtained: 20.61% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: e9cdb5b5)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e9cdb5b5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6134, acc=68.12% (best=68.12%)\n",
      "          Fold 2 Epoch 1: loss=0.5807, acc=60.31% (best=60.31%)\n",
      "          Fold 5 Epoch 1: loss=0.6002, acc=56.17% (best=56.17%)\n",
      "          Fold 1 Epoch 1: loss=0.4616, acc=74.92% (best=74.92%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 70.86%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 78.28%\n",
      "          Fold 2 Epoch 30: loss=0.1237, acc=64.22% (best=65.47%)\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 65.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e9cdb5b5:\n",
      "        Fold accuracies: ['78.28%', '65.47%', '0.00%', '71.17%', '70.86%']\n",
      "        Average fitness: 57.16% Â± 28.87%\n",
      "        Best fold: Fold 1 with 78.28%\n",
      "      Fitness obtained: 57.16% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: a4d3baa9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model a4d3baa9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6964, acc=62.03% (best=62.03%)\n",
      "          Fold 4 Epoch 1: loss=0.7159, acc=54.22% (best=54.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6866, acc=60.08% (best=60.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7100, acc=59.22% (best=59.22%)\n",
      "          Fold 2 Epoch 1: loss=0.7221, acc=65.47% (best=65.47%)\n",
      "          Fold 5: Early stopping at epoch 12          Fold 1: Early stopping at epoch 12\n",
      "\n",
      "      â†’ Fold 1 completed: 77.89%\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.75%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 75.62%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 75.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a4d3baa9:\n",
      "        Fold accuracies: ['77.89%', '75.31%', '75.62%', '68.75%', '66.88%']\n",
      "        Average fitness: 72.89% Â± 4.28%\n",
      "        Best fold: Fold 1 with 77.89%\n",
      "      Fitness obtained: 72.89% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: cea9ae8d)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model cea9ae8d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6457, acc=63.52% (best=63.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6760, acc=80.00% (best=80.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6465, acc=68.67% (best=68.67%)\n",
      "          Fold 5 Epoch 1: loss=0.6524, acc=61.41% (best=61.41%)\n",
      "          Fold 1 Epoch 1: loss=0.5848, acc=71.41% (best=71.41%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 73.44%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 83.20%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.95%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 76.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cea9ae8d:\n",
      "        Fold accuracies: ['76.72%', '73.44%', '83.20%', '66.95%', '62.81%']\n",
      "        Average fitness: 72.62% Â± 7.18%\n",
      "        Best fold: Fold 3 with 83.20%\n",
      "      Fitness obtained: 72.62% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: ba8d7418)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ba8d7418 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6411, acc=55.94% (best=55.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6521, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 1: loss=0.5659, acc=77.89% (best=77.89%)\n",
      "          Fold 5 Epoch 1: loss=0.6682, acc=64.69% (best=64.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6265, acc=74.14% (best=74.14%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.89%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 68.20%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 72.73%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 84.92%\n",
      "          Fold 2 Epoch 30: loss=0.1853, acc=67.58% (best=68.91%)\n",
      "          Fold 2: Early stopping at epoch 44\n",
      "      â†’ Fold 2 completed: 69.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ba8d7418:\n",
      "        Fold accuracies: ['77.89%', '69.53%', '84.92%', '72.73%', '68.20%']\n",
      "        Average fitness: 74.66% Â± 6.12%\n",
      "        Best fold: Fold 3 with 84.92%\n",
      "      Fitness obtained: 74.66% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 998833fc)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 998833fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6273, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6500, acc=64.69% (best=64.69%)\n",
      "          Fold 1 Epoch 1: loss=0.5370, acc=71.09% (best=71.09%)\n",
      "          Fold 5 Epoch 1: loss=0.5954, acc=44.45% (best=44.45%)\n",
      "          Fold 2 Epoch 1: loss=0.6318, acc=69.22% (best=69.22%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.41%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.70%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 68.67%\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 998833fc:\n",
      "        Fold accuracies: ['75.70%', '71.17%', '66.41%', '71.25%', '68.67%']\n",
      "        Average fitness: 70.64% Â± 3.10%\n",
      "        Best fold: Fold 1 with 75.70%\n",
      "      Fitness obtained: 70.64% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: d53af64b)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d53af64b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5481, acc=70.31% (best=70.31%)\n",
      "          Fold 2 Epoch 1: loss=0.6183, acc=58.83% (best=58.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6352, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 1: loss=0.6388, acc=78.98% (best=78.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6325, acc=64.14% (best=64.14%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 70.31%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 79.38%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "          Fold 5 Epoch 30: loss=0.1378, acc=57.58% (best=64.06%)\n",
      "          Fold 4 Epoch 30: loss=0.1482, acc=81.25% (best=85.00%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 85.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d53af64b:\n",
      "        Fold accuracies: ['70.31%', '69.84%', '79.38%', '85.00%', '64.06%']\n",
      "        Average fitness: 73.72% Â± 7.47%\n",
      "        Best fold: Fold 4 with 85.00%\n",
      "      Fitness obtained: 73.72% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: f48dc059)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f48dc059 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5998, acc=78.12% (best=78.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6518, acc=61.41% (best=61.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6664, acc=83.36% (best=83.36%)\n",
      "          Fold 5 Epoch 1: loss=0.6488, acc=55.16% (best=55.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6526, acc=52.03% (best=52.03%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.41%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.75%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 87.03%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 70.94%\n",
      "          Fold 2 Epoch 30: loss=0.2074, acc=68.98% (best=73.91%)\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 73.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f48dc059:\n",
      "        Fold accuracies: ['78.75%', '73.91%', '87.03%', '61.41%', '70.94%']\n",
      "        Average fitness: 74.41% Â± 8.48%\n",
      "        Best fold: Fold 3 with 87.03%\n",
      "      Fitness obtained: 74.41% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: d7953478)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d7953478 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6240, acc=73.28% (best=73.28%)\n",
      "          Fold 2 Epoch 1: loss=0.6227, acc=67.03% (best=67.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6105, acc=58.67% (best=58.67%)\n",
      "          Fold 3 Epoch 1: loss=0.6142, acc=78.83% (best=78.83%)\n",
      "          Fold 1 Epoch 1: loss=0.5349, acc=71.41% (best=71.41%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 71.41%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 76.48%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 74.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d7953478:\n",
      "        Fold accuracies: ['71.41%', '74.61%', '78.83%', '76.48%', '58.67%']\n",
      "        Average fitness: 72.00% Â± 7.09%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 72.00% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 331dc895)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 331dc895 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 331dc895:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 9f2fa2c6)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9f2fa2c6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6323, acc=61.33% (best=61.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6421, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 1: loss=0.6281, acc=80.55% (best=80.55%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 83.83%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 76.88%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9f2fa2c6:\n",
      "        Fold accuracies: ['0.00%', '68.91%', '83.83%', '76.88%', '0.00%']\n",
      "        Average fitness: 45.92% Â± 37.79%\n",
      "        Best fold: Fold 3 with 83.83%\n",
      "      Fitness obtained: 45.92% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: c9e4c519)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model c9e4c519 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6865, acc=72.81% (best=72.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6922, acc=48.67% (best=48.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7166, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 1: loss=0.6982, acc=65.62% (best=65.62%)\n",
      "          Fold 5 Epoch 1: loss=0.7020, acc=48.91% (best=48.91%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 78.12%\n",
      "          Fold 5 Epoch 30: loss=0.2260, acc=62.11% (best=64.92%)\n",
      "          Fold 5: Early stopping at epoch 34\n",
      "      â†’ Fold 5 completed: 64.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c9e4c519:\n",
      "        Fold accuracies: ['77.19%', '68.20%', '78.12%', '70.70%', '64.92%']\n",
      "        Average fitness: 71.83% Â± 5.11%\n",
      "        Best fold: Fold 3 with 78.12%\n",
      "      Fitness obtained: 71.83% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 1e33c5d1)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e33c5d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6493, acc=76.56% (best=76.56%)\n",
      "          Fold 5 Epoch 1: loss=0.6720, acc=63.52% (best=63.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6871, acc=66.25% (best=66.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6799, acc=66.41% (best=66.41%)\n",
      "          Fold 2 Epoch 1: loss=0.6674, acc=66.41% (best=66.41%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.52%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 72.97%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 84.77%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 82.81%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e33c5d1:\n",
      "        Fold accuracies: ['84.77%', '70.16%', '82.81%', '72.97%', '63.52%']\n",
      "        Average fitness: 74.84% Â± 7.95%\n",
      "        Best fold: Fold 1 with 84.77%\n",
      "      Fitness obtained: 74.84% | Best in generation: 75.61% | Global best: 79.20%\n",
      "\n",
      "GENERATION 23 STATISTICS:\n",
      "   Maximum fitness: 75.61%\n",
      "   Average fitness: 61.22%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 24.13%\n",
      "   Best individual: 982d2e17 with 75.61%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 12/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=24.13)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 982d2e17 (fitness: 75.61%)\n",
      "   Elite 2: b818078d (fitness: 75.11%)\n",
      "   Elite 3: cda09c18 (fitness: 74.98%)\n",
      "   Elite 4: 1e33c5d1 (fitness: 74.84%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 13/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 24\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 24)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 982d2e17)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 982d2e17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6283, acc=53.83% (best=53.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6432, acc=79.45% (best=79.45%)\n",
      "          Fold 1 Epoch 1: loss=0.5634, acc=76.02% (best=76.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6283, acc=61.88% (best=61.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6735, acc=60.16% (best=60.16%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.45%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 71.88%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 982d2e17:\n",
      "        Fold accuracies: ['77.19%', '65.86%', '79.45%', '71.88%', '61.88%']\n",
      "        Average fitness: 71.25% Â± 6.63%\n",
      "        Best fold: Fold 3 with 79.45%\n",
      "      New best fitness in this generation: 71.25%!\n",
      "      Fitness obtained: 71.25% | Best in generation: 71.25% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b818078d)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b818078d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6581, acc=76.64% (best=76.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6667, acc=62.11% (best=62.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6677, acc=60.94% (best=60.94%)\n",
      "          Fold 3 Epoch 1: loss=0.6770, acc=75.62% (best=75.62%)\n",
      "          Fold 5 Epoch 1: loss=0.6881, acc=70.39% (best=70.39%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 70.39%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 80.70%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 91.64%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b818078d:\n",
      "        Fold accuracies: ['80.70%', '68.91%', '91.64%', '73.28%', '70.39%']\n",
      "        Average fitness: 76.98% Â± 8.38%\n",
      "        Best fold: Fold 3 with 91.64%\n",
      "      New best fitness in this generation: 76.98%!\n",
      "      Fitness obtained: 76.98% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: cda09c18)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model cda09c18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7463, acc=58.44% (best=58.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6960, acc=51.72% (best=51.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6792, acc=67.58% (best=67.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6934, acc=70.47% (best=70.47%)\n",
      "          Fold 5 Epoch 1: loss=0.6763, acc=67.11% (best=67.11%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.11%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 72.58%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 87.50%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 78.98%\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 73.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cda09c18:\n",
      "        Fold accuracies: ['87.50%', '72.58%', '78.98%', '73.28%', '67.11%']\n",
      "        Average fitness: 75.89% Â± 6.92%\n",
      "        Best fold: Fold 1 with 87.50%\n",
      "      Fitness obtained: 75.89% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1e33c5d1)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e33c5d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6756, acc=71.33% (best=71.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6832, acc=62.81% (best=62.81%)\n",
      "          Fold 1 Epoch 1: loss=0.6381, acc=76.33% (best=76.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6704, acc=81.80% (best=81.80%)\n",
      "          Fold 5 Epoch 1: loss=0.6596, acc=72.11% (best=72.11%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 73.36%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 83.12%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 72.11%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 83.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e33c5d1:\n",
      "        Fold accuracies: ['83.12%', '73.36%', '83.83%', '69.61%', '72.11%']\n",
      "        Average fitness: 76.41% Â± 5.90%\n",
      "        Best fold: Fold 3 with 83.83%\n",
      "      Fitness obtained: 76.41% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 67eb31a4)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 67eb31a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6166, acc=86.02% (best=86.02%)\n",
      "          Fold 1 Epoch 1: loss=0.5763, acc=73.67% (best=73.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6451, acc=69.61% (best=69.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6400, acc=69.06% (best=69.06%)\n",
      "          Fold 5 Epoch 1: loss=0.6329, acc=66.95% (best=66.95%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.02%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 77.03%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 75.78%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 75.47%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 67eb31a4:\n",
      "        Fold accuracies: ['77.03%', '75.78%', '86.02%', '75.47%', '68.36%']\n",
      "        Average fitness: 76.53% Â± 5.63%\n",
      "        Best fold: Fold 3 with 86.02%\n",
      "      Fitness obtained: 76.53% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 34c4e9b4)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 34c4e9b4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5630, acc=62.34% (best=62.34%)\n",
      "          Fold 3 Epoch 1: loss=0.5965, acc=86.33% (best=86.33%)\n",
      "          Fold 1 Epoch 1: loss=0.4370, acc=68.28% (best=68.28%)\n",
      "          Fold 5 Epoch 1: loss=0.5592, acc=57.50% (best=57.50%)\n",
      "          Fold 4 Epoch 1: loss=0.5773, acc=71.48% (best=71.48%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 86.33%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 67.66%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 76.95%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 71.48%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 72.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 34c4e9b4:\n",
      "        Fold accuracies: ['76.95%', '67.66%', '86.33%', '72.89%', '71.48%']\n",
      "        Average fitness: 75.06% Â± 6.37%\n",
      "        Best fold: Fold 3 with 86.33%\n",
      "      Fitness obtained: 75.06% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 9dae32a0)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9dae32a0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7076, acc=63.44% (best=63.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7015, acc=45.23% (best=45.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6890, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 1: loss=0.7055, acc=57.89% (best=57.89%)\n",
      "          Fold 1 Epoch 1: loss=0.6912, acc=54.92% (best=54.92%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 61.09%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 75.08%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 79.38%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9dae32a0:\n",
      "        Fold accuracies: ['75.08%', '61.09%', '77.58%', '79.38%', '68.36%']\n",
      "        Average fitness: 72.30% Â± 6.73%\n",
      "        Best fold: Fold 4 with 79.38%\n",
      "      Fitness obtained: 72.30% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: cb805dd2)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model cb805dd2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5846, acc=60.70% (best=60.70%)\n",
      "          Fold 3 Epoch 1: loss=0.5461, acc=71.72% (best=71.72%)\n",
      "          Fold 5 Epoch 1: loss=0.5022, acc=61.25% (best=61.25%)\n",
      "          Fold 2 Epoch 1: loss=0.5459, acc=66.80% (best=66.80%)\n",
      "          Fold 1 Epoch 1: loss=0.3881, acc=73.05% (best=73.05%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.42%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 70.78%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.25%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 64.92%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 72.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cb805dd2:\n",
      "        Fold accuracies: ['82.42%', '72.58%', '81.25%', '70.78%', '64.92%']\n",
      "        Average fitness: 74.39% Â± 6.60%\n",
      "        Best fold: Fold 1 with 82.42%\n",
      "      Fitness obtained: 74.39% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: fa6b058b)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model fa6b058b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6484, acc=50.70% (best=50.70%)\n",
      "          Fold 3 Epoch 1: loss=0.6432, acc=78.75% (best=78.75%)\n",
      "          Fold 5 Epoch 1: loss=0.6361, acc=70.23% (best=70.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6296, acc=65.39% (best=65.39%)\n",
      "          Fold 1 Epoch 1: loss=0.5418, acc=66.48% (best=66.48%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 78.75%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 70.23%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 68.28%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 72.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fa6b058b:\n",
      "        Fold accuracies: ['68.28%', '65.39%', '78.75%', '72.73%', '70.23%']\n",
      "        Average fitness: 71.08% Â± 4.53%\n",
      "        Best fold: Fold 3 with 78.75%\n",
      "      Fitness obtained: 71.08% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 95ffc0a0)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 95ffc0a0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6372, acc=59.77% (best=59.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6690, acc=59.84% (best=59.84%)\n",
      "          Fold 1 Epoch 1: loss=0.5538, acc=67.11% (best=67.11%)\n",
      "          Fold 4 Epoch 1: loss=0.6630, acc=54.69% (best=54.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6437, acc=63.44% (best=63.44%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 71.33%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 72.03%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 73.52%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 77.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 95ffc0a0:\n",
      "        Fold accuracies: ['77.97%', '73.52%', '71.33%', '72.03%', '67.03%']\n",
      "        Average fitness: 72.38% Â± 3.53%\n",
      "        Best fold: Fold 1 with 77.97%\n",
      "      Fitness obtained: 72.38% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 0194df16)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 0194df16 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6836, acc=73.44% (best=73.44%)          Fold 1 Epoch 1: loss=0.6560, acc=67.73% (best=67.73%)\n",
      "\n",
      "          Fold 2 Epoch 1: loss=0.7195, acc=57.89% (best=57.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6891, acc=68.52% (best=68.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6972, acc=60.00% (best=60.00%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 73.52%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 78.83%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 73.05%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 76.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0194df16:\n",
      "        Fold accuracies: ['73.52%', '65.86%', '78.83%', '76.95%', '73.05%']\n",
      "        Average fitness: 73.64% Â± 4.45%\n",
      "        Best fold: Fold 3 with 78.83%\n",
      "      Fitness obtained: 73.64% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 4f6add52)\n",
      "      Architecture: 7 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 4f6add52 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.4426, acc=74.38% (best=74.38%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 79.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4f6add52:\n",
      "        Fold accuracies: ['79.69%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 15.94% Â± 31.88%\n",
      "        Best fold: Fold 1 with 79.69%\n",
      "      Fitness obtained: 15.94% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: f1b1fa3d)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f1b1fa3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6682, acc=69.77% (best=69.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6760, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6752, acc=57.97% (best=57.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6663, acc=66.64% (best=66.64%)\n",
      "          Fold 3 Epoch 1: loss=0.7032, acc=60.47% (best=60.47%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.64%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 84.53%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 84.92%\n",
      "          Fold 4 Epoch 30: loss=0.2391, acc=64.30% (best=73.20%)\n",
      "          Fold 4: Early stopping at epoch 30\n",
      "      â†’ Fold 4 completed: 73.20%\n",
      "          Fold 2 Epoch 30: loss=0.2309, acc=61.33% (best=64.53%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f1b1fa3d:\n",
      "        Fold accuracies: ['84.53%', '64.53%', '84.92%', '73.20%', '66.64%']\n",
      "        Average fitness: 74.77% Â± 8.62%\n",
      "        Best fold: Fold 3 with 84.92%\n",
      "      Fitness obtained: 74.77% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 3ae4bfd7)\n",
      "      Architecture: 4 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 3ae4bfd7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.2867, acc=54.92% (best=54.92%)\n",
      "          Fold 3 Epoch 1: loss=0.3326, acc=67.66% (best=67.66%)\n",
      "          Fold 2 Epoch 1: loss=0.2739, acc=59.61% (best=59.61%)\n",
      "          Fold 5 Epoch 1: loss=0.2677, acc=58.67% (best=58.67%)\n",
      "          Fold 1 Epoch 1: loss=0.2245, acc=68.28% (best=68.28%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 68.91%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 56.09%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.20%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3ae4bfd7:\n",
      "        Fold accuracies: ['70.08%', '63.20%', '68.91%', '56.09%', '64.06%']\n",
      "        Average fitness: 64.47% Â± 4.96%\n",
      "        Best fold: Fold 1 with 70.08%\n",
      "      Fitness obtained: 64.47% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 35619b3d)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 35619b3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5177, acc=72.97% (best=72.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6057, acc=48.98% (best=48.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6083, acc=66.41% (best=66.41%)\n",
      "          Fold 4 Epoch 1: loss=0.6156, acc=68.44% (best=68.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6111, acc=70.23% (best=70.23%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 75.00%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 71.56%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 62.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 35619b3d:\n",
      "        Fold accuracies: ['77.19%', '70.23%', '75.00%', '71.56%', '62.42%']\n",
      "        Average fitness: 71.28% Â± 5.07%\n",
      "        Best fold: Fold 1 with 77.19%\n",
      "      Fitness obtained: 71.28% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 546c5522)\n",
      "      Architecture: 10 conv + 2 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 546c5522 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7194, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6947, acc=60.00% (best=60.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7001, acc=66.33% (best=66.33%)\n",
      "          Fold 3 Epoch 1: loss=0.7039, acc=79.22% (best=79.22%)\n",
      "          Fold 4 Epoch 1: loss=0.7024, acc=60.94% (best=60.94%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 86.80%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.81%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 62.89%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 70.08%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 546c5522:\n",
      "        Fold accuracies: ['75.70%', '62.89%', '86.80%', '70.08%', '67.81%']\n",
      "        Average fitness: 72.66% Â± 8.18%\n",
      "        Best fold: Fold 3 with 86.80%\n",
      "      Fitness obtained: 72.66% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: e648c8ce)\n",
      "      Architecture: 10 conv + 2 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model e648c8ce with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7372, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7301, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 1: loss=0.7180, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7180, acc=50.70% (best=50.70%)\n",
      "          Fold 1 Epoch 1: loss=0.7104, acc=49.61% (best=49.61%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.61%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 53.20%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 53.91%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 50.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e648c8ce:\n",
      "        Fold accuracies: ['53.20%', '50.47%', '51.02%', '49.61%', '53.91%']\n",
      "        Average fitness: 51.64% Â± 1.64%\n",
      "        Best fold: Fold 5 with 53.91%\n",
      "      Fitness obtained: 51.64% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 5d6fca56)\n",
      "      Architecture: 10 conv + 5 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5d6fca56 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7004, acc=53.59% (best=53.59%)\n",
      "          Fold 3 Epoch 1: loss=0.7052, acc=70.70% (best=70.70%)\n",
      "          Fold 4 Epoch 1: loss=0.7105, acc=64.61% (best=64.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7158, acc=61.25% (best=61.25%)\n",
      "          Fold 2 Epoch 1: loss=0.7222, acc=55.62% (best=55.62%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.25%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 76.88%\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 1 Epoch 30: loss=0.0487, acc=82.50% (best=82.50%)\n",
      "          Fold 1: Early stopping at epoch 40\n",
      "      â†’ Fold 1 completed: 82.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5d6fca56:\n",
      "        Fold accuracies: ['82.50%', '68.20%', '76.88%', '72.42%', '61.25%']\n",
      "        Average fitness: 72.25% Â± 7.26%\n",
      "        Best fold: Fold 1 with 82.50%\n",
      "      Fitness obtained: 72.25% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: ee50ea45)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ee50ea45 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6108, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.5348, acc=65.62% (best=65.62%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 61.48%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 70.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ee50ea45:\n",
      "        Fold accuracies: ['70.55%', '61.48%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 26.41% Â± 32.47%\n",
      "        Best fold: Fold 1 with 70.55%\n",
      "      Fitness obtained: 26.41% | Best in generation: 76.98% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 8cbcbacb)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8cbcbacb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6424, acc=76.02% (best=76.02%)\n",
      "          Fold 4 Epoch 1: loss=0.6367, acc=54.14% (best=54.14%)\n",
      "          Fold 5 Epoch 1: loss=0.6263, acc=57.97% (best=57.97%)\n",
      "          Fold 2 Epoch 1: loss=0.6142, acc=50.94% (best=50.94%)\n",
      "          Fold 1 Epoch 1: loss=0.5833, acc=77.19% (best=77.19%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 83.12%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 82.66%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 72.66%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 67.97%\n",
      "          Fold 4 Epoch 30: loss=0.1743, acc=75.08% (best=80.78%)\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 80.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8cbcbacb:\n",
      "        Fold accuracies: ['82.66%', '72.66%', '83.12%', '80.78%', '67.97%']\n",
      "        Average fitness: 77.44% Â± 6.05%\n",
      "        Best fold: Fold 3 with 83.12%\n",
      "      New best fitness in this generation: 77.44%!\n",
      "      Fitness obtained: 77.44% | Best in generation: 77.44% | Global best: 79.20%\n",
      "\n",
      "GENERATION 24 STATISTICS:\n",
      "   Maximum fitness: 77.44%\n",
      "   Average fitness: 67.14%\n",
      "   Minimum fitness: 15.94%\n",
      "   Standard deviation: 16.37%\n",
      "   Best individual: 8cbcbacb with 77.44%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 14/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=16.37)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 8cbcbacb (fitness: 77.44%)\n",
      "   Elite 2: b818078d (fitness: 76.98%)\n",
      "   Elite 3: 67eb31a4 (fitness: 76.53%)\n",
      "   Elite 4: 1e33c5d1 (fitness: 76.41%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 15/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 25\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 25)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 8cbcbacb)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 8cbcbacb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6470, acc=43.98% (best=43.98%)\n",
      "          Fold 1 Epoch 1: loss=0.5925, acc=83.52% (best=83.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6325, acc=52.27% (best=52.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6361, acc=77.03% (best=77.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6423, acc=65.47% (best=65.47%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 83.52%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.03%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 67.42%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 75.08%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 71.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8cbcbacb:\n",
      "        Fold accuracies: ['83.52%', '75.08%', '77.03%', '71.02%', '67.42%']\n",
      "        Average fitness: 74.81% Â± 5.47%\n",
      "        Best fold: Fold 1 with 83.52%\n",
      "      New best fitness in this generation: 74.81%!\n",
      "      Fitness obtained: 74.81% | Best in generation: 74.81% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b818078d)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b818078d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6853, acc=62.50% (best=62.50%)\n",
      "          Fold 5 Epoch 1: loss=0.6635, acc=65.00% (best=65.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6558, acc=67.27% (best=67.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6675, acc=75.08% (best=75.08%)\n",
      "          Fold 1 Epoch 1: loss=0.6366, acc=68.12% (best=68.12%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 71.80%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.78%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 77.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b818078d:\n",
      "        Fold accuracies: ['77.42%', '67.27%', '79.69%', '71.80%', '65.78%']\n",
      "        Average fitness: 72.39% Â± 5.46%\n",
      "        Best fold: Fold 3 with 79.69%\n",
      "      Fitness obtained: 72.39% | Best in generation: 74.81% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 67eb31a4)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 67eb31a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6531, acc=66.09% (best=66.09%)\n",
      "          Fold 1 Epoch 1: loss=0.5374, acc=75.00% (best=75.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6528, acc=68.52% (best=68.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6279, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6262, acc=88.44% (best=88.44%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.00%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 88.44%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 78.59%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 67eb31a4:\n",
      "        Fold accuracies: ['75.00%', '70.23%', '88.44%', '78.59%', '63.20%']\n",
      "        Average fitness: 75.09% Â± 8.43%\n",
      "        Best fold: Fold 3 with 88.44%\n",
      "      New best fitness in this generation: 75.09%!\n",
      "      Fitness obtained: 75.09% | Best in generation: 75.09% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1e33c5d1)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1e33c5d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6632, acc=76.48% (best=76.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6824, acc=65.86% (best=65.86%)\n",
      "          Fold 5 Epoch 1: loss=0.6637, acc=66.88% (best=66.88%)\n",
      "          Fold 2 Epoch 1: loss=0.6639, acc=59.45% (best=59.45%)\n",
      "          Fold 1 Epoch 1: loss=0.6296, acc=81.64% (best=81.64%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 81.64%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.50%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 74.69%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 70.55%\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e33c5d1:\n",
      "        Fold accuracies: ['81.64%', '69.84%', '82.50%', '74.69%', '70.55%']\n",
      "        Average fitness: 75.84% Â± 5.35%\n",
      "        Best fold: Fold 3 with 82.50%\n",
      "      New best fitness in this generation: 75.84%!\n",
      "      Fitness obtained: 75.84% | Best in generation: 75.84% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: da3bd809)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model da3bd809 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.5210, acc=76.95% (best=76.95%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 77.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for da3bd809:\n",
      "        Fold accuracies: ['77.27%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 15.45% Â± 30.91%\n",
      "        Best fold: Fold 1 with 77.27%\n",
      "      Fitness obtained: 15.45% | Best in generation: 75.84% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: c02e7f59)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model c02e7f59 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5990, acc=61.33% (best=61.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6665, acc=82.42% (best=82.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6613, acc=73.12% (best=73.12%)\n",
      "          Fold 5 Epoch 1: loss=0.6523, acc=52.97% (best=52.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6617, acc=47.42% (best=47.42%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 83.83%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 74.30%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 66.64%\n",
      "          Fold 4 Epoch 30: loss=0.1942, acc=62.19% (best=68.44%)\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 68.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c02e7f59:\n",
      "        Fold accuracies: ['66.64%', '74.30%', '83.83%', '68.59%', '64.77%']\n",
      "        Average fitness: 71.62% Â± 6.89%\n",
      "        Best fold: Fold 3 with 83.83%\n",
      "      Fitness obtained: 71.62% | Best in generation: 75.84% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: ee141d5c)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ee141d5c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6658, acc=61.80% (best=61.80%)          Fold 5 Epoch 1: loss=0.6514, acc=58.67% (best=58.67%)\n",
      "\n",
      "          Fold 1 Epoch 1: loss=0.6153, acc=67.50% (best=67.50%)\n",
      "          Fold 3 Epoch 1: loss=0.6472, acc=72.27% (best=72.27%)\n",
      "          Fold 2 Epoch 1: loss=0.6646, acc=62.03% (best=62.03%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 68.28%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 64.38%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 75.47%\n",
      "          Fold 4 Epoch 30: loss=0.1808, acc=68.28% (best=73.05%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 73.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ee141d5c:\n",
      "        Fold accuracies: ['68.28%', '64.38%', '75.47%', '73.05%', '58.67%']\n",
      "        Average fitness: 67.97% Â± 6.02%\n",
      "        Best fold: Fold 3 with 75.47%\n",
      "      Fitness obtained: 67.97% | Best in generation: 75.84% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 831cc9c9)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 831cc9c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6374, acc=59.61% (best=59.61%)\n",
      "          Fold 1 Epoch 1: loss=0.5767, acc=80.86% (best=80.86%)\n",
      "          Fold 5 Epoch 1: loss=0.6494, acc=64.61% (best=64.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6583, acc=81.48% (best=81.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6198, acc=53.28% (best=53.28%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 80.86%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 74.84%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 87.11%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 73.75%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 73.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 831cc9c9:\n",
      "        Fold accuracies: ['80.86%', '73.12%', '87.11%', '73.75%', '74.84%']\n",
      "        Average fitness: 77.94% Â± 5.35%\n",
      "        Best fold: Fold 3 with 87.11%\n",
      "      New best fitness in this generation: 77.94%!\n",
      "      Fitness obtained: 77.94% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 832d5ffc)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 832d5ffc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7198, acc=55.86% (best=55.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6922, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6871, acc=61.25% (best=61.25%)\n",
      "          Fold 1 Epoch 1: loss=0.7028, acc=57.03% (best=57.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6987, acc=50.47% (best=50.47%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 67.97%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 84.06%\n",
      "          Fold 1 Epoch 30: loss=0.0582, acc=81.25% (best=83.52%)\n",
      "          Fold 4 Epoch 30: loss=0.2156, acc=79.53% (best=81.25%)\n",
      "          Fold 5 Epoch 30: loss=0.1831, acc=60.39% (best=67.58%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 67.58%\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 83.52%\n",
      "          Fold 4: Early stopping at epoch 43\n",
      "      â†’ Fold 4 completed: 83.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 832d5ffc:\n",
      "        Fold accuracies: ['83.52%', '67.97%', '84.06%', '83.28%', '67.58%']\n",
      "        Average fitness: 77.28% Â± 7.77%\n",
      "        Best fold: Fold 3 with 84.06%\n",
      "      Fitness obtained: 77.28% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 7f69065a)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 7f69065a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6527, acc=83.28% (best=83.28%)\n",
      "          Fold 5 Epoch 1: loss=0.6586, acc=56.48% (best=56.48%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.48%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 92.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7f69065a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '92.42%', '0.00%', '56.48%']\n",
      "        Average fitness: 29.78% Â± 38.20%\n",
      "        Best fold: Fold 3 with 92.42%\n",
      "      Fitness obtained: 29.78% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 31ee2d99)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 31ee2d99 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch.       ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.5088, acc=60.39% (best=60.39%)\n",
      "          Fold 3 Epoch 1: loss=0.4899, acc=73.20% (best=73.20%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 77.03%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 71.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 31ee2d99:\n",
      "        Fold accuracies: ['0.00%', '71.72%', '77.03%', '0.00%', '0.00%']\n",
      "        Average fitness: 29.75% Â± 36.47%\n",
      "        Best fold: Fold 3 with 77.03%\n",
      "      Fitness obtained: 29.75% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 19ccfaf2)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 19ccfaf2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6688, acc=65.47% (best=65.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6492, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6366, acc=69.30% (best=69.30%)\n",
      "          Fold 2 Epoch 1: loss=0.6368, acc=62.66% (best=62.66%)\n",
      "          Fold 5 Epoch 1: loss=0.6609, acc=58.75% (best=58.75%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 82.66%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 71.95%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 82.73%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 75.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19ccfaf2:\n",
      "        Fold accuracies: ['82.66%', '75.00%', '82.73%', '73.36%', '71.95%']\n",
      "        Average fitness: 77.14% Â± 4.64%\n",
      "        Best fold: Fold 3 with 82.73%\n",
      "      Fitness obtained: 77.14% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: e2bf6d93)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model e2bf6d93 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5855, acc=57.34% (best=57.34%)\n",
      "          Fold 5 Epoch 1: loss=0.5984, acc=66.25% (best=66.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6333, acc=68.67% (best=68.67%)\n",
      "          Fold 1 Epoch 1: loss=0.4978, acc=70.31% (best=70.31%)\n",
      "          Fold 3 Epoch 1: loss=0.6096, acc=75.00% (best=75.00%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 75.00%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 74.22%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 69.38%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 79.77%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 77.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e2bf6d93:\n",
      "        Fold accuracies: ['79.77%', '74.22%', '75.00%', '77.50%', '69.38%']\n",
      "        Average fitness: 75.17% Â± 3.49%\n",
      "        Best fold: Fold 1 with 79.77%\n",
      "      Fitness obtained: 75.17% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 499cdb3d)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 499cdb3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6268, acc=74.84% (best=74.84%)\n",
      "          Fold 5 Epoch 1: loss=0.6346, acc=58.59% (best=58.59%)\n",
      "          Fold 3 Epoch 1: loss=0.6456, acc=73.75% (best=73.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6618, acc=67.66% (best=67.66%)\n",
      "          Fold 1 Epoch 1: loss=0.5892, acc=83.75% (best=83.75%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.75%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 83.75%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 77.97%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 74.06%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 72.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 499cdb3d:\n",
      "        Fold accuracies: ['83.75%', '77.97%', '73.75%', '74.06%', '72.11%']\n",
      "        Average fitness: 76.33% Â± 4.18%\n",
      "        Best fold: Fold 1 with 83.75%\n",
      "      Fitness obtained: 76.33% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 259b9c98)\n",
      "      Architecture: 1 conv + 5 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 259b9c98 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7041, acc=49.06% (best=49.06%)\n",
      "          Fold 3 Epoch 1: loss=0.6983, acc=49.06% (best=49.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7005, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.6934, acc=46.72% (best=46.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6933, acc=47.66% (best=47.66%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 54.53%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 52.34%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 64.92%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 52.34%\n",
      "          Fold 1 Epoch 30: loss=0.0023, acc=53.36% (best=55.62%)\n",
      "          Fold 1: Early stopping at epoch 46\n",
      "      â†’ Fold 1 completed: 57.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 259b9c98:\n",
      "        Fold accuracies: ['57.73%', '64.92%', '54.53%', '52.34%', '52.34%']\n",
      "        Average fitness: 56.38% Â± 4.71%\n",
      "        Best fold: Fold 2 with 64.92%\n",
      "      Fitness obtained: 56.38% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 45c6dbcc)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 45c6dbcc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6927, acc=66.41% (best=66.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6829, acc=73.98% (best=73.98%)\n",
      "          Fold 1 Epoch 1: loss=0.6695, acc=74.06% (best=74.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6770, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6900, acc=59.53% (best=59.53%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 72.50%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 81.64%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 84.06%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 72.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 45c6dbcc:\n",
      "        Fold accuracies: ['81.64%', '68.91%', '84.06%', '72.03%', '72.50%']\n",
      "        Average fitness: 75.83% Â± 5.92%\n",
      "        Best fold: Fold 3 with 84.06%\n",
      "      Fitness obtained: 75.83% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 41f23c70)\n",
      "      Architecture: 5 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 41f23c70 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5058, acc=78.52% (best=78.52%)\n",
      "          Fold 2 Epoch 1: loss=0.4743, acc=63.91% (best=63.91%)\n",
      "          Fold 4 Epoch 1: loss=0.4875, acc=45.62% (best=45.62%)\n",
      "          Fold 5 Epoch 1: loss=0.4507, acc=61.80% (best=61.80%)\n",
      "          Fold 1 Epoch 1: loss=0.4012, acc=77.11% (best=77.11%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 63.91%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.72%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 59.77%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 41f23c70:\n",
      "        Fold accuracies: ['77.11%', '63.91%', '81.72%', '59.77%', '65.94%']\n",
      "        Average fitness: 69.69% Â± 8.32%\n",
      "        Best fold: Fold 3 with 81.72%\n",
      "      Fitness obtained: 69.69% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 2b1d1588)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 2b1d1588 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 5: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 2: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 1: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "      ERROR in Fold 4: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 137, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 102, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 155, in _calculate_conv_output_size\n",
      "    raise ValueError(\n",
      "ValueError: Error calculating conv output size: Given normalized_shape=[1], expected input with shape [*, 1], but got input of size[1, 1, 11520]. Genome may produce invalid architecture. num_conv_layers=9, sequence_length=11520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 2b1d1588:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: aae87ffd)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model aae87ffd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6882, acc=67.03% (best=67.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6951, acc=62.73% (best=62.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6997, acc=55.47% (best=55.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6908, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6797, acc=64.14% (best=64.14%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 71.17%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 75.00%\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 81.41%\n",
      "          Fold 4 Epoch 30: loss=0.2188, acc=79.61% (best=79.69%)\n",
      "          Fold 4: Early stopping at epoch 52\n",
      "      â†’ Fold 4 completed: 80.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for aae87ffd:\n",
      "        Fold accuracies: ['75.00%', '71.17%', '81.41%', '80.86%', '67.58%']\n",
      "        Average fitness: 75.20% Â± 5.38%\n",
      "        Best fold: Fold 3 with 81.41%\n",
      "      Fitness obtained: 75.20% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 972fde83)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 972fde83 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7058, acc=54.06% (best=54.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7092, acc=49.77% (best=49.77%)\n",
      "          Fold 1 Epoch 1: loss=0.6891, acc=71.41% (best=71.41%)\n",
      "          Fold 3 Epoch 1: loss=0.7087, acc=74.14% (best=74.14%)\n",
      "          Fold 2 Epoch 1: loss=0.7017, acc=58.05% (best=58.05%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 79.77%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.94%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 75.70%\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 79.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 972fde83:\n",
      "        Fold accuracies: ['75.70%', '68.20%', '79.77%', '79.69%', '60.94%']\n",
      "        Average fitness: 72.86% Â± 7.30%\n",
      "        Best fold: Fold 3 with 79.77%\n",
      "      Fitness obtained: 72.86% | Best in generation: 77.94% | Global best: 79.20%\n",
      "\n",
      "GENERATION 25 STATISTICS:\n",
      "   Maximum fitness: 77.94%\n",
      "   Average fitness: 62.33%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 22.93%\n",
      "   Best individual: 831cc9c9 with 77.94%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 16/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=22.93)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 831cc9c9 (fitness: 77.94%)\n",
      "   Elite 2: 832d5ffc (fitness: 77.28%)\n",
      "   Elite 3: 19ccfaf2 (fitness: 77.14%)\n",
      "   Elite 4: 499cdb3d (fitness: 76.33%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 17/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 26\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 26)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 831cc9c9)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 831cc9c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6160, acc=65.62% (best=65.62%)\n",
      "          Fold 3 Epoch 1: loss=0.6471, acc=77.11% (best=77.11%)\n",
      "          Fold 4 Epoch 1: loss=0.6568, acc=60.39% (best=60.39%)\n",
      "          Fold 5 Epoch 1: loss=0.6211, acc=60.62% (best=60.62%)\n",
      "          Fold 1 Epoch 1: loss=0.5447, acc=70.78% (best=70.78%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.39%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 77.27%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 78.52%\n",
      "          Fold 1 Epoch 30: loss=0.0061, acc=79.38% (best=84.30%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 84.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 831cc9c9:\n",
      "        Fold accuracies: ['84.30%', '78.52%', '77.27%', '60.39%', '62.27%']\n",
      "        Average fitness: 72.55% Â± 9.48%\n",
      "        Best fold: Fold 1 with 84.30%\n",
      "      New best fitness in this generation: 72.55%!\n",
      "      Fitness obtained: 72.55% | Best in generation: 72.55% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 832d5ffc)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 832d5ffc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7294, acc=51.48% (best=51.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6927, acc=68.83% (best=68.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6972, acc=47.19% (best=47.19%)\n",
      "          Fold 2 Epoch 1: loss=0.7635, acc=62.27% (best=62.27%)\n",
      "          Fold 1 Epoch 1: loss=0.6817, acc=71.25% (best=71.25%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 62.27%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 83.75%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 87.58%\n",
      "          Fold 4 Epoch 30: loss=0.2579, acc=73.59% (best=77.66%)\n",
      "          Fold 4: Early stopping at epoch 42\n",
      "      â†’ Fold 4 completed: 77.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 832d5ffc:\n",
      "        Fold accuracies: ['87.58%', '62.27%', '83.75%', '77.89%', '65.39%']\n",
      "        Average fitness: 75.38% Â± 9.97%\n",
      "        Best fold: Fold 1 with 87.58%\n",
      "      New best fitness in this generation: 75.38%!\n",
      "      Fitness obtained: 75.38% | Best in generation: 75.38% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 19ccfaf2)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 19ccfaf2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5873, acc=73.12% (best=73.12%)\n",
      "          Fold 3 Epoch 1: loss=0.6520, acc=71.56% (best=71.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6573, acc=73.59% (best=73.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6679, acc=58.98% (best=58.98%)\n",
      "          Fold 5 Epoch 1: loss=0.6533, acc=56.64% (best=56.64%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.59%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 71.56%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 74.69%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 73.91%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 64.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19ccfaf2:\n",
      "        Fold accuracies: ['73.91%', '73.59%', '71.56%', '74.69%', '64.84%']\n",
      "        Average fitness: 71.72% Â± 3.59%\n",
      "        Best fold: Fold 4 with 74.69%\n",
      "      Fitness obtained: 71.72% | Best in generation: 75.38% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 499cdb3d)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 499cdb3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6881, acc=71.56% (best=71.56%)\n",
      "          Fold 2 Epoch 1: loss=0.6179, acc=69.22% (best=69.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6447, acc=90.86% (best=90.86%)\n",
      "          Fold 1 Epoch 1: loss=0.6209, acc=83.05% (best=83.05%)\n",
      "          Fold 5 Epoch 1: loss=0.6486, acc=66.88% (best=66.88%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 90.86%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 83.59%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 73.44%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 73.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 499cdb3d:\n",
      "        Fold accuracies: ['83.59%', '73.44%', '90.86%', '73.52%', '66.88%']\n",
      "        Average fitness: 77.66% Â± 8.49%\n",
      "        Best fold: Fold 3 with 90.86%\n",
      "      New best fitness in this generation: 77.66%!\n",
      "      Fitness obtained: 77.66% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: b47156b0)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b47156b0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6843, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 1: loss=0.7277, acc=67.27% (best=67.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6878, acc=64.38% (best=64.38%)\n",
      "          Fold 5 Epoch 1: loss=0.6680, acc=65.55% (best=65.55%)\n",
      "          Fold 1 Epoch 1: loss=0.6444, acc=78.36% (best=78.36%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 77.11%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 81.09%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 70.86%\n",
      "          Fold 2 Epoch 30: loss=0.1691, acc=66.80% (best=76.25%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 76.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b47156b0:\n",
      "        Fold accuracies: ['81.09%', '76.25%', '77.11%', '73.12%', '70.86%']\n",
      "        Average fitness: 75.69% Â± 3.51%\n",
      "        Best fold: Fold 1 with 81.09%\n",
      "      Fitness obtained: 75.69% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: b30e5663)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b30e5663 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6203, acc=68.83% (best=68.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6919, acc=69.45% (best=69.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6467, acc=67.89% (best=67.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6704, acc=57.03% (best=57.03%)\n",
      "          Fold 3 Epoch 1: loss=0.6480, acc=79.14% (best=79.14%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.89%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 71.48%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 93.05%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 75.39%\n",
      "          Fold 1 Epoch 30: loss=0.0057, acc=72.73% (best=76.09%)\n",
      "          Fold 1: Early stopping at epoch 35\n",
      "      â†’ Fold 1 completed: 76.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30e5663:\n",
      "        Fold accuracies: ['76.09%', '71.48%', '93.05%', '75.39%', '67.89%']\n",
      "        Average fitness: 76.78% Â± 8.65%\n",
      "        Best fold: Fold 3 with 93.05%\n",
      "      Fitness obtained: 76.78% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 18417f50)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 18417f50 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5923, acc=77.58% (best=77.58%)\n",
      "          Fold 1 Epoch 1: loss=0.5005, acc=69.30% (best=69.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6168, acc=68.83% (best=68.83%)\n",
      "          Fold 2 Epoch 1: loss=0.5816, acc=50.78% (best=50.78%)\n",
      "          Fold 5 Epoch 1: loss=0.5830, acc=56.25% (best=56.25%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 82.34%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 75.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 18417f50:\n",
      "        Fold accuracies: ['82.34%', '67.11%', '77.58%', '75.86%', '69.84%']\n",
      "        Average fitness: 74.55% Â± 5.46%\n",
      "        Best fold: Fold 1 with 82.34%\n",
      "      Fitness obtained: 74.55% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 799edae6)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 799edae6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6734, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 1: loss=0.6822, acc=62.81% (best=62.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6772, acc=71.25% (best=71.25%)\n",
      "          Fold 1 Epoch 1: loss=0.6404, acc=73.83% (best=73.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6885, acc=58.83% (best=58.83%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.83%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 71.02%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 71.64%\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 80.23%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 799edae6:\n",
      "        Fold accuracies: ['78.83%', '70.16%', '80.23%', '71.64%', '71.02%']\n",
      "        Average fitness: 74.38% Â± 4.26%\n",
      "        Best fold: Fold 3 with 80.23%\n",
      "      Fitness obtained: 74.38% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 040e15ae)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 040e15ae with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7065, acc=49.06% (best=49.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7191, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7165, acc=46.02% (best=46.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7227, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.7579, acc=41.02% (best=41.02%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.39%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 78.28%\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 1 Epoch 30: loss=0.1071, acc=65.31% (best=75.70%)\n",
      "          Fold 3 Epoch 30: loss=0.2963, acc=59.84% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 75.70%\n",
      "          Fold 3 Epoch 60: loss=0.1764, acc=67.19% (best=68.59%)\n",
      "          Fold 3: Early stopping at epoch 63\n",
      "      â†’ Fold 3 completed: 68.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 040e15ae:\n",
      "        Fold accuracies: ['75.70%', '78.28%', '68.59%', '50.39%', '54.92%']\n",
      "        Average fitness: 65.58% Â± 11.11%\n",
      "        Best fold: Fold 2 with 78.28%\n",
      "      Fitness obtained: 65.58% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: b4b6c81c)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b4b6c81c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6990, acc=47.50% (best=47.50%)\n",
      "          Fold 4 Epoch 1: loss=0.7141, acc=49.84% (best=49.84%)\n",
      "          Fold 5 Epoch 1: loss=0.7153, acc=53.12% (best=53.12%)\n",
      "          Fold 3 Epoch 1: loss=0.7132, acc=51.17% (best=51.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7021, acc=72.03% (best=72.03%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 74.92%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 79.53%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 69.45%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 71.09%\n",
      "          Fold 5 Epoch 30: loss=0.1649, acc=69.22% (best=74.92%)\n",
      "          Fold 5: Early stopping at epoch 39\n",
      "      â†’ Fold 5 completed: 74.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b4b6c81c:\n",
      "        Fold accuracies: ['74.92%', '71.09%', '79.53%', '69.45%', '74.92%']\n",
      "        Average fitness: 73.98% Â± 3.50%\n",
      "        Best fold: Fold 3 with 79.53%\n",
      "      Fitness obtained: 73.98% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 10c1908e)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 10c1908e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5637, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.5607, acc=67.89% (best=67.89%)\n",
      "          Fold 3 Epoch 1: loss=0.5462, acc=61.41% (best=61.41%)\n",
      "          Fold 5 Epoch 1: loss=0.5470, acc=68.05% (best=68.05%)\n",
      "          Fold 1 Epoch 1: loss=0.4142, acc=55.94% (best=55.94%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 84.22%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 73.28%\n",
      "          Fold 4 Epoch 30: loss=0.0778, acc=68.28% (best=73.59%)\n",
      "          Fold 1 Epoch 30: loss=0.0004, acc=63.67% (best=74.69%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 74.69%\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 73.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 10c1908e:\n",
      "        Fold accuracies: ['74.69%', '70.39%', '84.22%', '73.59%', '73.28%']\n",
      "        Average fitness: 75.23% Â± 4.71%\n",
      "        Best fold: Fold 3 with 84.22%\n",
      "      Fitness obtained: 75.23% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: aeacb72a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model aeacb72a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7100, acc=58.67% (best=58.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7112, acc=60.39% (best=60.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7055, acc=60.16% (best=60.16%)\n",
      "          Fold 4 Epoch 1: loss=0.7113, acc=51.72% (best=51.72%)\n",
      "          Fold 2 Epoch 1: loss=0.7222, acc=57.58% (best=57.58%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 83.59%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 76.09%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 72.03%\n",
      "          Fold 4 Epoch 30: loss=0.2917, acc=60.00% (best=73.36%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for aeacb72a:\n",
      "        Fold accuracies: ['76.09%', '70.23%', '83.59%', '73.36%', '72.03%']\n",
      "        Average fitness: 75.06% Â± 4.67%\n",
      "        Best fold: Fold 3 with 83.59%\n",
      "      Fitness obtained: 75.06% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 786ca22a)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 786ca22a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6973, acc=58.44% (best=58.44%)\n",
      "          Fold 1 Epoch 1: loss=0.6984, acc=73.28% (best=73.28%)\n",
      "          Fold 5 Epoch 1: loss=0.6771, acc=67.81% (best=67.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6851, acc=72.19% (best=72.19%)\n",
      "          Fold 3 Epoch 1: loss=0.6837, acc=75.70% (best=75.70%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 69.84%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 79.61%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 89.06%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 60.86%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 77.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 786ca22a:\n",
      "        Fold accuracies: ['79.61%', '60.86%', '89.06%', '77.11%', '69.84%']\n",
      "        Average fitness: 75.30% Â± 9.48%\n",
      "        Best fold: Fold 3 with 89.06%\n",
      "      Fitness obtained: 75.30% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 9306ab40)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 9306ab40 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6729, acc=66.64% (best=66.64%)\n",
      "          Fold 3 Epoch 1: loss=0.6566, acc=79.69% (best=79.69%)\n",
      "          Fold 5 Epoch 1: loss=0.6481, acc=64.14% (best=64.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6564, acc=63.44% (best=63.44%)\n",
      "          Fold 1 Epoch 1: loss=0.6244, acc=77.11% (best=77.11%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 77.11%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 79.69%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 69.45%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9306ab40:\n",
      "        Fold accuracies: ['77.11%', '70.16%', '79.69%', '68.75%', '69.45%']\n",
      "        Average fitness: 73.03% Â± 4.48%\n",
      "        Best fold: Fold 3 with 79.69%\n",
      "      Fitness obtained: 73.03% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 5423c05b)\n",
      "      Architecture: 9 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5423c05b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7032, acc=54.06% (best=54.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7008, acc=58.28% (best=58.28%)\n",
      "          Fold 2 Epoch 1: loss=0.7075, acc=73.05% (best=73.05%)\n",
      "          Fold 4 Epoch 1: loss=0.7002, acc=53.52% (best=53.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6880, acc=73.83% (best=73.83%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 74.61%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 80.47%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 77.03%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 81.02%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5423c05b:\n",
      "        Fold accuracies: ['80.47%', '74.61%', '81.02%', '77.03%', '65.00%']\n",
      "        Average fitness: 75.62% Â± 5.80%\n",
      "        Best fold: Fold 3 with 81.02%\n",
      "      Fitness obtained: 75.62% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: ef626a9f)\n",
      "      Architecture: 10 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model ef626a9f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6571, acc=77.11% (best=77.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6727, acc=68.67% (best=68.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6678, acc=74.30% (best=74.30%)\n",
      "          Fold 1 Epoch 1: loss=0.6485, acc=78.75% (best=78.75%)\n",
      "          Fold 5 Epoch 1: loss=0.6819, acc=56.25% (best=56.25%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 77.11%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 74.30%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 88.91%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ef626a9f:\n",
      "        Fold accuracies: ['88.91%', '70.16%', '77.11%', '74.30%', '63.75%']\n",
      "        Average fitness: 74.84% Â± 8.35%\n",
      "        Best fold: Fold 1 with 88.91%\n",
      "      Fitness obtained: 74.84% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 43b9084a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 43b9084a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5139, acc=71.25% (best=71.25%)\n",
      "          Fold 4 Epoch 1: loss=0.5342, acc=67.58% (best=67.58%)\n",
      "          Fold 2 Epoch 1: loss=0.5112, acc=65.00% (best=65.00%)\n",
      "          Fold 5 Epoch 1: loss=0.4905, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.3011, acc=76.95% (best=76.95%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 76.95%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 68.36%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 75.55%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 76.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 43b9084a:\n",
      "        Fold accuracies: ['76.95%', '68.36%', '76.33%', '75.55%', '63.20%']\n",
      "        Average fitness: 72.08% Â± 5.41%\n",
      "        Best fold: Fold 1 with 76.95%\n",
      "      Fitness obtained: 72.08% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 7b3b983e)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 7b3b983e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6332, acc=67.27% (best=67.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6231, acc=69.53% (best=69.53%)\n",
      "          Fold 2 Epoch 1: loss=0.6037, acc=62.58% (best=62.58%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 72.19%\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 77.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7b3b983e:\n",
      "        Fold accuracies: ['0.00%', '72.19%', '77.58%', '68.91%', '0.00%']\n",
      "        Average fitness: 43.73% Â± 35.82%\n",
      "        Best fold: Fold 3 with 77.58%\n",
      "      Fitness obtained: 43.73% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: f23bb213)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model f23bb213 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6818, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6833, acc=54.61% (best=54.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7260, acc=59.53% (best=59.53%)\n",
      "          Fold 3 Epoch 1: loss=0.6902, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6906, acc=75.00% (best=75.00%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 59.53%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.73%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 58.05%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 71.02%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 80.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f23bb213:\n",
      "        Fold accuracies: ['80.78%', '58.05%', '71.02%', '59.53%', '62.73%']\n",
      "        Average fitness: 66.42% Â± 8.47%\n",
      "        Best fold: Fold 1 with 80.78%\n",
      "      Fitness obtained: 66.42% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: f735801e)\n",
      "      Architecture: 3 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model f735801e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.2878, acc=62.58% (best=62.58%)\n",
      "          Fold 5 Epoch 1: loss=0.2444, acc=58.05% (best=58.05%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.58%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f735801e:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '62.58%', '60.47%']\n",
      "        Average fitness: 24.61% Â± 30.15%\n",
      "        Best fold: Fold 4 with 62.58%\n",
      "      Fitness obtained: 24.61% | Best in generation: 77.66% | Global best: 79.20%\n",
      "\n",
      "GENERATION 26 STATISTICS:\n",
      "   Maximum fitness: 77.66%\n",
      "   Average fitness: 69.71%\n",
      "   Minimum fitness: 24.61%\n",
      "   Standard deviation: 12.57%\n",
      "   Best individual: 499cdb3d with 77.66%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 18/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=12.57)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 499cdb3d (fitness: 77.66%)\n",
      "   Elite 2: b30e5663 (fitness: 76.78%)\n",
      "   Elite 3: b47156b0 (fitness: 75.69%)\n",
      "   Elite 4: 5423c05b (fitness: 75.62%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 19/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 27\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 27)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 499cdb3d)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 499cdb3d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6364, acc=73.28% (best=73.28%)\n",
      "          Fold 1 Epoch 1: loss=0.5557, acc=75.78% (best=75.78%)\n",
      "          Fold 3 Epoch 1: loss=0.6550, acc=83.44% (best=83.44%)\n",
      "          Fold 5 Epoch 1: loss=0.6377, acc=60.23% (best=60.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6545, acc=50.31% (best=50.31%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 83.44%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 75.78%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 78.75%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 72.19%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 499cdb3d:\n",
      "        Fold accuracies: ['75.78%', '78.75%', '83.44%', '72.19%', '65.70%']\n",
      "        Average fitness: 75.17% Â± 6.00%\n",
      "        Best fold: Fold 3 with 83.44%\n",
      "      New best fitness in this generation: 75.17%!\n",
      "      Fitness obtained: 75.17% | Best in generation: 75.17% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b30e5663)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b30e5663 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6422, acc=72.42% (best=72.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6405, acc=74.77% (best=74.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6487, acc=71.02% (best=71.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6490, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.5788, acc=70.16% (best=70.16%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 75.16%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 76.48%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 79.69%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 80.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30e5663:\n",
      "        Fold accuracies: ['80.31%', '79.69%', '76.48%', '75.16%', '66.17%']\n",
      "        Average fitness: 75.56% Â± 5.07%\n",
      "        Best fold: Fold 1 with 80.31%\n",
      "      New best fitness in this generation: 75.56%!\n",
      "      Fitness obtained: 75.56% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: b47156b0)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model b47156b0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6997, acc=43.67% (best=43.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7103, acc=68.83% (best=68.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7068, acc=62.81% (best=62.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6895, acc=56.80% (best=56.80%)\n",
      "          Fold 1 Epoch 1: loss=0.6444, acc=78.59% (best=78.59%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 78.59%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 66.33%\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 90.00%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 66.41%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b47156b0:\n",
      "        Fold accuracies: ['78.59%', '65.16%', '90.00%', '66.41%', '66.33%']\n",
      "        Average fitness: 73.30% Â± 9.69%\n",
      "        Best fold: Fold 3 with 90.00%\n",
      "      Fitness obtained: 73.30% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 5423c05b)\n",
      "      Architecture: 9 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5423c05b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6962, acc=62.27% (best=62.27%)\n",
      "          Fold 3 Epoch 1: loss=0.7059, acc=67.81% (best=67.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6979, acc=65.31% (best=65.31%)\n",
      "          Fold 4 Epoch 1: loss=0.7015, acc=47.42% (best=47.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7173, acc=56.95% (best=56.95%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 74.84%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 63.28%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 79.06%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 73.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5423c05b:\n",
      "        Fold accuracies: ['79.06%', '69.61%', '74.84%', '73.75%', '63.28%']\n",
      "        Average fitness: 72.11% Â± 5.34%\n",
      "        Best fold: Fold 1 with 79.06%\n",
      "      Fitness obtained: 72.11% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 565b3c74)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 565b3c74 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7026, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7074, acc=52.89% (best=52.89%)\n",
      "          Fold 2 Epoch 1: loss=0.7304, acc=69.14% (best=69.14%)\n",
      "          Fold 5 Epoch 1: loss=0.6943, acc=58.52% (best=58.52%)\n",
      "          Fold 1 Epoch 1: loss=0.7014, acc=77.97% (best=77.97%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 79.77%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 69.14%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.12%\n",
      "          Fold 4 Epoch 30: loss=0.3546, acc=70.78% (best=70.78%)\n",
      "          Fold 3 Epoch 30: loss=0.2870, acc=83.28% (best=88.12%)\n",
      "          Fold 3: Early stopping at epoch 38\n",
      "      â†’ Fold 3 completed: 88.12%\n",
      "          Fold 4: Early stopping at epoch 40\n",
      "      â†’ Fold 4 completed: 70.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 565b3c74:\n",
      "        Fold accuracies: ['79.77%', '69.14%', '88.12%', '70.78%', '68.12%']\n",
      "        Average fitness: 75.19% Â± 7.67%\n",
      "        Best fold: Fold 3 with 88.12%\n",
      "      Fitness obtained: 75.19% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 4cbe74ec)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 4cbe74ec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6982, acc=44.69% (best=44.69%)\n",
      "          Fold 3 Epoch 1: loss=0.7165, acc=64.22% (best=64.22%)\n",
      "          Fold 4 Epoch 1: loss=0.7071, acc=66.41% (best=66.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6966, acc=66.95% (best=66.95%)\n",
      "          Fold 2 Epoch 1: loss=0.7045, acc=47.27% (best=47.27%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 59.84%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 85.86%\n",
      "          Fold 4 Epoch 30: loss=0.3368, acc=74.14% (best=82.11%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 82.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4cbe74ec:\n",
      "        Fold accuracies: ['71.56%', '59.84%', '85.86%', '82.11%', '58.52%']\n",
      "        Average fitness: 71.58% Â± 11.16%\n",
      "        Best fold: Fold 3 with 85.86%\n",
      "      Fitness obtained: 71.58% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 454d3645)\n",
      "      Architecture: 9 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 454d3645 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6570, acc=58.83% (best=58.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6981, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6826, acc=57.66% (best=57.66%)\n",
      "          Fold 3 Epoch 1: loss=0.6877, acc=73.83% (best=73.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6853, acc=49.92% (best=49.92%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 73.83%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 68.20%\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "          Fold 4 Epoch 30: loss=0.1594, acc=68.12% (best=72.58%)\n",
      "          Fold 4: Early stopping at epoch 47\n",
      "      â†’ Fold 4 completed: 75.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 454d3645:\n",
      "        Fold accuracies: ['58.83%', '68.83%', '73.83%', '75.78%', '68.20%']\n",
      "        Average fitness: 69.09% Â± 5.89%\n",
      "        Best fold: Fold 4 with 75.78%\n",
      "      Fitness obtained: 69.09% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 1d6d656d)\n",
      "      Architecture: 9 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 1d6d656d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6741, acc=47.89% (best=47.89%)\n",
      "          Fold 3 Epoch 1: loss=0.6541, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6595, acc=63.75% (best=63.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6642, acc=46.17% (best=46.17%)\n",
      "          Fold 1 Epoch 1: loss=0.6090, acc=65.23% (best=65.23%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 46.17%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 70.00%\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 56.48%\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 86.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d6d656d:\n",
      "        Fold accuracies: ['70.00%', '67.81%', '86.56%', '46.17%', '56.48%']\n",
      "        Average fitness: 65.41% Â± 13.59%\n",
      "        Best fold: Fold 3 with 86.56%\n",
      "      Fitness obtained: 65.41% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 34859278)\n",
      "      Architecture: 11 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 34859278 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6766, acc=70.31% (best=70.31%)\n",
      "          Fold 2 Epoch 1: loss=0.6846, acc=64.45% (best=64.45%)\n",
      "          Fold 1 Epoch 1: loss=0.6551, acc=68.91% (best=68.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6916, acc=66.48% (best=66.48%)\n",
      "          Fold 5 Epoch 1: loss=0.6767, acc=68.59% (best=68.59%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.75%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 68.59%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 82.11%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 71.09%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 34859278:\n",
      "        Fold accuracies: ['78.75%', '71.09%', '82.11%', '75.23%', '68.59%']\n",
      "        Average fitness: 75.16% Â± 4.92%\n",
      "        Best fold: Fold 3 with 82.11%\n",
      "      Fitness obtained: 75.16% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 92af2143)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 92af2143 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.5271, acc=62.66% (best=62.66%)\n",
      "          Fold 3 Epoch 1: loss=0.6182, acc=63.83% (best=63.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6566, acc=62.50% (best=62.50%)\n",
      "          Fold 5 Epoch 1: loss=0.6117, acc=60.39% (best=60.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6371, acc=68.75% (best=68.75%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 67.66%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 73.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 92af2143:\n",
      "        Fold accuracies: ['73.20%', '68.75%', '67.66%', '73.12%', '60.39%']\n",
      "        Average fitness: 68.62% Â± 4.69%\n",
      "        Best fold: Fold 1 with 73.20%\n",
      "      Fitness obtained: 68.62% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 6b5c6b0b)\n",
      "      Architecture: 9 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 6b5c6b0b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6110, acc=68.20% (best=68.20%)\n",
      "          Fold 3 Epoch 1: loss=0.6550, acc=75.55% (best=75.55%)\n",
      "          Fold 5 Epoch 1: loss=0.6299, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6351, acc=72.42% (best=72.42%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 81.25%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 73.75%\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 77.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6b5c6b0b:\n",
      "        Fold accuracies: ['0.00%', '73.75%', '81.25%', '77.58%', '65.39%']\n",
      "        Average fitness: 59.59% Â± 30.26%\n",
      "        Best fold: Fold 3 with 81.25%\n",
      "      Fitness obtained: 59.59% | Best in generation: 75.56% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 2806d728)\n",
      "      Architecture: 9 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2806d728 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7180, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 1: loss=0.7134, acc=73.91% (best=73.91%)\n",
      "          Fold 1 Epoch 1: loss=0.7084, acc=74.30% (best=74.30%)\n",
      "          Fold 4 Epoch 1: loss=0.7202, acc=52.03% (best=52.03%)\n",
      "          Fold 5 Epoch 1: loss=0.7155, acc=52.27% (best=52.27%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 73.91%\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 78.12%\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 87.19%\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 69.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2806d728:\n",
      "        Fold accuracies: ['78.12%', '73.91%', '87.19%', '73.36%', '69.45%']\n",
      "        Average fitness: 76.41% Â± 6.05%\n",
      "        Best fold: Fold 3 with 87.19%\n",
      "      New best fitness in this generation: 76.41%!\n",
      "      Fitness obtained: 76.41% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: d61854c4)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model d61854c4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7080, acc=65.00% (best=65.00%)\n",
      "          Fold 2 Epoch 1: loss=0.8095, acc=57.19% (best=57.19%)\n",
      "          Fold 5 Epoch 1: loss=0.8332, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6774, acc=60.16% (best=60.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6902, acc=55.94% (best=55.94%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 67.42%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 68.52%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 1 Epoch 30: loss=0.0378, acc=76.02% (best=78.28%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 78.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d61854c4:\n",
      "        Fold accuracies: ['78.28%', '67.42%', '68.52%', '70.70%', '66.48%']\n",
      "        Average fitness: 70.28% Â± 4.24%\n",
      "        Best fold: Fold 1 with 78.28%\n",
      "      Fitness obtained: 70.28% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 65d1c808)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 65d1c808 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6631, acc=76.48% (best=76.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7006, acc=62.34% (best=62.34%)\n",
      "          Fold 2 Epoch 1: loss=0.7125, acc=63.52% (best=63.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6934, acc=68.98% (best=68.98%)\n",
      "          Fold 5 Epoch 1: loss=0.6783, acc=50.31% (best=50.31%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 78.83%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 65.31%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 77.97%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 76.33%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 70.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 65d1c808:\n",
      "        Fold accuracies: ['78.83%', '65.31%', '76.33%', '77.97%', '70.31%']\n",
      "        Average fitness: 73.75% Â± 5.16%\n",
      "        Best fold: Fold 1 with 78.83%\n",
      "      Fitness obtained: 73.75% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 3f6052f9)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 3f6052f9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6671, acc=70.08% (best=70.08%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 80.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3f6052f9:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '80.16%', '0.00%']\n",
      "        Average fitness: 16.03% Â± 32.06%\n",
      "        Best fold: Fold 4 with 80.16%\n",
      "      Fitness obtained: 16.03% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 00ff3dc2)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 00ff3dc2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6701, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 1: loss=0.6641, acc=79.77% (best=79.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6703, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6754, acc=67.34% (best=67.34%)\n",
      "          Fold 1 Epoch 1: loss=0.6433, acc=68.12% (best=68.12%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 84.30%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 73.28%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "          Fold 2 Epoch 30: loss=0.1728, acc=67.50% (best=70.55%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 00ff3dc2:\n",
      "        Fold accuracies: ['73.28%', '70.55%', '84.30%', '69.61%', '63.98%']\n",
      "        Average fitness: 72.34% Â± 6.70%\n",
      "        Best fold: Fold 3 with 84.30%\n",
      "      Fitness obtained: 72.34% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 1d6e3c78)\n",
      "      Architecture: 10 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 1d6e3c78 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6230, acc=72.58% (best=72.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6678, acc=51.95% (best=51.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6591, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6608, acc=52.89% (best=52.89%)\n",
      "          Fold 3 Epoch 1: loss=0.6768, acc=65.47% (best=65.47%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 72.58%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.75%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 83.20%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d6e3c78:\n",
      "        Fold accuracies: ['72.58%', '70.55%', '83.20%', '63.75%', '63.20%']\n",
      "        Average fitness: 70.66% Â± 7.27%\n",
      "        Best fold: Fold 3 with 83.20%\n",
      "      Fitness obtained: 70.66% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: de7e0047)\n",
      "      Architecture: 9 conv + 2 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model de7e0047 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7148, acc=59.06% (best=59.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6848, acc=65.86% (best=65.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6844, acc=70.94% (best=70.94%)\n",
      "          Fold 3 Epoch 1: loss=0.6818, acc=67.58% (best=67.58%)\n",
      "          Fold 5 Epoch 1: loss=0.6736, acc=66.09% (best=66.09%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 66.09%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 75.94%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 62.42%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 83.91%\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 76.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for de7e0047:\n",
      "        Fold accuracies: ['75.94%', '62.42%', '83.91%', '76.25%', '66.09%']\n",
      "        Average fitness: 72.92% Â± 7.72%\n",
      "        Best fold: Fold 3 with 83.91%\n",
      "      Fitness obtained: 72.92% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 2ea4b39a)\n",
      "      Architecture: 6 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 2ea4b39a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5426, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.5100, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 1: loss=0.5693, acc=54.84% (best=54.84%)\n",
      "          Fold 5 Epoch 1: loss=0.5494, acc=58.05% (best=58.05%)\n",
      "          Fold 4 Epoch 1: loss=0.5543, acc=73.91% (best=73.91%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.39%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 73.91%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.05%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 77.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2ea4b39a:\n",
      "        Fold accuracies: ['50.39%', '54.84%', '77.97%', '73.91%', '58.05%']\n",
      "        Average fitness: 63.03% Â± 10.89%\n",
      "        Best fold: Fold 3 with 77.97%\n",
      "      Fitness obtained: 63.03% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 6877894d)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 6877894d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 117, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/3072186574.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_591137/1727256860.py\", line 225, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.7325, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7147, acc=53.28% (best=53.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7001, acc=59.22% (best=59.22%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 74.14%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 80.39%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6877894d:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '74.14%', '80.39%', '68.75%']\n",
      "        Average fitness: 44.66% Â± 36.65%\n",
      "        Best fold: Fold 4 with 80.39%\n",
      "      Fitness obtained: 44.66% | Best in generation: 76.41% | Global best: 79.20%\n",
      "\n",
      "GENERATION 27 STATISTICS:\n",
      "   Maximum fitness: 76.41%\n",
      "   Average fitness: 67.04%\n",
      "   Minimum fitness: 16.03%\n",
      "   Standard deviation: 13.71%\n",
      "   Best individual: 2806d728 with 76.41%\n",
      "   Global best individual: 275f7b79 with 79.20%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 20/20\n",
      "\n",
      "ðŸ›‘ EARLY STOPPING: No improvement for 20 generations\n",
      "   Best fitness plateau: 79.20%\n",
      "\n",
      "================================================================================\n",
      "EVOLUTION COMPLETED!\n",
      "================================================================================\n",
      "Best individual found:\n",
      "   ID: 275f7b79\n",
      "   Fitness: 79.20%\n",
      "   Origin generation: 27\n",
      "   Total generations processed: 28\n",
      "   Generations without improvement: 20/20\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "EVOLUTION PROCESS COMPLETED\n",
      "============================================================\n",
      "Completed at: 15:19:26\n",
      "Total execution time: 1 day, 2:31:33.967733\n",
      "Total generations: 27\n",
      "Best fitness achieved: 79.20%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CONFIGURACIÃ“N DE DATASET DE AUDIO\n",
    "# ==========================================\n",
    "\n",
    "# Ruta OS-independiente usando os.path.join\n",
    "CONFIG['data_path'] = os.path.join('data', 'sets', 'folds_5')\n",
    "\n",
    "# ==========================================\n",
    "# AJUSTES OPCIONALES\n",
    "# ==========================================\n",
    "\n",
    "# Ajustar poblaciÃ³n y generaciones si es necesario\n",
    "# CONFIG['population_size'] = 8\n",
    "# CONFIG['max_generations'] = 20\n",
    "# CONFIG['fitness_threshold'] = 85.0  # Para audio, 85% es buen objetivo\n",
    "# CONFIG['batch_size'] = 16  # Reducir si hay problemas de memoria\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUDIO NEUROEVOLUTION CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Dataset: Audio (Parkinson Classification)\")\n",
    "print(f\"   Dataset ID: {CONFIG['dataset_id']}\")\n",
    "print(f\"   Fold ID: {CONFIG['fold_id']}\")\n",
    "print(f\"   Number of folds: {CONFIG['num_folds']} (all used during evolution)\")\n",
    "print(f\"   Data Path: {CONFIG['data_path']}\")\n",
    "print(f\"   Number of channels: {CONFIG['num_channels']} (1D audio)\")\n",
    "print(f\"   Sequence length: {CONFIG['sequence_length']} (will be auto-detected)\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']} (Control vs Pathological)\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Population: {CONFIG['population_size']} individuals\")\n",
    "print(f\"   Maximum generations: {CONFIG['max_generations']}\")\n",
    "print(f\"   Target fitness: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Platform: {os.name} ({'Windows' if os.name == 'nt' else 'Unix/Linux/Mac'})\")\n",
    "print(f\"   Parallelization: Enabled (5 threads per individual)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify dataset availability with the new configuration\n",
    "print(f\"\\nVerifying audio dataset...\")\n",
    "load_dataset(CONFIG)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET VERIFIED - READY FOR PARALLEL 5-FOLD CV EVOLUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Initialize neuroevolution system\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nStarting audio neuroevolution at {start_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Architecture: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC\")\n",
    "print(f\"Each individual will be evaluated on all 5 folds IN PARALLEL\")\n",
    "print(f\"Using ThreadPoolExecutor with 5 workers (one per fold)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create system instance (no need for train/test loaders anymore)\n",
    "neuroevolution = HybridNeuroevolution(CONFIG)\n",
    "\n",
    "# Execute evolution process\n",
    "best_genome = neuroevolution.evolve()\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVOLUTION PROCESS COMPLETED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Completed at: {end_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Total execution time: {execution_time}\")\n",
    "print(f\"Total generations: {neuroevolution.generation}\")\n",
    "print(f\"Best fitness achieved: {best_genome['fitness']:.2f}%\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555d9b",
   "metadata": {},
   "source": [
    "## 8. Results Visualization and Analysis\n",
    "\n",
    "### 8.1 Fitness Evolution Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "308a9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Fitness visualization function defined\n"
     ]
    }
   ],
   "source": [
    "# Configure matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Function to visualize fitness evolution\n",
    "def plot_fitness_evolution(neuroevolution):\n",
    "    \"\"\"Plots fitness evolution across generations.\"\"\"\n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extract data and filter 0.00 fitness\n",
    "    generations = []\n",
    "    avg_fitness = []\n",
    "    max_fitness = []\n",
    "    min_fitness = []\n",
    "    std_fitness = []\n",
    "    \n",
    "    for stat in neuroevolution.generation_stats:\n",
    "        # Only include if valid fitness (> 0.00)\n",
    "        if stat['max_fitness'] > 0.00:\n",
    "            generations.append(stat['generation'])\n",
    "            avg_fitness.append(stat['avg_fitness'])\n",
    "            max_fitness.append(stat['max_fitness'])\n",
    "            min_fitness.append(stat['min_fitness'])\n",
    "            std_fitness.append(stat['std_fitness'])\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"WARNING: No valid fitness data to plot (all are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    # Graph 1: Fitness evolution\n",
    "    ax1.plot(generations, max_fitness, 'g-', linewidth=2, marker='o', label='Maximum Fitness')\n",
    "    ax1.plot(generations, avg_fitness, 'b-', linewidth=2, marker='s', label='Average Fitness')\n",
    "    ax1.plot(generations, min_fitness, 'r-', linewidth=2, marker='^', label='Minimum Fitness')\n",
    "    ax1.fill_between(generations, \n",
    "                     [max(0, avg - std) for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     [avg + std for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     alpha=0.2, color='blue')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness (%)')\n",
    "    ax1.set_title('Fitness Evolution by Generation (Excluding 0.00%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add target fitness line\n",
    "    ax1.axhline(y=CONFIG['fitness_threshold'], color='orange', linestyle='--', \n",
    "                label=f\"Target ({CONFIG['fitness_threshold']}%)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Set Y axis limits for better visualization\n",
    "    y_min = max(0, min(min_fitness) - 5)\n",
    "    y_max = min(100, max(max_fitness) + 5)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Graph 2: Diversity (standard deviation)\n",
    "    ax2.plot(generations, std_fitness, 'purple', linewidth=2, marker='D')\n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Fitness Standard Deviation')\n",
    "    ax2.set_title('Population Diversity (Excluding 0.00%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show additional information\n",
    "    print(f\"Plotted data:\")\n",
    "    print(f\"   Generations with valid fitness: {len(generations)}\")\n",
    "    print(f\"   Best fitness achieved: {max(max_fitness):.2f}%\")\n",
    "    print(f\"   Final average fitness: {avg_fitness[-1]:.2f}%\")\n",
    "    if len(generations) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(generations)\n",
    "        print(f\"   WARNING: Excluded generations (0.00 fitness): {excluded}\")\n",
    "\n",
    "print(\"âœ“ Fitness visualization function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f69d6",
   "metadata": {},
   "source": [
    "### 8.2 Detailed Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29684a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Evolution statistics function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to show detailed statistics\n",
    "def show_evolution_statistics(neuroevolution):\n",
    "    \"\"\"Shows detailed evolution statistics.\"\"\"\n",
    "    print(\"DETAILED EVOLUTION STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics available\")\n",
    "        return\n",
    "    \n",
    "    # Filter statistics with valid fitness\n",
    "    valid_stats = [stat for stat in neuroevolution.generation_stats if stat['max_fitness'] > 0.00]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"WARNING: No valid statistics (all fitness are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    final_stats = valid_stats[-1]\n",
    "    \n",
    "    print(f\"Completed generations: {neuroevolution.generation}\")\n",
    "    print(f\"Generations with valid fitness: {len(valid_stats)}\")\n",
    "    if len(valid_stats) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(valid_stats)\n",
    "        print(f\"WARNING: Generations with 0.00 fitness (excluded): {excluded}\")\n",
    "    \n",
    "    print(f\"\\nFINAL STATISTICS (excluding 0.00 fitness):\")\n",
    "    print(f\"   Final best fitness: {final_stats['max_fitness']:.2f}%\")\n",
    "    print(f\"   Final average fitness: {final_stats['avg_fitness']:.2f}%\")\n",
    "    print(f\"   Final minimum fitness: {final_stats['min_fitness']:.2f}%\")\n",
    "    print(f\"   Final standard deviation: {final_stats['std_fitness']:.2f}%\")\n",
    "    \n",
    "    # Progress across generations\n",
    "    if len(valid_stats) > 1:\n",
    "        initial_max = valid_stats[0]['max_fitness']\n",
    "        final_max = valid_stats[-1]['max_fitness']\n",
    "        improvement = final_max - initial_max\n",
    "        \n",
    "        print(f\"\\nPROGRESS:\")\n",
    "        print(f\"   Initial fitness: {initial_max:.2f}%\")\n",
    "        print(f\"   Final fitness: {final_max:.2f}%\")\n",
    "        print(f\"   Total improvement: {improvement:.2f}%\")\n",
    "        if initial_max > 0:\n",
    "            print(f\"   Relative improvement: {(improvement/initial_max)*100:.1f}%\")\n",
    "    \n",
    "    # Convergence analysis\n",
    "    print(f\"\\nCONVERGENCE CRITERIA:\")\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['fitness'] >= CONFIG['fitness_threshold']:\n",
    "        print(f\"   OK: Target fitness reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   ERROR: Target fitness NOT reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    \n",
    "    if neuroevolution.generation >= CONFIG['max_generations']:\n",
    "        print(f\"   TIME: Maximum generations reached ({CONFIG['max_generations']})\")\n",
    "    \n",
    "    # Additional performance statistics\n",
    "    all_max_fitness = [stat['max_fitness'] for stat in valid_stats]\n",
    "    all_avg_fitness = [stat['avg_fitness'] for stat in valid_stats]\n",
    "    \n",
    "    print(f\"\\nGENERAL STATISTICS:\")\n",
    "    print(f\"   Best fitness of entire evolution: {max(all_max_fitness):.2f}%\")\n",
    "    print(f\"   Average fitness of entire evolution: {np.mean(all_avg_fitness):.2f}%\")\n",
    "    print(f\"   Average improvement per generation: {(max(all_max_fitness) - min(all_max_fitness))/len(valid_stats):.2f}%\")\n",
    "    \n",
    "    if neuroevolution.best_individual:\n",
    "        print(f\"\\nBest individual ID: {neuroevolution.best_individual['id']}\")\n",
    "        print(f\"Best individual fitness: {neuroevolution.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "print(\"âœ“ Evolution statistics function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a17a2",
   "metadata": {},
   "source": [
    "### 8.3 Failure Analysis and Visualization Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103104c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted data:\n",
      "   Generations with valid fitness: 28\n",
      "   Best fitness achieved: 79.20%\n",
      "   Final average fitness: 67.04%\n",
      "DETAILED EVOLUTION STATISTICS\n",
      "============================================================\n",
      "Completed generations: 27\n",
      "Generations with valid fitness: 28\n",
      "\n",
      "FINAL STATISTICS (excluding 0.00 fitness):\n",
      "   Final best fitness: 76.41%\n",
      "   Final average fitness: 67.04%\n",
      "   Final minimum fitness: 16.03%\n",
      "   Final standard deviation: 13.71%\n",
      "\n",
      "PROGRESS:\n",
      "   Initial fitness: 71.27%\n",
      "   Final fitness: 76.41%\n",
      "   Total improvement: 5.14%\n",
      "   Relative improvement: 7.2%\n",
      "\n",
      "CONVERGENCE CRITERIA:\n",
      "   ERROR: Target fitness NOT reached (80.0%)\n",
      "\n",
      "GENERAL STATISTICS:\n",
      "   Best fitness of entire evolution: 79.20%\n",
      "   Average fitness of entire evolution: 63.49%\n",
      "   Average improvement per generation: 0.28%\n",
      "\n",
      "Best individual ID: 275f7b79\n",
      "Best individual fitness: 79.20%\n",
      "\n",
      "FAILED EVALUATIONS ANALYSIS\n",
      "==================================================\n",
      "OK: No failed evaluations (0.00 fitness)\n"
     ]
    }
   ],
   "source": [
    "# Additional function for failure analysis\n",
    "def analyze_failed_evaluations(neuroevolution):\n",
    "    \"\"\"Analyzes evaluations that resulted in 0.00 fitness.\"\"\"\n",
    "    print(\"\\nFAILED EVALUATIONS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_generations = len(neuroevolution.generation_stats)\n",
    "    failed_generations = len([stat for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00])\n",
    "    \n",
    "    if failed_generations == 0:\n",
    "        print(\"OK: No failed evaluations (0.00 fitness)\")\n",
    "        return\n",
    "    \n",
    "    success_rate = ((total_generations - failed_generations) / total_generations) * 100\n",
    "    \n",
    "    print(f\"Failure summary:\")\n",
    "    print(f\"   Total generations: {total_generations}\")\n",
    "    print(f\"   Failed generations: {failed_generations}\")\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    if failed_generations > 0:\n",
    "        failed_gens = [stat['generation'] for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00]\n",
    "        print(f\"   Generations with failures: {failed_gens}\")\n",
    "        \n",
    "        print(f\"\\nPossible causes of 0.00 fitness:\")\n",
    "        print(f\"   â€¢ Errors in model architecture\")\n",
    "        print(f\"   â€¢ Memory problems (GPU/RAM)\")\n",
    "        print(f\"   â€¢ Invalid hyperparameter configurations\")\n",
    "        print(f\"   â€¢ Errors during training\")\n",
    "\n",
    "# Execute visualizations\n",
    "plot_fitness_evolution(neuroevolution)\n",
    "show_evolution_statistics(neuroevolution)\n",
    "analyze_failed_evaluations(neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6688660",
   "metadata": {},
   "source": [
    "## 9. BEST ARCHITECTURE FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a847dd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "    BEST EVOLVED ARCHITECTURE (1D AUDIO)\n",
      "============================================================\n",
      "\n",
      "GENERAL INFORMATION:\n",
      "   Genome ID: 275f7b79\n",
      "   Fitness Achieved: 79.20%\n",
      "   Generation: 27\n",
      "   Dataset: AUDIO\n",
      "   Dataset ID: 40_1e5_N\n",
      "   Fold: N/A\n",
      "\n",
      "NETWORK ARCHITECTURE:\n",
      "   Input: 1D Audio Signal (length=11520)\n",
      "   Convolutional Layers (Conv1D): 9\n",
      "   Fully Connected Layers: 2\n",
      "   Output: 2 classes\n",
      "\n",
      "CONVOLUTIONAL LAYER DETAILS (1D):\n",
      "   Conv1D-1: 1 filters, kernel_size=3, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-2: 8 filters, kernel_size=11, activation=relu\n",
      "             -> BatchNorm1D -> RELU -> MaxPool1D(2)\n",
      "   Conv1D-3: 244 filters, kernel_size=7, activation=selu\n",
      "             -> BatchNorm1D -> SELU -> MaxPool1D(2)\n",
      "   Conv1D-4: 105 filters, kernel_size=11, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-5: 184 filters, kernel_size=9, activation=relu\n",
      "             -> BatchNorm1D -> RELU -> MaxPool1D(2)\n",
      "   Conv1D-6: 154 filters, kernel_size=1, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-7: 189 filters, kernel_size=1, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-8: 184 filters, kernel_size=13, activation=relu\n",
      "             -> BatchNorm1D -> RELU -> MaxPool1D(2)\n",
      "   Conv1D-9: 137 filters, kernel_size=3, activation=selu\n",
      "             -> BatchNorm1D -> SELU -> MaxPool1D(2)\n",
      "\n",
      "FULLY CONNECTED LAYER DETAILS:\n",
      "   FC1: 660 neurons -> BatchNorm1D -> ReLU -> Dropout(0.557)\n",
      "   FC2: 368 neurons -> BatchNorm1D -> ReLU -> Dropout(0.557)\n",
      "   Output: 2 neurons (Control vs Pathological)\n",
      "\n",
      "HYPERPARAMETERS:\n",
      "   Optimizer: ADAMW\n",
      "   Learning Rate: 0.000010\n",
      "   Dropout Rate: 0.557\n",
      "   Activation Functions: relu, tanh, selu\n",
      "\n",
      "CREATING FINAL MODEL...\n",
      "   Model created successfully\n",
      "   Total parameters: 3,409,053\n",
      "   Trainable parameters: 3,409,053\n",
      "   Model size: ~13.00 MB (float32)\n",
      "\n",
      "COMPACT SUMMARY:\n",
      "   Conv1D Layers: 9 | Filters: [1, 8, 244, 105, 184, 154, 189, 184, 137] | Kernel Sizes: [3, 11, 7, 11, 9, 1, 1, 13, 3] | FC Layers: 2 | FC Nodes: [660, 368] | Activations: ['tanh', 'relu', 'selu', 'tanh', 'relu', 'tanh'] | Normalization: batch | Dropout: 0.557 | Optimizer: adamw | Learning Rate: 0.0000\n",
      "\n",
      "SUMMARY TABLE:\n",
      "================================================================================\n",
      "Parameter                 Value                          Description              \n",
      "================================================================================\n",
      "ID                        275f7b79                       Unique identifier        \n",
      "Fitness                   79.20%                          Accuracy achieved        \n",
      "Architecture              Conv1D + FC                    1D Convolutional         \n",
      "Conv Layers               9                              Conv1D layers            \n",
      "FC Layers                 2                              FC layers                \n",
      "Optimizer                 adamw                          Optimization algorithm   \n",
      "Learning Rate             0.000010                       Learning rate            \n",
      "Dropout                   0.5568370151146347             Dropout rate             \n",
      "Input Length              11520                          Audio sequence length    \n",
      "Classes                   2                              Binary classification    \n",
      "================================================================================\n",
      "\n",
      "COMPARISON WITH OBJECTIVES:\n",
      "   âœ— TARGET NOT REACHED: 79.20% < 80.0%\n",
      "     Gap: 0.80%\n",
      "   Generations used: 27/100\n",
      "\n",
      "âœ“ Results saved to: best_architecture_audio_20251119_151927.json\n",
      "\n",
      "============================================================\n",
      "HYBRID NEUROEVOLUTION FOR AUDIO COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def display_best_architecture(best_genome, config):\n",
    "    \"\"\"\n",
    "    Shows the best architecture found in detailed and visual format.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"    BEST EVOLVED ARCHITECTURE (1D AUDIO)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # General information\n",
    "    print(f\"\\nGENERAL INFORMATION:\")\n",
    "    print(f\"   Genome ID: {best_genome['id']}\")\n",
    "    print(f\"   Fitness Achieved: {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Generation: {neuroevolution.generation}\")\n",
    "    print(f\"   Dataset: {config['dataset']}\")\n",
    "    print(f\"   Dataset ID: {config.get('dataset_id', 'N/A')}\")\n",
    "    print(f\"   Fold: {config.get('current_fold', 'N/A')}\")\n",
    "    \n",
    "    # Architecture details\n",
    "    print(f\"\\nNETWORK ARCHITECTURE:\")\n",
    "    print(f\"   Input: 1D Audio Signal (length={config['sequence_length']})\")\n",
    "    print(f\"   Convolutional Layers (Conv1D): {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   Fully Connected Layers: {best_genome['num_fc_layers']}\")\n",
    "    print(f\"   Output: {config['num_classes']} classes\")\n",
    "    \n",
    "    print(f\"\\nCONVOLUTIONAL LAYER DETAILS (1D):\")\n",
    "    for i in range(best_genome['num_conv_layers']):\n",
    "        filters = best_genome['filters'][i]\n",
    "        kernel = best_genome['kernel_sizes'][i]\n",
    "        activation = best_genome['activations'][i % len(best_genome['activations'])]\n",
    "        print(f\"   Conv1D-{i+1}: {filters} filters, kernel_size={kernel}, activation={activation}\")\n",
    "        print(f\"             -> BatchNorm1D -> {activation.upper()} -> MaxPool1D(2)\")\n",
    "    \n",
    "    print(f\"\\nFULLY CONNECTED LAYER DETAILS:\")\n",
    "    for i, nodes in enumerate(best_genome['fc_nodes']):\n",
    "        print(f\"   FC{i+1}: {nodes} neurons -> BatchNorm1D -> ReLU -> Dropout({best_genome['dropout_rate']:.3f})\")\n",
    "    print(f\"   Output: {config['num_classes']} neurons (Control vs Pathological)\")\n",
    "    \n",
    "    print(f\"\\nHYPERPARAMETERS:\")\n",
    "    print(f\"   Optimizer: {best_genome['optimizer'].upper()}\")\n",
    "    print(f\"   Learning Rate: {best_genome['learning_rate']:.6f}\")\n",
    "    print(f\"   Dropout Rate: {best_genome['dropout_rate']:.3f}\")\n",
    "    print(f\"   Activation Functions: {', '.join(set(best_genome['activations']))}\")\n",
    "    \n",
    "    # Create and show final model\n",
    "    print(f\"\\nCREATING FINAL MODEL...\")\n",
    "    try:\n",
    "        final_model = EvolvableCNN(best_genome, config)\n",
    "        total_params = sum(p.numel() for p in final_model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"   Model created successfully\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"   Model size: ~{total_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
    "        \n",
    "        # Architecture summary\n",
    "        print(f\"\\nCOMPACT SUMMARY:\")\n",
    "        print(f\"   {final_model.get_architecture_summary()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR creating model: {e}\")\n",
    "    \n",
    "    # Visualization in table format\n",
    "    print(f\"\\nSUMMARY TABLE:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Parameter':<25} {'Value':<30} {'Description':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'ID':<25} {best_genome['id']:<30} {'Unique identifier':<25}\")\n",
    "    print(f\"{'Fitness':<25} {best_genome['fitness']:.2f}%{'':<25} {'Accuracy achieved':<25}\")\n",
    "    print(f\"{'Architecture':<25} {'Conv1D + FC':<30} {'1D Convolutional':<25}\")\n",
    "    print(f\"{'Conv Layers':<25} {best_genome['num_conv_layers']:<30} {'Conv1D layers':<25}\")\n",
    "    print(f\"{'FC Layers':<25} {best_genome['num_fc_layers']:<30} {'FC layers':<25}\")\n",
    "    print(f\"{'Optimizer':<25} {best_genome['optimizer']:<30} {'Optimization algorithm':<25}\")\n",
    "    print(f\"{'Learning Rate':<25} {best_genome['learning_rate']:<30.6f} {'Learning rate':<25}\")\n",
    "    print(f\"{'Dropout':<25} {best_genome['dropout_rate']:<30} {'Dropout rate':<25}\")\n",
    "    print(f\"{'Input Length':<25} {config['sequence_length']:<30} {'Audio sequence length':<25}\")\n",
    "    print(f\"{'Classes':<25} {config['num_classes']:<30} {'Binary classification':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Comparison with initial configuration\n",
    "    print(f\"\\nCOMPARISON WITH OBJECTIVES:\")\n",
    "    if best_genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"   âœ“ TARGET REACHED: {best_genome['fitness']:.2f}% >= {config['fitness_threshold']}%\")\n",
    "    else:\n",
    "        print(f\"   âœ— TARGET NOT REACHED: {best_genome['fitness']:.2f}% < {config['fitness_threshold']}%\")\n",
    "        print(f\"     Gap: {config['fitness_threshold'] - best_genome['fitness']:.2f}%\")\n",
    "    \n",
    "    print(f\"   Generations used: {neuroevolution.generation}/{config['max_generations']}\")\n",
    "    \n",
    "    # Save information to JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_audio_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'execution_time': str(execution_time),\n",
    "        'dataset_type': 'audio_1D',\n",
    "        'dataset_id': config.get('dataset_id', 'N/A'),\n",
    "        'fold': config.get('current_fold', 'N/A'),\n",
    "        'config_used': {k: v for k, v in config.items() if not k.startswith('_')},\n",
    "        'best_genome': best_genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\nâœ“ Results saved to: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— WARNING: Error saving results: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HYBRID NEUROEVOLUTION FOR AUDIO COMPLETED!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Show the best architecture found\n",
    "display_best_architecture(best_genome, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d17f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFORMACIÃ“N DEL CHECKPOINT DEL MEJOR MODELO\n",
      "================================================================================\n",
      "\n",
      "âœ“ Checkpoint guardado en: checkpoints/best_model_gen17_id275f7b79_fitness79.20.pth\n",
      "  TamaÃ±o: 13.05 MB\n",
      "\n",
      "  InformaciÃ³n del modelo guardado:\n",
      "    GeneraciÃ³n: 17\n",
      "    Fitness: 79.20%\n",
      "    ID Genoma: 275f7b79\n",
      "    Arquitectura: 9 Conv1D + 2 FC\n",
      "    Optimizador: adamw\n",
      "    Learning Rate: 1e-05\n",
      "\n",
      "  Este checkpoint se usarÃ¡ como punto de partida para el 5-fold CV\n",
      "  (Transfer learning desde el modelo pre-entrenado)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar informaciÃ³n del checkpoint guardado\n",
    "print(\"=\"*80)\n",
    "print(\"INFORMACIÃ“N DEL CHECKPOINT DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if neuroevolution.best_checkpoint_path:\n",
    "    print(f\"\\nâœ“ Checkpoint guardado en: {neuroevolution.best_checkpoint_path}\")\n",
    "    \n",
    "    # Obtener informaciÃ³n del archivo\n",
    "    import os\n",
    "    if os.path.exists(neuroevolution.best_checkpoint_path):\n",
    "        file_size = os.path.getsize(neuroevolution.best_checkpoint_path)\n",
    "        file_size_mb = file_size / (1024 * 1024)\n",
    "        print(f\"  TamaÃ±o: {file_size_mb:.2f} MB\")\n",
    "        \n",
    "        # Cargar y mostrar informaciÃ³n del checkpoint\n",
    "        checkpoint_data = torch.load(neuroevolution.best_checkpoint_path, map_location=device, weights_only=False)\n",
    "        print(f\"\\n  InformaciÃ³n del modelo guardado:\")\n",
    "        print(f\"    GeneraciÃ³n: {checkpoint_data['generation']}\")\n",
    "        print(f\"    Fitness: {checkpoint_data['fitness']:.2f}%\")\n",
    "        print(f\"    ID Genoma: {checkpoint_data['genome']['id']}\")\n",
    "        print(f\"    Arquitectura: {checkpoint_data['genome']['num_conv_layers']} Conv1D + {checkpoint_data['genome']['num_fc_layers']} FC\")\n",
    "        print(f\"    Optimizador: {checkpoint_data['genome']['optimizer']}\")\n",
    "        print(f\"    Learning Rate: {checkpoint_data['genome']['learning_rate']}\")\n",
    "        \n",
    "        print(f\"\\n  Este checkpoint se usarÃ¡ como punto de partida para el 5-fold CV\")\n",
    "        print(f\"  (Transfer learning desde el modelo pre-entrenado)\")\n",
    "    else:\n",
    "        print(f\"  âœ— Archivo no encontrado\")\n",
    "else:\n",
    "    print(\"\\nâœ— No hay checkpoint disponible\")\n",
    "    print(\"  El 5-fold CV entrenarÃ¡ desde cero\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
