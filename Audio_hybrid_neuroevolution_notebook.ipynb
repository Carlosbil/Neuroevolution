{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77d426",
   "metadata": {},
   "source": [
    "# Audio Hybrid Neuroevolution Notebook\n",
    "\n",
    "This notebook implements a hybrid neuroevolution process for audio classification (Parkinson detection). The system combines genetic algorithms with 1D convolutional neural networks to evolve optimal architectures for audio processing.\n",
    "\n",
    "## Main Features:\n",
    "- **Hybrid genetic algorithm**: Combines architecture and weight evolution\n",
    "- **1D Convolutional Networks**: Optimized for audio waveform processing\n",
    "- **Parallel 5-Fold Cross-Validation**: Each individual is evaluated on all 5 folds IN PARALLEL (fitness = average accuracy)\n",
    "- **Multi-threading**: Folds are trained simultaneously in separate threads for faster evaluation\n",
    "- **Adaptive mutation**: Dynamic mutation rate based on population diversity\n",
    "- **Audio dataset support**: Loads .npy files with train/val/test splits\n",
    "- **Intelligent stopping criteria**: By target fitness or maximum generations\n",
    "- **Complete visualization**: Shows progress and final best architecture\n",
    "\n",
    "## Objectives:\n",
    "1. Create initial population of 1D CNN architectures\n",
    "2. Evaluate fitness of each individual using **parallel 5-fold CV** (robust and faster with threading)\n",
    "3. Select best architectures (elitism)\n",
    "4. Apply crossover and mutation to create new generation\n",
    "5. Repeat process until convergence\n",
    "6. Display the best architecture found for Parkinson classification\n",
    "\n",
    "**âœ… Performance**: Multi-threaded 5-fold CV provides robustness against overfitting while being much faster than sequential training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f49a8",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ¨ CONFIGURACIÃ“N ACTUAL DEL DATASET âœ¨\n",
    "\n",
    "**Dataset configurado**: `files_all_real_syn_n` (Datos Reales + SintÃ©ticos Mezclados)\n",
    "\n",
    "Este notebook estÃ¡ configurado para usar el **nuevo dataset** que combina:\n",
    "- ðŸŽµ **Datos Reales**: Audios originales de pacientes  \n",
    "- ðŸ¤– **Datos SintÃ©ticos**: Audios generados por GANs (BigVSAN 40_1e5)\n",
    "\n",
    "**Ventajas de este dataset**:\n",
    "- Mayor diversidad de datos para entrenamiento\n",
    "- Combina la autenticidad de datos reales con la variedad de datos generados\n",
    "- Ideal para mejorar la generalizaciÃ³n del modelo\n",
    "- EstratificaciÃ³n balanceada entre clases (control/patolÃ³gico)\n",
    "\n",
    "**ðŸš€ Parallel 5-Fold Cross-Validation durante la EvoluciÃ³n**: \n",
    "- **CADA** individuo se evalÃºa en **TODOS** los 5 folds **EN PARALELO**\n",
    "- Los 5 folds se entrenan **simultÃ¡neamente** en threads separados\n",
    "- El fitness es el **promedio** de accuracy de los 5 folds\n",
    "- âœ… **Mucho mÃ¡s rÃ¡pido** que entrenamiento secuencial\n",
    "- âœ… **MÃ¡s robusto** - evita sobreajuste a un fold especÃ­fico\n",
    "\n",
    "**ðŸ“Š EvaluaciÃ³n Final**: \n",
    "- Al terminar la evoluciÃ³n, la mejor arquitectura se vuelve a evaluar con 5-fold CV\n",
    "- Se reportan mÃ©tricas completas (accuracy, sensitivity, specificity, F1, AUC)\n",
    "\n",
    "Para cambiar el dataset, modifica los parÃ¡metros `dataset_id` y `fold_id` en la celda de **ConfiguraciÃ³n** (SecciÃ³n 2).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f3cfb",
   "metadata": {},
   "source": [
    "## 1. Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50120a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dependency installation for Hybrid Neuroevolution...\n",
      "============================================================\n",
      "Installing torch>=2.0.0...\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=2.0.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torch>=2.0.0 installed correctly\n",
      "Installing torchvision>=0.15.0...\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (1.24.4)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torchvision>=0.15.0) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15.0) (10.0.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch==2.8.0->torchvision>=0.15.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->torchvision>=0.15.0) (68.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision>=0.15.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.8.0->torchvision>=0.15.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK torchvision>=0.15.0 installed correctly\n",
      "Installing numpy>=1.21.0...\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK numpy>=1.21.0 installed correctly\n",
      "Installing matplotlib>=3.5.0...\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/conda/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK matplotlib>=3.5.0 installed correctly\n",
      "Installing seaborn>=0.11.0...\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.11.0) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.25->seaborn>=0.11.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK seaborn>=0.11.0 installed correctly\n",
      "Installing tqdm>=4.64.0...\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (4.65.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK tqdm>=4.64.0 installed correctly\n",
      "Installing jupyter>=1.0.0...\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.5.4)\n",
      "Requirement already satisfied: jupyter-console in /home/jovyan/.local/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (8.0.6)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (from jupyter>=1.0.0) (4.0.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter>=1.0.0) (3.0.7)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.0.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (3.1.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.7.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (2.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab->jupyter>=1.0.0) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (3.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (5.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (0.17.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter>=1.0.0) (4.14.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0) (0.5.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0) (3.8.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.7.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (7.3.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.6.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0) (2.17.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->notebook->jupyter>=1.0.0) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0) (2.3.2.post1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (0.19.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0) (2.21)\n",
      "Requirement already satisfied: fqdn in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.0)\n",
      "Requirement already satisfied: uri-template in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jovyan/.local/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/jovyan/.local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter>=1.0.0) (2.9.0.20250809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK jupyter>=1.0.0 installed correctly\n",
      "Installing ipywidgets>=8.0.0...\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in /opt/conda/lib/python3.11/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.11/site-packages (from ipywidgets>=8.0.0) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (1.5.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.0) (6.3.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=8.0.0) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=8.0.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ipywidgets>=8.0.0 installed correctly\n",
      "\n",
      "All dependencies have been verified/installed\n",
      "Restart the kernel if this is the first time installing torch\n",
      "============================================================\n",
      "\n",
      "PyTorch 2.8.0+cu128 installed correctly\n",
      "CUDA available: Yes\n",
      "GPU detected: NVIDIA A100-PCIE-40GB MIG 7g.40gb\n",
      "GPU memory: 39 GB\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if not available.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0].split('[')[0])\n",
    "        print(f\"OK {package.split('==')[0]} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"OK {package} installed correctly\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchvision>=0.15.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"jupyter>=1.0.0\",\n",
    "    \"ipywidgets>=8.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Starting dependency installation for Hybrid Neuroevolution...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nAll dependencies have been verified/installed\")\n",
    "print(\"Restart the kernel if this is the first time installing torch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch {torch.__version__} installed correctly\")\n",
    "    print(f\"CUDA available: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: PyTorch could not be installed correctly\")\n",
    "    print(\"Try installing manually with: pip install torch torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865869c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configured: cuda\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Threading for parallel fold training\n",
    "import threading\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device configured: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1181c2a",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a6e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded (adaptive mutation enabled, 1D Conv for audio):\n",
      "   Dataset: Audio (Parkinson Classification)\n",
      "   population_size: 20\n",
      "   max_generations: 100\n",
      "   fitness_threshold: 80.0\n",
      "   base_mutation_rate: 0.25\n",
      "   mutation_rate_min: 0.1\n",
      "   mutation_rate_max: 0.8\n",
      "   current_mutation_rate: 0.25\n",
      "   crossover_rate: 0.99\n",
      "   elite_percentage: 0.2\n",
      "   dataset: AUDIO\n",
      "   num_channels: 1\n",
      "   sequence_length: 240000\n",
      "   num_classes: 2\n",
      "   batch_size: 64\n",
      "   test_split: 0.2\n",
      "   num_epochs: 100\n",
      "   learning_rate: 1e-05\n",
      "   early_stopping_patience: 100000\n",
      "   epoch_patience: 10\n",
      "   improvement_threshold: 0.01\n",
      "   early_stopping_generations: 20\n",
      "   min_improvement_threshold: 0.01\n",
      "   min_conv_layers: 1\n",
      "   max_conv_layers: 30\n",
      "   min_fc_layers: 1\n",
      "   max_fc_layers: 10\n",
      "   min_filters: 1\n",
      "   max_filters: 256\n",
      "   min_fc_nodes: 64\n",
      "   max_fc_nodes: 1024\n",
      "   kernel_size_options: [1, 3, 5, 7, 9, 11, 13, 15]\n",
      "   min_dropout: 0.2\n",
      "   max_dropout: 0.6\n",
      "   learning_rate_options: [0.001, 0.0005, 0.0001, 5e-05, 1e-05, 0.01, 0.1, 1e-05]\n",
      "   normalization_batch_weight: 0.8\n",
      "   normalization_layer_weight: 0.2\n",
      "   dataset_id: all_real_syn_n\n",
      "   fold_id: all_real_syn_n\n",
      "   num_folds: 5\n",
      "   data_path: data/sets/folds_5\n",
      "\n",
      "Available activation functions: ['relu', 'leaky_relu', 'tanh', 'sigmoid', 'selu']\n",
      "Available optimizers: ['adam', 'adamw', 'sgd', 'rmsprop']\n",
      "\n",
      "OS-independent path configured: data/sets/folds_5\n"
     ]
    }
   ],
   "source": [
    "# Main genetic algorithm configuration (updated for adaptive mutation & moderate elitism)\n",
    "CONFIG = {\n",
    "    # Genetic algorithm parameters\n",
    "    'population_size': 20,            # Population size\n",
    "    'max_generations': 100,            # Maximum number of generations\n",
    "    'fitness_threshold': 80.0,        # Target fitness (% accuracy) - Adjusted for audio\n",
    "\n",
    "    # Adaptive mutation parameters\n",
    "    'base_mutation_rate': 0.25,       # Starting mutation rate (moderate)\n",
    "    'mutation_rate_min': 0.10,        # Lower bound for adaptive mutation\n",
    "    'mutation_rate_max': 0.80,        # Upper bound for adaptive mutation\n",
    "    'current_mutation_rate': 0.25,    # Will be updated dynamically each generation\n",
    "\n",
    "    'crossover_rate': 0.99,           # Crossover rate\n",
    "    'elite_percentage': 0.2,          # Moderate elitism (20%) instead of 40%\n",
    "\n",
    "    # Dataset selection (AUDIO ONLY)\n",
    "    'dataset': 'AUDIO',               # Audio dataset for Parkinson classification\n",
    "\n",
    "    # Dataset parameters for audio\n",
    "    'num_channels': 1,                # Input channels (1 for audio waveform)\n",
    "    'sequence_length': 240000,        # Audio sequence length (will be auto-detected)\n",
    "    'num_classes': 2,                 # Number of classes (control vs pathological)\n",
    "    'batch_size': 64,                 # Batch size for audio\n",
    "    'test_split': 0.2,                # Validation percentage\n",
    "\n",
    "    # Training parameters\n",
    "    'num_epochs': 100,                 # Max training epochs per evaluation (may stop earlier)\n",
    "    'learning_rate': 0.00001,           # Base learning rate\n",
    "    'early_stopping_patience': 100000,   # Max batches per epoch (quick partial epoch)\n",
    "\n",
    "    # Epoch-level early stopping\n",
    "    'epoch_patience': 10,              # Stop if no significant improvement after N evaluations\n",
    "    'improvement_threshold': 0.01,     # Minimum (absolute) accuracy gain (%) to reset patience\n",
    "\n",
    "    # Generation-level early stopping \n",
    "    'early_stopping_generations': 20, # Stop if no improvement in X generations\n",
    "    'min_improvement_threshold': 0.01, # Minimum fitness improvement (%) to reset counter\n",
    "\n",
    "    # Allowed architecture range for 1D Conv\n",
    "    'min_conv_layers': 1,\n",
    "    'max_conv_layers': 30,             # Less layers for 1D audio\n",
    "    'min_fc_layers': 1,\n",
    "    'max_fc_layers': 10,               # Less FC layers\n",
    "    'min_filters': 1,\n",
    "    'max_filters': 256,               # Adjusted for 1D\n",
    "    'min_fc_nodes': 64,\n",
    "    'max_fc_nodes': 1024,              # Smaller for audio classification\n",
    "\n",
    "    # Mutation parameters - Kernel sizes for 1D Conv\n",
    "    'kernel_size_options': [1, 3, 5, 7, 9, 11, 13, 15],  # Available kernel sizes for Conv1D\n",
    "    \n",
    "    # Mutation parameters - Dropout range\n",
    "    'min_dropout': 0.2,               # Minimum dropout rate\n",
    "    'max_dropout': 0.6,               # Maximum dropout rate\n",
    "    \n",
    "    # Mutation parameters - Learning rate options\n",
    "    'learning_rate_options': [0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.01, 0.1, 0.00001 ],  # Available learning rates\n",
    "    \n",
    "    # Mutation parameters - Normalization type weights\n",
    "    'normalization_batch_weight': 0.8,  # Probability to use batch normalization\n",
    "    'normalization_layer_weight': 0.2,  # Probability to use layer normalization\n",
    "\n",
    "    # Audio dataset configuration (OS-independent paths)\n",
    "    \n",
    "    'dataset_id': 'all_real_syn_n',   # Dataset ID - Mixed real + synthetic data\n",
    "    'fold_id': 'all_real_syn_n',      # Fold ID for files\n",
    "    'num_folds': 5,                   # Number of folds (all used during evolution)\n",
    "    'data_path': os.path.join('data', 'sets', 'folds_5'),  # OS-independent path\n",
    "    'normalization': {'mean': (0.0,), 'std': (1.0,)}  # Audio normalization\n",
    "}\n",
    "\n",
    "# Activation function mapping\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'leaky_relu': nn.LeakyReLU,\n",
    "    'tanh': nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'selu': nn.SELU,\n",
    "}\n",
    "\n",
    "# Optimizer mapping\n",
    "OPTIMIZERS = {\n",
    "    'adam': optim.Adam,\n",
    "    'adamw': optim.AdamW,\n",
    "    'sgd': optim.SGD,\n",
    "    'rmsprop': optim.RMSprop,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded (adaptive mutation enabled, 1D Conv for audio):\")\n",
    "print(f\"   Dataset: Audio (Parkinson Classification)\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key not in ['normalization']:  # Hide normalization details\n",
    "        print(f\"   {key}: {value}\")\n",
    "print(f\"\\nAvailable activation functions: {list(ACTIVATION_FUNCTIONS.keys())}\")\n",
    "print(f\"Available optimizers: {list(OPTIMIZERS.keys())}\")\n",
    "print(f\"\\nOS-independent path configured: {CONFIG['data_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d2e08",
   "metadata": {},
   "source": [
    "### ðŸ“‹ ParÃ¡metros de MutaciÃ³n Configurables\n",
    "\n",
    "**Todos los parÃ¡metros de mutaciÃ³n ahora son configurables desde `CONFIG`**:\n",
    "\n",
    "#### Kernel Sizes (TamaÃ±os de kernel para Conv1D)\n",
    "- **`kernel_size_options`**: `[3, 5, 7, 9, 11, 13, 15]`\n",
    "  - Opciones disponibles para los tamaÃ±os de kernel en capas convolucionales 1D\n",
    "  - Se usa tanto en la creaciÃ³n inicial como en la mutaciÃ³n\n",
    "\n",
    "#### Dropout Range (Rango de dropout)\n",
    "- **`min_dropout`**: `0.2` - Tasa mÃ­nima de dropout\n",
    "- **`max_dropout`**: `0.6` - Tasa mÃ¡xima de dropout\n",
    "  - Durante la creaciÃ³n y mutaciÃ³n, el dropout se selecciona aleatoriamente dentro de este rango\n",
    "\n",
    "#### Learning Rate Options (Opciones de learning rate)\n",
    "- **`learning_rate_options`**: `[0.001, 0.0005, 0.0001, 0.00005, 0.00001]`\n",
    "  - Opciones disponibles para el learning rate\n",
    "  - Se selecciona aleatoriamente de esta lista durante creaciÃ³n y mutaciÃ³n\n",
    "\n",
    "#### Normalization Type Weights (Pesos para tipo de normalizaciÃ³n)\n",
    "- **`normalization_batch_weight`**: `0.8` - Probabilidad de usar batch normalization (80%)\n",
    "- **`normalization_layer_weight`**: `0.2` - Probabilidad de usar layer normalization (20%)\n",
    "  - Durante la mutaciÃ³n, se selecciona el tipo de normalizaciÃ³n con estas probabilidades\n",
    "\n",
    "âœ… **Beneficio**: Ahora puedes ajustar todos estos parÃ¡metros desde un solo lugar (CONFIG) sin modificar las funciones de mutaciÃ³n o creaciÃ³n de genomas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4964cc1",
   "metadata": {},
   "source": [
    "### InformaciÃ³n sobre el Dataset de Audio\n",
    "\n",
    "**Dataset de Audio para ClasificaciÃ³n de Parkinson**: \n",
    "- Archivos de audio de voz (clasificaciÃ³n Parkinson)\n",
    "- Datos 1D de forma de onda procesada\n",
    "- Estructura: archivos .npy con train/val/test splits\n",
    "- Dificultad: **Alta** - ClasificaciÃ³n mÃ©dica\n",
    "- Fitness objetivo recomendado: >85%\n",
    "- Clases: Control vs Pathological\n",
    "- Formato de archivos: `{data_path}/files_{fold_id}/X_train_{dataset_id}_fold_{fold}.npy`\n",
    "- Arquitectura: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC Layers\n",
    "\n",
    "**ConfiguraciÃ³n del Dataset:**\n",
    "- Modifica los parÃ¡metros en la celda de configuraciÃ³n:\n",
    "  - `dataset_id`: ID del dataset (ej: 'all_real_syn_n')\n",
    "  - `fold_id`: ID de la carpeta de folds (ej: 'all_real_syn_n')\n",
    "  - `data_path`: Ruta base a los datos (usa `os.path.join` para compatibilidad multiplataforma)\n",
    "\n",
    "**ðŸ”„ Uso de 5-Fold CV:**\n",
    "- **Durante la evoluciÃ³n**: Cada individuo se evalÃºa en los 5 folds automÃ¡ticamente\n",
    "- **No se necesita** especificar `current_fold` (se usan todos)\n",
    "- El fitness es el **promedio** de los 5 folds\n",
    "\n",
    "**Nota sobre Rutas:**\n",
    "- Las rutas son **independientes del sistema operativo** (Windows/Linux/Mac)\n",
    "- Usa `os.path.join()` para construir rutas compatibles\n",
    "- Ejemplo: `os.path.join('data', 'sets', 'folds_5')` funciona en cualquier OS\n",
    "\n",
    "---\n",
    "\n",
    "### Tipos de Carpetas de Folds Disponibles (generadas por `create_5_folds.ipynb`)\n",
    "\n",
    "El notebook `generating_csv/create_5_folds.ipynb` genera **5 tipos de carpetas** con diferentes combinaciones de datos **reales** y **sintÃ©ticos** (generados por GANs) para experimentaciÃ³n:\n",
    "\n",
    "#### 1. **`files_real_N`** - Solo Datos Reales\n",
    "   - **Train**: Datos reales (`test_together_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Baseline con datos 100% reales\n",
    "   - **fold_id**: `'real_N'`\n",
    "   - **dataset_id**: `'real_N'`\n",
    "\n",
    "#### 2. **`files_real_40_1e5_N`** - Entrenamiento SintÃ©tico, Test Real\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Evaluar si modelos entrenados con sintÃ©ticos generalizan a datos reales\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 3. **`files_syn_40_1e5_N`** - Solo Datos SintÃ©ticos (mismo conjunto)\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Uso**: Evaluar capacidad del modelo con datos 100% sintÃ©ticos\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 4. **`files_syn_1_N`** - Entrenamiento SintÃ©tico, Test SintÃ©tico Diferente\n",
    "   - **Train**: Datos sintÃ©ticos (`generated_together_train_40_1e5_N`)\n",
    "   - **Test**: Datos sintÃ©ticos diferentes (`test_together_syn_1_N`)\n",
    "   - **Uso**: Evaluar generalizaciÃ³n entre diferentes conjuntos sintÃ©ticos\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 5. **`files_syn_all_N`** - Solo Datos Reales (mal nombrado probablemente)\n",
    "   - **Train**: Datos reales (`test_together_N`)\n",
    "   - **Test**: Datos reales (`test_together_N`)\n",
    "   - **Uso**: Similar a `files_real_N` (posible duplicado o error de nomenclatura)\n",
    "   - **fold_id**: `'40_1e5_N'`\n",
    "   - **dataset_id**: `'40_1e5_N'`\n",
    "\n",
    "#### 6. **`files_all_real_syn_n`** - âœ¨ Datos Reales + SintÃ©ticos Mezclados âœ¨ **(NUEVO)**\n",
    "   - **Train**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Validation**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Test**: Datos reales + sintÃ©ticos mezclados\n",
    "   - **Uso**: Entrenar y evaluar con una mezcla equilibrada de datos reales y generados por GANs\n",
    "   - **fold_id**: `'all_real_syn_n'`\n",
    "   - **dataset_id**: `'all_real_syn_n'`\n",
    "   - **Ventajas**: Combina diversidad de datos sintÃ©ticos con autenticidad de datos reales\n",
    "   - **ConfiguraciÃ³n actual**: ðŸ”µ **ESTE ES EL DATASET CONFIGURADO POR DEFECTO**\n",
    "\n",
    "**Nota**: Cada carpeta contiene 5 folds de validaciÃ³n cruzada con:\n",
    "- `X_train_{dataset_id}_fold_{1-5}.npy` y `y_train_{dataset_id}_fold_{1-5}.npy`\n",
    "- `X_val_{dataset_id}_fold_{1-5}.npy` y `y_val_{dataset_id}_fold_{1-5}.npy`\n",
    "- `X_test_{dataset_id}_fold_{1-5}.npy` y `y_test_{dataset_id}_fold_{1-5}.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6d37",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f98ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICANDO DISPONIBILIDAD DE DATOS\n",
      "============================================================\n",
      "Dataset ID: all_real_syn_n, Verificando los 5 folds...\n",
      "   Looking for: /home/jovyan/audio_test/data/sets/folds_5/files_all_real_syn_n\n",
      "   âœ“ Directory found: /home/jovyan/audio_test/data/sets/folds_5/files_all_real_syn_n\n",
      "\n",
      "Checking for all 5 folds...\n",
      "   âœ“ Fold 1: All files present\n",
      "   âœ“ Fold 2: All files present\n",
      "   âœ“ Fold 3: All files present\n",
      "   âœ“ Fold 4: All files present\n",
      "   âœ“ Fold 5: All files present\n",
      "\n",
      "âœ“ All 5 folds verified successfully!\n",
      "\n",
      "Loading Fold 1 to detect sequence length...\n",
      "   Train samples: (8680, 11520)\n",
      "   Sequence length detected: 11520\n",
      "\n",
      "âœ“ Dataset verification complete!\n",
      "   During evolution, each individual will train on all 5 folds.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET READY FOR 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "   Sequence length: 11520\n",
      "   Input channels: 1\n",
      "   Number of classes: 2\n",
      "   Batch size: 64\n",
      "   Audio classification task: Control (0) vs Pathological (1)\n",
      "\n",
      "   âš ï¸ Each individual will be evaluated on ALL 5 folds\n",
      "   âš ï¸ This makes evolution ~5x slower but much more robust\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(config: dict) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Loads the audio dataset according to configuration.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading audio dataset from: {config['data_path']}\")\n",
    "    print(f\"Dataset ID: {config['dataset_id']}, Fold: {config['current_fold']}\")\n",
    "    \n",
    "    # Construct paths following ResNet convention\n",
    "    fold_files_directory = os.path.join(\n",
    "        config['data_path'], \n",
    "        f\"files_{config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    # Check if directory exists\n",
    "    print(f\"\\nChecking data directory...\")\n",
    "    print(f\"   Looking for: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    if not os.path.exists(fold_files_directory):\n",
    "        print(f\"\\nâŒ ERROR: Directory not found!\")\n",
    "        print(f\"   Expected: {os.path.abspath(fold_files_directory)}\")\n",
    "        \n",
    "        # Try to find the correct path\n",
    "        possible_paths = [\n",
    "            os.path.join('..', 'data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "            os.path.join('data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "            os.path.join('.', 'data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nSearching for data in alternative locations:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = os.path.exists(path)\n",
    "            print(f\"   {'âœ“' if exists else 'âœ—'} {abs_path}\")\n",
    "            if exists:\n",
    "                fold_files_directory = path\n",
    "                print(f\"\\nâœ“ Found data at: {os.path.abspath(fold_files_directory)}\")\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"\\nâŒ Could not find data directory!\\n\"\n",
    "                f\"   Tried paths:\\n\" + \n",
    "                \"\\n\".join([f\"      - {os.path.abspath(p)}\" for p in possible_paths]) +\n",
    "                f\"\\n\\n   Please check:\\n\"\n",
    "                f\"      1. CONFIG['data_path'] is correct\\n\"\n",
    "                f\"      2. The data files exist\\n\"\n",
    "                f\"      3. The fold_id '{config['fold_id']}' is correct\\n\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"   âœ“ Directory found: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "def load_dataset(config: dict):\n",
    "    \"\"\"\n",
    "    Verifica que los datos existen y carga el primer fold para detectar sequence_length.\n",
    "    Durante la evoluciÃ³n, cada individuo cargarÃ¡ todos los folds automÃ¡ticamente.\n",
    "    \n",
    "    Args:\n",
    "        config: Diccionario de configuraciÃ³n\n",
    "    \n",
    "    Returns:\n",
    "        None (solo actualiza config['sequence_length'])\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VERIFICANDO DISPONIBILIDAD DE DATOS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dataset ID: {config['dataset_id']}, Verificando los 5 folds...\")\n",
    "    \n",
    "    # Build directory path\n",
    "    fold_files_directory = os.path.join(\n",
    "        config['data_path'], \n",
    "        f\"files_{config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   Looking for: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    # If directory not found, try alternative locations\n",
    "    if not os.path.exists(fold_files_directory):\n",
    "        possible_paths = [\n",
    "            os.path.join('..', 'data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "            os.path.join('data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "            os.path.join('.', 'data', 'sets', 'folds_5', f\"files_{config['fold_id']}\"),\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nSearching for data in alternative locations:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = os.path.exists(path)\n",
    "            print(f\"   {'âœ“' if exists else 'âœ—'} {abs_path}\")\n",
    "            if exists:\n",
    "                fold_files_directory = path\n",
    "                print(f\"\\nâœ“ Found data at: {os.path.abspath(fold_files_directory)}\")\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"\\nâŒ Could not find data directory!\\n\"\n",
    "                f\"   Tried paths:\\n\" + \n",
    "                \"\\n\".join([f\"      - {os.path.abspath(p)}\" for p in possible_paths]) +\n",
    "                f\"\\n\\n   Please check:\\n\"\n",
    "                f\"      1. CONFIG['data_path'] is correct\\n\"\n",
    "                f\"      2. The data files exist\\n\"\n",
    "                f\"      3. The fold_id '{config['fold_id']}' is correct\\n\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"   âœ“ Directory found: {os.path.abspath(fold_files_directory)}\")\n",
    "    \n",
    "    dataset_id = config['dataset_id']\n",
    "    \n",
    "    # Check that all 5 folds exist\n",
    "    print(f\"\\nChecking for all 5 folds...\")\n",
    "    all_folds_ok = True\n",
    "    \n",
    "    for fold_num in range(1, 6):\n",
    "        required_files = [\n",
    "            f'X_train_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_train_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'X_val_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_val_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'X_test_{dataset_id}_fold_{fold_num}.npy',\n",
    "            f'y_test_{dataset_id}_fold_{fold_num}.npy',\n",
    "        ]\n",
    "        \n",
    "        fold_ok = True\n",
    "        for filename in required_files:\n",
    "            filepath = os.path.join(fold_files_directory, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                fold_ok = False\n",
    "                all_folds_ok = False\n",
    "                print(f\"   âœ— Fold {fold_num}: Missing {filename}\")\n",
    "                break\n",
    "        \n",
    "        if fold_ok:\n",
    "            print(f\"   âœ“ Fold {fold_num}: All files present\")\n",
    "    \n",
    "    if not all_folds_ok:\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\nâŒ Some fold files are missing!\\n\"\n",
    "            f\"   Please ensure all 5 folds have complete data files.\\n\"\n",
    "            f\"   dataset_id: '{dataset_id}'\\n\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nâœ“ All 5 folds verified successfully!\")\n",
    "    \n",
    "    # Load first fold to detect sequence_length\n",
    "    print(f\"\\nLoading Fold 1 to detect sequence length...\")\n",
    "    x_train = np.load(os.path.join(fold_files_directory, f'X_train_{dataset_id}_fold_1.npy'))\n",
    "    \n",
    "    print(f\"   Train samples: {x_train.shape}\")\n",
    "    \n",
    "    # Update sequence length from actual data\n",
    "    if len(x_train.shape) == 2:  # (samples, sequence_length)\n",
    "        config['sequence_length'] = x_train.shape[1]\n",
    "    elif len(x_train.shape) == 3:  # Already (samples, channels, sequence_length)\n",
    "        config['sequence_length'] = x_train.shape[2]\n",
    "    \n",
    "    print(f\"   Sequence length detected: {config['sequence_length']}\")\n",
    "    print(f\"\\nâœ“ Dataset verification complete!\")\n",
    "    print(f\"   During evolution, each individual will train on all 5 folds.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Verify dataset availability\n",
    "load_dataset(CONFIG)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET READY FOR 5-FOLD CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Sequence length: {CONFIG['sequence_length']}\")\n",
    "print(f\"   Input channels: {CONFIG['num_channels']}\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Audio classification task: Control (0) vs Pathological (1)\")\n",
    "print(f\"\\n   âš ï¸ Each individual will be evaluated on ALL 5 folds\")\n",
    "print(f\"   âš ï¸ This makes evolution ~5x slower but much more robust\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52de67",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc6abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvolvableCNN class defined correctly (Conv1D for audio)\n"
     ]
    }
   ],
   "source": [
    "class EvolvableCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolvable CNN class for 1D audio processing.\n",
    "    Uses Conv1D layers for audio/sequential data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genome: dict, config: dict):\n",
    "        super(EvolvableCNN, self).__init__()\n",
    "        self.genome = genome\n",
    "        self.config = config\n",
    "        \n",
    "        # Validate and fix genome structure before building\n",
    "        self._validate_genome()\n",
    "        \n",
    "        # Build convolutional layers (1D for audio)\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        \n",
    "        # Calculate output size after convolutions\n",
    "        self.conv_output_size = self._calculate_conv_output_size()\n",
    "        \n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "    \n",
    "    def _validate_genome(self):\n",
    "        \"\"\"Validates and fixes genome structure to ensure consistency.\"\"\"\n",
    "        # Ensure conv-related lists match num_conv_layers\n",
    "        num_conv = self.genome['num_conv_layers']\n",
    "        \n",
    "        if len(self.genome['filters']) != num_conv:\n",
    "            # Fix filters list\n",
    "            self.genome['filters'] = self.genome['filters'][:num_conv]\n",
    "            while len(self.genome['filters']) < num_conv:\n",
    "                self.genome['filters'].append(\n",
    "                    random.randint(self.config['min_filters'], self.config['max_filters'])\n",
    "                )\n",
    "        \n",
    "        if len(self.genome['kernel_sizes']) != num_conv:\n",
    "            # Fix kernel_sizes list\n",
    "            self.genome['kernel_sizes'] = self.genome['kernel_sizes'][:num_conv]\n",
    "            while len(self.genome['kernel_sizes']) < num_conv:\n",
    "                self.genome['kernel_sizes'].append(\n",
    "                    random.choice(self.config['kernel_size_options'])\n",
    "                )\n",
    "        \n",
    "        # Ensure fc-related lists match num_fc_layers\n",
    "        num_fc = self.genome['num_fc_layers']\n",
    "        \n",
    "        if len(self.genome['fc_nodes']) != num_fc:\n",
    "            # Fix fc_nodes list\n",
    "            self.genome['fc_nodes'] = self.genome['fc_nodes'][:num_fc]\n",
    "            while len(self.genome['fc_nodes']) < num_fc:\n",
    "                self.genome['fc_nodes'].append(\n",
    "                    random.randint(self.config['min_fc_nodes'], self.config['max_fc_nodes'])\n",
    "                )\n",
    "        \n",
    "    def _build_conv_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds 1D convolutional layers according to genome.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = self.config['num_channels']\n",
    "        normalization_type = self.genome.get('normalization_type', 'batch')  # Default to batch normalization\n",
    "\n",
    "        for i in range(self.genome['num_conv_layers']):\n",
    "            # Safe access with validation\n",
    "            if i >= len(self.genome['filters']) or i >= len(self.genome['kernel_sizes']):\n",
    "                raise IndexError(\n",
    "                    f\"Genome list mismatch: i={i}, num_conv_layers={self.genome['num_conv_layers']}, \"\n",
    "                    f\"filters_len={len(self.genome['filters'])}, kernel_sizes_len={len(self.genome['kernel_sizes'])}\"\n",
    "                )\n",
    "            \n",
    "            out_channels = self.genome['filters'][i]\n",
    "            kernel_size = self.genome['kernel_sizes'][i]\n",
    "            \n",
    "            # Ensure kernel size is odd and reasonable for 1D\n",
    "            kernel_size = max(3, kernel_size if kernel_size % 2 == 1 else kernel_size + 1)\n",
    "            padding = kernel_size // 2\n",
    "            \n",
    "            # 1D Convolutional layer\n",
    "            conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "            layers.append(conv)\n",
    "            \n",
    "            # Normalization layer (Layer Normalization or Batch Normalization)\n",
    "            if normalization_type == 'layer':\n",
    "                # Layer Normalization: normaliza sobre features, no sobre batch\n",
    "                # Para Conv1d output de shape (batch, channels, length), normalizamos los channels\n",
    "                layers.append(nn.LayerNorm(out_channels))\n",
    "            else:\n",
    "                # Batch normalization (default)\n",
    "                layers.append(nn.BatchNorm1d(out_channels))\n",
    "            \n",
    "            # Activation function\n",
    "            activation_name = self.genome['activations'][i % len(self.genome['activations'])]\n",
    "            activation_func = ACTIVATION_FUNCTIONS[activation_name]()\n",
    "            layers.append(activation_func)\n",
    "            \n",
    "            # Max pooling (1D) - reduce sequence length\n",
    "            pool_size = 2 if i < self.genome['num_conv_layers'] - 1 else 2\n",
    "            layers.append(nn.MaxPool1d(pool_size, pool_size))\n",
    "            \n",
    "            # Optional dropout after pooling\n",
    "            if i < self.genome['num_conv_layers'] - 1:\n",
    "                layers.append(nn.Dropout(0.1))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def _calculate_conv_output_size(self) -> int:\n",
    "        \"\"\"Calculates output size after convolutional layers.\"\"\"\n",
    "        # Create dummy tensor to calculate size\n",
    "        dummy_input = torch.zeros(1, self.config['num_channels'], \n",
    "                                 self.config['sequence_length'])\n",
    "        \n",
    "        # Pass through convolutional layers\n",
    "        x = dummy_input\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten and get size\n",
    "        return x.view(-1).shape[0]\n",
    "    \n",
    "    def _build_fc_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Builds fully connected layers.\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "        \n",
    "        input_size = self.conv_output_size\n",
    "        normalization_type = self.genome.get('normalization_type', 'batch')  # Default to batch normalization\n",
    "\n",
    "        for i in range(self.genome['num_fc_layers']):\n",
    "            # Safe access with validation\n",
    "            if i >= len(self.genome['fc_nodes']):\n",
    "                raise IndexError(\n",
    "                    f\"Genome list mismatch: i={i}, num_fc_layers={self.genome['num_fc_layers']}, \"\n",
    "                    f\"fc_nodes_len={len(self.genome['fc_nodes'])}\"\n",
    "                )\n",
    "            \n",
    "            output_size = self.genome['fc_nodes'][i]\n",
    "            \n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "            # Normalization layer (Layer Normalization or Batch Normalization)\n",
    "            if normalization_type == 'layer':\n",
    "                # Layer Normalization for FC layers\n",
    "                layers.append(nn.LayerNorm(output_size))\n",
    "            else:\n",
    "                # Batch normalization for FC layers (default)\n",
    "                layers.append(nn.BatchNorm1d(output_size))\n",
    "            \n",
    "            # Activation\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            # Dropout if not last layer\n",
    "            if i < self.genome['num_fc_layers'] - 1:\n",
    "                layers.append(nn.Dropout(self.genome['dropout_rate']))\n",
    "            \n",
    "            input_size = output_size\n",
    "        \n",
    "        # Final classification layer\n",
    "        layers.append(nn.Linear(input_size, self.config['num_classes']))\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        # Ensure input is in correct format for Conv1d\n",
    "        # Expected: (batch, channels, sequence_length)\n",
    "        if len(x.shape) == 2:  # (batch, sequence)\n",
    "            x = x.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_architecture_summary(self) -> str:\n",
    "        \"\"\"Returns an architecture summary.\"\"\"\n",
    "        summary = []\n",
    "        summary.append(f\"Conv1D Layers: {self.genome['num_conv_layers']}\")\n",
    "        summary.append(f\"Filters: {self.genome['filters']}\")\n",
    "        summary.append(f\"Kernel Sizes: {self.genome['kernel_sizes']}\")\n",
    "        summary.append(f\"FC Layers: {self.genome['num_fc_layers']}\")\n",
    "        summary.append(f\"FC Nodes: {self.genome['fc_nodes']}\")\n",
    "        summary.append(f\"Activations: {self.genome['activations']}\")\n",
    "        summary.append(f\"Normalization: {self.genome.get('normalization_type', 'batch')}\")\n",
    "        summary.append(f\"Dropout: {self.genome['dropout_rate']:.3f}\")\n",
    "        summary.append(f\"Optimizer: {self.genome['optimizer']}\")\n",
    "        summary.append(f\"Learning Rate: {self.genome['learning_rate']:.4f}\")\n",
    "        return \" | \".join(summary)\n",
    "\n",
    "print(\"EvolvableCNN class defined correctly (Conv1D for audio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021c7d8",
   "metadata": {},
   "source": [
    "## 5. Genetic Algorithm Components\n",
    "\n",
    "### 5.1 Genome Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be19766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ create_random_genome function defined (using configurable parameters)\n"
     ]
    }
   ],
   "source": [
    "def create_random_genome(config: dict) -> dict:\n",
    "    \"\"\"Creates a random genome within specified ranges (optimized for 1D audio, using configurable parameters).\"\"\"\n",
    "    # Number of layers\n",
    "    num_conv_layers = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "    num_fc_layers = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "    # Filters for each convolutional layer (progressive increase)\n",
    "    filters = []\n",
    "    base_filters = random.randint(config['min_filters'], config['min_filters'] * 2)\n",
    "    for i in range(num_conv_layers):\n",
    "        # Gradually increase filters in deeper layers\n",
    "        layer_filters = min(base_filters * (2 ** i), config['max_filters'])\n",
    "        filters.append(layer_filters)\n",
    "\n",
    "    # Kernel sizes (using configured options)\n",
    "    kernel_sizes = [random.choice(config['kernel_size_options']) for _ in range(num_conv_layers)]\n",
    "\n",
    "    # Nodes in fully connected layers (progressive decrease)\n",
    "    fc_nodes = []\n",
    "    base_fc = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "    for i in range(num_fc_layers):\n",
    "        layer_nodes = max(config['min_fc_nodes'], base_fc // (2 ** i))\n",
    "        fc_nodes.append(layer_nodes)\n",
    "\n",
    "    # Activation functions for each layer\n",
    "    activations = [random.choice(list(ACTIVATION_FUNCTIONS.keys())) for _ in range(max(num_conv_layers, num_fc_layers))]\n",
    "\n",
    "    # Other parameters (using configured ranges and options)\n",
    "    dropout_rate = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "    learning_rate = random.choice(config['learning_rate_options'])\n",
    "    optimizer = random.choice(list(OPTIMIZERS.keys()))\n",
    "    normalization_type = 'batch'  # Default to batch normalization\n",
    "\n",
    "    genome = {\n",
    "        'num_conv_layers': num_conv_layers,\n",
    "        'num_fc_layers': num_fc_layers,\n",
    "        'filters': filters,\n",
    "        'kernel_sizes': kernel_sizes,\n",
    "        'fc_nodes': fc_nodes,\n",
    "        'activations': activations,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'normalization_type': normalization_type,\n",
    "        'fitness': 0.0,\n",
    "        'id': str(uuid.uuid4())[:8]\n",
    "    }\n",
    "    return genome\n",
    "\n",
    "print(\"âœ“ create_random_genome function defined (using configurable parameters)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc26f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ validate_and_fix_genome function defined\n"
     ]
    }
   ],
   "source": [
    "def validate_and_fix_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Validates and fixes a genome to ensure all lists match their corresponding layer counts.\n",
    "    This prevents IndexError when building the model.\n",
    "    \n",
    "    Args:\n",
    "        genome: The genome to validate\n",
    "        config: Configuration dictionary with min/max values\n",
    "    \n",
    "    Returns:\n",
    "        Fixed genome with correct list lengths\n",
    "    \"\"\"\n",
    "    # Fix filters and kernel_sizes to match num_conv_layers\n",
    "    num_conv = genome['num_conv_layers']\n",
    "    \n",
    "    # Fix filters list\n",
    "    if len(genome['filters']) != num_conv:\n",
    "        genome['filters'] = genome['filters'][:num_conv]\n",
    "        while len(genome['filters']) < num_conv:\n",
    "            genome['filters'].append(\n",
    "                random.randint(config['min_filters'], config['max_filters'])\n",
    "            )\n",
    "    \n",
    "    # Fix kernel_sizes list\n",
    "    if len(genome['kernel_sizes']) != num_conv:\n",
    "        genome['kernel_sizes'] = genome['kernel_sizes'][:num_conv]\n",
    "        while len(genome['kernel_sizes']) < num_conv:\n",
    "            genome['kernel_sizes'].append(\n",
    "                random.choice(config['kernel_size_options'])\n",
    "            )\n",
    "    \n",
    "    # Fix fc_nodes to match num_fc_layers\n",
    "    num_fc = genome['num_fc_layers']\n",
    "    \n",
    "    if len(genome['fc_nodes']) != num_fc:\n",
    "        genome['fc_nodes'] = genome['fc_nodes'][:num_fc]\n",
    "        while len(genome['fc_nodes']) < num_fc:\n",
    "            genome['fc_nodes'].append(\n",
    "                random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "            )\n",
    "    \n",
    "    return genome\n",
    "\n",
    "print(\"âœ“ validate_and_fix_genome function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b0659",
   "metadata": {},
   "source": [
    "### 5.2 Genome Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5895358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ mutate_genome function defined (using configurable parameters)\n"
     ]
    }
   ],
   "source": [
    "def mutate_genome(genome: dict, config: dict) -> dict:\n",
    "    \"\"\"Applies mutation to a genome using adaptive mutation rate and configurable parameters.\"\"\"\n",
    "    mutated_genome = copy.deepcopy(genome)\n",
    "    mutation_rate = config['current_mutation_rate']  # adaptive\n",
    "\n",
    "    # Mutate number of convolutional layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_conv_layers'] = random.randint(config['min_conv_layers'], config['max_conv_layers'])\n",
    "\n",
    "    # Mutate number of FC layers\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['num_fc_layers'] = random.randint(config['min_fc_layers'], config['max_fc_layers'])\n",
    "\n",
    "    # Validate and fix lists to match layer counts\n",
    "    mutated_genome = validate_and_fix_genome(mutated_genome, config)\n",
    "\n",
    "    # Mutate filters\n",
    "    for i in range(len(mutated_genome['filters'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['filters'][i] = random.randint(config['min_filters'], config['max_filters'])\n",
    "\n",
    "    # Mutate kernel sizes (using configured options)\n",
    "    for i in range(len(mutated_genome['kernel_sizes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['kernel_sizes'][i] = random.choice(config['kernel_size_options'])\n",
    "\n",
    "    # Mutate FC nodes\n",
    "    for i in range(len(mutated_genome['fc_nodes'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['fc_nodes'][i] = random.randint(config['min_fc_nodes'], config['max_fc_nodes'])\n",
    "\n",
    "    # Mutate activation functions\n",
    "    for i in range(len(mutated_genome['activations'])):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_genome['activations'][i] = random.choice(list(ACTIVATION_FUNCTIONS.keys()))\n",
    "\n",
    "    # Mutate dropout (using configured range)\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['dropout_rate'] = random.uniform(config['min_dropout'], config['max_dropout'])\n",
    "\n",
    "    # Mutate learning rate (using configured options)\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['learning_rate'] = random.choice(config['learning_rate_options'])\n",
    "\n",
    "    # Mutate optimizer\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['optimizer'] = random.choice(list(OPTIMIZERS.keys()))\n",
    "\n",
    "    # Mutate normalization type (using configured weights)\n",
    "    if random.random() < mutation_rate:\n",
    "        mutated_genome['normalization_type'] = random.choices(\n",
    "            ['batch', 'layer'], \n",
    "            weights=[config['normalization_batch_weight'], config['normalization_layer_weight']]\n",
    "        )[0]\n",
    "\n",
    "    mutated_genome['id'] = str(uuid.uuid4())[:8]\n",
    "    mutated_genome['fitness'] = 0.0\n",
    "    \n",
    "    # Final validation to ensure consistency\n",
    "    mutated_genome = validate_and_fix_genome(mutated_genome, config)\n",
    "    \n",
    "    return mutated_genome\n",
    "\n",
    "print(\"âœ“ mutate_genome function defined (using configurable parameters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b06729",
   "metadata": {},
   "source": [
    "### 5.3 Genome Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029effe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Genetic functions updated for adaptive mutation and 1D audio processing\n"
     ]
    }
   ],
   "source": [
    "def crossover_genomes(parent1: dict, parent2: dict, config: dict) -> Tuple[dict, dict]:\n",
    "    \"\"\"Performs crossover between two genomes.\"\"\"\n",
    "    if random.random() > config['crossover_rate']:\n",
    "        return copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "\n",
    "    # Crossover scalar parameters\n",
    "    for key in ['num_conv_layers', 'num_fc_layers', 'dropout_rate', 'learning_rate', 'optimizer', 'normalization_type']:\n",
    "        if random.random() < 0.5:\n",
    "            child1[key], child2[key] = child2[key], child1[key]\n",
    "\n",
    "    # Crossover lists (random cut point)\n",
    "    for list_key in ['filters', 'kernel_sizes', 'fc_nodes', 'activations']:\n",
    "        if random.random() < 0.5:\n",
    "            list1 = child1[list_key]\n",
    "            list2 = child2[list_key]\n",
    "            if len(list1) > 1 and len(list2) > 1:\n",
    "                point1 = random.randint(1, len(list1) - 1)\n",
    "                point2 = random.randint(1, len(list2) - 1)\n",
    "                child1[list_key] = list1[:point1] + list2[point2:]\n",
    "                child2[list_key] = list2[:point2] + list1[point1:]\n",
    "\n",
    "    child1['id'] = str(uuid.uuid4())[:8]\n",
    "    child2['id'] = str(uuid.uuid4())[:8]\n",
    "    child1['fitness'] = 0.0\n",
    "    child2['fitness'] = 0.0\n",
    "    \n",
    "    # Validate and fix both children to ensure consistency\n",
    "    child1 = validate_and_fix_genome(child1, config)\n",
    "    child2 = validate_and_fix_genome(child2, config)\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "print(\"âœ“ Genetic functions updated for adaptive mutation and 1D audio processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a74a50",
   "metadata": {},
   "source": [
    "## 6. Hybrid Neuroevolution Implementation\n",
    "\n",
    "### 6.1 Class Initialization and Checkpoint Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda046ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 1/5): Initialization and Checkpoint Management\n"
     ]
    }
   ],
   "source": [
    "class HybridNeuroevolution:\n",
    "    \"\"\"Main class that implements hybrid neuroevolution with 5-fold CV and adaptive mutation.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.population = []\n",
    "        self.generation = 0\n",
    "        self.best_individual = None\n",
    "        self.fitness_history = []\n",
    "        self.generation_stats = []\n",
    "        self.best_checkpoint_path = None  # Ruta del checkpoint del mejor modelo\n",
    "        \n",
    "        # Early stopping configuration at generation level\n",
    "        self.generations_without_improvement = 0\n",
    "        self.best_fitness_overall = -float('inf')\n",
    "        self.min_improvement_threshold = 0.1  # MÃ­nima mejora en fitness (%) para resetear contador\n",
    "        self.max_generations_without_improvement = config.get('early_stopping_generations', 10)\n",
    "\n",
    "    def initialize_population(self):\n",
    "        print(f\"Initializing population of {self.config['population_size']} individuals...\")\n",
    "        self.population = [create_random_genome(self.config) for _ in range(self.config['population_size'])]\n",
    "        print(f\"Population initialized with {len(self.population)} individuals\")\n",
    "    \n",
    "    def save_best_checkpoint(self, genome: dict, model: nn.Module):\n",
    "        \"\"\"\n",
    "        Guarda el checkpoint del mejor modelo global y elimina el anterior.\n",
    "        \n",
    "        Args:\n",
    "            genome: Genoma del mejor modelo\n",
    "            model: Modelo de PyTorch a guardar\n",
    "        \"\"\"\n",
    "        # Crear directorio para checkpoints si no existe\n",
    "        checkpoint_dir = \"checkpoints\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Eliminar checkpoint anterior si existe\n",
    "        if self.best_checkpoint_path and os.path.exists(self.best_checkpoint_path):\n",
    "            try:\n",
    "                os.remove(self.best_checkpoint_path)\n",
    "                print(f\"      âœ“ Checkpoint anterior eliminado: {self.best_checkpoint_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"      âœ— Error eliminando checkpoint anterior: {e}\")\n",
    "        \n",
    "        # Crear nuevo checkpoint\n",
    "        checkpoint_filename = f\"best_model_gen{self.generation}_id{genome['id']}_fitness{genome['fitness']:.2f}.pth\"\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_filename)\n",
    "        \n",
    "        # Guardar modelo y genoma\n",
    "        checkpoint_data = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'genome': genome,\n",
    "            'generation': self.generation,\n",
    "            'fitness': genome['fitness'],\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            torch.save(checkpoint_data, checkpoint_path)\n",
    "            self.best_checkpoint_path = checkpoint_path\n",
    "            print(f\"      âœ“ Nuevo checkpoint guardado: {checkpoint_path}\")\n",
    "            print(f\"        Fitness: {genome['fitness']:.2f}%, ID: {genome['id']}, Gen: {self.generation}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      âœ— Error guardando checkpoint: {e}\")\n",
    "    \n",
    "    def load_best_checkpoint(self):\n",
    "        \"\"\"\n",
    "        Carga el mejor checkpoint guardado.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple de (genome, model) o (None, None) si no hay checkpoint\n",
    "        \"\"\"\n",
    "        if not self.best_checkpoint_path or not os.path.exists(self.best_checkpoint_path):\n",
    "            print(\"No hay checkpoint disponible para cargar\")\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            checkpoint_data = torch.load(self.best_checkpoint_path, map_location=device, weights_only=False)\n",
    "            genome = checkpoint_data['genome']\n",
    "            \n",
    "            # Crear modelo y cargar pesos\n",
    "            model = EvolvableCNN(genome, self.config).to(device)\n",
    "            model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "            \n",
    "            print(f\"âœ“ Checkpoint cargado exitosamente: {self.best_checkpoint_path}\")\n",
    "            print(f\"  Fitness: {checkpoint_data['fitness']:.2f}%, Gen: {checkpoint_data['generation']}, ID: {genome['id']}\")\n",
    "            \n",
    "            return genome, model\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error cargando checkpoint: {e}\")\n",
    "            return None, None\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 1/5): Initialization and Checkpoint Management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a69b0",
   "metadata": {},
   "source": [
    "### 6.2 Training Functions (Single Fold & Thread-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a22a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 2/5): Training Functions\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 1: Training Functions\n",
    "\n",
    "# Add training methods to HybridNeuroevolution class\n",
    "def _train_one_fold(self, model, optimizer, criterion, train_loader, test_loader, genome_id: str, fold_num: int):\n",
    "    \"\"\"\n",
    "    Entrena y evalÃºa un modelo en un fold especÃ­fico.\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy del fold\n",
    "    \"\"\"\n",
    "    best_acc = 0.0\n",
    "    best_epoch = -1\n",
    "    patience_left = self.config['epoch_patience']\n",
    "    last_improvement_acc = 0.0\n",
    "    max_epochs = self.config['num_epochs']\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "        max_batches = min(len(train_loader), self.config['early_stopping_patience'])\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            if batch_count >= max_batches:\n",
    "                break\n",
    "        \n",
    "        avg_loss = running_loss / max(1, batch_count)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        eval_batches = 0\n",
    "        max_eval_batches = min(len(test_loader), 20)\n",
    "        total_eval_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                total_eval_loss += loss.item()\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "                eval_batches += 1\n",
    "                if eval_batches >= max_eval_batches:\n",
    "                    break\n",
    "        \n",
    "        acc = 100.0 * correct / max(1, total)\n",
    "        avg_eval_loss = total_eval_loss / max(1, eval_batches)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        improvement = acc - last_improvement_acc\n",
    "        if improvement >= self.config['improvement_threshold']:\n",
    "            patience_left = self.config['epoch_patience']\n",
    "            last_improvement_acc = acc\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Solo mostrar cada 5 Ã©pocas para no saturar el log\n",
    "        if epoch % 5 == 0 or epoch == 1 or epoch == max_epochs:\n",
    "            print(f\"          Fold {fold_num} Epoch {epoch}: loss={avg_loss:.4f}, acc={acc:.2f}% (best={best_acc:.2f}%)\")\n",
    "\n",
    "        if patience_left <= 0:\n",
    "            print(f\"          Fold {fold_num}: Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "def _train_fold_in_thread(self, genome: dict, fold_num: int) -> Tuple[int, float, nn.Module]:\n",
    "    \"\"\"\n",
    "    Entrena un modelo en un fold especÃ­fico (diseÃ±ado para ejecutarse en un thread).\n",
    "    \n",
    "    Args:\n",
    "        genome: Genoma del modelo\n",
    "        fold_num: NÃºmero de fold (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (fold_num, accuracy, model)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar datos del fold\n",
    "        fold_train_loader, fold_test_loader = self._load_fold_data(fold_num)\n",
    "        \n",
    "        # Crear nuevo modelo para este fold\n",
    "        model = EvolvableCNN(genome, self.config).to(device)\n",
    "        optimizer_class = OPTIMIZERS[genome['optimizer']]\n",
    "        optimizer = optimizer_class(model.parameters(), lr=genome['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Entrenar y evaluar en este fold\n",
    "        fold_acc = self._train_one_fold(\n",
    "            model, optimizer, criterion, \n",
    "            fold_train_loader, fold_test_loader,\n",
    "            genome['id'], fold_num\n",
    "        )\n",
    "        \n",
    "        print(f\"      â†’ Fold {fold_num} completed: {fold_acc:.2f}%\")\n",
    "        \n",
    "        return fold_num, fold_acc, model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR in Fold {fold_num}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return fold_num, 0.0, None\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution._train_one_fold = _train_one_fold\n",
    "HybridNeuroevolution._train_fold_in_thread = _train_fold_in_thread\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 2/5): Training Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c1fea",
   "metadata": {},
   "source": [
    "### 6.3 Fitness Evaluation and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0d74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 3/5): Fitness Evaluation and Data Loading\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 2: Fitness Evaluation\n",
    "\n",
    "def evaluate_fitness(self, genome: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    EvalÃºa el fitness de un genoma usando 5-fold cross-validation PARALELO.\n",
    "    Los 5 folds se entrenan en threads separados y se espera a que terminen todos.\n",
    "    El fitness final es el promedio de accuracy de los 5 folds.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (fitness, model) donde:\n",
    "            - fitness: promedio de accuracies de los 5 folds\n",
    "            - model: modelo entrenado en el mejor fold (para checkpoint)\n",
    "    \"\"\"\n",
    "    print(f\"      Training/Evaluating model {genome['id']} with PARALLEL 5-FOLD CROSS-VALIDATION\")\n",
    "    \n",
    "    fold_accuracies = {}\n",
    "    fold_models = {}\n",
    "    \n",
    "    try:\n",
    "        # Usar ThreadPoolExecutor para ejecutar los 5 folds en paralelo\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            # Enviar los 5 folds a threads separados\n",
    "            print(f\"      â†’ Submitting 5 folds to thread pool...\")\n",
    "            futures = {\n",
    "                executor.submit(self._train_fold_in_thread, genome, fold_num): fold_num\n",
    "                for fold_num in range(1, 6)\n",
    "            }\n",
    "            \n",
    "            # Esperar a que todos los folds terminen\n",
    "            print(f\"      â†’ Waiting for all 5 folds to complete...\")\n",
    "            for future in as_completed(futures):\n",
    "                fold_num, fold_acc, model = future.result()\n",
    "                fold_accuracies[fold_num] = fold_acc\n",
    "                fold_models[fold_num] = model\n",
    "        \n",
    "        # Ordenar resultados por fold_num\n",
    "        sorted_folds = sorted(fold_accuracies.keys())\n",
    "        accuracies_list = [fold_accuracies[f] for f in sorted_folds]\n",
    "        \n",
    "        # Encontrar el mejor modelo\n",
    "        best_fold_num = max(fold_accuracies, key=fold_accuracies.get)\n",
    "        best_fold_acc = fold_accuracies[best_fold_num]\n",
    "        best_model = fold_models[best_fold_num]\n",
    "        \n",
    "        # Calcular fitness como promedio de los 5 folds\n",
    "        avg_fitness = np.mean(accuracies_list)\n",
    "        std_fitness = np.std(accuracies_list)\n",
    "        \n",
    "        print(f\"      âœ“ PARALLEL 5-Fold CV Results for {genome['id']}:\")\n",
    "        print(f\"        Fold accuracies: {[f'{acc:.2f}%' for acc in accuracies_list]}\")\n",
    "        print(f\"        Average fitness: {avg_fitness:.2f}% Â± {std_fitness:.2f}%\")\n",
    "        print(f\"        Best fold: Fold {best_fold_num} with {best_fold_acc:.2f}%\")\n",
    "        \n",
    "        return avg_fitness, best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR evaluating genome {genome['id']}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0.0, None\n",
    "\n",
    "def _load_fold_data(self, fold_number: int):\n",
    "    \"\"\"\n",
    "    Carga los datos de un fold especÃ­fico para el entrenamiento.\n",
    "    \n",
    "    Args:\n",
    "        fold_number: NÃºmero de fold (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    fold_files_directory = os.path.join(\n",
    "        self.config['data_path'], \n",
    "        f\"files_{self.config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    dataset_id = self.config['dataset_id']\n",
    "    \n",
    "    # Cargar datos del fold\n",
    "    x_train = np.load(os.path.join(fold_files_directory, f'X_train_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_train = np.load(os.path.join(fold_files_directory, f'y_train_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    x_val = np.load(os.path.join(fold_files_directory, f'X_val_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_val = np.load(os.path.join(fold_files_directory, f'y_val_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    x_test = np.load(os.path.join(fold_files_directory, f'X_test_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    y_test = np.load(os.path.join(fold_files_directory, f'y_test_{dataset_id}_fold_{fold_number}.npy'))\n",
    "    \n",
    "    # Reshape si es necesario\n",
    "    if len(x_train.shape) == 2:\n",
    "        x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "        x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "        x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "    \n",
    "    # Convertir a tensores\n",
    "    x_train_tensor = torch.FloatTensor(x_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train.astype(np.int64))\n",
    "    x_val_tensor = torch.FloatTensor(x_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val.astype(np.int64))\n",
    "    x_test_tensor = torch.FloatTensor(x_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test.astype(np.int64))\n",
    "    \n",
    "    # Crear datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    x_eval = torch.cat([x_val_tensor, x_test_tensor], dim=0)\n",
    "    y_eval = torch.cat([y_val_tensor, y_test_tensor], dim=0)\n",
    "    test_dataset = torch.utils.data.TensorDataset(x_eval, y_eval)\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    fold_train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=self.config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    fold_test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=self.config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return fold_train_loader, fold_test_loader\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution.evaluate_fitness = evaluate_fitness\n",
    "HybridNeuroevolution._load_fold_data = _load_fold_data\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 3/5): Fitness Evaluation and Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9ae0c",
   "metadata": {},
   "source": [
    "### 6.4 Population Evaluation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ce67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 4/5): Population Evaluation and Selection\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 3: Population Evaluation\n",
    "\n",
    "def evaluate_population(self):\n",
    "    print(f\"\\nEvaluating population (Generation {self.generation})...\")\n",
    "    print(f\"Processing {len(self.population)} individuals...\")\n",
    "    fitness_scores = []\n",
    "    best_fitness_so_far = 0.0\n",
    "    current_global_best_fitness = self.best_individual['fitness'] if self.best_individual else 0.0\n",
    "    \n",
    "    for i, genome in enumerate(self.population):\n",
    "        print(f\"\\n   Evaluating individual {i+1}/{len(self.population)} (ID: {genome['id']})\")\n",
    "        print(f\"      Architecture: {genome['num_conv_layers']} conv + {genome['num_fc_layers']} fc, opt={genome['optimizer']}, lr={genome['learning_rate']}\")\n",
    "        \n",
    "        # Evaluar y obtener fitness y modelo\n",
    "        fitness, model = self.evaluate_fitness(genome)\n",
    "        genome['fitness'] = fitness\n",
    "        fitness_scores.append(fitness)\n",
    "        \n",
    "        if fitness > best_fitness_so_far:\n",
    "            best_fitness_so_far = fitness\n",
    "            print(f\"      New best fitness in this generation: {fitness:.2f}%!\")\n",
    "        \n",
    "        # Verificar si es un nuevo mejor global\n",
    "        if fitness > current_global_best_fitness:\n",
    "            print(f\"      ðŸŒŸ NEW GLOBAL BEST! {fitness:.2f}% > {current_global_best_fitness:.2f}%\")\n",
    "            current_global_best_fitness = fitness\n",
    "            \n",
    "            # Guardar checkpoint (elimina el anterior automÃ¡ticamente)\n",
    "            if model is not None:\n",
    "                self.save_best_checkpoint(genome, model)\n",
    "        \n",
    "        print(f\"      Fitness obtained: {fitness:.2f}% | Best in generation: {best_fitness_so_far:.2f}% | Global best: {current_global_best_fitness:.2f}%\")\n",
    "    \n",
    "    # Generation statistics\n",
    "    if fitness_scores:\n",
    "        avg_fitness = np.mean(fitness_scores)\n",
    "        max_fitness = np.max(fitness_scores)\n",
    "        min_fitness = np.min(fitness_scores)\n",
    "        std_fitness = np.std(fitness_scores)\n",
    "    else:\n",
    "        avg_fitness = max_fitness = min_fitness = std_fitness = 0.0\n",
    "\n",
    "    stats = {\n",
    "        'generation': self.generation,\n",
    "        'avg_fitness': avg_fitness,\n",
    "        'max_fitness': max_fitness,\n",
    "        'min_fitness': min_fitness,\n",
    "        'std_fitness': std_fitness\n",
    "    }\n",
    "    self.generation_stats.append(stats)\n",
    "    self.fitness_history.append(max_fitness)\n",
    "\n",
    "    best_genome = max(self.population, key=lambda x: x['fitness'])\n",
    "    if self.best_individual is None or best_genome['fitness'] > self.best_individual['fitness']:\n",
    "        self.best_individual = copy.deepcopy(best_genome)\n",
    "        print(f\"\\nNew global best individual found!\")\n",
    "\n",
    "    print(f\"\\nGENERATION {self.generation} STATISTICS:\")\n",
    "    print(f\"   Maximum fitness: {max_fitness:.2f}%\")\n",
    "    print(f\"   Average fitness: {avg_fitness:.2f}%\")\n",
    "    print(f\"   Minimum fitness: {min_fitness:.2f}%\")\n",
    "    print(f\"   Standard deviation: {std_fitness:.2f}%\")\n",
    "    print(f\"   Best individual: {best_genome['id']} with {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Global best individual: {self.best_individual['id']} with {self.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "def selection_and_reproduction(self):\n",
    "    print(f\"\\nStarting selection and reproduction...\")\n",
    "    # Sort by fitness\n",
    "    self.population.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "    elite_size = max(1, int(self.config['population_size'] * self.config['elite_percentage']))\n",
    "    elite = self.population[:elite_size]\n",
    "    print(f\"Selecting {elite_size} elite individuals:\")\n",
    "    for i, individual in enumerate(elite):\n",
    "        print(f\"   Elite {i+1}: {individual['id']} (fitness: {individual['fitness']:.2f}%)\")\n",
    "    new_population = copy.deepcopy(elite)\n",
    "    offspring_needed = self.config['population_size'] - len(new_population)\n",
    "    print(f\"Creating {offspring_needed} new individuals through crossover and mutation...\")\n",
    "    offspring_created = 0\n",
    "    while len(new_population) < self.config['population_size']:\n",
    "        parent1 = self.tournament_selection()\n",
    "        parent2 = self.tournament_selection()\n",
    "        child1, child2 = crossover_genomes(parent1, parent2, self.config)\n",
    "        child1 = mutate_genome(child1, self.config)\n",
    "        if len(new_population) < self.config['population_size']:\n",
    "            new_population.append(child1)\n",
    "        child2 = mutate_genome(child2, self.config)\n",
    "        if len(new_population) < self.config['population_size']:\n",
    "            new_population.append(child2)\n",
    "        offspring_created += 2\n",
    "        if offspring_created % 4 == 0:\n",
    "            print(f\"   Created {min(offspring_created, offspring_needed)} of {offspring_needed} new individuals...\")\n",
    "    self.population = new_population[:self.config['population_size']]\n",
    "    print(f\"New generation created with {len(self.population)} individuals\")\n",
    "    print(f\"   Elite preserved: {elite_size}\")\n",
    "    print(f\"   New individuals: {len(self.population) - elite_size}\")\n",
    "\n",
    "def tournament_selection(self, tournament_size: int = 3) -> dict:\n",
    "    tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
    "    return max(tournament, key=lambda x: x['fitness'])\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution.evaluate_population = evaluate_population\n",
    "HybridNeuroevolution.selection_and_reproduction = selection_and_reproduction\n",
    "HybridNeuroevolution.tournament_selection = tournament_selection\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 4/5): Population Evaluation and Selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4aae0",
   "metadata": {},
   "source": [
    "### 6.5 Convergence Check and Main Evolution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea180cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HybridNeuroevolution class (Part 5/5): Convergence and Main Evolution Loop\n",
      "âœ“ HybridNeuroevolution class COMPLETE with PARALLEL 5-fold CV and adaptive mutation\n"
     ]
    }
   ],
   "source": [
    "# Continued from Part 4: Convergence and Evolution\n",
    "\n",
    "def _update_adaptive_mutation(self):\n",
    "    # Diversity measured via std of fitness in last generation\n",
    "    if not self.generation_stats:\n",
    "        self.config['current_mutation_rate'] = self.config['base_mutation_rate']\n",
    "        return\n",
    "    last_std = self.generation_stats[-1]['std_fitness']\n",
    "    # Heuristic: more diversity -> lower mutation, low diversity -> higher\n",
    "    # Normalize std roughly assuming fitness in [0,100]\n",
    "    diversity_factor = min(1.0, last_std / 10.0)  # std 10% -> factor 1\n",
    "    # Invert: low diversity (small std) should raise mutation\n",
    "    inverted = 1 - diversity_factor\n",
    "    new_rate = self.config['base_mutation_rate'] + (inverted - 0.5) * 0.4  # adjust +/-0.2 range\n",
    "    new_rate = max(self.config['mutation_rate_min'], min(self.config['mutation_rate_max'], new_rate))\n",
    "    self.config['current_mutation_rate'] = round(new_rate, 4)\n",
    "    print(f\"Adaptive mutation rate updated to {self.config['current_mutation_rate']} (std_fitness={last_std:.2f})\")\n",
    "\n",
    "def check_convergence(self) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica criterios de convergencia:\n",
    "    1. Target fitness alcanzado\n",
    "    2. MÃ¡ximo de generaciones alcanzado\n",
    "    3. Early stopping: sin mejora en N generaciones\n",
    "    4. Estancamiento detectado en Ãºltimas generaciones\n",
    "    \"\"\"\n",
    "    # Criterion 1: Target fitness reached\n",
    "    if self.best_individual and self.best_individual['fitness'] >= self.config['fitness_threshold']:\n",
    "        print(f\"\\nâœ… Target fitness reached! ({self.best_individual['fitness']:.2f}% >= {self.config['fitness_threshold']}%)\")\n",
    "        return True\n",
    "    \n",
    "    # Criterion 2: Maximum generations reached\n",
    "    if self.generation >= self.config['max_generations']:\n",
    "        print(f\"\\nâ±ï¸ Maximum generations reached ({self.generation}/{self.config['max_generations']})\")\n",
    "        return True\n",
    "    \n",
    "    # Criterion 3: Early stopping - no improvement in N generations\n",
    "    if self.generation > 0:  # No check on generation 0\n",
    "        current_best = self.best_individual['fitness'] if self.best_individual else 0.0\n",
    "        \n",
    "        # Check if there's improvement compared to best overall\n",
    "        improvement = current_best - self.best_fitness_overall\n",
    "        \n",
    "        if improvement >= self.min_improvement_threshold:\n",
    "            # Significant improvement! Reset counter\n",
    "            self.best_fitness_overall = current_best\n",
    "            self.generations_without_improvement = 0\n",
    "            print(f\"\\nðŸ”„ Improvement detected: {improvement:.2f}% | Generations without improvement: {self.generations_without_improvement}\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.generations_without_improvement += 1\n",
    "            print(f\"\\nâ³ No significant improvement | Generations without improvement: {self.generations_without_improvement}/{self.max_generations_without_improvement}\")\n",
    "            \n",
    "            if self.generations_without_improvement >= self.max_generations_without_improvement:\n",
    "                print(f\"\\nðŸ›‘ EARLY STOPPING: No improvement for {self.max_generations_without_improvement} generations\")\n",
    "                print(f\"   Best fitness plateau: {self.best_fitness_overall:.2f}%\")\n",
    "                return True\n",
    "    \n",
    "    # Criterion 4: Stagnation in last 3 generations (additional safety check)\n",
    "    if len(self.fitness_history) >= 3:\n",
    "        recent = self.fitness_history[-3:]\n",
    "        if max(recent) - min(recent) < 0.5:\n",
    "            print(f\"\\nðŸ“‰ Stagnation detected in last 3 generations (all within {max(recent) - min(recent):.2f}%)\")\n",
    "            # Don't stop immediately, let generation-level early stopping handle it\n",
    "    \n",
    "    return False\n",
    "\n",
    "def evolve(self) -> dict:\n",
    "    print(\"STARTING HYBRID NEUROEVOLUTION PROCESS (adaptive mutation + generation-level early stopping)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"   Population: {self.config['population_size']} individuals\")\n",
    "    print(f\"   Maximum generations: {self.config['max_generations']}\")\n",
    "    print(f\"   Target fitness: {self.config['fitness_threshold']}%\")\n",
    "    print(f\"   Early stopping (generations): {self.config['early_stopping_generations']} without improvement\")\n",
    "    print(f\"   Min improvement threshold: {self.config['min_improvement_threshold']}%\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(\"=\"*80)\n",
    "    self.initialize_population()\n",
    "    while not self.check_convergence():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"GENERATION {self.generation}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        self.evaluate_population()\n",
    "        if self.check_convergence():\n",
    "            break\n",
    "        self._update_adaptive_mutation()\n",
    "        self.selection_and_reproduction()\n",
    "        self.generation += 1\n",
    "        print(f\"\\nPreparing for next generation...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EVOLUTION COMPLETED!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Best individual found:\")\n",
    "    print(f\"   ID: {self.best_individual['id']}\")\n",
    "    print(f\"   Fitness: {self.best_individual['fitness']:.2f}%\")\n",
    "    print(f\"   Origin generation: {self.generation}\")\n",
    "    print(f\"   Total generations processed: {self.generation + 1}\")\n",
    "    print(f\"   Generations without improvement: {self.generations_without_improvement}/{self.max_generations_without_improvement}\")\n",
    "    print(\"=\"*80)\n",
    "    return self.best_individual\n",
    "\n",
    "# Add methods to class\n",
    "HybridNeuroevolution._update_adaptive_mutation = _update_adaptive_mutation\n",
    "HybridNeuroevolution.check_convergence = check_convergence\n",
    "HybridNeuroevolution.evolve = evolve\n",
    "\n",
    "print(\"âœ“ HybridNeuroevolution class (Part 5/5): Convergence and Main Evolution Loop\")\n",
    "print(\"âœ“ HybridNeuroevolution class COMPLETE with PARALLEL 5-fold CV and adaptive mutation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59597ef1",
   "metadata": {},
   "source": [
    "## 7. Evolution Process Execution\n",
    "\n",
    "### ðŸš€ Importante: Parallel 5-Fold Cross-Validation durante la EvoluciÃ³n\n",
    "\n",
    "**Cambio clave**: Ahora cada individuo se evalÃºa con **5-fold cross-validation PARALELO** durante el proceso evolutivo:\n",
    "\n",
    "1. **Durante la evoluciÃ³n**:\n",
    "   - Cada individuo se entrena y evalÃºa en **cada uno de los 5 folds SIMULTÃNEAMENTE**\n",
    "   - Los 5 folds se ejecutan en **threads separados** (paralelizaciÃ³n)\n",
    "   - El **fitness final** es el **promedio** de las accuracies de los 5 folds\n",
    "   - Se espera a que **todos los folds terminen** antes de calcular el fitness\n",
    "   - Esto garantiza que la arquitectura seleccionada no estÃ© sobreajustada a un fold especÃ­fico\n",
    "\n",
    "2. **Ventajas de la paralelizaciÃ³n**:\n",
    "   - ðŸš€ **Mucho mÃ¡s rÃ¡pido**: Los 5 folds se entrenan simultÃ¡neamente (en threads)\n",
    "   - âœ… **MÃ¡s robusto**: La mejor arquitectura generaliza mejor\n",
    "   - âœ… **Menos sesgado**: No depende de un solo split de datos\n",
    "   - ðŸ’¡ **Aprovecha multi-core**: Usa mÃºltiples nÃºcleos de CPU para acelerar\n",
    "   \n",
    "3. **Proceso paralelo**:\n",
    "   - GeneraciÃ³n 0: Se crean N individuos aleatorios\n",
    "   - Para cada individuo:\n",
    "     - **Thread Pool**: Se crean 5 threads (uno por fold)\n",
    "     - **Fold 1-5**: Se entrenan y evalÃºan **SIMULTÃNEAMENTE** â†’ accuracyâ‚...accuracyâ‚…\n",
    "     - **Espera**: Se espera a que **todos los threads terminen**\n",
    "     - **Fitness** = (accuracyâ‚ + accuracyâ‚‚ + accuracyâ‚ƒ + accuracyâ‚„ + accuracyâ‚…) / 5\n",
    "   - Se seleccionan los mejores segÃºn fitness promedio\n",
    "   - Se aplica crossover y mutaciÃ³n\n",
    "   - Siguiente generaciÃ³n...\n",
    "\n",
    "4. **Rendimiento**:\n",
    "   - Tiempo de evaluaciÃ³n â‰ˆ tiempo del fold mÃ¡s lento (en lugar de suma de todos)\n",
    "   - AceleraciÃ³n teÃ³rica: ~5x mÃ¡s rÃ¡pido que secuencial\n",
    "   - AceleraciÃ³n real: depende del nÃºmero de cores disponibles\n",
    "\n",
    "**Nota**: Para hacer pruebas rÃ¡pidas, puedes reducir `population_size` y `max_generations` en la configuraciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be51ada5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUDIO NEUROEVOLUTION CONFIGURATION\n",
      "============================================================\n",
      "   Dataset: Audio (Parkinson Classification)\n",
      "   Dataset ID: all_real_syn_n\n",
      "   Fold ID: all_real_syn_n\n",
      "   Number of folds: 5 (all used during evolution)\n",
      "   Data Path: data/sets/folds_5\n",
      "   Number of channels: 1 (1D audio)\n",
      "   Sequence length: 11520 (will be auto-detected)\n",
      "   Number of classes: 2 (Control vs Pathological)\n",
      "   Batch size: 64\n",
      "   Population: 20 individuals\n",
      "   Maximum generations: 100\n",
      "   Target fitness: 80.0%\n",
      "   Device: cuda\n",
      "   Platform: posix (Unix/Linux/Mac)\n",
      "   Parallelization: Enabled (5 threads per individual)\n",
      "============================================================\n",
      "\n",
      "Verifying audio dataset...\n",
      "\n",
      "============================================================\n",
      "VERIFICANDO DISPONIBILIDAD DE DATOS\n",
      "============================================================\n",
      "Dataset ID: all_real_syn_n, Verificando los 5 folds...\n",
      "   Looking for: /home/jovyan/audio_test/data/sets/folds_5/files_all_real_syn_n\n",
      "   âœ“ Directory found: /home/jovyan/audio_test/data/sets/folds_5/files_all_real_syn_n\n",
      "\n",
      "Checking for all 5 folds...\n",
      "   âœ“ Fold 1: All files present\n",
      "   âœ“ Fold 2: All files present\n",
      "   âœ“ Fold 3: All files present\n",
      "   âœ“ Fold 4: All files present\n",
      "   âœ“ Fold 5: All files present\n",
      "\n",
      "âœ“ All 5 folds verified successfully!\n",
      "\n",
      "Loading Fold 1 to detect sequence length...\n",
      "   Train samples: (8680, 11520)\n",
      "   Sequence length detected: 11520\n",
      "\n",
      "âœ“ Dataset verification complete!\n",
      "   During evolution, each individual will train on all 5 folds.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET VERIFIED - READY FOR PARALLEL 5-FOLD CV EVOLUTION\n",
      "============================================================\n",
      "\n",
      "Starting audio neuroevolution at 18:50:00\n",
      "Architecture: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC\n",
      "Each individual will be evaluated on all 5 folds IN PARALLEL\n",
      "Using ThreadPoolExecutor with 5 workers (one per fold)\n",
      "============================================================\n",
      "\n",
      "STARTING HYBRID NEUROEVOLUTION PROCESS (adaptive mutation + generation-level early stopping)\n",
      "================================================================================\n",
      "Configuration:\n",
      "   Population: 20 individuals\n",
      "   Maximum generations: 100\n",
      "   Target fitness: 80.0%\n",
      "   Early stopping (generations): 20 without improvement\n",
      "   Min improvement threshold: 0.01%\n",
      "   Device: cuda\n",
      "================================================================================\n",
      "Initializing population of 20 individuals...\n",
      "Population initialized with 20 individuals\n",
      "\n",
      "================================================================================\n",
      "GENERATION 0\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 0)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 54b40718)\n",
      "      Architecture: 21 conv + 2 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 54b40718 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 54b40718:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 0.00% | Global best: 0.00%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: de4ae238)\n",
      "      Architecture: 23 conv + 2 fc, opt=sgd, lr=0.1\n",
      "      Training/Evaluating model de4ae238 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for de4ae238:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 0.00% | Global best: 0.00%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: e6bef0a6)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model e6bef0a6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6852, acc=46.33% (best=46.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6628, acc=45.78% (best=45.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6727, acc=62.11% (best=62.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6838, acc=53.20% (best=53.20%)\n",
      "          Fold 5 Epoch 1: loss=0.6972, acc=44.14% (best=44.14%)\n",
      "          Fold 2 Epoch 5: loss=0.3529, acc=42.73% (best=53.67%)\n",
      "          Fold 3 Epoch 5: loss=0.2984, acc=57.34% (best=59.53%)\n",
      "          Fold 4 Epoch 5: loss=0.3514, acc=58.98% (best=66.48%)\n",
      "          Fold 1 Epoch 5: loss=0.2878, acc=57.66% (best=57.66%)\n",
      "          Fold 5 Epoch 5: loss=0.3368, acc=56.17% (best=56.17%)\n",
      "          Fold 2 Epoch 10: loss=0.2341, acc=58.83% (best=60.94%)\n",
      "          Fold 3 Epoch 10: loss=0.2271, acc=45.31% (best=60.39%)\n",
      "          Fold 4 Epoch 10: loss=0.2237, acc=51.25% (best=66.48%)\n",
      "          Fold 1 Epoch 10: loss=0.2154, acc=57.34% (best=60.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2327, acc=35.39% (best=59.61%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 66.48%\n",
      "          Fold 2 Epoch 15: loss=0.2094, acc=55.16% (best=68.12%)\n",
      "          Fold 3 Epoch 15: loss=0.2148, acc=53.59% (best=60.39%)\n",
      "          Fold 1 Epoch 15: loss=0.2035, acc=61.88% (best=61.88%)\n",
      "          Fold 5 Epoch 15: loss=0.2106, acc=37.11% (best=59.61%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 59.61%\n",
      "          Fold 2 Epoch 20: loss=0.1998, acc=61.25% (best=68.12%)\n",
      "          Fold 3 Epoch 20: loss=0.2092, acc=60.16% (best=67.66%)\n",
      "          Fold 1 Epoch 20: loss=0.1989, acc=48.75% (best=63.52%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 68.12%\n",
      "          Fold 3 Epoch 25: loss=0.1963, acc=54.69% (best=67.66%)\n",
      "          Fold 1 Epoch 25: loss=0.1929, acc=58.83% (best=63.52%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 67.66%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e6bef0a6:\n",
      "        Fold accuracies: ['63.52%', '68.12%', '67.66%', '66.48%', '59.61%']\n",
      "        Average fitness: 65.08% Â± 3.17%\n",
      "        Best fold: Fold 2 with 68.12%\n",
      "      New best fitness in this generation: 65.08%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 65.08% > 0.00%\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen0_ide6bef0a6_fitness65.08.pth\n",
      "        Fitness: 65.08%, ID: e6bef0a6, Gen: 0\n",
      "      Fitness obtained: 65.08% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 907391b2)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 907391b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7043, acc=33.98% (best=33.98%)\n",
      "          Fold 3 Epoch 1: loss=0.7080, acc=46.48% (best=46.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6753, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6924, acc=46.80% (best=46.80%)\n",
      "          Fold 1 Epoch 1: loss=0.7001, acc=47.03% (best=47.03%)\n",
      "          Fold 5 Epoch 5: loss=0.6388, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 5: loss=0.5755, acc=57.50% (best=58.67%)\n",
      "          Fold 3 Epoch 5: loss=0.5774, acc=50.39% (best=51.09%)\n",
      "          Fold 2 Epoch 5: loss=0.6513, acc=64.69% (best=64.69%)\n",
      "          Fold 1 Epoch 5: loss=0.6336, acc=55.39% (best=55.39%)\n",
      "          Fold 4 Epoch 10: loss=0.4173, acc=58.20% (best=58.67%)\n",
      "          Fold 3 Epoch 10: loss=0.4214, acc=49.38% (best=51.09%)\n",
      "          Fold 5 Epoch 10: loss=0.4499, acc=51.56% (best=52.58%)\n",
      "          Fold 2 Epoch 10: loss=0.4593, acc=51.09% (best=64.69%)\n",
      "          Fold 1 Epoch 10: loss=0.4676, acc=60.62% (best=60.62%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 51.09%\n",
      "          Fold 4 Epoch 15: loss=0.3308, acc=57.34% (best=65.23%)\n",
      "          Fold 5 Epoch 15: loss=0.3297, acc=46.88% (best=52.58%)\n",
      "          Fold 2 Epoch 15: loss=0.3437, acc=42.97% (best=67.50%)\n",
      "          Fold 1 Epoch 15: loss=0.3923, acc=63.83% (best=63.83%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 52.58%\n",
      "          Fold 4 Epoch 20: loss=0.2796, acc=47.34% (best=65.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2926, acc=53.75% (best=67.50%)\n",
      "          Fold 1 Epoch 20: loss=0.3277, acc=46.09% (best=63.83%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 67.50%\n",
      "          Fold 1 Epoch 25: loss=0.2897, acc=55.16% (best=63.83%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 63.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 907391b2:\n",
      "        Fold accuracies: ['63.83%', '67.50%', '51.09%', '65.23%', '52.58%']\n",
      "        Average fitness: 60.05% Â± 6.82%\n",
      "        Best fold: Fold 2 with 67.50%\n",
      "      Fitness obtained: 60.05% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 8a9ef2fb)\n",
      "      Architecture: 24 conv + 8 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model 8a9ef2fb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 8a9ef2fb:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 17b55cbd)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 17b55cbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6999, acc=49.84% (best=49.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6901, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6240, acc=51.88% (best=51.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6852, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 1: loss=0.7024, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.3015, acc=55.08% (best=55.08%)\n",
      "          Fold 5 Epoch 5: loss=0.3069, acc=58.67% (best=58.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3081, acc=55.55% (best=55.55%)\n",
      "          Fold 4 Epoch 5: loss=0.3115, acc=41.95% (best=51.88%)\n",
      "          Fold 1 Epoch 5: loss=0.3088, acc=44.45% (best=59.22%)\n",
      "          Fold 2 Epoch 10: loss=0.2426, acc=52.97% (best=59.77%)\n",
      "          Fold 3 Epoch 10: loss=0.2435, acc=51.56% (best=55.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2451, acc=57.03% (best=66.02%)\n",
      "          Fold 4 Epoch 10: loss=0.2504, acc=49.61% (best=51.88%)\n",
      "          Fold 1 Epoch 10: loss=0.2492, acc=46.56% (best=59.22%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 51.88%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.22%\n",
      "          Fold 2 Epoch 15: loss=0.2228, acc=56.48% (best=59.77%)\n",
      "          Fold 3 Epoch 15: loss=0.2270, acc=49.38% (best=55.70%)\n",
      "          Fold 5 Epoch 15: loss=0.2216, acc=59.92% (best=66.02%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 55.70%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.02%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 59.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17b55cbd:\n",
      "        Fold accuracies: ['59.22%', '59.77%', '55.70%', '51.88%', '66.02%']\n",
      "        Average fitness: 58.52% Â± 4.70%\n",
      "        Best fold: Fold 5 with 66.02%\n",
      "      Fitness obtained: 58.52% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 638b661b)\n",
      "      Architecture: 26 conv + 9 fc, opt=sgd, lr=0.01\n",
      "      Training/Evaluating model 638b661b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 638b661b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 4701ff0d)\n",
      "      Architecture: 7 conv + 6 fc, opt=sgd, lr=0.0001\n",
      "      Training/Evaluating model 4701ff0d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7344, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7080, acc=38.20% (best=38.20%)\n",
      "          Fold 4 Epoch 1: loss=0.7284, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 1: loss=0.7457, acc=39.38% (best=39.38%)\n",
      "          Fold 5 Epoch 1: loss=0.7212, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.7302, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 5: loss=0.7084, acc=49.38% (best=49.38%)\n",
      "          Fold 4 Epoch 5: loss=0.7204, acc=48.36% (best=53.28%)\n",
      "          Fold 1 Epoch 5: loss=0.7300, acc=63.12% (best=63.12%)\n",
      "          Fold 5 Epoch 5: loss=0.7241, acc=49.84% (best=49.84%)\n",
      "          Fold 2 Epoch 10: loss=0.7192, acc=49.61% (best=49.84%)\n",
      "          Fold 3 Epoch 10: loss=0.7068, acc=46.95% (best=49.38%)\n",
      "          Fold 1 Epoch 10: loss=0.7214, acc=42.11% (best=63.12%)\n",
      "          Fold 4 Epoch 10: loss=0.7133, acc=49.53% (best=53.28%)\n",
      "          Fold 5 Epoch 10: loss=0.7214, acc=48.98% (best=50.70%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 53.28%\n",
      "          Fold 3 Epoch 15: loss=0.7059, acc=44.61% (best=49.38%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 49.38%\n",
      "          Fold 2 Epoch 15: loss=0.7152, acc=49.84% (best=49.84%)\n",
      "          Fold 1 Epoch 15: loss=0.7205, acc=62.58% (best=63.75%)\n",
      "          Fold 5 Epoch 15: loss=0.7147, acc=49.61% (best=54.53%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 49.84%\n",
      "          Fold 1 Epoch 20: loss=0.7109, acc=63.59% (best=66.25%)\n",
      "          Fold 5 Epoch 20: loss=0.7177, acc=57.73% (best=57.73%)\n",
      "          Fold 1 Epoch 25: loss=0.7142, acc=57.66% (best=66.25%)\n",
      "          Fold 5 Epoch 25: loss=0.7146, acc=48.28% (best=57.73%)\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 66.25%\n",
      "          Fold 5 Epoch 30: loss=0.7109, acc=52.50% (best=57.73%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 57.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4701ff0d:\n",
      "        Fold accuracies: ['66.25%', '49.84%', '49.38%', '53.28%', '57.73%']\n",
      "        Average fitness: 55.30% Â± 6.24%\n",
      "        Best fold: Fold 1 with 66.25%\n",
      "      Fitness obtained: 55.30% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: ef577d5c)\n",
      "      Architecture: 29 conv + 2 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model ef577d5c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for ef577d5c:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: ec3c7f2a)\n",
      "      Architecture: 28 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model ec3c7f2a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for ec3c7f2a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 2a0b0f70)\n",
      "      Architecture: 20 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2a0b0f70 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 2a0b0f70:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: d2b0f118)\n",
      "      Architecture: 14 conv + 10 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model d2b0f118 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for d2b0f118:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 93f13a57)\n",
      "      Architecture: 25 conv + 9 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model 93f13a57 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 93f13a57:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: e4e961ac)\n",
      "      Architecture: 19 conv + 10 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model e4e961ac with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for e4e961ac:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: edea52d0)\n",
      "      Architecture: 20 conv + 10 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model edea52d0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for edea52d0:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 2f1e4dc8)\n",
      "      Architecture: 29 conv + 8 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 2f1e4dc8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 2f1e4dc8:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 1136351f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 1136351f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7187, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7192, acc=56.33% (best=56.33%)\n",
      "          Fold 4 Epoch 1: loss=0.7636, acc=65.31% (best=65.31%)\n",
      "          Fold 1 Epoch 1: loss=0.7236, acc=58.91% (best=58.91%)\n",
      "          Fold 5 Epoch 1: loss=0.7889, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.7084, acc=43.98% (best=49.61%)\n",
      "          Fold 3 Epoch 5: loss=0.7154, acc=49.14% (best=56.33%)\n",
      "          Fold 1 Epoch 5: loss=0.7054, acc=59.06% (best=62.97%)\n",
      "          Fold 4 Epoch 5: loss=0.7165, acc=59.45% (best=68.20%)\n",
      "          Fold 5 Epoch 5: loss=0.7547, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.6953, acc=42.66% (best=49.61%)\n",
      "          Fold 3 Epoch 10: loss=0.7052, acc=50.86% (best=56.33%)\n",
      "          Fold 1 Epoch 10: loss=0.7016, acc=56.25% (best=62.97%)\n",
      "          Fold 4 Epoch 10: loss=0.6931, acc=59.84% (best=68.20%)\n",
      "          Fold 5 Epoch 10: loss=0.7291, acc=50.16% (best=50.16%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.61%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 56.33%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.20%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.97%\n",
      "          Fold 5 Epoch 15: loss=0.7177, acc=50.31% (best=53.20%)\n",
      "          Fold 5 Epoch 20: loss=0.7137, acc=53.75% (best=53.75%)\n",
      "          Fold 5 Epoch 25: loss=0.7045, acc=50.94% (best=53.98%)\n",
      "          Fold 5 Epoch 30: loss=0.7059, acc=50.78% (best=53.98%)\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 53.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1136351f:\n",
      "        Fold accuracies: ['62.97%', '49.61%', '56.33%', '68.20%', '53.98%']\n",
      "        Average fitness: 58.22% Â± 6.60%\n",
      "        Best fold: Fold 4 with 68.20%\n",
      "      Fitness obtained: 58.22% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 7515a9ca)\n",
      "      Architecture: 27 conv + 2 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 7515a9ca with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 7515a9ca:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 6344f10c)\n",
      "      Architecture: 4 conv + 8 fc, opt=sgd, lr=0.001\n",
      "      Training/Evaluating model 6344f10c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7334, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7156, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7277, acc=50.31% (best=50.31%)\n",
      "          Fold 4 Epoch 1: loss=0.7272, acc=50.47% (best=50.47%)\n",
      "          Fold 5 Epoch 1: loss=0.7258, acc=47.89% (best=47.89%)\n",
      "          Fold 2 Epoch 5: loss=0.7076, acc=42.27% (best=50.47%)\n",
      "          Fold 3 Epoch 5: loss=0.7069, acc=50.55% (best=51.02%)\n",
      "          Fold 1 Epoch 5: loss=0.7098, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 5: loss=0.6984, acc=52.34% (best=67.27%)\n",
      "          Fold 5 Epoch 5: loss=0.7124, acc=48.12% (best=53.91%)\n",
      "          Fold 2 Epoch 10: loss=0.7010, acc=43.91% (best=50.47%)\n",
      "          Fold 3 Epoch 10: loss=0.7007, acc=47.97% (best=51.09%)\n",
      "          Fold 1 Epoch 10: loss=0.6956, acc=50.39% (best=50.55%)\n",
      "          Fold 4 Epoch 10: loss=0.6826, acc=55.16% (best=67.27%)\n",
      "          Fold 5 Epoch 10: loss=0.7092, acc=47.73% (best=54.53%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.47%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.27%\n",
      "          Fold 3 Epoch 15: loss=0.7003, acc=47.97% (best=51.17%)\n",
      "          Fold 1 Epoch 15: loss=0.6790, acc=50.31% (best=50.55%)\n",
      "          Fold 5 Epoch 15: loss=0.7013, acc=59.69% (best=60.08%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 50.55%\n",
      "          Fold 3 Epoch 20: loss=0.6966, acc=51.95% (best=53.44%)\n",
      "          Fold 5 Epoch 20: loss=0.6958, acc=53.12% (best=61.64%)\n",
      "          Fold 3 Epoch 25: loss=0.6911, acc=51.02% (best=53.44%)\n",
      "          Fold 5 Epoch 25: loss=0.6783, acc=50.00% (best=61.64%)\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 53.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6344f10c:\n",
      "        Fold accuracies: ['50.55%', '50.47%', '53.44%', '67.27%', '61.64%']\n",
      "        Average fitness: 56.67% Â± 6.68%\n",
      "        Best fold: Fold 4 with 67.27%\n",
      "      Fitness obtained: 56.67% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: f1c0f491)\n",
      "      Architecture: 19 conv + 1 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model f1c0f491 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for f1c0f491:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.08% | Global best: 65.08%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 0 STATISTICS:\n",
      "   Maximum fitness: 65.08%\n",
      "   Average fitness: 17.69%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 27.08%\n",
      "   Best individual: e6bef0a6 with 65.08%\n",
      "   Global best individual: e6bef0a6 with 65.08%\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=27.08)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: e6bef0a6 (fitness: 65.08%)\n",
      "   Elite 2: 907391b2 (fitness: 60.05%)\n",
      "   Elite 3: 17b55cbd (fitness: 58.52%)\n",
      "   Elite 4: 1136351f (fitness: 58.22%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "ðŸ”„ Improvement detected: inf% | Generations without improvement: 0\n",
      "\n",
      "================================================================================\n",
      "GENERATION 1\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 1)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: e6bef0a6)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model e6bef0a6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6872, acc=58.59% (best=58.59%)\n",
      "          Fold 2 Epoch 1: loss=0.6646, acc=43.28% (best=43.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6588, acc=55.78% (best=55.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6765, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6894, acc=51.88% (best=51.88%)\n",
      "          Fold 2 Epoch 5: loss=0.2728, acc=51.48% (best=51.48%)\n",
      "          Fold 3 Epoch 5: loss=0.3203, acc=58.52% (best=59.14%)\n",
      "          Fold 4 Epoch 5: loss=0.3123, acc=54.14% (best=60.94%)\n",
      "          Fold 1 Epoch 5: loss=0.3423, acc=47.03% (best=56.09%)\n",
      "          Fold 5 Epoch 5: loss=0.3013, acc=50.47% (best=51.88%)\n",
      "          Fold 2 Epoch 10: loss=0.2210, acc=46.09% (best=59.92%)\n",
      "          Fold 3 Epoch 10: loss=0.2289, acc=54.14% (best=59.14%)\n",
      "          Fold 4 Epoch 10: loss=0.2194, acc=50.94% (best=64.61%)\n",
      "          Fold 1 Epoch 10: loss=0.2330, acc=60.08% (best=70.00%)\n",
      "          Fold 5 Epoch 10: loss=0.2250, acc=43.44% (best=51.88%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 59.14%\n",
      "          Fold 2 Epoch 15: loss=0.2060, acc=56.72% (best=59.92%)\n",
      "          Fold 4 Epoch 15: loss=0.2082, acc=61.02% (best=65.47%)\n",
      "          Fold 1 Epoch 15: loss=0.2166, acc=63.05% (best=70.00%)\n",
      "          Fold 5 Epoch 15: loss=0.2109, acc=46.33% (best=52.73%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 70.00%\n",
      "          Fold 2 Epoch 20: loss=0.1965, acc=57.03% (best=63.98%)\n",
      "          Fold 4 Epoch 20: loss=0.1961, acc=65.62% (best=68.67%)\n",
      "          Fold 5 Epoch 20: loss=0.1980, acc=44.30% (best=52.73%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 52.73%\n",
      "          Fold 2 Epoch 25: loss=0.1989, acc=51.80% (best=63.98%)\n",
      "          Fold 4 Epoch 25: loss=0.2028, acc=57.58% (best=68.67%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 63.98%\n",
      "          Fold 4: Early stopping at epoch 29\n",
      "      â†’ Fold 4 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e6bef0a6:\n",
      "        Fold accuracies: ['70.00%', '63.98%', '59.14%', '68.67%', '52.73%']\n",
      "        Average fitness: 62.91% Â± 6.36%\n",
      "        Best fold: Fold 1 with 70.00%\n",
      "      New best fitness in this generation: 62.91%!\n",
      "      Fitness obtained: 62.91% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 907391b2)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 907391b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6849, acc=51.33% (best=51.33%)\n",
      "          Fold 3 Epoch 1: loss=0.7036, acc=46.09% (best=46.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6735, acc=45.39% (best=45.39%)\n",
      "          Fold 1 Epoch 1: loss=0.6931, acc=55.47% (best=55.47%)\n",
      "          Fold 5 Epoch 1: loss=0.7084, acc=54.61% (best=54.61%)\n",
      "          Fold 2 Epoch 5: loss=0.5996, acc=50.62% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.6147, acc=51.17% (best=53.67%)\n",
      "          Fold 1 Epoch 5: loss=0.6196, acc=59.45% (best=59.45%)\n",
      "          Fold 4 Epoch 5: loss=0.5286, acc=52.27% (best=52.27%)\n",
      "          Fold 5 Epoch 5: loss=0.6770, acc=46.25% (best=57.89%)\n",
      "          Fold 2 Epoch 10: loss=0.4061, acc=40.16% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.4710, acc=50.08% (best=53.67%)\n",
      "          Fold 1 Epoch 10: loss=0.4806, acc=59.77% (best=59.92%)\n",
      "          Fold 4 Epoch 10: loss=0.3515, acc=49.61% (best=53.12%)\n",
      "          Fold 5 Epoch 10: loss=0.4813, acc=48.75% (best=61.02%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 56.95%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 53.67%\n",
      "          Fold 1 Epoch 15: loss=0.3920, acc=61.25% (best=66.95%)\n",
      "          Fold 4 Epoch 15: loss=0.2865, acc=38.83% (best=53.12%)\n",
      "          Fold 5 Epoch 15: loss=0.3676, acc=44.53% (best=61.02%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 53.12%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 61.02%\n",
      "          Fold 1 Epoch 20: loss=0.3343, acc=61.56% (best=66.95%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 66.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 907391b2:\n",
      "        Fold accuracies: ['66.95%', '56.95%', '53.67%', '53.12%', '61.02%']\n",
      "        Average fitness: 58.34% Â± 5.14%\n",
      "        Best fold: Fold 1 with 66.95%\n",
      "      Fitness obtained: 58.34% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 17b55cbd)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 17b55cbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6972, acc=49.53% (best=49.53%)\n",
      "          Fold 5 Epoch 1: loss=0.6902, acc=50.31% (best=50.31%)\n",
      "          Fold 3 Epoch 1: loss=0.6813, acc=46.72% (best=46.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6937, acc=56.25% (best=56.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6485, acc=49.30% (best=49.30%)\n",
      "          Fold 2 Epoch 5: loss=0.2975, acc=48.98% (best=58.98%)\n",
      "          Fold 3 Epoch 5: loss=0.3302, acc=45.39% (best=48.75%)\n",
      "          Fold 1 Epoch 5: loss=0.3062, acc=42.97% (best=56.25%)\n",
      "          Fold 5 Epoch 5: loss=0.2796, acc=53.75% (best=57.03%)\n",
      "          Fold 4 Epoch 5: loss=0.3175, acc=49.69% (best=51.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2407, acc=49.06% (best=58.98%)\n",
      "          Fold 3 Epoch 10: loss=0.2566, acc=53.44% (best=61.72%)\n",
      "          Fold 1 Epoch 10: loss=0.2436, acc=44.61% (best=56.25%)\n",
      "          Fold 5 Epoch 10: loss=0.2336, acc=51.25% (best=59.30%)\n",
      "          Fold 4 Epoch 10: loss=0.2452, acc=46.95% (best=53.20%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.25%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.98%\n",
      "          Fold 3 Epoch 15: loss=0.2328, acc=45.08% (best=61.72%)\n",
      "          Fold 5 Epoch 15: loss=0.2216, acc=50.62% (best=59.30%)\n",
      "          Fold 4 Epoch 15: loss=0.2195, acc=44.84% (best=53.20%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 59.30%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 61.72%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 53.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17b55cbd:\n",
      "        Fold accuracies: ['56.25%', '58.98%', '61.72%', '53.20%', '59.30%']\n",
      "        Average fitness: 57.89% Â± 2.92%\n",
      "        Best fold: Fold 3 with 61.72%\n",
      "      Fitness obtained: 57.89% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1136351f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 1136351f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7189, acc=59.61% (best=59.61%)\n",
      "          Fold 2 Epoch 1: loss=0.7218, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7250, acc=49.06% (best=49.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7324, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7262, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.7077, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.7060, acc=59.38% (best=59.61%)\n",
      "          Fold 3 Epoch 5: loss=0.7176, acc=62.58% (best=62.58%)\n",
      "          Fold 4 Epoch 5: loss=0.7008, acc=55.23% (best=55.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7162, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.6973, acc=53.28% (best=53.52%)\n",
      "          Fold 3 Epoch 10: loss=0.7142, acc=65.55% (best=67.11%)\n",
      "          Fold 1 Epoch 10: loss=0.7021, acc=60.70% (best=60.70%)\n",
      "          Fold 4 Epoch 10: loss=0.6879, acc=63.67% (best=63.75%)\n",
      "          Fold 5 Epoch 10: loss=0.7067, acc=50.00% (best=50.00%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 2 Epoch 15: loss=0.6976, acc=45.86% (best=56.64%)\n",
      "          Fold 3 Epoch 15: loss=0.7093, acc=57.27% (best=67.11%)\n",
      "          Fold 1 Epoch 15: loss=0.6971, acc=60.39% (best=62.27%)\n",
      "          Fold 4 Epoch 15: loss=0.6809, acc=63.75% (best=64.06%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 67.11%\n",
      "          Fold 2 Epoch 20: loss=0.6938, acc=49.06% (best=56.64%)\n",
      "          Fold 1 Epoch 20: loss=0.6901, acc=56.41% (best=63.59%)\n",
      "          Fold 4 Epoch 20: loss=0.6761, acc=56.41% (best=64.06%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 64.06%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 56.64%\n",
      "          Fold 1 Epoch 25: loss=0.6917, acc=56.56% (best=63.59%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1136351f:\n",
      "        Fold accuracies: ['63.59%', '56.64%', '67.11%', '64.06%', '50.00%']\n",
      "        Average fitness: 60.28% Â± 6.18%\n",
      "        Best fold: Fold 3 with 67.11%\n",
      "      Fitness obtained: 60.28% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 3e03bf6c)\n",
      "      Architecture: 4 conv + 8 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 3e03bf6c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7623, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7764, acc=49.22% (best=49.22%)\n",
      "          Fold 4 Epoch 1: loss=0.7098, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7524, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 1: loss=0.7712, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 5: loss=0.2730, acc=44.06% (best=53.59%)\n",
      "          Fold 5 Epoch 5: loss=0.6970, acc=50.39% (best=55.23%)\n",
      "          Fold 3 Epoch 5: loss=0.2830, acc=61.72% (best=61.72%)\n",
      "          Fold 4 Epoch 5: loss=0.2624, acc=48.52% (best=51.88%)\n",
      "          Fold 1 Epoch 5: loss=0.2550, acc=52.19% (best=54.77%)\n",
      "          Fold 2 Epoch 10: loss=0.2360, acc=48.75% (best=57.58%)\n",
      "          Fold 3 Epoch 10: loss=0.2379, acc=48.59% (best=61.72%)\n",
      "          Fold 4 Epoch 10: loss=0.2312, acc=46.02% (best=51.88%)\n",
      "          Fold 5 Epoch 10: loss=0.6947, acc=42.81% (best=55.23%)\n",
      "          Fold 1 Epoch 10: loss=0.2391, acc=51.72% (best=54.77%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 51.88%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.23%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 54.77%\n",
      "          Fold 2 Epoch 15: loss=0.2275, acc=55.08% (best=59.77%)\n",
      "          Fold 3 Epoch 15: loss=0.2338, acc=48.52% (best=61.72%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 61.72%\n",
      "          Fold 2 Epoch 20: loss=0.2243, acc=52.27% (best=59.77%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 59.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3e03bf6c:\n",
      "        Fold accuracies: ['54.77%', '59.77%', '61.72%', '51.88%', '55.23%']\n",
      "        Average fitness: 56.67% Â± 3.57%\n",
      "        Best fold: Fold 3 with 61.72%\n",
      "      Fitness obtained: 56.67% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 21dd2200)\n",
      "      Architecture: 21 conv + 2 fc, opt=sgd, lr=0.001\n",
      "      Training/Evaluating model 21dd2200 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 234, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 21dd2200:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 62.91% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 1b300487)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b300487 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7128, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 1: loss=0.7102, acc=39.22% (best=39.22%)\n",
      "          Fold 4 Epoch 1: loss=0.6855, acc=54.53% (best=54.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7188, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6896, acc=46.80% (best=46.80%)\n",
      "          Fold 3 Epoch 5: loss=0.5880, acc=44.45% (best=51.95%)\n",
      "          Fold 1 Epoch 5: loss=0.5232, acc=52.66% (best=52.66%)\n",
      "          Fold 4 Epoch 5: loss=0.5726, acc=28.98% (best=58.12%)\n",
      "          Fold 5 Epoch 5: loss=0.6136, acc=45.94% (best=53.28%)\n",
      "          Fold 2 Epoch 5: loss=0.5582, acc=43.28% (best=46.80%)\n",
      "          Fold 3 Epoch 10: loss=0.4152, acc=64.14% (best=64.14%)\n",
      "          Fold 1 Epoch 10: loss=0.4088, acc=47.97% (best=61.95%)\n",
      "          Fold 4 Epoch 10: loss=0.4182, acc=44.92% (best=58.12%)\n",
      "          Fold 5 Epoch 10: loss=0.4091, acc=39.14% (best=53.28%)\n",
      "          Fold 2 Epoch 10: loss=0.4077, acc=45.08% (best=55.94%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 58.12%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.28%\n",
      "          Fold 3 Epoch 15: loss=0.3225, acc=47.66% (best=64.14%)\n",
      "          Fold 1 Epoch 15: loss=0.3449, acc=69.06% (best=69.06%)\n",
      "          Fold 2 Epoch 15: loss=0.3441, acc=55.23% (best=55.94%)\n",
      "          Fold 3 Epoch 20: loss=0.2961, acc=41.41% (best=64.14%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 64.14%\n",
      "          Fold 1 Epoch 20: loss=0.3074, acc=63.28% (best=69.06%)\n",
      "          Fold 2 Epoch 20: loss=0.3082, acc=64.53% (best=64.53%)\n",
      "          Fold 1 Epoch 25: loss=0.2888, acc=66.25% (best=69.06%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 69.06%\n",
      "          Fold 2 Epoch 25: loss=0.2841, acc=55.78% (best=70.39%)\n",
      "          Fold 2 Epoch 30: loss=0.2666, acc=52.50% (best=70.39%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b300487:\n",
      "        Fold accuracies: ['69.06%', '70.39%', '64.14%', '58.12%', '53.28%']\n",
      "        Average fitness: 63.00% Â± 6.49%\n",
      "        Best fold: Fold 2 with 70.39%\n",
      "      New best fitness in this generation: 63.00%!\n",
      "      Fitness obtained: 63.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: e73fb53b)\n",
      "      Architecture: 23 conv + 2 fc, opt=sgd, lr=0.1\n",
      "      Training/Evaluating model e73fb53b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for e73fb53b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 91a5a7b6)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 91a5a7b6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5337, acc=53.20% (best=53.20%)\n",
      "          Fold 1 Epoch 1: loss=0.4822, acc=49.69% (best=49.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6377, acc=45.08% (best=45.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6358, acc=52.73% (best=52.73%)\n",
      "          Fold 4 Epoch 1: loss=0.5542, acc=50.94% (best=50.94%)\n",
      "          Fold 2 Epoch 5: loss=0.2483, acc=54.61% (best=58.91%)\n",
      "          Fold 1 Epoch 5: loss=0.2372, acc=57.42% (best=57.42%)\n",
      "          Fold 3 Epoch 5: loss=0.2806, acc=46.33% (best=53.59%)\n",
      "          Fold 5 Epoch 5: loss=0.2846, acc=52.27% (best=53.83%)\n",
      "          Fold 4 Epoch 5: loss=0.2606, acc=50.55% (best=53.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2225, acc=57.73% (best=60.78%)\n",
      "          Fold 3 Epoch 10: loss=0.2271, acc=50.62% (best=56.09%)\n",
      "          Fold 1 Epoch 10: loss=0.2144, acc=52.66% (best=61.48%)\n",
      "          Fold 5 Epoch 10: loss=0.2404, acc=54.77% (best=55.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2258, acc=52.81% (best=54.14%)\n",
      "          Fold 2 Epoch 15: loss=0.2045, acc=60.94% (best=66.88%)\n",
      "          Fold 3 Epoch 15: loss=0.2116, acc=55.31% (best=63.83%)\n",
      "          Fold 1 Epoch 15: loss=0.2057, acc=52.42% (best=62.50%)\n",
      "          Fold 4 Epoch 15: loss=0.2089, acc=50.94% (best=54.14%)\n",
      "          Fold 5 Epoch 15: loss=0.2190, acc=56.95% (best=60.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2057, acc=53.36% (best=66.88%)\n",
      "          Fold 3 Epoch 20: loss=0.2103, acc=59.92% (best=63.83%)\n",
      "          Fold 1 Epoch 20: loss=0.2045, acc=56.80% (best=62.50%)\n",
      "          Fold 4 Epoch 20: loss=0.2021, acc=49.61% (best=55.78%)\n",
      "          Fold 5 Epoch 20: loss=0.2078, acc=59.69% (best=60.23%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 63.83%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 66.88%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 62.50%\n",
      "          Fold 4 Epoch 25: loss=0.1977, acc=45.16% (best=55.78%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 55.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 91a5a7b6:\n",
      "        Fold accuracies: ['62.50%', '66.88%', '63.83%', '55.78%', '60.23%']\n",
      "        Average fitness: 61.84% Â± 3.72%\n",
      "        Best fold: Fold 2 with 66.88%\n",
      "      Fitness obtained: 61.84% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 04949042)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 04949042 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6602, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6283, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6873, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7024, acc=47.27% (best=47.27%)\n",
      "          Fold 5 Epoch 1: loss=0.6991, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.3017, acc=48.12% (best=54.53%)\n",
      "          Fold 3 Epoch 5: loss=0.3287, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 5: loss=0.3062, acc=44.92% (best=50.62%)\n",
      "          Fold 1 Epoch 5: loss=0.3017, acc=46.17% (best=56.88%)\n",
      "          Fold 5 Epoch 5: loss=0.2831, acc=60.31% (best=61.25%)\n",
      "          Fold 2 Epoch 10: loss=0.2424, acc=49.84% (best=54.53%)\n",
      "          Fold 3 Epoch 10: loss=0.2450, acc=49.53% (best=58.20%)\n",
      "          Fold 1 Epoch 10: loss=0.2390, acc=55.39% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2425, acc=50.86% (best=57.66%)\n",
      "          Fold 5 Epoch 10: loss=0.2356, acc=60.08% (best=61.88%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.88%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 54.53%\n",
      "          Fold 3 Epoch 15: loss=0.2191, acc=45.78% (best=58.20%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 58.20%\n",
      "          Fold 4 Epoch 15: loss=0.2256, acc=48.28% (best=57.66%)\n",
      "          Fold 5 Epoch 15: loss=0.2193, acc=58.83% (best=66.25%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 57.66%\n",
      "          Fold 5 Epoch 20: loss=0.2155, acc=52.42% (best=66.25%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 66.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 04949042:\n",
      "        Fold accuracies: ['56.88%', '54.53%', '58.20%', '57.66%', '66.25%']\n",
      "        Average fitness: 58.70% Â± 3.98%\n",
      "        Best fold: Fold 5 with 66.25%\n",
      "      Fitness obtained: 58.70% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 58367dab)\n",
      "      Architecture: 21 conv + 2 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 58367dab with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 58367dab:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 39f226f7)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 39f226f7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=55.00% (best=55.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7130, acc=43.52% (best=43.52%)\n",
      "          Fold 1 Epoch 1: loss=0.7394, acc=59.06% (best=59.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6914, acc=63.12% (best=63.12%)\n",
      "          Fold 5 Epoch 1: loss=0.7570, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.3978, acc=43.05% (best=53.44%)\n",
      "          Fold 3 Epoch 5: loss=0.4029, acc=58.98% (best=58.98%)\n",
      "          Fold 1 Epoch 5: loss=0.4322, acc=40.86% (best=63.67%)\n",
      "          Fold 4 Epoch 5: loss=0.3498, acc=56.33% (best=63.12%)\n",
      "          Fold 5 Epoch 5: loss=0.4168, acc=38.91% (best=52.34%)\n",
      "          Fold 2 Epoch 10: loss=0.2434, acc=52.42% (best=53.44%)\n",
      "          Fold 3 Epoch 10: loss=0.2548, acc=54.06% (best=60.47%)\n",
      "          Fold 1 Epoch 10: loss=0.2641, acc=54.69% (best=65.78%)\n",
      "          Fold 4 Epoch 10: loss=0.2349, acc=60.86% (best=63.12%)\n",
      "          Fold 5 Epoch 10: loss=0.2385, acc=42.19% (best=52.34%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.12%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 52.34%\n",
      "          Fold 2 Epoch 15: loss=0.2264, acc=56.09% (best=61.95%)\n",
      "          Fold 3 Epoch 15: loss=0.2346, acc=50.47% (best=60.47%)\n",
      "          Fold 1 Epoch 15: loss=0.2302, acc=65.39% (best=65.78%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 60.47%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 65.78%\n",
      "          Fold 2 Epoch 20: loss=0.2090, acc=53.20% (best=61.95%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 61.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 39f226f7:\n",
      "        Fold accuracies: ['65.78%', '61.95%', '60.47%', '63.12%', '52.34%']\n",
      "        Average fitness: 60.73% Â± 4.54%\n",
      "        Best fold: Fold 1 with 65.78%\n",
      "      Fitness obtained: 60.73% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: eafd56d7)\n",
      "      Architecture: 4 conv + 7 fc, opt=sgd, lr=0.001\n",
      "      Training/Evaluating model eafd56d7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7208, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7238, acc=46.95% (best=46.95%)\n",
      "          Fold 4 Epoch 1: loss=0.7133, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 1: loss=0.7184, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7369, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 5: loss=0.7042, acc=48.59% (best=49.61%)\n",
      "          Fold 2 Epoch 5: loss=0.7055, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 5: loss=0.6845, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 5: loss=0.7127, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7098, acc=51.33% (best=51.33%)\n",
      "          Fold 2 Epoch 10: loss=0.6977, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 10: loss=0.7018, acc=49.38% (best=52.27%)\n",
      "          Fold 4 Epoch 10: loss=0.6624, acc=49.14% (best=49.30%)\n",
      "          Fold 1 Epoch 10: loss=0.6972, acc=50.16% (best=50.23%)\n",
      "          Fold 5 Epoch 10: loss=0.7046, acc=44.61% (best=51.33%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.61%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 49.30%\n",
      "          Fold 3 Epoch 15: loss=0.7006, acc=54.38% (best=54.45%)\n",
      "          Fold 1 Epoch 15: loss=0.6777, acc=50.23% (best=50.23%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 50.23%\n",
      "          Fold 5 Epoch 15: loss=0.7019, acc=43.28% (best=51.33%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 51.33%\n",
      "          Fold 3 Epoch 20: loss=0.6968, acc=51.25% (best=54.45%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 54.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eafd56d7:\n",
      "        Fold accuracies: ['50.23%', '49.61%', '54.45%', '49.30%', '51.33%']\n",
      "        Average fitness: 50.98% Â± 1.87%\n",
      "        Best fold: Fold 3 with 54.45%\n",
      "      Fitness obtained: 50.98% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 1844dca2)\n",
      "      Architecture: 2 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 1844dca2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6981, acc=47.66% (best=47.66%)\n",
      "          Fold 2 Epoch 1: loss=0.6668, acc=43.91% (best=43.91%)\n",
      "          Fold 4 Epoch 1: loss=0.5960, acc=51.56% (best=51.56%)\n",
      "          Fold 1 Epoch 1: loss=0.6280, acc=55.08% (best=55.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7064, acc=51.41% (best=51.41%)\n",
      "          Fold 2 Epoch 5: loss=0.2795, acc=49.22% (best=52.19%)\n",
      "          Fold 3 Epoch 5: loss=0.3038, acc=45.31% (best=53.28%)\n",
      "          Fold 1 Epoch 5: loss=0.2871, acc=45.47% (best=55.08%)\n",
      "          Fold 4 Epoch 5: loss=0.2819, acc=53.83% (best=53.83%)\n",
      "          Fold 5 Epoch 5: loss=0.2864, acc=61.33% (best=61.33%)\n",
      "          Fold 3 Epoch 10: loss=0.2389, acc=51.41% (best=53.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2280, acc=45.23% (best=55.08%)\n",
      "          Fold 2 Epoch 10: loss=0.2284, acc=50.08% (best=55.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2324, acc=44.53% (best=54.14%)\n",
      "          Fold 5 Epoch 10: loss=0.2354, acc=57.73% (best=61.33%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 55.08%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 53.28%\n",
      "          Fold 2 Epoch 15: loss=0.2166, acc=58.12% (best=58.12%)\n",
      "          Fold 4 Epoch 15: loss=0.2156, acc=46.25% (best=54.14%)\n",
      "          Fold 5 Epoch 15: loss=0.2156, acc=49.45% (best=61.33%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 61.33%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 54.14%\n",
      "          Fold 2 Epoch 20: loss=0.2109, acc=52.89% (best=58.83%)\n",
      "          Fold 2 Epoch 25: loss=0.2039, acc=57.97% (best=58.83%)\n",
      "          Fold 2 Epoch 30: loss=0.2012, acc=58.12% (best=60.70%)\n",
      "          Fold 2 Epoch 35: loss=0.1960, acc=48.91% (best=60.86%)\n",
      "          Fold 2 Epoch 40: loss=0.1964, acc=55.55% (best=63.52%)\n",
      "          Fold 2 Epoch 45: loss=0.1946, acc=60.86% (best=66.72%)\n",
      "          Fold 2 Epoch 50: loss=0.1961, acc=55.62% (best=66.72%)\n",
      "          Fold 2: Early stopping at epoch 51\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1844dca2:\n",
      "        Fold accuracies: ['55.08%', '66.72%', '53.28%', '54.14%', '61.33%']\n",
      "        Average fitness: 58.11% Â± 5.15%\n",
      "        Best fold: Fold 2 with 66.72%\n",
      "      Fitness obtained: 58.11% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 92997b5d)\n",
      "      Architecture: 4 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 92997b5d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 92997b5d:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 51095bd1)\n",
      "      Architecture: 17 conv + 8 fc, opt=adamw, lr=0.001\n",
      "      Training/Evaluating model 51095bd1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 124, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 51095bd1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 77eb49c5)\n",
      "      Architecture: 2 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 77eb49c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7044, acc=62.27% (best=62.27%)\n",
      "          Fold 3 Epoch 1: loss=0.7253, acc=48.91% (best=48.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6790, acc=48.20% (best=48.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6967, acc=43.98% (best=43.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7119, acc=47.27% (best=47.27%)\n",
      "          Fold 2 Epoch 5: loss=0.5450, acc=51.56% (best=51.56%)\n",
      "          Fold 3 Epoch 5: loss=0.5916, acc=45.31% (best=56.64%)\n",
      "          Fold 4 Epoch 5: loss=0.5781, acc=64.77% (best=64.77%)\n",
      "          Fold 1 Epoch 5: loss=0.5671, acc=48.52% (best=48.52%)\n",
      "          Fold 5 Epoch 5: loss=0.5744, acc=58.67% (best=61.72%)\n",
      "          Fold 2 Epoch 10: loss=0.4416, acc=50.00% (best=51.56%)\n",
      "          Fold 3 Epoch 10: loss=0.4880, acc=42.73% (best=56.64%)\n",
      "          Fold 4 Epoch 10: loss=0.4873, acc=61.72% (best=65.70%)\n",
      "          Fold 1 Epoch 10: loss=0.4766, acc=49.77% (best=52.27%)\n",
      "          Fold 5 Epoch 10: loss=0.4689, acc=63.28% (best=65.78%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 56.64%\n",
      "          Fold 2 Epoch 15: loss=0.3684, acc=50.70% (best=51.56%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 51.56%\n",
      "          Fold 4 Epoch 15: loss=0.4072, acc=61.56% (best=66.02%)\n",
      "          Fold 1 Epoch 15: loss=0.4101, acc=52.11% (best=52.27%)\n",
      "          Fold 5 Epoch 15: loss=0.3980, acc=68.36% (best=68.98%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 52.27%\n",
      "          Fold 4 Epoch 20: loss=0.3533, acc=58.36% (best=66.02%)\n",
      "          Fold 5 Epoch 20: loss=0.3496, acc=63.67% (best=68.98%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 66.02%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 68.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 77eb49c5:\n",
      "        Fold accuracies: ['52.27%', '51.56%', '56.64%', '66.02%', '68.98%']\n",
      "        Average fitness: 59.09% Â± 7.14%\n",
      "        Best fold: Fold 5 with 68.98%\n",
      "      Fitness obtained: 59.09% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 6f36d22f)\n",
      "      Architecture: 28 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6f36d22f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6f36d22f:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 98081308)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 98081308 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 149, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7290, acc=47.73% (best=47.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7218, acc=48.98% (best=48.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7234, acc=64.06% (best=64.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7193, acc=50.78% (best=50.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7318, acc=57.11% (best=57.11%)\n",
      "          Fold 3 Epoch 5: loss=0.7148, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 5: loss=0.6961, acc=46.64% (best=50.78%)\n",
      "          Fold 1 Epoch 5: loss=0.7078, acc=62.50% (best=64.06%)\n",
      "          Fold 2 Epoch 5: loss=0.7073, acc=42.19% (best=47.73%)\n",
      "          Fold 5 Epoch 5: loss=0.7217, acc=54.77% (best=57.11%)\n",
      "          Fold 3 Epoch 10: loss=0.7088, acc=49.30% (best=49.30%)\n",
      "          Fold 4 Epoch 10: loss=0.6847, acc=64.92% (best=64.92%)\n",
      "          Fold 1 Epoch 10: loss=0.7026, acc=59.61% (best=64.06%)\n",
      "          Fold 2 Epoch 10: loss=0.6987, acc=38.28% (best=50.62%)\n",
      "          Fold 5 Epoch 10: loss=0.7155, acc=65.00% (best=65.00%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.06%\n",
      "          Fold 3 Epoch 15: loss=0.7067, acc=49.14% (best=52.03%)\n",
      "          Fold 4 Epoch 15: loss=0.6772, acc=62.58% (best=64.92%)\n",
      "          Fold 2 Epoch 15: loss=0.6890, acc=47.50% (best=50.62%)\n",
      "          Fold 5 Epoch 15: loss=0.7105, acc=59.14% (best=65.00%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 50.62%\n",
      "          Fold 3 Epoch 20: loss=0.7013, acc=48.91% (best=52.03%)\n",
      "          Fold 4 Epoch 20: loss=0.6705, acc=58.98% (best=64.92%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 64.92%\n",
      "          Fold 5 Epoch 20: loss=0.7058, acc=57.66% (best=65.00%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 98081308:\n",
      "        Fold accuracies: ['64.06%', '50.62%', '52.03%', '64.92%', '65.00%']\n",
      "        Average fitness: 59.33% Â± 6.56%\n",
      "        Best fold: Fold 5 with 65.00%\n",
      "      Fitness obtained: 59.33% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: c699c8dd)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model c699c8dd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6878, acc=41.88% (best=41.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7091, acc=61.88% (best=61.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6884, acc=61.41% (best=61.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6958, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 1: loss=0.7090, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 5: loss=0.5942, acc=44.77% (best=50.62%)\n",
      "          Fold 3 Epoch 5: loss=0.6480, acc=56.09% (best=61.88%)\n",
      "          Fold 4 Epoch 5: loss=0.5827, acc=46.64% (best=61.41%)\n",
      "          Fold 1 Epoch 5: loss=0.5990, acc=43.05% (best=59.45%)\n",
      "          Fold 5 Epoch 5: loss=0.6563, acc=63.91% (best=63.91%)\n",
      "          Fold 2 Epoch 10: loss=0.3821, acc=53.91% (best=57.27%)\n",
      "          Fold 3 Epoch 10: loss=0.4113, acc=52.19% (best=61.88%)\n",
      "          Fold 4 Epoch 10: loss=0.3833, acc=43.91% (best=61.41%)\n",
      "          Fold 1 Epoch 10: loss=0.4664, acc=50.39% (best=59.45%)\n",
      "          Fold 5 Epoch 10: loss=0.4547, acc=59.22% (best=63.91%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 61.88%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.41%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 2 Epoch 15: loss=0.3425, acc=51.17% (best=57.27%)\n",
      "          Fold 5 Epoch 15: loss=0.3563, acc=67.58% (best=72.81%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 57.27%\n",
      "          Fold 5 Epoch 20: loss=0.3142, acc=61.41% (best=72.81%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 72.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c699c8dd:\n",
      "        Fold accuracies: ['59.45%', '57.27%', '61.88%', '61.41%', '72.81%']\n",
      "        Average fitness: 62.56% Â± 5.38%\n",
      "        Best fold: Fold 5 with 72.81%\n",
      "      Fitness obtained: 62.56% | Best in generation: 63.00% | Global best: 65.08%\n",
      "\n",
      "GENERATION 1 STATISTICS:\n",
      "   Maximum fitness: 63.00%\n",
      "   Average fitness: 41.52%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 27.30%\n",
      "   Best individual: 1b300487 with 63.00%\n",
      "   Global best individual: e6bef0a6 with 65.08%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=27.30)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1b300487 (fitness: 63.00%)\n",
      "   Elite 2: e6bef0a6 (fitness: 62.91%)\n",
      "   Elite 3: c699c8dd (fitness: 62.56%)\n",
      "   Elite 4: 91a5a7b6 (fitness: 61.84%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 2\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 2)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1b300487)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b300487 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6906, acc=43.75% (best=43.75%)\n",
      "          Fold 3 Epoch 1: loss=0.7134, acc=40.55% (best=40.55%)\n",
      "          Fold 1 Epoch 1: loss=0.7097, acc=60.86% (best=60.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6930, acc=66.56% (best=66.56%)\n",
      "          Fold 5 Epoch 1: loss=0.7190, acc=57.19% (best=57.19%)\n",
      "          Fold 2 Epoch 5: loss=0.5656, acc=53.44% (best=53.98%)\n",
      "          Fold 5 Epoch 5: loss=0.5933, acc=67.73% (best=67.73%)\n",
      "          Fold 4 Epoch 5: loss=0.5384, acc=56.02% (best=68.83%)\n",
      "          Fold 1 Epoch 5: loss=0.5996, acc=51.41% (best=60.86%)\n",
      "          Fold 3 Epoch 5: loss=0.5787, acc=49.38% (best=55.31%)\n",
      "          Fold 2 Epoch 10: loss=0.3791, acc=34.06% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.4018, acc=60.94% (best=68.83%)\n",
      "          Fold 5 Epoch 10: loss=0.4676, acc=54.61% (best=67.73%)\n",
      "          Fold 1 Epoch 10: loss=0.4253, acc=53.05% (best=60.86%)\n",
      "          Fold 3 Epoch 10: loss=0.4262, acc=49.30% (best=55.31%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.86%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 2 Epoch 15: loss=0.3147, acc=49.53% (best=56.88%)\n",
      "          Fold 5 Epoch 15: loss=0.4060, acc=52.97% (best=67.73%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 67.73%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 56.88%\n",
      "          Fold 3 Epoch 15: loss=0.3559, acc=53.12% (best=58.67%)\n",
      "          Fold 3 Epoch 20: loss=0.3031, acc=44.22% (best=58.67%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 58.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b300487:\n",
      "        Fold accuracies: ['60.86%', '56.88%', '58.67%', '68.83%', '67.73%']\n",
      "        Average fitness: 62.59% Â± 4.82%\n",
      "        Best fold: Fold 4 with 68.83%\n",
      "      New best fitness in this generation: 62.59%!\n",
      "      Fitness obtained: 62.59% | Best in generation: 62.59% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: e6bef0a6)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model e6bef0a6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7063, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6855, acc=55.86% (best=55.86%)\n",
      "          Fold 2 Epoch 1: loss=0.6774, acc=50.62% (best=50.62%)\n",
      "          Fold 3 Epoch 1: loss=0.6785, acc=58.52% (best=58.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6648, acc=49.84% (best=49.84%)\n",
      "          Fold 2 Epoch 5: loss=0.3192, acc=43.83% (best=50.62%)\n",
      "          Fold 1 Epoch 5: loss=0.3048, acc=43.44% (best=55.86%)\n",
      "          Fold 5 Epoch 5: loss=0.3393, acc=33.05% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.3298, acc=54.53% (best=59.22%)\n",
      "          Fold 4 Epoch 5: loss=0.3102, acc=50.47% (best=58.20%)\n",
      "          Fold 2 Epoch 10: loss=0.2291, acc=45.16% (best=68.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2166, acc=48.05% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.2349, acc=43.20% (best=51.02%)\n",
      "          Fold 3 Epoch 10: loss=0.2330, acc=51.17% (best=59.22%)\n",
      "          Fold 4 Epoch 10: loss=0.2230, acc=46.88% (best=69.30%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 59.22%\n",
      "          Fold 2 Epoch 15: loss=0.2068, acc=54.22% (best=68.28%)\n",
      "          Fold 1 Epoch 15: loss=0.2037, acc=45.86% (best=65.23%)\n",
      "          Fold 5 Epoch 15: loss=0.2169, acc=33.75% (best=51.02%)\n",
      "          Fold 4 Epoch 15: loss=0.2029, acc=58.83% (best=69.30%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 51.02%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 68.28%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e6bef0a6:\n",
      "        Fold accuracies: ['65.23%', '68.28%', '59.22%', '69.30%', '51.02%']\n",
      "        Average fitness: 62.61% Â± 6.78%\n",
      "        Best fold: Fold 4 with 69.30%\n",
      "      New best fitness in this generation: 62.61%!\n",
      "      Fitness obtained: 62.61% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: c699c8dd)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model c699c8dd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7040, acc=52.50% (best=52.50%)\n",
      "          Fold 2 Epoch 1: loss=0.6955, acc=46.95% (best=46.95%)\n",
      "          Fold 3 Epoch 1: loss=0.7012, acc=50.70% (best=50.70%)\n",
      "          Fold 4 Epoch 1: loss=0.6795, acc=46.09% (best=46.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6986, acc=62.11% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.6514, acc=47.19% (best=52.50%)\n",
      "          Fold 2 Epoch 5: loss=0.5877, acc=49.06% (best=52.19%)\n",
      "          Fold 3 Epoch 5: loss=0.5998, acc=55.08% (best=62.81%)\n",
      "          Fold 4 Epoch 5: loss=0.5643, acc=54.06% (best=56.17%)\n",
      "          Fold 1 Epoch 5: loss=0.5981, acc=44.45% (best=62.11%)\n",
      "          Fold 2 Epoch 10: loss=0.3921, acc=52.42% (best=52.42%)\n",
      "          Fold 5 Epoch 10: loss=0.3920, acc=51.56% (best=53.59%)\n",
      "          Fold 3 Epoch 10: loss=0.4336, acc=56.33% (best=65.31%)\n",
      "          Fold 4 Epoch 10: loss=0.3982, acc=56.02% (best=56.17%)\n",
      "          Fold 1 Epoch 10: loss=0.4376, acc=52.34% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 2 Epoch 15: loss=0.3514, acc=48.05% (best=52.42%)\n",
      "          Fold 3 Epoch 15: loss=0.3792, acc=49.84% (best=65.31%)\n",
      "          Fold 5 Epoch 15: loss=0.3157, acc=55.94% (best=56.02%)\n",
      "          Fold 4 Epoch 15: loss=0.3329, acc=45.31% (best=60.23%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.31%\n",
      "          Fold 2 Epoch 20: loss=0.3120, acc=53.52% (best=53.52%)\n",
      "          Fold 5 Epoch 20: loss=0.2803, acc=57.03% (best=57.03%)\n",
      "          Fold 4 Epoch 20: loss=0.3109, acc=54.14% (best=60.23%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 60.23%\n",
      "          Fold 2 Epoch 25: loss=0.2894, acc=43.75% (best=53.52%)\n",
      "          Fold 5 Epoch 25: loss=0.2673, acc=49.14% (best=57.03%)\n",
      "          Fold 2 Epoch 30: loss=0.2799, acc=57.73% (best=57.73%)\n",
      "          Fold 5 Epoch 30: loss=0.2476, acc=39.53% (best=57.03%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 2 Epoch 35: loss=0.2662, acc=43.67% (best=57.73%)\n",
      "          Fold 2 Epoch 40: loss=0.2596, acc=61.41% (best=61.41%)\n",
      "          Fold 2 Epoch 45: loss=0.2495, acc=58.20% (best=61.41%)\n",
      "          Fold 2 Epoch 50: loss=0.2439, acc=54.30% (best=61.41%)\n",
      "          Fold 2: Early stopping at epoch 50\n",
      "      â†’ Fold 2 completed: 61.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c699c8dd:\n",
      "        Fold accuracies: ['62.11%', '61.41%', '65.31%', '60.23%', '57.03%']\n",
      "        Average fitness: 61.22% Â± 2.69%\n",
      "        Best fold: Fold 3 with 65.31%\n",
      "      Fitness obtained: 61.22% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 91a5a7b6)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 91a5a7b6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.5512, acc=44.06% (best=44.06%)\n",
      "          Fold 1 Epoch 1: loss=0.5787, acc=52.58% (best=52.58%)\n",
      "          Fold 2 Epoch 1: loss=0.4858, acc=47.81% (best=47.81%)\n",
      "          Fold 5 Epoch 1: loss=0.6167, acc=48.20% (best=48.20%)\n",
      "          Fold 4 Epoch 1: loss=0.5833, acc=46.72% (best=46.72%)\n",
      "          Fold 2 Epoch 5: loss=0.2343, acc=54.92% (best=57.50%)\n",
      "          Fold 3 Epoch 5: loss=0.2535, acc=49.38% (best=49.38%)\n",
      "          Fold 1 Epoch 5: loss=0.2726, acc=50.62% (best=55.55%)\n",
      "          Fold 5 Epoch 5: loss=0.2571, acc=45.08% (best=55.47%)\n",
      "          Fold 4 Epoch 5: loss=0.2480, acc=43.44% (best=46.72%)\n",
      "          Fold 2 Epoch 10: loss=0.2123, acc=56.64% (best=62.66%)\n",
      "          Fold 3 Epoch 10: loss=0.2232, acc=41.41% (best=49.38%)\n",
      "          Fold 1 Epoch 10: loss=0.2295, acc=50.86% (best=55.55%)\n",
      "          Fold 4 Epoch 10: loss=0.2152, acc=49.45% (best=57.03%)\n",
      "          Fold 5 Epoch 10: loss=0.2169, acc=53.91% (best=58.67%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 55.55%\n",
      "          Fold 2 Epoch 15: loss=0.2035, acc=51.56% (best=62.66%)\n",
      "          Fold 3 Epoch 15: loss=0.2156, acc=48.91% (best=50.39%)\n",
      "          Fold 4 Epoch 15: loss=0.1995, acc=49.22% (best=57.03%)\n",
      "          Fold 5 Epoch 15: loss=0.2111, acc=51.41% (best=58.67%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 57.03%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 62.66%\n",
      "          Fold 3 Epoch 20: loss=0.2048, acc=45.00% (best=50.39%)\n",
      "          Fold 5 Epoch 20: loss=0.2033, acc=52.58% (best=61.72%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 50.39%\n",
      "          Fold 5 Epoch 25: loss=0.2004, acc=57.42% (best=64.77%)\n",
      "          Fold 5 Epoch 30: loss=0.2027, acc=54.53% (best=64.77%)\n",
      "          Fold 5: Early stopping at epoch 33\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 91a5a7b6:\n",
      "        Fold accuracies: ['55.55%', '62.66%', '50.39%', '57.03%', '64.77%']\n",
      "        Average fitness: 58.08% Â± 5.14%\n",
      "        Best fold: Fold 5 with 64.77%\n",
      "      Fitness obtained: 58.08% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: fbc11e9f)\n",
      "      Architecture: 10 conv + 4 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model fbc11e9f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7677, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7391, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 1: loss=0.7223, acc=48.98% (best=48.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7201, acc=61.64% (best=61.64%)\n",
      "          Fold 5 Epoch 1: loss=0.7561, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.7394, acc=53.75% (best=53.75%)\n",
      "          Fold 3 Epoch 5: loss=0.7647, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 5: loss=0.7197, acc=48.67% (best=49.53%)\n",
      "          Fold 1 Epoch 5: loss=0.7200, acc=58.98% (best=61.64%)\n",
      "          Fold 5 Epoch 5: loss=0.7463, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.7388, acc=53.75% (best=53.83%)\n",
      "          Fold 3 Epoch 10: loss=0.7617, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 10: loss=0.7155, acc=48.67% (best=50.78%)\n",
      "          Fold 1 Epoch 10: loss=0.7206, acc=59.14% (best=63.98%)\n",
      "          Fold 5 Epoch 10: loss=0.7475, acc=50.00% (best=50.00%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 48.98%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 2 Epoch 15: loss=0.7395, acc=50.78% (best=59.38%)\n",
      "          Fold 4 Epoch 15: loss=0.7158, acc=50.16% (best=50.78%)\n",
      "          Fold 1 Epoch 15: loss=0.7160, acc=58.83% (best=63.98%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 50.78%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 63.98%\n",
      "          Fold 2 Epoch 20: loss=0.7341, acc=50.55% (best=59.38%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 59.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fbc11e9f:\n",
      "        Fold accuracies: ['63.98%', '59.38%', '48.98%', '50.78%', '50.00%']\n",
      "        Average fitness: 54.62% Â± 5.97%\n",
      "        Best fold: Fold 1 with 63.98%\n",
      "      Fitness obtained: 54.62% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 826c01aa)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 826c01aa with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7867, acc=63.28% (best=63.28%)\n",
      "          Fold 4 Epoch 1: loss=0.7371, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7434, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7128, acc=50.94% (best=50.94%)\n",
      "          Fold 5 Epoch 1: loss=0.7217, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 5: loss=0.7432, acc=52.42% (best=63.28%)\n",
      "          Fold 4 Epoch 5: loss=0.7007, acc=58.36% (best=58.36%)\n",
      "          Fold 1 Epoch 5: loss=0.7050, acc=47.81% (best=56.95%)\n",
      "          Fold 2 Epoch 5: loss=0.7160, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 5: loss=0.7146, acc=48.36% (best=50.47%)\n",
      "          Fold 3 Epoch 10: loss=0.7241, acc=50.00% (best=63.28%)\n",
      "          Fold 4 Epoch 10: loss=0.6870, acc=55.55% (best=58.67%)\n",
      "          Fold 1 Epoch 10: loss=0.6967, acc=64.69% (best=66.25%)\n",
      "          Fold 2 Epoch 10: loss=0.7002, acc=44.22% (best=50.39%)\n",
      "          Fold 5 Epoch 10: loss=0.7122, acc=41.25% (best=50.47%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 63.28%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.39%\n",
      "          Fold 4 Epoch 15: loss=0.6760, acc=52.66% (best=58.67%)\n",
      "          Fold 1 Epoch 15: loss=0.6937, acc=67.97% (best=67.97%)\n",
      "          Fold 5 Epoch 15: loss=0.7060, acc=54.38% (best=54.38%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 58.67%\n",
      "          Fold 1 Epoch 20: loss=0.6927, acc=67.34% (best=67.97%)\n",
      "          Fold 5 Epoch 20: loss=0.7055, acc=46.80% (best=57.89%)\n",
      "          Fold 1 Epoch 25: loss=0.6911, acc=67.11% (best=67.97%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 67.97%\n",
      "          Fold 5 Epoch 25: loss=0.7049, acc=53.83% (best=57.89%)\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 826c01aa:\n",
      "        Fold accuracies: ['67.97%', '50.39%', '63.28%', '58.67%', '57.89%']\n",
      "        Average fitness: 59.64% Â± 5.87%\n",
      "        Best fold: Fold 1 with 67.97%\n",
      "      Fitness obtained: 59.64% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 5ecf8b0e)\n",
      "      Architecture: 21 conv + 2 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 5ecf8b0e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 69, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 5ecf8b0e:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 62.61% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 2a2ee145)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 2a2ee145 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7063, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6811, acc=43.20% (best=43.20%)\n",
      "          Fold 3 Epoch 1: loss=0.6893, acc=52.42% (best=52.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6716, acc=64.38% (best=64.38%)\n",
      "          Fold 1 Epoch 1: loss=0.6919, acc=57.50% (best=57.50%)\n",
      "          Fold 5 Epoch 5: loss=0.6301, acc=44.77% (best=57.89%)\n",
      "          Fold 2 Epoch 5: loss=0.5636, acc=35.55% (best=43.83%)\n",
      "          Fold 3 Epoch 5: loss=0.5187, acc=53.91% (best=60.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6563, acc=53.05% (best=57.50%)\n",
      "          Fold 4 Epoch 5: loss=0.5858, acc=49.61% (best=64.38%)\n",
      "          Fold 5 Epoch 10: loss=0.4383, acc=48.91% (best=57.89%)\n",
      "          Fold 2 Epoch 10: loss=0.3837, acc=44.06% (best=53.75%)\n",
      "          Fold 3 Epoch 10: loss=0.3742, acc=55.70% (best=64.77%)\n",
      "          Fold 4 Epoch 10: loss=0.4836, acc=43.67% (best=64.38%)\n",
      "          Fold 1 Epoch 10: loss=0.5811, acc=49.84% (best=57.50%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.38%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "          Fold 2 Epoch 15: loss=0.3079, acc=45.31% (best=53.75%)\n",
      "          Fold 3 Epoch 15: loss=0.3389, acc=61.72% (best=69.69%)\n",
      "          Fold 1 Epoch 15: loss=0.4230, acc=49.77% (best=62.11%)\n",
      "          Fold 2 Epoch 20: loss=0.2873, acc=44.38% (best=54.84%)\n",
      "          Fold 3 Epoch 20: loss=0.2969, acc=52.34% (best=69.69%)\n",
      "          Fold 1 Epoch 20: loss=0.3229, acc=55.23% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 69.69%\n",
      "          Fold 2 Epoch 25: loss=0.2792, acc=51.41% (best=54.84%)\n",
      "          Fold 2 Epoch 30: loss=0.2572, acc=43.91% (best=60.78%)\n",
      "          Fold 2 Epoch 35: loss=0.2488, acc=55.08% (best=60.78%)\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 60.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2a2ee145:\n",
      "        Fold accuracies: ['62.11%', '60.78%', '69.69%', '64.38%', '57.89%']\n",
      "        Average fitness: 62.97% Â± 3.96%\n",
      "        Best fold: Fold 3 with 69.69%\n",
      "      New best fitness in this generation: 62.97%!\n",
      "      Fitness obtained: 62.97% | Best in generation: 62.97% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: f82a1828)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f82a1828 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7019, acc=48.44% (best=48.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6512, acc=60.31% (best=60.31%)\n",
      "          Fold 4 Epoch 1: loss=0.6447, acc=50.62% (best=50.62%)\n",
      "          Fold 3 Epoch 1: loss=0.6681, acc=47.19% (best=47.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6730, acc=50.00% (best=50.00%)\n",
      "          Fold 5 Epoch 5: loss=0.4108, acc=36.17% (best=50.78%)\n",
      "          Fold 2 Epoch 5: loss=0.3348, acc=52.73% (best=63.20%)\n",
      "          Fold 4 Epoch 5: loss=0.3247, acc=52.58% (best=59.53%)\n",
      "          Fold 3 Epoch 5: loss=0.3783, acc=53.67% (best=53.98%)\n",
      "          Fold 1 Epoch 5: loss=0.3522, acc=63.36% (best=64.45%)\n",
      "          Fold 2 Epoch 10: loss=0.2554, acc=58.28% (best=63.20%)\n",
      "          Fold 5 Epoch 10: loss=0.3130, acc=55.00% (best=55.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2491, acc=56.09% (best=62.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2811, acc=43.91% (best=63.52%)\n",
      "          Fold 1 Epoch 10: loss=0.2591, acc=62.58% (best=64.45%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 63.20%\n",
      "          Fold 5 Epoch 15: loss=0.2645, acc=42.81% (best=58.12%)\n",
      "          Fold 4 Epoch 15: loss=0.2244, acc=49.84% (best=62.97%)\n",
      "          Fold 3 Epoch 15: loss=0.2434, acc=61.80% (best=63.52%)\n",
      "          Fold 1 Epoch 15: loss=0.2352, acc=58.59% (best=69.22%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 63.52%\n",
      "          Fold 5 Epoch 20: loss=0.2356, acc=51.64% (best=58.12%)\n",
      "          Fold 1 Epoch 20: loss=0.2222, acc=59.14% (best=69.22%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 58.12%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f82a1828:\n",
      "        Fold accuracies: ['69.22%', '63.20%', '63.52%', '62.97%', '58.12%']\n",
      "        Average fitness: 63.41% Â± 3.52%\n",
      "        Best fold: Fold 1 with 69.22%\n",
      "      New best fitness in this generation: 63.41%!\n",
      "      Fitness obtained: 63.41% | Best in generation: 63.41% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 739a9f48)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 739a9f48 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6731, acc=47.42% (best=47.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6549, acc=60.39% (best=60.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6554, acc=47.19% (best=47.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6839, acc=62.81% (best=62.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7083, acc=42.34% (best=42.34%)\n",
      "          Fold 2 Epoch 5: loss=0.3243, acc=47.97% (best=50.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3298, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3039, acc=66.25% (best=66.25%)\n",
      "          Fold 1 Epoch 5: loss=0.4524, acc=47.81% (best=62.81%)\n",
      "          Fold 5 Epoch 5: loss=0.3491, acc=43.44% (best=47.34%)\n",
      "          Fold 3 Epoch 10: loss=0.2426, acc=59.69% (best=59.69%)\n",
      "          Fold 4 Epoch 10: loss=0.2355, acc=45.16% (best=66.25%)\n",
      "          Fold 2 Epoch 10: loss=0.2460, acc=44.69% (best=50.62%)\n",
      "          Fold 1 Epoch 10: loss=0.2908, acc=50.16% (best=62.81%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.81%\n",
      "          Fold 5 Epoch 10: loss=0.2563, acc=41.88% (best=52.34%)\n",
      "          Fold 3 Epoch 15: loss=0.2306, acc=63.83% (best=63.83%)\n",
      "          Fold 4 Epoch 15: loss=0.2272, acc=56.64% (best=66.25%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.25%\n",
      "          Fold 2 Epoch 15: loss=0.2271, acc=55.70% (best=55.70%)\n",
      "          Fold 5 Epoch 15: loss=0.2287, acc=51.88% (best=52.34%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 52.34%\n",
      "          Fold 3 Epoch 20: loss=0.2322, acc=55.62% (best=63.83%)\n",
      "          Fold 2 Epoch 20: loss=0.2168, acc=53.20% (best=58.05%)\n",
      "          Fold 3 Epoch 25: loss=0.2175, acc=49.69% (best=63.83%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 63.83%\n",
      "          Fold 2 Epoch 25: loss=0.2096, acc=46.88% (best=63.28%)\n",
      "          Fold 2 Epoch 30: loss=0.2131, acc=55.08% (best=63.28%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 63.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 739a9f48:\n",
      "        Fold accuracies: ['62.81%', '63.28%', '63.83%', '66.25%', '52.34%']\n",
      "        Average fitness: 61.70% Â± 4.83%\n",
      "        Best fold: Fold 4 with 66.25%\n",
      "      Fitness obtained: 61.70% | Best in generation: 63.41% | Global best: 65.08%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 58e30ee6)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 58e30ee6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6899, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 1: loss=0.6815, acc=44.61% (best=44.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6903, acc=58.12% (best=58.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6720, acc=65.08% (best=65.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7027, acc=52.11% (best=52.11%)\n",
      "          Fold 2 Epoch 5: loss=0.5081, acc=71.33% (best=71.33%)\n",
      "          Fold 1 Epoch 5: loss=0.5633, acc=56.56% (best=66.17%)\n",
      "          Fold 3 Epoch 5: loss=0.4570, acc=61.41% (best=61.41%)\n",
      "          Fold 4 Epoch 5: loss=0.4923, acc=50.39% (best=65.08%)\n",
      "          Fold 5 Epoch 5: loss=0.6921, acc=53.52% (best=57.50%)\n",
      "          Fold 2 Epoch 10: loss=0.3153, acc=61.95% (best=71.33%)\n",
      "          Fold 1 Epoch 10: loss=0.3823, acc=41.95% (best=71.48%)\n",
      "          Fold 3 Epoch 10: loss=0.3364, acc=49.84% (best=61.95%)\n",
      "          Fold 4 Epoch 10: loss=0.3452, acc=48.28% (best=65.08%)\n",
      "          Fold 5 Epoch 10: loss=0.4288, acc=48.83% (best=57.50%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.08%\n",
      "          Fold 2 Epoch 15: loss=0.2668, acc=56.56% (best=71.33%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 71.33%\n",
      "          Fold 3 Epoch 15: loss=0.2843, acc=55.78% (best=61.95%)\n",
      "          Fold 1 Epoch 15: loss=0.3023, acc=67.03% (best=71.48%)\n",
      "          Fold 5 Epoch 15: loss=0.3194, acc=51.33% (best=62.19%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 71.48%\n",
      "          Fold 3 Epoch 20: loss=0.2641, acc=60.86% (best=63.36%)\n",
      "          Fold 5 Epoch 20: loss=0.2777, acc=50.70% (best=62.19%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 3 Epoch 25: loss=0.2494, acc=55.70% (best=63.36%)\n",
      "          Fold 3 Epoch 30: loss=0.2347, acc=62.27% (best=63.67%)\n",
      "          Fold 3 Epoch 35: loss=0.2228, acc=53.05% (best=63.67%)\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 63.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 58e30ee6:\n",
      "        Fold accuracies: ['71.48%', '71.33%', '63.67%', '65.08%', '62.19%']\n",
      "        Average fitness: 66.75% Â± 3.91%\n",
      "        Best fold: Fold 1 with 71.48%\n",
      "      New best fitness in this generation: 66.75%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 66.75% > 65.08%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen0_ide6bef0a6_fitness65.08.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen2_id58e30ee6_fitness66.75.pth\n",
      "        Fitness: 66.75%, ID: 58e30ee6, Gen: 2\n",
      "      Fitness obtained: 66.75% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: e258cf63)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model e258cf63 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7289, acc=49.45% (best=49.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7315, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 1: loss=0.7312, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7324, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7051, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 5: loss=0.7019, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 5: loss=0.7037, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 5: loss=0.6072, acc=49.30% (best=49.30%)\n",
      "          Fold 3 Epoch 5: loss=0.7044, acc=50.78% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.7012, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 10: loss=0.6716, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 10: loss=0.6288, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 10: loss=0.5102, acc=49.45% (best=52.58%)\n",
      "          Fold 3 Epoch 10: loss=0.6880, acc=48.98% (best=51.02%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 2 Epoch 10: loss=0.6948, acc=50.55% (best=50.55%)\n",
      "          Fold 1 Epoch 15: loss=0.5179, acc=49.45% (best=53.05%)\n",
      "          Fold 5 Epoch 15: loss=0.6225, acc=50.86% (best=51.02%)\n",
      "          Fold 4 Epoch 15: loss=0.4745, acc=49.69% (best=52.58%)\n",
      "          Fold 2 Epoch 15: loss=0.5399, acc=50.31% (best=55.94%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 52.58%\n",
      "          Fold 1 Epoch 20: loss=0.4628, acc=50.23% (best=53.05%)\n",
      "          Fold 5 Epoch 20: loss=0.5282, acc=50.31% (best=51.56%)\n",
      "          Fold 2 Epoch 20: loss=0.4343, acc=52.58% (best=55.94%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 53.05%\n",
      "          Fold 5 Epoch 25: loss=0.4057, acc=50.23% (best=51.56%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 55.94%\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 51.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e258cf63:\n",
      "        Fold accuracies: ['53.05%', '55.94%', '51.02%', '52.58%', '51.56%']\n",
      "        Average fitness: 52.83% Â± 1.71%\n",
      "        Best fold: Fold 2 with 55.94%\n",
      "      Fitness obtained: 52.83% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 62469ea1)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 62469ea1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7195, acc=64.06% (best=64.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7446, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7172, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.7766, acc=48.52% (best=48.52%)\n",
      "          Fold 1 Epoch 1: loss=0.7352, acc=53.44% (best=53.44%)\n",
      "          Fold 3 Epoch 5: loss=0.7124, acc=55.08% (best=64.06%)\n",
      "          Fold 5 Epoch 5: loss=0.7125, acc=52.42% (best=55.47%)\n",
      "          Fold 4 Epoch 5: loss=0.6948, acc=53.75% (best=55.16%)\n",
      "          Fold 1 Epoch 5: loss=0.7066, acc=54.84% (best=57.19%)\n",
      "          Fold 2 Epoch 5: loss=0.7112, acc=50.39% (best=53.44%)\n",
      "          Fold 3 Epoch 10: loss=0.7082, acc=54.77% (best=64.06%)\n",
      "          Fold 4 Epoch 10: loss=0.6822, acc=59.69% (best=59.69%)\n",
      "          Fold 5 Epoch 10: loss=0.7108, acc=50.08% (best=61.72%)\n",
      "          Fold 1 Epoch 10: loss=0.6994, acc=58.83% (best=61.09%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 2 Epoch 10: loss=0.6998, acc=37.97% (best=53.44%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 53.44%\n",
      "          Fold 4 Epoch 15: loss=0.6797, acc=58.36% (best=59.69%)\n",
      "          Fold 5 Epoch 15: loss=0.7040, acc=51.48% (best=61.72%)\n",
      "          Fold 1 Epoch 15: loss=0.6950, acc=56.56% (best=61.09%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 61.09%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 61.72%\n",
      "          Fold 4 Epoch 20: loss=0.6700, acc=58.75% (best=59.69%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 59.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 62469ea1:\n",
      "        Fold accuracies: ['61.09%', '53.44%', '64.06%', '59.69%', '61.72%']\n",
      "        Average fitness: 60.00% Â± 3.57%\n",
      "        Best fold: Fold 3 with 64.06%\n",
      "      Fitness obtained: 60.00% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 9fcd1a6a)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 9fcd1a6a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6637, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6505, acc=42.66% (best=42.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6785, acc=56.48% (best=56.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6263, acc=46.25% (best=46.25%)\n",
      "          Fold 5 Epoch 1: loss=0.6811, acc=61.64% (best=61.64%)\n",
      "          Fold 3 Epoch 5: loss=0.3385, acc=49.38% (best=65.86%)\n",
      "          Fold 2 Epoch 5: loss=0.3250, acc=40.70% (best=53.91%)\n",
      "          Fold 1 Epoch 5: loss=0.4246, acc=50.55% (best=60.62%)\n",
      "          Fold 4 Epoch 5: loss=0.3235, acc=53.75% (best=53.75%)\n",
      "          Fold 5 Epoch 5: loss=0.3719, acc=58.20% (best=64.84%)\n",
      "          Fold 2 Epoch 10: loss=0.2443, acc=52.89% (best=55.55%)\n",
      "          Fold 3 Epoch 10: loss=0.2727, acc=56.25% (best=65.86%)\n",
      "          Fold 1 Epoch 10: loss=0.2914, acc=60.78% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.2416, acc=41.64% (best=57.42%)\n",
      "          Fold 5 Epoch 10: loss=0.2808, acc=50.16% (best=64.84%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 65.86%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 64.84%\n",
      "          Fold 2 Epoch 15: loss=0.2225, acc=55.16% (best=60.08%)\n",
      "          Fold 1 Epoch 15: loss=0.2517, acc=62.19% (best=63.59%)\n",
      "          Fold 4 Epoch 15: loss=0.2216, acc=51.09% (best=57.42%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 57.42%\n",
      "          Fold 2 Epoch 20: loss=0.2128, acc=53.91% (best=60.39%)\n",
      "          Fold 1 Epoch 20: loss=0.2314, acc=58.20% (best=66.33%)\n",
      "          Fold 2 Epoch 25: loss=0.2078, acc=59.06% (best=60.39%)\n",
      "          Fold 1 Epoch 25: loss=0.2166, acc=63.75% (best=68.36%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 60.39%\n",
      "          Fold 1 Epoch 30: loss=0.2120, acc=78.52% (best=78.52%)\n",
      "          Fold 1 Epoch 35: loss=0.2065, acc=65.31% (best=78.52%)\n",
      "          Fold 1 Epoch 40: loss=0.2055, acc=68.59% (best=78.52%)\n",
      "          Fold 1: Early stopping at epoch 40\n",
      "      â†’ Fold 1 completed: 78.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fcd1a6a:\n",
      "        Fold accuracies: ['78.52%', '60.39%', '65.86%', '57.42%', '64.84%']\n",
      "        Average fitness: 65.41% Â± 7.23%\n",
      "        Best fold: Fold 1 with 78.52%\n",
      "      Fitness obtained: 65.41% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 17ad26d1)\n",
      "      Architecture: 2 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 17ad26d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.5291, acc=47.81% (best=47.81%)\n",
      "          Fold 1 Epoch 1: loss=0.5751, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6520, acc=52.42% (best=52.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6585, acc=46.64% (best=46.64%)\n",
      "          Fold 5 Epoch 1: loss=0.7004, acc=49.45% (best=49.45%)\n",
      "          Fold 2 Epoch 5: loss=0.2559, acc=45.08% (best=53.44%)\n",
      "          Fold 3 Epoch 5: loss=0.2652, acc=51.17% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.2616, acc=45.23% (best=47.81%)\n",
      "          Fold 1 Epoch 5: loss=0.2621, acc=49.45% (best=53.05%)\n",
      "          Fold 5 Epoch 5: loss=0.2571, acc=53.83% (best=55.31%)\n",
      "          Fold 2 Epoch 10: loss=0.2209, acc=51.95% (best=53.44%)\n",
      "          Fold 3 Epoch 10: loss=0.2217, acc=54.45% (best=59.30%)\n",
      "          Fold 4 Epoch 10: loss=0.2231, acc=42.73% (best=47.81%)\n",
      "          Fold 1 Epoch 10: loss=0.2221, acc=51.95% (best=53.05%)\n",
      "          Fold 5 Epoch 10: loss=0.2179, acc=53.12% (best=55.70%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 47.81%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 53.05%\n",
      "          Fold 2 Epoch 15: loss=0.2108, acc=49.30% (best=54.30%)\n",
      "          Fold 3 Epoch 15: loss=0.2086, acc=52.27% (best=60.16%)\n",
      "          Fold 5 Epoch 15: loss=0.2068, acc=48.98% (best=57.11%)\n",
      "          Fold 2 Epoch 20: loss=0.2081, acc=58.12% (best=58.12%)\n",
      "          Fold 3 Epoch 20: loss=0.2021, acc=58.44% (best=60.16%)\n",
      "          Fold 5 Epoch 20: loss=0.2036, acc=52.89% (best=57.11%)\n",
      "          Fold 2 Epoch 25: loss=0.2064, acc=47.42% (best=58.12%)\n",
      "          Fold 3 Epoch 25: loss=0.2018, acc=64.22% (best=64.22%)\n",
      "          Fold 5 Epoch 25: loss=0.1978, acc=55.08% (best=57.66%)\n",
      "          Fold 2 Epoch 30: loss=0.2025, acc=48.83% (best=58.12%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 58.12%\n",
      "          Fold 3 Epoch 30: loss=0.2009, acc=60.00% (best=64.22%)\n",
      "          Fold 5 Epoch 30: loss=0.1979, acc=48.20% (best=57.66%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 3 Epoch 35: loss=0.1996, acc=58.75% (best=64.22%)\n",
      "          Fold 3: Early stopping at epoch 35\n",
      "      â†’ Fold 3 completed: 64.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17ad26d1:\n",
      "        Fold accuracies: ['53.05%', '58.12%', '64.22%', '47.81%', '57.66%']\n",
      "        Average fitness: 56.17% Â± 5.48%\n",
      "        Best fold: Fold 3 with 64.22%\n",
      "      Fitness obtained: 56.17% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 7d36950e)\n",
      "      Architecture: 2 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7d36950e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7043, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6978, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7041, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.7051, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6300, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.3420, acc=59.14% (best=59.14%)\n",
      "          Fold 3 Epoch 5: loss=0.4386, acc=47.34% (best=52.03%)\n",
      "          Fold 1 Epoch 5: loss=0.3548, acc=51.64% (best=51.72%)\n",
      "          Fold 5 Epoch 5: loss=0.3762, acc=60.08% (best=65.94%)\n",
      "          Fold 4 Epoch 5: loss=0.3273, acc=46.41% (best=50.78%)\n",
      "          Fold 1 Epoch 10: loss=0.2690, acc=43.52% (best=51.72%)\n",
      "          Fold 3 Epoch 10: loss=0.3032, acc=50.39% (best=53.52%)\n",
      "          Fold 5 Epoch 10: loss=0.2712, acc=55.08% (best=65.94%)\n",
      "          Fold 2 Epoch 10: loss=0.2850, acc=53.44% (best=59.14%)\n",
      "          Fold 4 Epoch 10: loss=0.2738, acc=50.16% (best=50.78%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 51.72%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 50.78%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "          Fold 3 Epoch 15: loss=0.2733, acc=38.91% (best=53.52%)\n",
      "          Fold 2 Epoch 15: loss=0.2531, acc=53.36% (best=59.14%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.14%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 53.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7d36950e:\n",
      "        Fold accuracies: ['51.72%', '59.14%', '53.52%', '50.78%', '65.94%']\n",
      "        Average fitness: 56.22% Â± 5.66%\n",
      "        Best fold: Fold 5 with 65.94%\n",
      "      Fitness obtained: 56.22% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 501ace38)\n",
      "      Architecture: 2 conv + 3 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 501ace38 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.3837, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.4016, acc=49.53% (best=49.53%)\n",
      "          Fold 4 Epoch 1: loss=0.3984, acc=53.91% (best=53.91%)\n",
      "          Fold 1 Epoch 1: loss=0.4092, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.3743, acc=50.08% (best=50.08%)\n",
      "          Fold 2 Epoch 5: loss=0.2189, acc=58.12% (best=58.12%)\n",
      "          Fold 3 Epoch 5: loss=0.2226, acc=49.06% (best=52.11%)\n",
      "          Fold 4 Epoch 5: loss=0.2076, acc=49.14% (best=56.80%)\n",
      "          Fold 1 Epoch 5: loss=0.2200, acc=52.50% (best=52.66%)\n",
      "          Fold 5 Epoch 5: loss=0.2163, acc=56.64% (best=59.30%)\n",
      "          Fold 2 Epoch 10: loss=0.2031, acc=69.06% (best=69.06%)\n",
      "          Fold 3 Epoch 10: loss=0.1994, acc=59.06% (best=59.06%)\n",
      "          Fold 4 Epoch 10: loss=0.1925, acc=46.80% (best=56.80%)\n",
      "          Fold 1 Epoch 10: loss=0.2025, acc=34.84% (best=52.66%)\n",
      "          Fold 5 Epoch 10: loss=0.1994, acc=58.36% (best=62.81%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 56.80%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 52.66%\n",
      "          Fold 2 Epoch 15: loss=0.1915, acc=55.31% (best=69.06%)\n",
      "          Fold 3 Epoch 15: loss=0.1980, acc=51.09% (best=59.06%)\n",
      "          Fold 5 Epoch 15: loss=0.1941, acc=50.94% (best=62.81%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 2 Epoch 20: loss=0.1900, acc=59.84% (best=69.06%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 69.06%\n",
      "          Fold 3 Epoch 20: loss=0.1953, acc=49.45% (best=59.06%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 59.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 501ace38:\n",
      "        Fold accuracies: ['52.66%', '69.06%', '59.06%', '56.80%', '62.81%']\n",
      "        Average fitness: 60.08% Â± 5.57%\n",
      "        Best fold: Fold 2 with 69.06%\n",
      "      Fitness obtained: 60.08% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: bea7b125)\n",
      "      Architecture: 8 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model bea7b125 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7021, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7075, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7090, acc=49.22% (best=49.22%)\n",
      "          Fold 4 Epoch 1: loss=0.6745, acc=47.66% (best=47.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7058, acc=45.78% (best=45.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6050, acc=50.31% (best=53.20%)\n",
      "          Fold 3 Epoch 5: loss=0.5789, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 5: loss=0.5477, acc=52.42% (best=56.09%)\n",
      "          Fold 2 Epoch 5: loss=0.6725, acc=44.53% (best=53.59%)\n",
      "          Fold 5 Epoch 5: loss=0.6967, acc=58.28% (best=58.28%)\n",
      "          Fold 3 Epoch 10: loss=0.4123, acc=48.67% (best=56.41%)\n",
      "          Fold 1 Epoch 10: loss=0.4164, acc=49.53% (best=53.36%)\n",
      "          Fold 4 Epoch 10: loss=0.3850, acc=49.69% (best=56.09%)\n",
      "          Fold 2 Epoch 10: loss=0.4605, acc=48.98% (best=53.59%)\n",
      "          Fold 5 Epoch 10: loss=0.6941, acc=46.09% (best=58.28%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 56.09%\n",
      "          Fold 3 Epoch 15: loss=0.3492, acc=50.16% (best=56.41%)\n",
      "          Fold 1 Epoch 15: loss=0.3296, acc=54.14% (best=62.50%)\n",
      "          Fold 2 Epoch 15: loss=0.3360, acc=48.20% (best=55.78%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 56.41%\n",
      "          Fold 5 Epoch 15: loss=0.4671, acc=46.72% (best=58.28%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 58.28%\n",
      "          Fold 1 Epoch 20: loss=0.2944, acc=48.20% (best=62.50%)\n",
      "          Fold 2 Epoch 20: loss=0.2938, acc=47.81% (best=56.41%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 62.50%\n",
      "          Fold 2 Epoch 25: loss=0.2632, acc=47.66% (best=56.41%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 56.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bea7b125:\n",
      "        Fold accuracies: ['62.50%', '56.41%', '56.41%', '56.09%', '58.28%']\n",
      "        Average fitness: 57.94% Â± 2.41%\n",
      "        Best fold: Fold 1 with 62.50%\n",
      "      Fitness obtained: 57.94% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: cd45db9d)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model cd45db9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6913, acc=57.66% (best=57.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6965, acc=59.61% (best=59.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6800, acc=39.84% (best=39.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6719, acc=47.34% (best=47.34%)\n",
      "          Fold 5 Epoch 1: loss=0.7075, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 5: loss=0.3017, acc=53.67% (best=53.67%)\n",
      "          Fold 3 Epoch 5: loss=0.2834, acc=55.23% (best=69.69%)\n",
      "          Fold 1 Epoch 5: loss=0.3599, acc=60.00% (best=60.00%)\n",
      "          Fold 4 Epoch 5: loss=0.3472, acc=62.58% (best=66.72%)\n",
      "          Fold 5 Epoch 5: loss=0.3290, acc=42.03% (best=54.14%)\n",
      "          Fold 2 Epoch 10: loss=0.2424, acc=44.61% (best=53.67%)\n",
      "          Fold 3 Epoch 10: loss=0.2361, acc=43.20% (best=69.69%)\n",
      "          Fold 1 Epoch 10: loss=0.2513, acc=61.95% (best=68.67%)\n",
      "          Fold 4 Epoch 10: loss=0.2248, acc=64.92% (best=66.72%)\n",
      "          Fold 5 Epoch 10: loss=0.2429, acc=46.17% (best=54.14%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 54.14%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 69.69%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 66.72%\n",
      "          Fold 2 Epoch 15: loss=0.2228, acc=50.86% (best=56.56%)\n",
      "          Fold 1 Epoch 15: loss=0.2281, acc=61.88% (best=68.67%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 68.67%\n",
      "          Fold 2 Epoch 20: loss=0.2184, acc=50.70% (best=56.56%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 56.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cd45db9d:\n",
      "        Fold accuracies: ['68.67%', '56.56%', '69.69%', '66.72%', '54.14%']\n",
      "        Average fitness: 63.16% Â± 6.49%\n",
      "        Best fold: Fold 3 with 69.69%\n",
      "      Fitness obtained: 63.16% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: e77c7b76)\n",
      "      Architecture: 10 conv + 5 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model e77c7b76 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=49.38% (best=49.38%)\n",
      "          Fold 2 Epoch 1: loss=0.7057, acc=56.48% (best=56.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6998, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7132, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7091, acc=53.12% (best=53.12%)\n",
      "          Fold 3 Epoch 5: loss=0.6715, acc=48.12% (best=52.81%)\n",
      "          Fold 2 Epoch 5: loss=0.6616, acc=52.19% (best=58.12%)\n",
      "          Fold 4 Epoch 5: loss=0.6418, acc=57.89% (best=58.05%)\n",
      "          Fold 5 Epoch 5: loss=0.7049, acc=45.94% (best=53.12%)\n",
      "          Fold 1 Epoch 5: loss=0.6820, acc=50.23% (best=53.44%)\n",
      "          Fold 3 Epoch 10: loss=0.5238, acc=47.58% (best=54.53%)\n",
      "          Fold 2 Epoch 10: loss=0.5167, acc=46.56% (best=58.12%)\n",
      "          Fold 4 Epoch 10: loss=0.5774, acc=52.97% (best=58.91%)\n",
      "          Fold 5 Epoch 10: loss=0.6973, acc=54.77% (best=56.56%)\n",
      "          Fold 1 Epoch 10: loss=0.5970, acc=50.55% (best=53.44%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.12%\n",
      "          Fold 3 Epoch 15: loss=0.4324, acc=48.91% (best=54.53%)\n",
      "          Fold 4 Epoch 15: loss=0.4853, acc=52.19% (best=58.91%)\n",
      "          Fold 5 Epoch 15: loss=0.5879, acc=46.17% (best=56.56%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 54.53%\n",
      "          Fold 1 Epoch 15: loss=0.5007, acc=52.81% (best=53.83%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 58.91%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "          Fold 1 Epoch 20: loss=0.4124, acc=52.11% (best=53.83%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 53.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e77c7b76:\n",
      "        Fold accuracies: ['53.83%', '58.12%', '54.53%', '58.91%', '56.56%']\n",
      "        Average fitness: 56.39% Â± 1.97%\n",
      "        Best fold: Fold 4 with 58.91%\n",
      "      Fitness obtained: 56.39% | Best in generation: 66.75% | Global best: 66.75%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 2 STATISTICS:\n",
      "   Maximum fitness: 66.75%\n",
      "   Average fitness: 57.09%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 13.57%\n",
      "   Best individual: 58e30ee6 with 66.75%\n",
      "   Global best individual: 58e30ee6 with 66.75%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.67% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=13.57)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 58e30ee6 (fitness: 66.75%)\n",
      "   Elite 2: 9fcd1a6a (fitness: 65.41%)\n",
      "   Elite 3: f82a1828 (fitness: 63.41%)\n",
      "   Elite 4: cd45db9d (fitness: 63.16%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 3\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 3)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 58e30ee6)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 58e30ee6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6656, acc=63.91% (best=63.91%)\n",
      "          Fold 2 Epoch 1: loss=0.6821, acc=59.69% (best=59.69%)\n",
      "          Fold 3 Epoch 1: loss=0.6882, acc=52.11% (best=52.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6879, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7034, acc=56.64% (best=56.64%)\n",
      "          Fold 2 Epoch 5: loss=0.5512, acc=52.11% (best=59.69%)\n",
      "          Fold 4 Epoch 5: loss=0.4433, acc=61.56% (best=63.91%)\n",
      "          Fold 1 Epoch 5: loss=0.5628, acc=42.97% (best=51.25%)\n",
      "          Fold 3 Epoch 5: loss=0.4498, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 5: loss=0.4834, acc=57.58% (best=57.58%)\n",
      "          Fold 2 Epoch 10: loss=0.3272, acc=48.20% (best=59.69%)\n",
      "          Fold 4 Epoch 10: loss=0.3397, acc=51.80% (best=67.11%)\n",
      "          Fold 1 Epoch 10: loss=0.3937, acc=47.11% (best=60.39%)\n",
      "          Fold 3 Epoch 10: loss=0.3389, acc=63.20% (best=67.81%)\n",
      "          Fold 5 Epoch 10: loss=0.3144, acc=42.50% (best=57.58%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 4 Epoch 15: loss=0.2737, acc=52.58% (best=67.11%)\n",
      "          Fold 1 Epoch 15: loss=0.3064, acc=55.86% (best=61.48%)\n",
      "          Fold 3 Epoch 15: loss=0.2840, acc=68.44% (best=68.44%)\n",
      "          Fold 5 Epoch 15: loss=0.2650, acc=42.27% (best=57.58%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.58%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "          Fold 1 Epoch 20: loss=0.2692, acc=42.27% (best=61.48%)\n",
      "          Fold 3 Epoch 20: loss=0.2604, acc=58.36% (best=72.27%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 61.48%\n",
      "          Fold 3 Epoch 25: loss=0.2359, acc=70.08% (best=72.27%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 58e30ee6:\n",
      "        Fold accuracies: ['61.48%', '59.69%', '72.27%', '67.11%', '57.58%']\n",
      "        Average fitness: 63.62% Â± 5.36%\n",
      "        Best fold: Fold 3 with 72.27%\n",
      "      New best fitness in this generation: 63.62%!\n",
      "      Fitness obtained: 63.62% | Best in generation: 63.62% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 9fcd1a6a)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 9fcd1a6a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6481, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6401, acc=58.59% (best=58.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6625, acc=64.61% (best=64.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6566, acc=51.64% (best=51.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6953, acc=46.95% (best=46.95%)\n",
      "          Fold 2 Epoch 5: loss=0.3405, acc=68.98% (best=68.98%)\n",
      "          Fold 3 Epoch 5: loss=0.3244, acc=48.44% (best=58.98%)\n",
      "          Fold 5 Epoch 5: loss=0.3617, acc=60.39% (best=60.39%)\n",
      "          Fold 4 Epoch 5: loss=0.3839, acc=38.75% (best=66.41%)\n",
      "          Fold 1 Epoch 5: loss=0.3829, acc=49.53% (best=51.64%)\n",
      "          Fold 2 Epoch 10: loss=0.2695, acc=53.44% (best=70.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2643, acc=46.95% (best=58.98%)\n",
      "          Fold 5 Epoch 10: loss=0.2648, acc=48.67% (best=60.39%)\n",
      "          Fold 4 Epoch 10: loss=0.2694, acc=57.58% (best=66.41%)\n",
      "          Fold 1 Epoch 10: loss=0.2941, acc=53.28% (best=55.78%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 58.98%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.41%\n",
      "          Fold 2 Epoch 15: loss=0.2400, acc=64.45% (best=70.00%)\n",
      "          Fold 5 Epoch 15: loss=0.2302, acc=48.36% (best=60.39%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 1 Epoch 15: loss=0.2432, acc=55.39% (best=58.75%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 70.00%\n",
      "          Fold 1 Epoch 20: loss=0.2297, acc=62.03% (best=62.34%)\n",
      "          Fold 1 Epoch 25: loss=0.2082, acc=60.08% (best=62.34%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 62.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fcd1a6a:\n",
      "        Fold accuracies: ['62.34%', '70.00%', '58.98%', '66.41%', '60.39%']\n",
      "        Average fitness: 63.62% Â± 4.05%\n",
      "        Best fold: Fold 2 with 70.00%\n",
      "      Fitness obtained: 63.62% | Best in generation: 63.62% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: f82a1828)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f82a1828 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6701, acc=45.39% (best=45.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6689, acc=44.69% (best=44.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6809, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6349, acc=47.50% (best=47.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7082, acc=57.81% (best=57.81%)\n",
      "          Fold 3 Epoch 5: loss=0.3753, acc=53.91% (best=58.44%)\n",
      "          Fold 2 Epoch 5: loss=0.3417, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 5: loss=0.3134, acc=61.88% (best=64.69%)\n",
      "          Fold 1 Epoch 5: loss=0.3733, acc=58.28% (best=61.48%)\n",
      "          Fold 5 Epoch 5: loss=0.3643, acc=63.05% (best=63.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2799, acc=54.69% (best=65.39%)\n",
      "          Fold 2 Epoch 10: loss=0.2604, acc=55.86% (best=55.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2390, acc=57.58% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.2661, acc=46.80% (best=63.05%)\n",
      "          Fold 1 Epoch 10: loss=0.2618, acc=56.02% (best=65.16%)\n",
      "          Fold 3 Epoch 15: loss=0.2428, acc=62.89% (best=65.39%)\n",
      "          Fold 2 Epoch 15: loss=0.2326, acc=44.45% (best=62.34%)\n",
      "          Fold 4 Epoch 15: loss=0.2165, acc=48.05% (best=65.23%)\n",
      "          Fold 5 Epoch 15: loss=0.2383, acc=53.20% (best=65.86%)\n",
      "          Fold 1 Epoch 15: loss=0.2395, acc=58.44% (best=65.16%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 65.16%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 65.39%\n",
      "          Fold 2 Epoch 20: loss=0.2215, acc=52.97% (best=62.34%)\n",
      "          Fold 5 Epoch 20: loss=0.2215, acc=45.23% (best=65.86%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 62.34%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 65.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f82a1828:\n",
      "        Fold accuracies: ['65.16%', '62.34%', '65.39%', '65.23%', '65.86%']\n",
      "        Average fitness: 64.80% Â± 1.25%\n",
      "        Best fold: Fold 5 with 65.86%\n",
      "      New best fitness in this generation: 64.80%!\n",
      "      Fitness obtained: 64.80% | Best in generation: 64.80% | Global best: 66.75%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: cd45db9d)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model cd45db9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6808, acc=48.20% (best=48.20%)\n",
      "          Fold 3 Epoch 1: loss=0.7046, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6951, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=60.55% (best=60.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6733, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 5: loss=0.3054, acc=48.98% (best=48.98%)\n",
      "          Fold 3 Epoch 5: loss=0.3419, acc=54.77% (best=59.53%)\n",
      "          Fold 1 Epoch 5: loss=0.3081, acc=71.56% (best=71.56%)\n",
      "          Fold 4 Epoch 5: loss=0.3815, acc=52.11% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.3285, acc=48.59% (best=64.84%)\n",
      "          Fold 2 Epoch 10: loss=0.2377, acc=40.47% (best=53.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2511, acc=58.75% (best=65.78%)\n",
      "          Fold 1 Epoch 10: loss=0.2250, acc=68.59% (best=71.56%)\n",
      "          Fold 4 Epoch 10: loss=0.2574, acc=62.11% (best=63.75%)\n",
      "          Fold 5 Epoch 10: loss=0.2341, acc=45.62% (best=64.84%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 64.84%\n",
      "          Fold 2 Epoch 15: loss=0.2212, acc=50.31% (best=53.05%)\n",
      "          Fold 3 Epoch 15: loss=0.2254, acc=54.77% (best=72.34%)\n",
      "          Fold 1 Epoch 15: loss=0.2149, acc=61.25% (best=71.56%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "          Fold 4 Epoch 15: loss=0.2261, acc=60.16% (best=67.73%)\n",
      "          Fold 2 Epoch 20: loss=0.2065, acc=48.20% (best=59.30%)\n",
      "          Fold 3 Epoch 20: loss=0.2116, acc=50.62% (best=72.34%)\n",
      "          Fold 4 Epoch 20: loss=0.2168, acc=57.81% (best=67.73%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 67.73%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 72.34%\n",
      "          Fold 2 Epoch 25: loss=0.2080, acc=50.08% (best=59.30%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 59.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cd45db9d:\n",
      "        Fold accuracies: ['71.56%', '59.30%', '72.34%', '67.73%', '64.84%']\n",
      "        Average fitness: 67.16% Â± 4.77%\n",
      "        Best fold: Fold 3 with 72.34%\n",
      "      New best fitness in this generation: 67.16%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 67.16% > 66.75%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen2_id58e30ee6_fitness66.75.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen3_idcd45db9d_fitness67.16.pth\n",
      "        Fitness: 67.16%, ID: cd45db9d, Gen: 3\n",
      "      Fitness obtained: 67.16% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 171de733)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 171de733 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6929, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6950, acc=54.30% (best=54.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6760, acc=50.16% (best=50.16%)\n",
      "          Fold 1 Epoch 1: loss=0.6961, acc=61.41% (best=61.41%)\n",
      "          Fold 5 Epoch 1: loss=0.7120, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 5: loss=0.4348, acc=50.94% (best=50.94%)\n",
      "          Fold 3 Epoch 5: loss=0.4474, acc=48.12% (best=54.30%)\n",
      "          Fold 1 Epoch 5: loss=0.4467, acc=60.16% (best=63.36%)\n",
      "          Fold 4 Epoch 5: loss=0.4488, acc=56.25% (best=56.25%)\n",
      "          Fold 5 Epoch 5: loss=0.4928, acc=52.66% (best=59.06%)\n",
      "          Fold 2 Epoch 10: loss=0.2997, acc=40.00% (best=56.25%)\n",
      "          Fold 3 Epoch 10: loss=0.3500, acc=54.69% (best=64.45%)\n",
      "          Fold 1 Epoch 10: loss=0.3337, acc=63.75% (best=63.75%)\n",
      "          Fold 4 Epoch 10: loss=0.3206, acc=38.05% (best=61.88%)\n",
      "          Fold 5 Epoch 10: loss=0.3417, acc=47.89% (best=59.06%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.06%\n",
      "          Fold 2 Epoch 15: loss=0.2770, acc=41.72% (best=56.25%)\n",
      "          Fold 3 Epoch 15: loss=0.2866, acc=60.31% (best=64.45%)\n",
      "          Fold 1 Epoch 15: loss=0.2918, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 15: loss=0.2701, acc=40.23% (best=61.88%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 61.88%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 56.25%\n",
      "          Fold 3 Epoch 20: loss=0.2569, acc=60.31% (best=69.14%)\n",
      "          Fold 1 Epoch 20: loss=0.2623, acc=59.14% (best=63.98%)\n",
      "          Fold 3 Epoch 25: loss=0.2367, acc=57.66% (best=69.14%)\n",
      "          Fold 1 Epoch 25: loss=0.2476, acc=55.23% (best=65.94%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 69.14%\n",
      "          Fold 1 Epoch 30: loss=0.2342, acc=61.72% (best=65.94%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 65.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 171de733:\n",
      "        Fold accuracies: ['65.94%', '56.25%', '69.14%', '61.88%', '59.06%']\n",
      "        Average fitness: 62.45% Â± 4.63%\n",
      "        Best fold: Fold 3 with 69.14%\n",
      "      Fitness obtained: 62.45% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 03e1941c)\n",
      "      Architecture: 12 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 03e1941c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6506, acc=44.14% (best=44.14%)\n",
      "          Fold 1 Epoch 1: loss=0.6913, acc=52.81% (best=52.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6519, acc=58.20% (best=58.20%)\n",
      "          Fold 2 Epoch 1: loss=0.6662, acc=49.45% (best=49.45%)\n",
      "          Fold 5 Epoch 1: loss=0.7035, acc=52.58% (best=52.58%)\n",
      "          Fold 3 Epoch 5: loss=0.3962, acc=55.00% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3650, acc=51.02% (best=58.20%)\n",
      "          Fold 1 Epoch 5: loss=0.5298, acc=56.02% (best=61.33%)\n",
      "          Fold 5 Epoch 5: loss=0.5317, acc=43.52% (best=52.58%)\n",
      "          Fold 2 Epoch 5: loss=0.4587, acc=48.20% (best=53.75%)\n",
      "          Fold 3 Epoch 10: loss=0.3015, acc=55.55% (best=56.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2665, acc=50.23% (best=64.45%)\n",
      "          Fold 1 Epoch 10: loss=0.3350, acc=52.81% (best=64.84%)\n",
      "          Fold 5 Epoch 10: loss=0.3058, acc=44.69% (best=54.92%)\n",
      "          Fold 2 Epoch 10: loss=0.3006, acc=45.78% (best=53.75%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 53.75%\n",
      "          Fold 3 Epoch 15: loss=0.2638, acc=62.66% (best=62.66%)\n",
      "          Fold 4 Epoch 15: loss=0.2407, acc=44.38% (best=64.45%)\n",
      "          Fold 1 Epoch 15: loss=0.2666, acc=55.94% (best=64.84%)\n",
      "          Fold 5 Epoch 15: loss=0.2710, acc=33.12% (best=54.92%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 64.45%\n",
      "          Fold 3 Epoch 20: loss=0.2515, acc=61.95% (best=69.14%)\n",
      "          Fold 3 Epoch 25: loss=0.2350, acc=58.20% (best=69.14%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 69.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 03e1941c:\n",
      "        Fold accuracies: ['64.84%', '53.75%', '69.14%', '64.45%', '54.92%']\n",
      "        Average fitness: 61.42% Â± 6.03%\n",
      "        Best fold: Fold 3 with 69.14%\n",
      "      Fitness obtained: 61.42% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: e60aac29)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model e60aac29 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6854, acc=57.27% (best=57.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6914, acc=45.94% (best=45.94%)\n",
      "          Fold 1 Epoch 1: loss=0.6887, acc=51.33% (best=51.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6670, acc=50.86% (best=50.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7100, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.3786, acc=29.53% (best=57.81%)\n",
      "          Fold 3 Epoch 5: loss=0.3922, acc=50.23% (best=55.08%)\n",
      "          Fold 1 Epoch 5: loss=0.4759, acc=55.00% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.4589, acc=64.38% (best=64.38%)\n",
      "          Fold 5 Epoch 5: loss=0.3920, acc=52.89% (best=53.05%)\n",
      "          Fold 2 Epoch 10: loss=0.2844, acc=46.95% (best=57.81%)\n",
      "          Fold 3 Epoch 10: loss=0.3019, acc=50.00% (best=58.12%)\n",
      "          Fold 1 Epoch 10: loss=0.3190, acc=60.86% (best=65.23%)\n",
      "          Fold 4 Epoch 10: loss=0.3116, acc=49.77% (best=64.38%)\n",
      "          Fold 5 Epoch 10: loss=0.2810, acc=52.89% (best=53.05%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 3 Epoch 15: loss=0.2600, acc=49.14% (best=58.12%)\n",
      "          Fold 1 Epoch 15: loss=0.2789, acc=63.36% (best=66.56%)\n",
      "          Fold 4 Epoch 15: loss=0.2571, acc=49.14% (best=64.38%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 64.38%\n",
      "          Fold 5 Epoch 15: loss=0.2530, acc=42.19% (best=53.28%)\n",
      "          Fold 3 Epoch 20: loss=0.2469, acc=52.73% (best=60.08%)\n",
      "          Fold 1 Epoch 20: loss=0.2507, acc=57.58% (best=66.56%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 66.56%\n",
      "          Fold 5 Epoch 20: loss=0.2328, acc=40.55% (best=53.28%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 53.28%\n",
      "          Fold 3 Epoch 25: loss=0.2353, acc=50.23% (best=60.08%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 60.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e60aac29:\n",
      "        Fold accuracies: ['66.56%', '57.81%', '60.08%', '64.38%', '53.28%']\n",
      "        Average fitness: 60.42% Â± 4.72%\n",
      "        Best fold: Fold 1 with 66.56%\n",
      "      Fitness obtained: 60.42% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 0a3fc526)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 0a3fc526 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7270, acc=54.30% (best=54.30%)\n",
      "          Fold 2 Epoch 1: loss=0.7453, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7228, acc=51.72% (best=51.72%)\n",
      "          Fold 1 Epoch 1: loss=0.7236, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7222, acc=45.31% (best=45.31%)\n",
      "          Fold 5 Epoch 5: loss=0.7133, acc=54.92% (best=56.41%)\n",
      "          Fold 3 Epoch 5: loss=0.7155, acc=52.42% (best=58.98%)\n",
      "          Fold 2 Epoch 5: loss=0.7137, acc=48.52% (best=49.61%)\n",
      "          Fold 1 Epoch 5: loss=0.7120, acc=49.14% (best=49.77%)\n",
      "          Fold 4 Epoch 5: loss=0.6918, acc=57.73% (best=57.73%)\n",
      "          Fold 3 Epoch 10: loss=0.7109, acc=44.84% (best=58.98%)\n",
      "          Fold 5 Epoch 10: loss=0.7108, acc=42.97% (best=56.41%)\n",
      "          Fold 1 Epoch 10: loss=0.7013, acc=50.62% (best=57.66%)\n",
      "          Fold 2 Epoch 10: loss=0.7098, acc=58.20% (best=61.41%)\n",
      "          Fold 4 Epoch 10: loss=0.6778, acc=58.28% (best=58.67%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 58.98%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 56.41%\n",
      "          Fold 2 Epoch 15: loss=0.7034, acc=61.72% (best=61.72%)\n",
      "          Fold 1 Epoch 15: loss=0.6963, acc=59.61% (best=59.61%)\n",
      "          Fold 4 Epoch 15: loss=0.6693, acc=52.11% (best=58.67%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 58.67%\n",
      "          Fold 2 Epoch 20: loss=0.6983, acc=58.59% (best=61.72%)\n",
      "          Fold 1 Epoch 20: loss=0.6909, acc=55.39% (best=59.61%)\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 59.61%\n",
      "          Fold 2 Epoch 25: loss=0.6989, acc=56.25% (best=61.72%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 61.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0a3fc526:\n",
      "        Fold accuracies: ['59.61%', '61.72%', '58.98%', '58.67%', '56.41%']\n",
      "        Average fitness: 59.08% Â± 1.71%\n",
      "        Best fold: Fold 2 with 61.72%\n",
      "      Fitness obtained: 59.08% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: be14b2c6)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model be14b2c6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6792, acc=45.00% (best=45.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6718, acc=62.97% (best=62.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6856, acc=46.41% (best=46.41%)\n",
      "          Fold 5 Epoch 1: loss=0.7095, acc=53.52% (best=53.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6882, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 5: loss=0.3178, acc=53.67% (best=59.92%)\n",
      "          Fold 3 Epoch 5: loss=0.3366, acc=53.12% (best=58.20%)\n",
      "          Fold 4 Epoch 5: loss=0.3250, acc=39.45% (best=67.27%)\n",
      "          Fold 5 Epoch 5: loss=0.3983, acc=46.95% (best=59.61%)\n",
      "          Fold 1 Epoch 5: loss=0.3435, acc=46.95% (best=50.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2416, acc=45.47% (best=59.92%)\n",
      "          Fold 3 Epoch 10: loss=0.2412, acc=51.09% (best=58.28%)\n",
      "          Fold 4 Epoch 10: loss=0.2301, acc=54.45% (best=67.27%)\n",
      "          Fold 5 Epoch 10: loss=0.2718, acc=35.23% (best=59.61%)\n",
      "          Fold 1 Epoch 10: loss=0.2360, acc=33.44% (best=52.58%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.27%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.61%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 3 Epoch 15: loss=0.2227, acc=63.44% (best=63.44%)\n",
      "          Fold 1 Epoch 15: loss=0.2087, acc=48.44% (best=54.61%)\n",
      "          Fold 3 Epoch 20: loss=0.2158, acc=45.78% (best=63.44%)\n",
      "          Fold 1 Epoch 20: loss=0.2125, acc=47.81% (best=54.61%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 54.61%\n",
      "          Fold 3 Epoch 25: loss=0.2082, acc=53.75% (best=63.44%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for be14b2c6:\n",
      "        Fold accuracies: ['54.61%', '59.92%', '63.44%', '67.27%', '59.61%']\n",
      "        Average fitness: 60.97% Â± 4.22%\n",
      "        Best fold: Fold 4 with 67.27%\n",
      "      Fitness obtained: 60.97% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 5664cf80)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 5664cf80 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7020, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7231, acc=54.14% (best=54.14%)\n",
      "          Fold 4 Epoch 1: loss=0.7095, acc=56.64% (best=56.64%)\n",
      "          Fold 1 Epoch 1: loss=0.7268, acc=41.88% (best=41.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7346, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6823, acc=49.14% (best=52.27%)\n",
      "          Fold 3 Epoch 5: loss=0.7110, acc=55.55% (best=55.55%)\n",
      "          Fold 1 Epoch 5: loss=0.7010, acc=49.61% (best=55.70%)\n",
      "          Fold 4 Epoch 5: loss=0.6778, acc=55.39% (best=57.03%)\n",
      "          Fold 5 Epoch 5: loss=0.7133, acc=49.69% (best=50.00%)\n",
      "          Fold 3 Epoch 10: loss=0.7007, acc=56.17% (best=56.17%)\n",
      "          Fold 2 Epoch 10: loss=0.6785, acc=52.27% (best=52.27%)\n",
      "          Fold 1 Epoch 10: loss=0.6894, acc=46.72% (best=55.70%)\n",
      "          Fold 4 Epoch 10: loss=0.6741, acc=54.84% (best=57.03%)\n",
      "          Fold 5 Epoch 10: loss=0.7030, acc=54.38% (best=54.38%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 52.27%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 55.70%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 57.03%\n",
      "          Fold 3 Epoch 15: loss=0.6907, acc=54.06% (best=56.17%)\n",
      "          Fold 5 Epoch 15: loss=0.6996, acc=53.91% (best=57.27%)\n",
      "          Fold 3 Epoch 20: loss=0.6800, acc=51.02% (best=56.17%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 56.17%\n",
      "          Fold 5 Epoch 20: loss=0.6926, acc=51.41% (best=57.27%)\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 57.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5664cf80:\n",
      "        Fold accuracies: ['55.70%', '52.27%', '56.17%', '57.03%', '57.27%']\n",
      "        Average fitness: 55.69% Â± 1.80%\n",
      "        Best fold: Fold 5 with 57.27%\n",
      "      Fitness obtained: 55.69% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 34b15000)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 34b15000 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6734, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6871, acc=45.55% (best=45.55%)\n",
      "          Fold 1 Epoch 1: loss=0.6925, acc=60.70% (best=60.70%)\n",
      "          Fold 2 Epoch 5: loss=0.4523, acc=45.86% (best=49.92%)\n",
      "          Fold 3 Epoch 5: loss=0.3837, acc=55.31% (best=56.17%)\n",
      "          Fold 1 Epoch 5: loss=0.5232, acc=52.81% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2890, acc=43.44% (best=50.23%)\n",
      "          Fold 3 Epoch 10: loss=0.2737, acc=52.89% (best=58.36%)\n",
      "          Fold 1 Epoch 10: loss=0.3092, acc=45.70% (best=60.70%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.70%\n",
      "          Fold 2 Epoch 15: loss=0.2424, acc=49.45% (best=55.70%)\n",
      "          Fold 3 Epoch 15: loss=0.2439, acc=48.36% (best=58.36%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 58.36%\n",
      "          Fold 2 Epoch 20: loss=0.2229, acc=56.88% (best=57.19%)\n",
      "          Fold 2 Epoch 25: loss=0.2162, acc=53.05% (best=57.19%)\n",
      "          Fold 2 Epoch 30: loss=0.2046, acc=54.84% (best=63.44%)\n",
      "          Fold 2 Epoch 35: loss=0.1971, acc=60.16% (best=65.16%)\n",
      "          Fold 2 Epoch 40: loss=0.2053, acc=50.94% (best=65.16%)\n",
      "          Fold 2: Early stopping at epoch 44\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 34b15000:\n",
      "        Fold accuracies: ['60.70%', '65.16%', '58.36%', '0.00%', '0.00%']\n",
      "        Average fitness: 36.84% Â± 30.16%\n",
      "        Best fold: Fold 2 with 65.16%\n",
      "      Fitness obtained: 36.84% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 0faa61fe)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 0faa61fe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6713, acc=53.59% (best=53.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3772, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 10: loss=0.2790, acc=48.36% (best=59.84%)\n",
      "          Fold 2 Epoch 15: loss=0.2389, acc=59.61% (best=59.84%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0faa61fe:\n",
      "        Fold accuracies: ['0.00%', '59.84%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 11.97% Â± 23.94%\n",
      "        Best fold: Fold 2 with 59.84%\n",
      "      Fitness obtained: 11.97% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 9fdbcda1)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 9fdbcda1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.8386, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7879, acc=46.33% (best=46.33%)\n",
      "          Fold 4 Epoch 1: loss=0.7654, acc=54.14% (best=54.14%)\n",
      "          Fold 1 Epoch 1: loss=0.8227, acc=57.11% (best=57.11%)\n",
      "          Fold 5 Epoch 1: loss=0.8096, acc=50.00% (best=50.00%)\n",
      "          Fold 5 Epoch 5: loss=0.6939, acc=44.77% (best=55.08%)\n",
      "          Fold 2 Epoch 5: loss=0.6571, acc=49.61% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.6309, acc=50.86% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.6501, acc=60.08% (best=62.66%)\n",
      "          Fold 4 Epoch 5: loss=0.6404, acc=58.59% (best=60.23%)\n",
      "          Fold 5 Epoch 10: loss=0.5017, acc=57.11% (best=57.11%)\n",
      "          Fold 2 Epoch 10: loss=0.4817, acc=54.45% (best=55.47%)\n",
      "          Fold 3 Epoch 10: loss=0.4774, acc=48.91% (best=59.45%)\n",
      "          Fold 4 Epoch 10: loss=0.4233, acc=43.83% (best=60.23%)\n",
      "          Fold 1 Epoch 10: loss=0.5694, acc=52.50% (best=62.66%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.66%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 60.23%\n",
      "          Fold 5 Epoch 15: loss=0.3402, acc=48.67% (best=57.11%)\n",
      "          Fold 2 Epoch 15: loss=0.3257, acc=41.72% (best=55.47%)\n",
      "          Fold 3 Epoch 15: loss=0.3888, acc=46.09% (best=59.45%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 55.47%\n",
      "          Fold 5 Epoch 20: loss=0.2915, acc=45.00% (best=57.11%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 57.11%\n",
      "          Fold 3 Epoch 20: loss=0.3477, acc=56.33% (best=65.23%)\n",
      "          Fold 3 Epoch 25: loss=0.3178, acc=64.92% (best=65.23%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fdbcda1:\n",
      "        Fold accuracies: ['62.66%', '55.47%', '65.23%', '60.23%', '57.11%']\n",
      "        Average fitness: 60.14% Â± 3.56%\n",
      "        Best fold: Fold 3 with 65.23%\n",
      "      Fitness obtained: 60.14% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 6b031dfb)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 6b031dfb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6536, acc=44.61% (best=44.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6768, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6953, acc=56.25% (best=56.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6567, acc=62.34% (best=62.34%)\n",
      "          Fold 5 Epoch 1: loss=0.6929, acc=53.59% (best=53.59%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 5: loss=0.3249, acc=56.95% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.3746, acc=46.64% (best=57.42%)\n",
      "          Fold 5 Epoch 5: loss=0.3421, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2505, acc=56.41% (best=59.45%)\n",
      "          Fold 3 Epoch 10: loss=0.2765, acc=55.08% (best=59.22%)\n",
      "          Fold 5 Epoch 10: loss=0.2473, acc=48.52% (best=56.09%)\n",
      "          Fold 2 Epoch 15: loss=0.2263, acc=56.41% (best=62.81%)\n",
      "          Fold 3 Epoch 15: loss=0.2469, acc=53.67% (best=59.22%)\n",
      "          Fold 5 Epoch 15: loss=0.2240, acc=46.48% (best=58.44%)\n",
      "          Fold 2 Epoch 20: loss=0.2098, acc=60.78% (best=65.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2263, acc=57.66% (best=61.17%)\n",
      "          Fold 5 Epoch 20: loss=0.2154, acc=49.53% (best=58.44%)\n",
      "          Fold 2 Epoch 25: loss=0.2123, acc=59.84% (best=65.08%)\n",
      "          Fold 3 Epoch 25: loss=0.2190, acc=55.23% (best=61.17%)\n",
      "          Fold 5 Epoch 25: loss=0.2107, acc=49.22% (best=58.98%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 61.17%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 65.08%\n",
      "          Fold 5 Epoch 30: loss=0.2002, acc=47.81% (best=58.98%)\n",
      "          Fold 5: Early stopping at epoch 34\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6b031dfb:\n",
      "        Fold accuracies: ['0.00%', '65.08%', '61.17%', '0.00%', '58.98%']\n",
      "        Average fitness: 37.05% Â± 30.31%\n",
      "        Best fold: Fold 2 with 65.08%\n",
      "      Fitness obtained: 37.05% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 6ef4e250)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 6ef4e250 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7072, acc=43.83% (best=43.83%)\n",
      "          Fold 3 Epoch 1: loss=0.7173, acc=58.12% (best=58.12%)\n",
      "          Fold 1 Epoch 1: loss=0.7090, acc=55.39% (best=55.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7036, acc=57.19% (best=57.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7164, acc=42.66% (best=42.66%)\n",
      "          Fold 3 Epoch 5: loss=0.6974, acc=64.14% (best=67.97%)\n",
      "          Fold 2 Epoch 5: loss=0.6773, acc=50.55% (best=50.55%)\n",
      "          Fold 1 Epoch 5: loss=0.6919, acc=58.98% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.7072, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.6729, acc=60.70% (best=60.70%)\n",
      "          Fold 3 Epoch 10: loss=0.6647, acc=63.36% (best=67.97%)\n",
      "          Fold 2 Epoch 10: loss=0.6542, acc=50.39% (best=50.55%)\n",
      "          Fold 1 Epoch 10: loss=0.6795, acc=53.05% (best=62.27%)\n",
      "          Fold 5 Epoch 10: loss=0.6939, acc=53.28% (best=56.41%)\n",
      "          Fold 4 Epoch 10: loss=0.6369, acc=32.03% (best=60.70%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 67.97%\n",
      "          Fold 2 Epoch 15: loss=0.6240, acc=50.23% (best=50.55%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 50.55%\n",
      "          Fold 1 Epoch 15: loss=0.6441, acc=52.97% (best=62.27%)\n",
      "          Fold 4 Epoch 15: loss=0.5983, acc=35.94% (best=60.70%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 60.70%\n",
      "          Fold 5 Epoch 15: loss=0.6709, acc=53.98% (best=60.55%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.27%\n",
      "          Fold 5 Epoch 20: loss=0.6030, acc=53.28% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6ef4e250:\n",
      "        Fold accuracies: ['62.27%', '50.55%', '67.97%', '60.70%', '60.55%']\n",
      "        Average fitness: 60.41% Â± 5.62%\n",
      "        Best fold: Fold 3 with 67.97%\n",
      "      Fitness obtained: 60.41% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 50257b37)\n",
      "      Architecture: 10 conv + 8 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 50257b37 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7162, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 1: loss=0.7280, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7435, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7428, acc=51.88% (best=51.88%)\n",
      "          Fold 1 Epoch 1: loss=0.7412, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 5: loss=0.5414, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 5: loss=0.5989, acc=49.69% (best=49.69%)\n",
      "          Fold 3 Epoch 5: loss=0.5979, acc=49.30% (best=51.33%)\n",
      "          Fold 5 Epoch 5: loss=0.6531, acc=50.00% (best=51.88%)\n",
      "          Fold 1 Epoch 5: loss=0.6414, acc=49.53% (best=50.23%)\n",
      "          Fold 2 Epoch 10: loss=0.4387, acc=49.61% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.4369, acc=53.91% (best=61.25%)\n",
      "          Fold 3 Epoch 10: loss=0.4379, acc=47.66% (best=51.33%)\n",
      "          Fold 5 Epoch 10: loss=0.4770, acc=56.09% (best=56.09%)\n",
      "          Fold 1 Epoch 10: loss=0.4488, acc=59.61% (best=59.61%)\n",
      "          Fold 2 Epoch 15: loss=0.3754, acc=56.64% (best=61.64%)\n",
      "          Fold 4 Epoch 15: loss=0.3822, acc=44.45% (best=61.25%)\n",
      "          Fold 3 Epoch 15: loss=0.3881, acc=37.03% (best=53.52%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "          Fold 5 Epoch 15: loss=0.4010, acc=56.88% (best=61.88%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 61.64%\n",
      "          Fold 1 Epoch 15: loss=0.3853, acc=52.42% (best=59.61%)\n",
      "          Fold 3 Epoch 20: loss=0.3597, acc=43.20% (best=53.52%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 53.52%\n",
      "          Fold 5 Epoch 20: loss=0.3606, acc=60.86% (best=61.88%)\n",
      "          Fold 1 Epoch 20: loss=0.3496, acc=56.33% (best=61.25%)\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 1 Epoch 25: loss=0.3268, acc=57.73% (best=63.44%)\n",
      "          Fold 1 Epoch 30: loss=0.3145, acc=53.91% (best=63.44%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 50257b37:\n",
      "        Fold accuracies: ['63.44%', '61.64%', '53.52%', '61.25%', '61.88%']\n",
      "        Average fitness: 60.34% Â± 3.49%\n",
      "        Best fold: Fold 1 with 63.44%\n",
      "      Fitness obtained: 60.34% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: d5a6992c)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model d5a6992c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6780, acc=46.25% (best=46.25%)\n",
      "          Fold 1 Epoch 1: loss=0.6743, acc=56.09% (best=56.09%)\n",
      "          Fold 5 Epoch 1: loss=0.7082, acc=51.48% (best=51.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6977, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6624, acc=60.55% (best=60.55%)\n",
      "          Fold 2 Epoch 5: loss=0.4060, acc=60.31% (best=62.66%)\n",
      "          Fold 3 Epoch 5: loss=0.4256, acc=44.38% (best=57.73%)\n",
      "          Fold 1 Epoch 5: loss=0.5102, acc=56.95% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.4647, acc=41.88% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.4631, acc=49.14% (best=51.48%)\n",
      "          Fold 2 Epoch 10: loss=0.3171, acc=50.08% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.3489, acc=53.67% (best=57.73%)\n",
      "          Fold 1 Epoch 10: loss=0.3970, acc=53.28% (best=60.62%)\n",
      "          Fold 4 Epoch 10: loss=0.3504, acc=53.36% (best=62.11%)\n",
      "          Fold 5 Epoch 10: loss=0.3276, acc=46.64% (best=54.84%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 57.73%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.11%\n",
      "          Fold 2 Epoch 15: loss=0.2925, acc=65.70% (best=65.70%)\n",
      "          Fold 1 Epoch 15: loss=0.3450, acc=59.22% (best=60.62%)\n",
      "          Fold 5 Epoch 15: loss=0.2736, acc=50.62% (best=54.84%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 60.62%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 54.84%\n",
      "          Fold 2 Epoch 20: loss=0.2592, acc=59.45% (best=65.70%)\n",
      "          Fold 2 Epoch 25: loss=0.2397, acc=62.81% (best=66.25%)\n",
      "          Fold 2 Epoch 30: loss=0.2381, acc=53.12% (best=66.25%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 66.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d5a6992c:\n",
      "        Fold accuracies: ['60.62%', '66.25%', '57.73%', '62.11%', '54.84%']\n",
      "        Average fitness: 60.31% Â± 3.88%\n",
      "        Best fold: Fold 2 with 66.25%\n",
      "      Fitness obtained: 60.31% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 48977c37)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 48977c37 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7374, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7738, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7561, acc=54.61% (best=54.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7517, acc=62.89% (best=62.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7831, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 5: loss=0.4971, acc=42.66% (best=52.42%)\n",
      "          Fold 3 Epoch 5: loss=0.5494, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 5: loss=0.6939, acc=50.00% (best=56.33%)\n",
      "          Fold 1 Epoch 5: loss=0.6262, acc=50.23% (best=63.44%)\n",
      "          Fold 4 Epoch 5: loss=0.5116, acc=53.75% (best=58.91%)\n",
      "          Fold 2 Epoch 10: loss=0.2880, acc=49.92% (best=52.81%)\n",
      "          Fold 3 Epoch 10: loss=0.3500, acc=54.92% (best=61.02%)\n",
      "          Fold 5 Epoch 10: loss=0.5048, acc=42.97% (best=58.83%)\n",
      "          Fold 1 Epoch 10: loss=0.3935, acc=56.09% (best=63.44%)\n",
      "          Fold 4 Epoch 10: loss=0.3036, acc=57.58% (best=61.17%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 63.44%\n",
      "          Fold 2 Epoch 15: loss=0.2473, acc=46.02% (best=52.89%)\n",
      "          Fold 3 Epoch 15: loss=0.2861, acc=52.27% (best=61.02%)\n",
      "          Fold 5 Epoch 15: loss=0.3038, acc=45.00% (best=58.83%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 61.02%\n",
      "          Fold 4 Epoch 15: loss=0.2655, acc=50.55% (best=61.17%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 61.17%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 58.83%\n",
      "          Fold 2 Epoch 20: loss=0.2896, acc=45.86% (best=52.89%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 52.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 48977c37:\n",
      "        Fold accuracies: ['63.44%', '52.89%', '61.02%', '61.17%', '58.83%']\n",
      "        Average fitness: 59.47% Â± 3.60%\n",
      "        Best fold: Fold 1 with 63.44%\n",
      "      Fitness obtained: 59.47% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 1ea96fc4)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 1ea96fc4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.8453, acc=51.56% (best=51.56%)\n",
      "          Fold 3 Epoch 1: loss=0.8398, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.7893, acc=66.88% (best=66.88%)\n",
      "          Fold 1 Epoch 1: loss=0.8363, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7957, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 5: loss=0.5067, acc=43.67% (best=51.56%)\n",
      "          Fold 1 Epoch 5: loss=0.5576, acc=42.58% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.4971, acc=49.53% (best=54.38%)\n",
      "          Fold 4 Epoch 5: loss=0.4823, acc=41.64% (best=66.88%)\n",
      "          Fold 5 Epoch 5: loss=0.5526, acc=52.66% (best=59.53%)\n",
      "          Fold 2 Epoch 10: loss=0.3454, acc=50.55% (best=53.59%)\n",
      "          Fold 1 Epoch 10: loss=0.3458, acc=52.81% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.3326, acc=53.20% (best=58.59%)\n",
      "          Fold 4 Epoch 10: loss=0.2826, acc=60.00% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 5 Epoch 10: loss=0.3234, acc=58.36% (best=59.61%)\n",
      "          Fold 2 Epoch 15: loss=0.2740, acc=49.14% (best=53.59%)\n",
      "          Fold 1 Epoch 15: loss=0.2650, acc=58.12% (best=61.88%)\n",
      "          Fold 3 Epoch 15: loss=0.2819, acc=51.88% (best=58.59%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 53.59%\n",
      "          Fold 5 Epoch 15: loss=0.2644, acc=47.58% (best=60.78%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 58.59%\n",
      "          Fold 1 Epoch 20: loss=0.2307, acc=51.17% (best=61.88%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 61.88%\n",
      "          Fold 5 Epoch 20: loss=0.2307, acc=60.78% (best=60.78%)\n",
      "          Fold 5 Epoch 25: loss=0.2249, acc=42.19% (best=61.33%)\n",
      "          Fold 5 Epoch 30: loss=0.2161, acc=50.62% (best=61.33%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 61.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1ea96fc4:\n",
      "        Fold accuracies: ['61.88%', '53.59%', '58.59%', '66.88%', '61.33%']\n",
      "        Average fitness: 60.45% Â± 4.35%\n",
      "        Best fold: Fold 4 with 66.88%\n",
      "      Fitness obtained: 60.45% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 1796945b)\n",
      "      Architecture: 2 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1796945b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 237, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 177, in _init_group\n",
      "    state[\"exp_avg\"] = torch.zeros_like(\n",
      "                       ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 237, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 177, in _init_group\n",
      "    state[\"exp_avg\"] = torch.zeros_like(\n",
      "                       ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1796945b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 67.16% | Global best: 67.16%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 3 STATISTICS:\n",
      "   Maximum fitness: 67.16%\n",
      "   Average fitness: 53.31%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 17.61%\n",
      "   Best individual: cd45db9d with 67.16%\n",
      "   Global best individual: cd45db9d with 67.16%\n",
      "\n",
      "ðŸ”„ Improvement detected: 0.41% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=17.61)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: cd45db9d (fitness: 67.16%)\n",
      "   Elite 2: f82a1828 (fitness: 64.80%)\n",
      "   Elite 3: 58e30ee6 (fitness: 63.62%)\n",
      "   Elite 4: 9fcd1a6a (fitness: 63.62%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 4\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 4)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: cd45db9d)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model cd45db9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 247, in step\n",
      "    adam(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 949, in adam\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 773, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 247, in step\n",
      "    adam(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 949, in adam\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/adam.py\", line 773, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6799, acc=45.86% (best=45.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6824, acc=56.17% (best=56.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6987, acc=43.59% (best=43.59%)\n",
      "          Fold 5 Epoch 1: loss=0.7095, acc=54.22% (best=54.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6896, acc=56.02% (best=56.02%)\n",
      "          Fold 2 Epoch 5: loss=0.2891, acc=50.55% (best=54.22%)\n",
      "          Fold 3 Epoch 5: loss=0.3373, acc=65.39% (best=65.39%)\n",
      "          Fold 4 Epoch 5: loss=0.2879, acc=61.80% (best=61.80%)\n",
      "          Fold 1 Epoch 5: loss=0.3395, acc=52.97% (best=60.62%)\n",
      "          Fold 5 Epoch 5: loss=0.5310, acc=51.17% (best=55.00%)\n",
      "          Fold 2 Epoch 10: loss=0.2312, acc=52.27% (best=54.22%)\n",
      "          Fold 3 Epoch 10: loss=0.2384, acc=59.61% (best=68.12%)\n",
      "          Fold 4 Epoch 10: loss=0.2184, acc=55.08% (best=63.83%)\n",
      "          Fold 1 Epoch 10: loss=0.2429, acc=53.83% (best=60.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2657, acc=51.17% (best=60.55%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 60.62%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 54.22%\n",
      "          Fold 3 Epoch 15: loss=0.2219, acc=55.39% (best=68.12%)\n",
      "          Fold 4 Epoch 15: loss=0.2073, acc=60.31% (best=65.70%)\n",
      "          Fold 5 Epoch 15: loss=0.2326, acc=51.25% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 68.12%\n",
      "          Fold 4 Epoch 20: loss=0.1966, acc=56.95% (best=65.70%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cd45db9d:\n",
      "        Fold accuracies: ['60.62%', '54.22%', '68.12%', '65.70%', '60.55%']\n",
      "        Average fitness: 61.84% Â± 4.81%\n",
      "        Best fold: Fold 3 with 68.12%\n",
      "      New best fitness in this generation: 61.84%!\n",
      "      Fitness obtained: 61.84% | Best in generation: 61.84% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: f82a1828)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f82a1828 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7052, acc=61.17% (best=61.17%)\n",
      "          Fold 2 Epoch 1: loss=0.6754, acc=50.94% (best=50.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6525, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6735, acc=55.78% (best=55.78%)\n",
      "          Fold 3 Epoch 1: loss=0.6292, acc=34.69% (best=34.69%)\n",
      "          Fold 2 Epoch 5: loss=0.3591, acc=38.98% (best=50.94%)\n",
      "          Fold 4 Epoch 5: loss=0.3931, acc=51.64% (best=55.70%)\n",
      "          Fold 5 Epoch 5: loss=0.3410, acc=57.50% (best=61.17%)\n",
      "          Fold 1 Epoch 5: loss=0.3676, acc=48.75% (best=57.27%)\n",
      "          Fold 3 Epoch 5: loss=0.3145, acc=61.56% (best=65.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2786, acc=43.20% (best=50.94%)\n",
      "          Fold 4 Epoch 10: loss=0.2715, acc=59.30% (best=66.33%)\n",
      "          Fold 5 Epoch 10: loss=0.2631, acc=57.66% (best=61.17%)\n",
      "          Fold 1 Epoch 10: loss=0.2757, acc=55.31% (best=60.31%)\n",
      "          Fold 3 Epoch 10: loss=0.2548, acc=67.34% (best=67.34%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.94%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 61.17%\n",
      "          Fold 4 Epoch 15: loss=0.2270, acc=60.62% (best=66.33%)\n",
      "          Fold 1 Epoch 15: loss=0.2432, acc=48.52% (best=60.31%)\n",
      "          Fold 3 Epoch 15: loss=0.2376, acc=61.48% (best=68.75%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 66.33%\n",
      "          Fold 3 Epoch 20: loss=0.2235, acc=61.64% (best=68.75%)\n",
      "          Fold 1 Epoch 20: loss=0.2222, acc=62.03% (best=62.03%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 68.75%\n",
      "          Fold 1 Epoch 25: loss=0.2130, acc=64.69% (best=64.69%)\n",
      "          Fold 1 Epoch 30: loss=0.2096, acc=60.00% (best=64.69%)\n",
      "          Fold 1 Epoch 35: loss=0.2048, acc=56.17% (best=69.61%)\n",
      "          Fold 1 Epoch 40: loss=0.2049, acc=57.34% (best=69.61%)\n",
      "          Fold 1 Epoch 45: loss=0.2001, acc=63.36% (best=71.56%)\n",
      "          Fold 1 Epoch 50: loss=0.2009, acc=56.41% (best=71.56%)\n",
      "          Fold 1: Early stopping at epoch 53\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f82a1828:\n",
      "        Fold accuracies: ['71.56%', '50.94%', '68.75%', '66.33%', '61.17%']\n",
      "        Average fitness: 63.75% Â± 7.26%\n",
      "        Best fold: Fold 1 with 71.56%\n",
      "      New best fitness in this generation: 63.75%!\n",
      "      Fitness obtained: 63.75% | Best in generation: 63.75% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 58e30ee6)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 58e30ee6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6767, acc=45.08% (best=45.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6932, acc=50.55% (best=50.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6643, acc=36.41% (best=36.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6874, acc=52.42% (best=52.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7045, acc=52.89% (best=52.89%)\n",
      "          Fold 2 Epoch 5: loss=0.4209, acc=42.89% (best=52.97%)\n",
      "          Fold 3 Epoch 5: loss=0.5394, acc=50.31% (best=50.55%)\n",
      "          Fold 4 Epoch 5: loss=0.4672, acc=43.20% (best=51.80%)\n",
      "          Fold 1 Epoch 5: loss=0.5621, acc=64.22% (best=64.22%)\n",
      "          Fold 5 Epoch 5: loss=0.5855, acc=43.12% (best=55.39%)\n",
      "          Fold 2 Epoch 10: loss=0.3113, acc=53.91% (best=56.17%)\n",
      "          Fold 3 Epoch 10: loss=0.3852, acc=58.67% (best=58.67%)\n",
      "          Fold 4 Epoch 10: loss=0.3538, acc=48.36% (best=54.77%)\n",
      "          Fold 1 Epoch 10: loss=0.3846, acc=53.83% (best=64.22%)\n",
      "          Fold 5 Epoch 10: loss=0.3876, acc=47.97% (best=55.47%)\n",
      "          Fold 2 Epoch 15: loss=0.2585, acc=57.73% (best=60.47%)\n",
      "          Fold 3 Epoch 15: loss=0.3223, acc=46.95% (best=58.83%)\n",
      "          Fold 4 Epoch 15: loss=0.2806, acc=46.09% (best=54.77%)\n",
      "          Fold 1 Epoch 15: loss=0.3189, acc=46.48% (best=64.22%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 64.22%\n",
      "          Fold 5 Epoch 15: loss=0.2948, acc=55.86% (best=64.69%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 54.77%\n",
      "          Fold 2 Epoch 20: loss=0.2438, acc=52.81% (best=62.34%)\n",
      "          Fold 3 Epoch 20: loss=0.2957, acc=68.67% (best=68.67%)\n",
      "          Fold 5 Epoch 20: loss=0.2636, acc=53.36% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 2 Epoch 25: loss=0.2198, acc=54.38% (best=66.72%)\n",
      "          Fold 3 Epoch 25: loss=0.2629, acc=62.97% (best=68.67%)\n",
      "          Fold 2 Epoch 30: loss=0.2161, acc=54.92% (best=66.72%)\n",
      "          Fold 3 Epoch 30: loss=0.2520, acc=53.75% (best=69.53%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "          Fold 3 Epoch 35: loss=0.2296, acc=55.31% (best=69.53%)\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 69.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 58e30ee6:\n",
      "        Fold accuracies: ['64.22%', '66.72%', '69.53%', '54.77%', '64.69%']\n",
      "        Average fitness: 63.98% Â± 4.98%\n",
      "        Best fold: Fold 3 with 69.53%\n",
      "      New best fitness in this generation: 63.98%!\n",
      "      Fitness obtained: 63.98% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 9fcd1a6a)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 9fcd1a6a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6452, acc=52.97% (best=52.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6457, acc=67.97% (best=67.97%)\n",
      "          Fold 1 Epoch 1: loss=0.6695, acc=59.38% (best=59.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6128, acc=60.62% (best=60.62%)\n",
      "          Fold 5 Epoch 1: loss=0.6904, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.3136, acc=47.19% (best=54.84%)\n",
      "          Fold 4 Epoch 5: loss=0.3609, acc=57.34% (best=67.97%)\n",
      "          Fold 1 Epoch 5: loss=0.3888, acc=51.72% (best=59.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3540, acc=61.33% (best=63.98%)\n",
      "          Fold 5 Epoch 5: loss=0.3986, acc=56.25% (best=56.25%)\n",
      "          Fold 2 Epoch 10: loss=0.2635, acc=43.91% (best=54.84%)\n",
      "          Fold 4 Epoch 10: loss=0.2583, acc=40.39% (best=67.97%)\n",
      "          Fold 1 Epoch 10: loss=0.2954, acc=45.39% (best=64.92%)\n",
      "          Fold 3 Epoch 10: loss=0.2770, acc=65.62% (best=65.62%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 5 Epoch 10: loss=0.2849, acc=53.28% (best=58.20%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "          Fold 1 Epoch 15: loss=0.2480, acc=53.83% (best=64.92%)\n",
      "          Fold 3 Epoch 15: loss=0.2397, acc=53.52% (best=65.62%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "          Fold 5 Epoch 15: loss=0.2480, acc=48.52% (best=59.77%)\n",
      "          Fold 3 Epoch 20: loss=0.2252, acc=61.64% (best=65.62%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 65.62%\n",
      "          Fold 5 Epoch 20: loss=0.2292, acc=46.56% (best=59.77%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 59.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fcd1a6a:\n",
      "        Fold accuracies: ['64.92%', '54.84%', '65.62%', '67.97%', '59.77%']\n",
      "        Average fitness: 62.62% Â± 4.72%\n",
      "        Best fold: Fold 4 with 67.97%\n",
      "      Fitness obtained: 62.62% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 0e3ad011)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 0e3ad011 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7216, acc=43.59% (best=43.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6969, acc=55.16% (best=55.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7281, acc=56.02% (best=56.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7325, acc=46.41% (best=46.41%)\n",
      "          Fold 1 Epoch 1: loss=0.7264, acc=61.64% (best=61.64%)\n",
      "          Fold 2 Epoch 5: loss=0.4972, acc=50.00% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.5041, acc=44.14% (best=54.30%)\n",
      "          Fold 4 Epoch 5: loss=0.4716, acc=43.12% (best=62.66%)\n",
      "          Fold 3 Epoch 5: loss=0.4165, acc=56.88% (best=61.80%)\n",
      "          Fold 1 Epoch 5: loss=0.5340, acc=59.77% (best=61.64%)\n",
      "          Fold 2 Epoch 10: loss=0.3495, acc=53.05% (best=67.27%)\n",
      "          Fold 5 Epoch 10: loss=0.3375, acc=48.75% (best=56.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3385, acc=52.42% (best=62.66%)\n",
      "          Fold 3 Epoch 10: loss=0.3115, acc=54.53% (best=61.80%)\n",
      "          Fold 1 Epoch 10: loss=0.3924, acc=47.34% (best=61.64%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.64%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 61.80%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 62.66%\n",
      "          Fold 2 Epoch 15: loss=0.3012, acc=59.53% (best=67.27%)\n",
      "          Fold 5 Epoch 15: loss=0.2856, acc=48.36% (best=56.64%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 56.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0e3ad011:\n",
      "        Fold accuracies: ['61.64%', '67.27%', '61.80%', '62.66%', '56.64%']\n",
      "        Average fitness: 62.00% Â± 3.38%\n",
      "        Best fold: Fold 2 with 67.27%\n",
      "      Fitness obtained: 62.00% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 20b42d29)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 20b42d29 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.8761, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.9167, acc=55.08% (best=55.08%)\n",
      "          Fold 5 Epoch 1: loss=0.8543, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.8391, acc=60.47% (best=60.47%)\n",
      "          Fold 4 Epoch 1: loss=0.9330, acc=69.38% (best=69.38%)\n",
      "          Fold 2 Epoch 5: loss=0.4029, acc=51.41% (best=52.42%)\n",
      "          Fold 3 Epoch 5: loss=0.5765, acc=49.38% (best=55.08%)\n",
      "          Fold 5 Epoch 5: loss=0.5027, acc=46.02% (best=50.00%)\n",
      "          Fold 1 Epoch 5: loss=0.5588, acc=60.70% (best=64.69%)\n",
      "          Fold 4 Epoch 5: loss=0.4623, acc=50.39% (best=69.38%)\n",
      "          Fold 2 Epoch 10: loss=0.2637, acc=47.97% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.2990, acc=54.53% (best=55.08%)\n",
      "          Fold 5 Epoch 10: loss=0.2884, acc=56.33% (best=56.33%)\n",
      "          Fold 1 Epoch 10: loss=0.3022, acc=59.06% (best=64.69%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 55.08%\n",
      "          Fold 4 Epoch 10: loss=0.2683, acc=53.20% (best=69.38%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 64.69%\n",
      "          Fold 2 Epoch 15: loss=0.2331, acc=46.17% (best=56.95%)\n",
      "          Fold 5 Epoch 15: loss=0.2521, acc=42.97% (best=56.33%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 56.95%\n",
      "          Fold 5 Epoch 20: loss=0.2358, acc=44.22% (best=59.22%)\n",
      "          Fold 5 Epoch 25: loss=0.2164, acc=49.06% (best=59.22%)\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 59.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 20b42d29:\n",
      "        Fold accuracies: ['64.69%', '56.95%', '55.08%', '69.38%', '59.22%']\n",
      "        Average fitness: 61.06% Â± 5.26%\n",
      "        Best fold: Fold 4 with 69.38%\n",
      "      Fitness obtained: 61.06% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 07cff352)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 07cff352 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7338, acc=54.69% (best=54.69%)\n",
      "          Fold 2 Epoch 1: loss=0.7106, acc=43.52% (best=43.52%)\n",
      "          Fold 1 Epoch 1: loss=0.7109, acc=57.97% (best=57.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7423, acc=49.30% (best=49.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6782, acc=64.45% (best=64.45%)\n",
      "          Fold 2 Epoch 5: loss=0.6522, acc=36.33% (best=43.52%)\n",
      "          Fold 3 Epoch 5: loss=0.6377, acc=51.02% (best=54.69%)\n",
      "          Fold 1 Epoch 5: loss=0.6642, acc=50.31% (best=61.56%)\n",
      "          Fold 4 Epoch 5: loss=0.6250, acc=56.88% (best=66.17%)\n",
      "          Fold 5 Epoch 5: loss=0.6744, acc=55.62% (best=55.62%)\n",
      "          Fold 2 Epoch 10: loss=0.5678, acc=51.64% (best=52.27%)\n",
      "          Fold 3 Epoch 10: loss=0.5302, acc=50.86% (best=54.69%)\n",
      "          Fold 1 Epoch 10: loss=0.5760, acc=50.47% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.5327, acc=47.42% (best=66.17%)\n",
      "          Fold 5 Epoch 10: loss=0.5339, acc=40.70% (best=55.62%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 54.69%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 61.56%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.17%\n",
      "          Fold 2 Epoch 15: loss=0.4443, acc=59.77% (best=60.55%)\n",
      "          Fold 5 Epoch 15: loss=0.4328, acc=45.78% (best=55.62%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 55.62%\n",
      "          Fold 2 Epoch 20: loss=0.3616, acc=48.52% (best=61.88%)\n",
      "          Fold 2 Epoch 25: loss=0.3179, acc=45.94% (best=61.88%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 61.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 07cff352:\n",
      "        Fold accuracies: ['61.56%', '61.88%', '54.69%', '66.17%', '55.62%']\n",
      "        Average fitness: 59.98% Â± 4.28%\n",
      "        Best fold: Fold 4 with 66.17%\n",
      "      Fitness obtained: 59.98% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 512ed574)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 512ed574 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[1, 2, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 512ed574:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 1ce3d552)\n",
      "      Architecture: 10 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 1ce3d552 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6700, acc=39.14% (best=39.14%)\n",
      "          Fold 3 Epoch 1: loss=0.6914, acc=52.34% (best=52.34%)\n",
      "          Fold 4 Epoch 1: loss=0.6625, acc=56.64% (best=56.64%)\n",
      "          Fold 1 Epoch 1: loss=0.6783, acc=43.67% (best=43.67%)\n",
      "          Fold 5 Epoch 1: loss=0.7031, acc=63.20% (best=63.20%)\n",
      "          Fold 2 Epoch 5: loss=0.3801, acc=59.53% (best=59.53%)\n",
      "          Fold 3 Epoch 5: loss=0.3875, acc=44.84% (best=56.25%)\n",
      "          Fold 1 Epoch 5: loss=0.4282, acc=59.06% (best=59.06%)\n",
      "          Fold 4 Epoch 5: loss=0.3848, acc=56.33% (best=65.70%)\n",
      "          Fold 5 Epoch 5: loss=0.3918, acc=57.89% (best=63.20%)\n",
      "          Fold 2 Epoch 10: loss=0.2874, acc=48.20% (best=59.53%)\n",
      "          Fold 3 Epoch 10: loss=0.3002, acc=53.75% (best=56.25%)\n",
      "          Fold 1 Epoch 10: loss=0.3000, acc=50.78% (best=59.06%)\n",
      "          Fold 4 Epoch 10: loss=0.2781, acc=49.61% (best=65.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2965, acc=45.08% (best=63.20%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.70%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 56.25%\n",
      "          Fold 2 Epoch 15: loss=0.2572, acc=52.27% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "          Fold 1 Epoch 15: loss=0.2570, acc=60.70% (best=60.70%)\n",
      "          Fold 1 Epoch 20: loss=0.2393, acc=54.69% (best=60.70%)\n",
      "          Fold 1 Epoch 25: loss=0.2261, acc=54.45% (best=64.14%)\n",
      "          Fold 1 Epoch 30: loss=0.2221, acc=64.61% (best=64.61%)\n",
      "          Fold 1 Epoch 35: loss=0.2197, acc=57.97% (best=68.44%)\n",
      "          Fold 1 Epoch 40: loss=0.2131, acc=57.42% (best=68.44%)\n",
      "          Fold 1: Early stopping at epoch 41\n",
      "      â†’ Fold 1 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1ce3d552:\n",
      "        Fold accuracies: ['68.44%', '59.53%', '56.25%', '65.70%', '63.20%']\n",
      "        Average fitness: 62.62% Â± 4.33%\n",
      "        Best fold: Fold 1 with 68.44%\n",
      "      Fitness obtained: 62.62% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 15188f32)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 15188f32 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6792, acc=46.48% (best=46.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6926, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6529, acc=59.14% (best=59.14%)\n",
      "          Fold 1 Epoch 1: loss=0.6877, acc=54.69% (best=54.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7080, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 5: loss=0.4196, acc=47.97% (best=54.22%)\n",
      "          Fold 3 Epoch 5: loss=0.4253, acc=52.03% (best=67.11%)\n",
      "          Fold 1 Epoch 5: loss=0.5126, acc=53.67% (best=59.77%)\n",
      "          Fold 4 Epoch 5: loss=0.4577, acc=49.14% (best=61.25%)\n",
      "          Fold 5 Epoch 5: loss=0.4895, acc=50.86% (best=56.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2936, acc=38.59% (best=54.22%)\n",
      "          Fold 3 Epoch 10: loss=0.3260, acc=59.69% (best=67.11%)\n",
      "          Fold 1 Epoch 10: loss=0.3582, acc=52.19% (best=66.48%)\n",
      "          Fold 4 Epoch 10: loss=0.3576, acc=25.39% (best=61.25%)\n",
      "          Fold 5 Epoch 10: loss=0.3037, acc=50.47% (best=56.09%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.09%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 54.22%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 67.11%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "          Fold 1 Epoch 15: loss=0.2933, acc=57.03% (best=66.48%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 66.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15188f32:\n",
      "        Fold accuracies: ['66.48%', '54.22%', '67.11%', '61.25%', '56.09%']\n",
      "        Average fitness: 61.03% Â± 5.24%\n",
      "        Best fold: Fold 3 with 67.11%\n",
      "      Fitness obtained: 61.03% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 589d1096)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 589d1096 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6851, acc=42.27% (best=42.27%)\n",
      "          Fold 1 Epoch 1: loss=0.6803, acc=47.19% (best=47.19%)\n",
      "          Fold 3 Epoch 1: loss=0.6845, acc=52.73% (best=52.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6649, acc=60.78% (best=60.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7022, acc=43.59% (best=43.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3392, acc=40.08% (best=46.95%)\n",
      "          Fold 3 Epoch 5: loss=0.3507, acc=50.70% (best=61.56%)\n",
      "          Fold 1 Epoch 5: loss=0.3949, acc=52.34% (best=53.12%)\n",
      "          Fold 4 Epoch 5: loss=0.3742, acc=47.81% (best=60.78%)\n",
      "          Fold 5 Epoch 5: loss=0.4154, acc=53.91% (best=53.91%)\n",
      "          Fold 2 Epoch 10: loss=0.2416, acc=41.25% (best=47.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2604, acc=62.97% (best=62.97%)\n",
      "          Fold 1 Epoch 10: loss=0.2603, acc=58.59% (best=61.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2334, acc=35.55% (best=60.78%)\n",
      "          Fold 5 Epoch 10: loss=0.2450, acc=53.28% (best=53.91%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.78%\n",
      "          Fold 2 Epoch 15: loss=0.2215, acc=43.59% (best=47.97%)\n",
      "          Fold 3 Epoch 15: loss=0.2259, acc=63.52% (best=63.52%)\n",
      "          Fold 1 Epoch 15: loss=0.2191, acc=53.59% (best=61.09%)\n",
      "          Fold 5 Epoch 15: loss=0.2143, acc=46.33% (best=53.91%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 53.91%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 61.09%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 47.97%\n",
      "          Fold 3 Epoch 20: loss=0.2159, acc=59.14% (best=63.52%)\n",
      "          Fold 3 Epoch 25: loss=0.2045, acc=49.06% (best=63.52%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 63.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 589d1096:\n",
      "        Fold accuracies: ['61.09%', '47.97%', '63.52%', '60.78%', '53.91%']\n",
      "        Average fitness: 57.45% Â± 5.72%\n",
      "        Best fold: Fold 3 with 63.52%\n",
      "      Fitness obtained: 57.45% | Best in generation: 63.98% | Global best: 67.16%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 64530a51)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 64530a51 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6787, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6775, acc=37.73% (best=37.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6613, acc=53.12% (best=53.12%)\n",
      "          Fold 1 Epoch 1: loss=0.6772, acc=47.34% (best=47.34%)\n",
      "          Fold 5 Epoch 1: loss=0.6901, acc=50.55% (best=50.55%)\n",
      "          Fold 3 Epoch 5: loss=0.3799, acc=57.89% (best=59.77%)\n",
      "          Fold 2 Epoch 5: loss=0.3589, acc=49.45% (best=55.39%)\n",
      "          Fold 4 Epoch 5: loss=0.3407, acc=37.42% (best=60.78%)\n",
      "          Fold 5 Epoch 5: loss=0.3557, acc=53.67% (best=62.27%)\n",
      "          Fold 1 Epoch 5: loss=0.4353, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 10: loss=0.2790, acc=57.34% (best=71.02%)\n",
      "          Fold 2 Epoch 10: loss=0.2621, acc=60.00% (best=60.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2542, acc=54.06% (best=63.05%)\n",
      "          Fold 5 Epoch 10: loss=0.2668, acc=48.83% (best=62.27%)\n",
      "          Fold 1 Epoch 10: loss=0.2961, acc=57.97% (best=71.02%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "          Fold 3 Epoch 15: loss=0.2486, acc=54.92% (best=71.02%)\n",
      "          Fold 2 Epoch 15: loss=0.2336, acc=57.50% (best=61.72%)\n",
      "          Fold 4 Epoch 15: loss=0.2285, acc=48.05% (best=63.05%)\n",
      "          Fold 1 Epoch 15: loss=0.2514, acc=63.59% (best=71.02%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 71.02%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 63.05%\n",
      "          Fold 2 Epoch 20: loss=0.2330, acc=59.84% (best=63.28%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 71.02%\n",
      "          Fold 2 Epoch 25: loss=0.2155, acc=52.58% (best=70.16%)\n",
      "          Fold 2 Epoch 30: loss=0.2072, acc=55.70% (best=70.16%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 64530a51:\n",
      "        Fold accuracies: ['71.02%', '70.16%', '71.02%', '63.05%', '62.27%']\n",
      "        Average fitness: 67.50% Â± 3.98%\n",
      "        Best fold: Fold 3 with 71.02%\n",
      "      New best fitness in this generation: 67.50%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 67.50% > 67.16%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen3_idcd45db9d_fitness67.16.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen4_id64530a51_fitness67.50.pth\n",
      "        Fitness: 67.50%, ID: 64530a51, Gen: 4\n",
      "      Fitness obtained: 67.50% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: cfda70af)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cfda70af with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7000, acc=43.91% (best=43.91%)\n",
      "          Fold 4 Epoch 1: loss=0.7017, acc=64.84% (best=64.84%)\n",
      "          Fold 5 Epoch 1: loss=0.7377, acc=48.28% (best=48.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7235, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7167, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 5: loss=0.5149, acc=46.02% (best=49.61%)\n",
      "          Fold 4 Epoch 5: loss=0.5882, acc=56.95% (best=64.84%)\n",
      "          Fold 5 Epoch 5: loss=0.6363, acc=46.72% (best=55.47%)\n",
      "          Fold 3 Epoch 5: loss=0.6010, acc=46.64% (best=50.00%)\n",
      "          Fold 1 Epoch 5: loss=0.6110, acc=50.16% (best=55.70%)\n",
      "          Fold 2 Epoch 10: loss=0.3843, acc=52.34% (best=55.31%)\n",
      "          Fold 4 Epoch 10: loss=0.4975, acc=50.70% (best=64.84%)\n",
      "          Fold 5 Epoch 10: loss=0.4667, acc=44.77% (best=55.47%)\n",
      "          Fold 3 Epoch 10: loss=0.4319, acc=52.19% (best=59.77%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 1 Epoch 10: loss=0.4671, acc=57.50% (best=57.66%)\n",
      "          Fold 2 Epoch 15: loss=0.3362, acc=44.30% (best=55.31%)\n",
      "          Fold 3 Epoch 15: loss=0.3879, acc=50.16% (best=61.48%)\n",
      "          Fold 5 Epoch 15: loss=0.3741, acc=53.83% (best=58.59%)\n",
      "          Fold 1 Epoch 15: loss=0.3889, acc=50.94% (best=61.88%)\n",
      "          Fold 2 Epoch 20: loss=0.2918, acc=59.38% (best=59.38%)\n",
      "          Fold 3 Epoch 20: loss=0.3522, acc=52.66% (best=61.48%)\n",
      "          Fold 5 Epoch 20: loss=0.3105, acc=57.19% (best=59.77%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 61.48%\n",
      "          Fold 1 Epoch 20: loss=0.3351, acc=48.05% (best=61.88%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 61.88%\n",
      "          Fold 2 Epoch 25: loss=0.2729, acc=57.97% (best=65.16%)\n",
      "          Fold 5 Epoch 25: loss=0.2805, acc=53.52% (best=59.77%)\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 59.77%\n",
      "          Fold 2 Epoch 30: loss=0.2721, acc=48.20% (best=65.16%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cfda70af:\n",
      "        Fold accuracies: ['61.88%', '65.16%', '61.48%', '64.84%', '59.77%']\n",
      "        Average fitness: 62.62% Â± 2.07%\n",
      "        Best fold: Fold 2 with 65.16%\n",
      "      Fitness obtained: 62.62% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 447cde61)\n",
      "      Architecture: 22 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 447cde61 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[71], expected input with shape [*, 71], but got input of size[1, 71, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 447cde61:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: f69f41c9)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f69f41c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6790, acc=38.83% (best=38.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6866, acc=57.27% (best=57.27%)\n",
      "          Fold 4 Epoch 1: loss=0.6621, acc=52.19% (best=52.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6729, acc=61.95% (best=61.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7023, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.3592, acc=46.95% (best=56.09%)\n",
      "          Fold 3 Epoch 5: loss=0.3239, acc=52.34% (best=60.62%)\n",
      "          Fold 4 Epoch 5: loss=0.3871, acc=62.58% (best=67.97%)\n",
      "          Fold 1 Epoch 5: loss=0.3909, acc=47.42% (best=66.64%)\n",
      "          Fold 5 Epoch 5: loss=0.3828, acc=50.78% (best=56.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2578, acc=49.61% (best=56.17%)\n",
      "          Fold 3 Epoch 10: loss=0.2434, acc=51.48% (best=65.47%)\n",
      "          Fold 4 Epoch 10: loss=0.2568, acc=60.62% (best=67.97%)\n",
      "          Fold 1 Epoch 10: loss=0.2685, acc=56.88% (best=66.64%)\n",
      "          Fold 5 Epoch 10: loss=0.2770, acc=51.25% (best=56.48%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 66.64%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 56.48%\n",
      "          Fold 2 Epoch 15: loss=0.2229, acc=56.64% (best=56.64%)\n",
      "          Fold 3 Epoch 15: loss=0.2226, acc=49.61% (best=65.47%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 65.47%\n",
      "          Fold 2 Epoch 20: loss=0.2141, acc=53.91% (best=63.28%)\n",
      "          Fold 2 Epoch 25: loss=0.2039, acc=52.73% (best=63.28%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 63.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f69f41c9:\n",
      "        Fold accuracies: ['66.64%', '63.28%', '65.47%', '67.97%', '56.48%']\n",
      "        Average fitness: 63.97% Â± 4.05%\n",
      "        Best fold: Fold 4 with 67.97%\n",
      "      Fitness obtained: 63.97% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 9b16dbf2)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 9b16dbf2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=53.98% (best=53.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7385, acc=54.84% (best=54.84%)\n",
      "          Fold 4 Epoch 1: loss=0.7069, acc=64.53% (best=64.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7138, acc=57.58% (best=57.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7254, acc=52.58% (best=52.58%)\n",
      "          Fold 3 Epoch 5: loss=0.6991, acc=56.17% (best=60.31%)\n",
      "          Fold 2 Epoch 5: loss=0.6870, acc=46.48% (best=54.84%)\n",
      "          Fold 4 Epoch 5: loss=0.6749, acc=61.02% (best=68.20%)\n",
      "          Fold 1 Epoch 5: loss=0.6946, acc=49.84% (best=57.58%)\n",
      "          Fold 5 Epoch 5: loss=0.7120, acc=51.95% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.6855, acc=58.83% (best=62.58%)\n",
      "          Fold 2 Epoch 10: loss=0.6731, acc=49.45% (best=54.84%)\n",
      "          Fold 4 Epoch 10: loss=0.6555, acc=51.41% (best=68.20%)\n",
      "          Fold 1 Epoch 10: loss=0.6887, acc=56.02% (best=57.58%)\n",
      "          Fold 5 Epoch 10: loss=0.6980, acc=50.00% (best=56.95%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 57.58%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.20%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.95%\n",
      "          Fold 3 Epoch 15: loss=0.6733, acc=50.16% (best=62.58%)\n",
      "          Fold 3 Epoch 20: loss=0.6593, acc=53.44% (best=67.66%)\n",
      "          Fold 3 Epoch 25: loss=0.6213, acc=55.23% (best=67.66%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 67.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9b16dbf2:\n",
      "        Fold accuracies: ['57.58%', '54.84%', '67.66%', '68.20%', '56.95%']\n",
      "        Average fitness: 61.05% Â± 5.70%\n",
      "        Best fold: Fold 4 with 68.20%\n",
      "      Fitness obtained: 61.05% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: f4148e1b)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.1\n",
      "      Training/Evaluating model f4148e1b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=1.4634, acc=49.92% (best=49.92%)\n",
      "          Fold 1 Epoch 1: loss=1.2406, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 1: loss=1.4606, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 1: loss=1.5945, acc=58.98% (best=58.98%)\n",
      "          Fold 5 Epoch 1: loss=1.5351, acc=47.66% (best=47.66%)\n",
      "          Fold 2 Epoch 5: loss=0.6601, acc=45.31% (best=49.92%)\n",
      "          Fold 1 Epoch 5: loss=0.6569, acc=55.00% (best=62.11%)\n",
      "          Fold 3 Epoch 5: loss=0.6683, acc=47.50% (best=51.02%)\n",
      "          Fold 5 Epoch 5: loss=0.6956, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.6486, acc=62.81% (best=62.81%)\n",
      "          Fold 2 Epoch 10: loss=0.5992, acc=49.69% (best=49.92%)\n",
      "          Fold 1 Epoch 10: loss=0.6159, acc=50.08% (best=62.11%)\n",
      "          Fold 3 Epoch 10: loss=0.6283, acc=46.17% (best=54.53%)\n",
      "          Fold 4 Epoch 10: loss=0.5925, acc=52.19% (best=62.81%)\n",
      "          Fold 5 Epoch 10: loss=0.6958, acc=50.00% (best=50.00%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.92%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 3 Epoch 15: loss=0.5918, acc=53.36% (best=54.53%)\n",
      "          Fold 4 Epoch 15: loss=0.5202, acc=49.84% (best=62.81%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 62.81%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 54.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f4148e1b:\n",
      "        Fold accuracies: ['62.11%', '49.92%', '54.53%', '62.81%', '50.00%']\n",
      "        Average fitness: 55.88% Â± 5.63%\n",
      "        Best fold: Fold 4 with 62.81%\n",
      "      Fitness obtained: 55.88% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 0511639a)\n",
      "      Architecture: 10 conv + 8 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 0511639a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7080, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7082, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6856, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7066, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7108, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.5301, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.5753, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 5: loss=0.6389, acc=50.08% (best=50.16%)\n",
      "          Fold 1 Epoch 5: loss=0.5839, acc=51.56% (best=52.89%)\n",
      "          Fold 4 Epoch 5: loss=0.5004, acc=49.22% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.3694, acc=50.62% (best=56.88%)\n",
      "          Fold 3 Epoch 10: loss=0.4300, acc=59.84% (best=59.84%)\n",
      "          Fold 5 Epoch 10: loss=0.4322, acc=52.19% (best=55.78%)\n",
      "          Fold 1 Epoch 10: loss=0.4261, acc=50.23% (best=58.28%)\n",
      "          Fold 4 Epoch 10: loss=0.3973, acc=48.75% (best=53.91%)\n",
      "          Fold 2 Epoch 15: loss=0.3419, acc=50.47% (best=56.88%)\n",
      "          Fold 3 Epoch 15: loss=0.3761, acc=62.81% (best=62.81%)\n",
      "          Fold 5 Epoch 15: loss=0.3638, acc=54.14% (best=62.73%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 56.88%\n",
      "          Fold 1 Epoch 15: loss=0.3659, acc=48.44% (best=69.14%)\n",
      "          Fold 4 Epoch 15: loss=0.3382, acc=49.77% (best=53.91%)\n",
      "          Fold 3 Epoch 20: loss=0.3246, acc=50.23% (best=62.81%)\n",
      "          Fold 5 Epoch 20: loss=0.3269, acc=53.52% (best=62.73%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 62.73%\n",
      "          Fold 1 Epoch 20: loss=0.3271, acc=59.06% (best=69.14%)\n",
      "          Fold 4 Epoch 20: loss=0.3053, acc=48.91% (best=56.09%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 69.14%\n",
      "          Fold 3 Epoch 25: loss=0.3046, acc=47.58% (best=62.81%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 62.81%\n",
      "          Fold 4 Epoch 25: loss=0.2907, acc=48.52% (best=60.16%)\n",
      "          Fold 4 Epoch 30: loss=0.2728, acc=49.77% (best=60.16%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 60.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0511639a:\n",
      "        Fold accuracies: ['69.14%', '56.88%', '62.81%', '60.16%', '62.73%']\n",
      "        Average fitness: 62.34% Â± 4.03%\n",
      "        Best fold: Fold 1 with 69.14%\n",
      "      Fitness obtained: 62.34% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 0184b592)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 0184b592 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6702, acc=45.00% (best=45.00%)\n",
      "          Fold 3 Epoch 1: loss=0.6767, acc=58.75% (best=58.75%)\n",
      "          Fold 1 Epoch 1: loss=0.6768, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6537, acc=54.69% (best=54.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7069, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 5: loss=0.3845, acc=43.44% (best=52.34%)\n",
      "          Fold 1 Epoch 5: loss=0.4413, acc=50.31% (best=57.66%)\n",
      "          Fold 4 Epoch 5: loss=0.4357, acc=53.91% (best=68.05%)\n",
      "          Fold 5 Epoch 5: loss=0.6586, acc=60.62% (best=60.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3744, acc=48.67% (best=58.75%)\n",
      "          Fold 2 Epoch 10: loss=0.2903, acc=38.12% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.3205, acc=55.23% (best=62.97%)\n",
      "          Fold 4 Epoch 10: loss=0.2949, acc=51.33% (best=68.05%)\n",
      "          Fold 5 Epoch 10: loss=0.3834, acc=53.83% (best=60.62%)\n",
      "          Fold 3 Epoch 10: loss=0.2951, acc=61.56% (best=65.31%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 2 Epoch 15: loss=0.2537, acc=35.00% (best=63.20%)\n",
      "          Fold 1 Epoch 15: loss=0.2690, acc=62.50% (best=62.97%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 63.20%\n",
      "          Fold 5 Epoch 15: loss=0.2876, acc=56.48% (best=61.64%)\n",
      "          Fold 3 Epoch 15: loss=0.2543, acc=60.00% (best=65.31%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.97%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 65.31%\n",
      "          Fold 5 Epoch 20: loss=0.2540, acc=47.11% (best=61.64%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0184b592:\n",
      "        Fold accuracies: ['62.97%', '63.20%', '65.31%', '68.05%', '61.64%']\n",
      "        Average fitness: 64.23% Â± 2.24%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      Fitness obtained: 64.23% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: c46c47e7)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model c46c47e7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6954, acc=43.44% (best=43.44%)\n",
      "          Fold 3 Epoch 1: loss=0.6949, acc=44.14% (best=44.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6486, acc=58.83% (best=58.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6907, acc=52.19% (best=52.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7090, acc=57.42% (best=57.42%)\n",
      "          Fold 2 Epoch 5: loss=0.4482, acc=45.55% (best=49.45%)\n",
      "          Fold 3 Epoch 5: loss=0.4556, acc=39.22% (best=44.14%)\n",
      "          Fold 4 Epoch 5: loss=0.4941, acc=68.36% (best=68.36%)\n",
      "          Fold 1 Epoch 5: loss=0.5628, acc=56.02% (best=56.48%)\n",
      "          Fold 5 Epoch 5: loss=0.5920, acc=47.89% (best=57.42%)\n",
      "          Fold 2 Epoch 10: loss=0.3067, acc=39.61% (best=49.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3624, acc=52.19% (best=52.19%)\n",
      "          Fold 1 Epoch 10: loss=0.4072, acc=56.56% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3722, acc=48.12% (best=68.36%)\n",
      "          Fold 5 Epoch 10: loss=0.3661, acc=54.77% (best=57.42%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.42%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 49.45%\n",
      "          Fold 3 Epoch 15: loss=0.3295, acc=54.22% (best=54.22%)\n",
      "          Fold 1 Epoch 15: loss=0.3366, acc=59.53% (best=61.64%)\n",
      "          Fold 4 Epoch 15: loss=0.3174, acc=49.14% (best=68.36%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 68.36%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 61.64%\n",
      "          Fold 3 Epoch 20: loss=0.3010, acc=55.31% (best=55.55%)\n",
      "          Fold 3 Epoch 25: loss=0.2644, acc=49.69% (best=55.55%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 55.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c46c47e7:\n",
      "        Fold accuracies: ['61.64%', '49.45%', '55.55%', '68.36%', '57.42%']\n",
      "        Average fitness: 58.48% Â± 6.31%\n",
      "        Best fold: Fold 4 with 68.36%\n",
      "      Fitness obtained: 58.48% | Best in generation: 67.50% | Global best: 67.50%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 4 STATISTICS:\n",
      "   Maximum fitness: 67.50%\n",
      "   Average fitness: 55.62%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 18.71%\n",
      "   Best individual: 64530a51 with 67.50%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "ðŸ”„ Improvement detected: 0.34% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=18.71)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 64530a51 (fitness: 67.50%)\n",
      "   Elite 2: 0184b592 (fitness: 64.23%)\n",
      "   Elite 3: 58e30ee6 (fitness: 63.98%)\n",
      "   Elite 4: f69f41c9 (fitness: 63.97%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 5\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 5)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 64530a51)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 64530a51 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6613, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6730, acc=52.27% (best=52.27%)\n",
      "          Fold 4 Epoch 1: loss=0.6636, acc=68.28% (best=68.28%)\n",
      "          Fold 1 Epoch 1: loss=0.6793, acc=45.00% (best=45.00%)\n",
      "          Fold 5 Epoch 1: loss=0.7065, acc=45.94% (best=45.94%)\n",
      "          Fold 2 Epoch 5: loss=0.3218, acc=47.97% (best=51.95%)\n",
      "          Fold 3 Epoch 5: loss=0.3409, acc=64.45% (best=64.45%)\n",
      "          Fold 4 Epoch 5: loss=0.3617, acc=46.56% (best=68.28%)\n",
      "          Fold 1 Epoch 5: loss=0.3713, acc=48.20% (best=65.55%)\n",
      "          Fold 5 Epoch 5: loss=0.4262, acc=45.08% (best=61.41%)\n",
      "          Fold 2 Epoch 10: loss=0.2518, acc=56.64% (best=56.64%)\n",
      "          Fold 3 Epoch 10: loss=0.2669, acc=64.69% (best=64.69%)\n",
      "          Fold 4 Epoch 10: loss=0.2683, acc=41.02% (best=68.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2662, acc=53.59% (best=65.55%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.28%\n",
      "          Fold 5 Epoch 10: loss=0.2869, acc=42.34% (best=61.41%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 65.55%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 61.41%\n",
      "          Fold 2 Epoch 15: loss=0.2284, acc=57.97% (best=58.67%)\n",
      "          Fold 3 Epoch 15: loss=0.2465, acc=58.59% (best=64.69%)\n",
      "          Fold 2 Epoch 20: loss=0.2192, acc=57.89% (best=60.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2299, acc=46.09% (best=64.69%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 64.69%\n",
      "          Fold 2 Epoch 25: loss=0.2105, acc=52.50% (best=60.08%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 60.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 64530a51:\n",
      "        Fold accuracies: ['65.55%', '60.08%', '64.69%', '68.28%', '61.41%']\n",
      "        Average fitness: 64.00% Â± 2.94%\n",
      "        Best fold: Fold 4 with 68.28%\n",
      "      New best fitness in this generation: 64.00%!\n",
      "      Fitness obtained: 64.00% | Best in generation: 64.00% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 0184b592)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 0184b592 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6782, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6662, acc=49.84% (best=49.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6793, acc=45.00% (best=45.00%)\n",
      "          Fold 3 Epoch 1: loss=0.6781, acc=46.33% (best=46.33%)\n",
      "          Fold 5 Epoch 1: loss=0.7037, acc=47.73% (best=47.73%)\n",
      "          Fold 1 Epoch 5: loss=0.4656, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 5: loss=0.4160, acc=50.08% (best=56.72%)\n",
      "          Fold 4 Epoch 5: loss=0.4367, acc=55.70% (best=55.70%)\n",
      "          Fold 3 Epoch 5: loss=0.3974, acc=55.08% (best=55.08%)\n",
      "          Fold 2 Epoch 5: loss=0.3939, acc=41.25% (best=49.38%)\n",
      "          Fold 1 Epoch 10: loss=0.3213, acc=54.22% (best=64.14%)\n",
      "          Fold 5 Epoch 10: loss=0.2783, acc=53.75% (best=56.72%)\n",
      "          Fold 4 Epoch 10: loss=0.2993, acc=42.66% (best=61.25%)\n",
      "          Fold 3 Epoch 10: loss=0.3020, acc=52.50% (best=56.02%)\n",
      "          Fold 2 Epoch 10: loss=0.2950, acc=40.39% (best=56.33%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 1 Epoch 15: loss=0.2676, acc=57.27% (best=64.14%)\n",
      "          Fold 4 Epoch 15: loss=0.2590, acc=53.75% (best=61.25%)\n",
      "          Fold 3 Epoch 15: loss=0.2642, acc=55.31% (best=63.20%)\n",
      "          Fold 2 Epoch 15: loss=0.2646, acc=38.52% (best=56.33%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 64.14%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 56.33%\n",
      "          Fold 3 Epoch 20: loss=0.2451, acc=62.66% (best=63.20%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0184b592:\n",
      "        Fold accuracies: ['64.14%', '56.33%', '63.20%', '61.25%', '56.72%']\n",
      "        Average fitness: 60.33% Â± 3.25%\n",
      "        Best fold: Fold 1 with 64.14%\n",
      "      Fitness obtained: 60.33% | Best in generation: 64.00% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 58e30ee6)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 58e30ee6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6768, acc=59.92% (best=59.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6741, acc=39.84% (best=39.84%)\n",
      "          Fold 3 Epoch 1: loss=0.6554, acc=47.03% (best=47.03%)\n",
      "          Fold 5 Epoch 1: loss=0.7030, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6844, acc=52.03% (best=52.03%)\n",
      "          Fold 2 Epoch 5: loss=0.4174, acc=39.61% (best=50.47%)\n",
      "          Fold 4 Epoch 5: loss=0.4912, acc=52.11% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.6195, acc=45.00% (best=52.03%)\n",
      "          Fold 3 Epoch 5: loss=0.4000, acc=47.89% (best=51.41%)\n",
      "          Fold 1 Epoch 5: loss=0.5410, acc=58.67% (best=58.67%)\n",
      "          Fold 2 Epoch 10: loss=0.3085, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 10: loss=0.3560, acc=47.34% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3793, acc=48.91% (best=58.12%)\n",
      "          Fold 3 Epoch 10: loss=0.3324, acc=43.44% (best=62.11%)\n",
      "          Fold 1 Epoch 10: loss=0.3678, acc=47.89% (best=58.67%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 60.86%\n",
      "          Fold 2 Epoch 15: loss=0.2645, acc=54.61% (best=59.92%)\n",
      "          Fold 5 Epoch 15: loss=0.2999, acc=48.28% (best=58.12%)\n",
      "          Fold 3 Epoch 15: loss=0.2847, acc=51.25% (best=62.11%)\n",
      "          Fold 1 Epoch 15: loss=0.2941, acc=49.84% (best=58.67%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 58.67%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 58.12%\n",
      "          Fold 2 Epoch 20: loss=0.2452, acc=56.80% (best=59.92%)\n",
      "          Fold 3 Epoch 20: loss=0.2465, acc=50.78% (best=63.28%)\n",
      "          Fold 2 Epoch 25: loss=0.2302, acc=63.20% (best=67.11%)\n",
      "          Fold 3 Epoch 25: loss=0.2326, acc=54.61% (best=63.28%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 63.28%\n",
      "          Fold 2 Epoch 30: loss=0.2228, acc=53.91% (best=67.11%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 58e30ee6:\n",
      "        Fold accuracies: ['58.67%', '67.11%', '63.28%', '60.86%', '58.12%']\n",
      "        Average fitness: 61.61% Â± 3.30%\n",
      "        Best fold: Fold 2 with 67.11%\n",
      "      Fitness obtained: 61.61% | Best in generation: 64.00% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: f69f41c9)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f69f41c9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6808, acc=37.58% (best=37.58%)\n",
      "          Fold 1 Epoch 1: loss=0.6902, acc=65.23% (best=65.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6624, acc=57.50% (best=57.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7092, acc=48.91% (best=48.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6651, acc=40.55% (best=40.55%)\n",
      "          Fold 2 Epoch 5: loss=0.3729, acc=49.84% (best=63.67%)\n",
      "          Fold 1 Epoch 5: loss=0.4731, acc=53.44% (best=65.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3979, acc=50.08% (best=57.50%)\n",
      "          Fold 3 Epoch 5: loss=0.2842, acc=54.92% (best=62.58%)\n",
      "          Fold 5 Epoch 5: loss=0.4328, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.2680, acc=53.91% (best=63.67%)\n",
      "          Fold 1 Epoch 10: loss=0.2981, acc=53.67% (best=65.23%)\n",
      "          Fold 4 Epoch 10: loss=0.2442, acc=61.88% (best=66.41%)\n",
      "          Fold 3 Epoch 10: loss=0.2283, acc=52.50% (best=62.58%)\n",
      "          Fold 5 Epoch 10: loss=0.2928, acc=53.44% (best=58.44%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 63.67%\n",
      "          Fold 4 Epoch 15: loss=0.2195, acc=60.62% (best=66.41%)\n",
      "          Fold 5 Epoch 15: loss=0.2486, acc=54.53% (best=59.77%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 66.41%\n",
      "          Fold 5 Epoch 20: loss=0.2233, acc=54.38% (best=59.77%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 59.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f69f41c9:\n",
      "        Fold accuracies: ['65.23%', '63.67%', '62.58%', '66.41%', '59.77%']\n",
      "        Average fitness: 63.53% Â± 2.29%\n",
      "        Best fold: Fold 4 with 66.41%\n",
      "      Fitness obtained: 63.53% | Best in generation: 64.00% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 7b867c19)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7b867c19 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6780, acc=47.81% (best=47.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6783, acc=64.22% (best=64.22%)\n",
      "          Fold 4 Epoch 1: loss=0.6646, acc=56.09% (best=56.09%)\n",
      "          Fold 1 Epoch 1: loss=0.6900, acc=53.44% (best=53.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7045, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 5: loss=0.5441, acc=48.59% (best=57.42%)\n",
      "          Fold 3 Epoch 5: loss=0.4548, acc=58.59% (best=65.47%)\n",
      "          Fold 1 Epoch 5: loss=0.5928, acc=50.55% (best=56.17%)\n",
      "          Fold 4 Epoch 5: loss=0.5758, acc=63.67% (best=66.25%)\n",
      "          Fold 5 Epoch 5: loss=0.5809, acc=62.34% (best=62.34%)\n",
      "          Fold 2 Epoch 10: loss=0.3596, acc=42.42% (best=57.42%)\n",
      "          Fold 3 Epoch 10: loss=0.3156, acc=54.14% (best=65.47%)\n",
      "          Fold 1 Epoch 10: loss=0.4640, acc=45.78% (best=56.17%)\n",
      "          Fold 4 Epoch 10: loss=0.4359, acc=63.28% (best=67.97%)\n",
      "          Fold 5 Epoch 10: loss=0.3801, acc=54.45% (best=66.56%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 65.47%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 57.42%\n",
      "          Fold 1 Epoch 15: loss=0.3700, acc=60.16% (best=60.16%)\n",
      "          Fold 4 Epoch 15: loss=0.3280, acc=50.39% (best=67.97%)\n",
      "          Fold 5 Epoch 15: loss=0.2899, acc=45.08% (best=66.56%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.56%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 1 Epoch 20: loss=0.3338, acc=49.30% (best=60.70%)\n",
      "          Fold 1 Epoch 25: loss=0.3075, acc=60.55% (best=64.53%)\n",
      "          Fold 1 Epoch 30: loss=0.2848, acc=60.39% (best=64.53%)\n",
      "          Fold 1 Epoch 35: loss=0.2663, acc=65.31% (best=69.92%)\n",
      "          Fold 1 Epoch 40: loss=0.2471, acc=59.06% (best=70.39%)\n",
      "          Fold 1 Epoch 45: loss=0.2352, acc=68.36% (best=74.69%)\n",
      "          Fold 1 Epoch 50: loss=0.2345, acc=65.31% (best=74.69%)\n",
      "          Fold 1: Early stopping at epoch 52\n",
      "      â†’ Fold 1 completed: 74.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7b867c19:\n",
      "        Fold accuracies: ['74.69%', '57.42%', '65.47%', '67.97%', '66.56%']\n",
      "        Average fitness: 66.42% Â± 5.53%\n",
      "        Best fold: Fold 1 with 74.69%\n",
      "      New best fitness in this generation: 66.42%!\n",
      "      Fitness obtained: 66.42% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 2e10376a)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2e10376a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 2e10376a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 89b34284)\n",
      "      Architecture: 8 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 89b34284 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6896, acc=49.45% (best=49.45%)\n",
      "          Fold 1 Epoch 1: loss=0.7164, acc=54.61% (best=54.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7227, acc=60.23% (best=60.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6781, acc=50.86% (best=50.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7129, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 5: loss=0.3407, acc=52.73% (best=55.86%)\n",
      "          Fold 1 Epoch 5: loss=0.5333, acc=45.62% (best=61.88%)\n",
      "          Fold 5 Epoch 5: loss=0.5677, acc=47.42% (best=60.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3089, acc=51.48% (best=57.66%)\n",
      "          Fold 3 Epoch 5: loss=0.3537, acc=57.34% (best=57.34%)\n",
      "          Fold 2 Epoch 10: loss=0.2720, acc=55.86% (best=55.86%)\n",
      "          Fold 1 Epoch 10: loss=0.3152, acc=53.28% (best=61.88%)\n",
      "          Fold 5 Epoch 10: loss=0.2944, acc=57.42% (best=63.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2526, acc=44.38% (best=57.66%)\n",
      "          Fold 3 Epoch 10: loss=0.2723, acc=56.17% (best=61.80%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 61.88%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 57.66%\n",
      "          Fold 2 Epoch 15: loss=0.2455, acc=54.30% (best=56.17%)\n",
      "          Fold 5 Epoch 15: loss=0.2550, acc=51.09% (best=63.83%)\n",
      "          Fold 3 Epoch 15: loss=0.2431, acc=64.69% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "          Fold 2 Epoch 20: loss=0.2273, acc=47.97% (best=56.17%)\n",
      "          Fold 3 Epoch 20: loss=0.2345, acc=58.05% (best=65.00%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 56.17%\n",
      "          Fold 3 Epoch 25: loss=0.2240, acc=53.28% (best=65.00%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 89b34284:\n",
      "        Fold accuracies: ['61.88%', '56.17%', '65.00%', '57.66%', '63.83%']\n",
      "        Average fitness: 60.91% Â± 3.44%\n",
      "        Best fold: Fold 3 with 65.00%\n",
      "      Fitness obtained: 60.91% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: d98824af)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d98824af with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6901, acc=48.20% (best=48.20%)\n",
      "          Fold 3 Epoch 1: loss=0.7069, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7123, acc=60.78% (best=60.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6791, acc=47.66% (best=47.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7220, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 5: loss=0.4715, acc=41.33% (best=55.78%)\n",
      "          Fold 3 Epoch 5: loss=0.5164, acc=49.30% (best=53.44%)\n",
      "          Fold 1 Epoch 5: loss=0.6295, acc=52.50% (best=60.78%)\n",
      "          Fold 4 Epoch 5: loss=0.5496, acc=47.19% (best=57.97%)\n",
      "          Fold 5 Epoch 5: loss=0.6261, acc=34.84% (best=53.59%)\n",
      "          Fold 2 Epoch 10: loss=0.3647, acc=46.02% (best=59.30%)\n",
      "          Fold 3 Epoch 10: loss=0.3924, acc=51.88% (best=56.88%)\n",
      "          Fold 1 Epoch 10: loss=0.4668, acc=44.45% (best=60.78%)\n",
      "          Fold 4 Epoch 10: loss=0.4310, acc=42.81% (best=59.69%)\n",
      "          Fold 5 Epoch 10: loss=0.4289, acc=50.00% (best=53.59%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.78%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.59%\n",
      "          Fold 2 Epoch 15: loss=0.3096, acc=50.23% (best=59.30%)\n",
      "          Fold 3 Epoch 15: loss=0.3332, acc=58.52% (best=63.59%)\n",
      "          Fold 4 Epoch 15: loss=0.3634, acc=47.27% (best=59.69%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 59.30%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 59.69%\n",
      "          Fold 3 Epoch 20: loss=0.2970, acc=63.28% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d98824af:\n",
      "        Fold accuracies: ['60.78%', '59.30%', '63.59%', '59.69%', '53.59%']\n",
      "        Average fitness: 59.39% Â± 3.26%\n",
      "        Best fold: Fold 3 with 63.59%\n",
      "      Fitness obtained: 59.39% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 2a3883b2)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2a3883b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6878, acc=41.17% (best=41.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6993, acc=49.06% (best=49.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6883, acc=54.30% (best=54.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6732, acc=59.77% (best=59.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7072, acc=49.38% (best=49.38%)\n",
      "          Fold 2 Epoch 5: loss=0.6013, acc=36.95% (best=56.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4661, acc=59.30% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.5805, acc=59.53% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.6976, acc=55.47% (best=55.47%)\n",
      "          Fold 1 Epoch 5: loss=0.5615, acc=50.47% (best=65.31%)\n",
      "          Fold 2 Epoch 10: loss=0.3508, acc=39.30% (best=66.72%)\n",
      "          Fold 3 Epoch 10: loss=0.3374, acc=52.42% (best=59.30%)\n",
      "          Fold 4 Epoch 10: loss=0.4046, acc=55.55% (best=64.84%)\n",
      "          Fold 5 Epoch 10: loss=0.6941, acc=50.70% (best=59.84%)\n",
      "          Fold 1 Epoch 10: loss=0.3845, acc=50.94% (best=65.31%)\n",
      "          Fold 2 Epoch 15: loss=0.2856, acc=47.11% (best=66.72%)\n",
      "          Fold 3 Epoch 15: loss=0.2868, acc=62.81% (best=64.69%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "          Fold 4 Epoch 15: loss=0.3217, acc=48.28% (best=64.84%)\n",
      "          Fold 5 Epoch 15: loss=0.5867, acc=55.78% (best=63.20%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 66.72%\n",
      "          Fold 3 Epoch 20: loss=0.2579, acc=56.17% (best=67.27%)\n",
      "          Fold 5 Epoch 20: loss=0.4122, acc=51.48% (best=63.20%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 3 Epoch 25: loss=0.2412, acc=59.92% (best=67.27%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2a3883b2:\n",
      "        Fold accuracies: ['65.31%', '66.72%', '67.27%', '64.84%', '63.20%']\n",
      "        Average fitness: 65.47% Â± 1.44%\n",
      "        Best fold: Fold 3 with 67.27%\n",
      "      Fitness obtained: 65.47% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: cb715bb6)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cb715bb6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6677, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6672, acc=47.11% (best=47.11%)\n",
      "          Fold 5 Epoch 1: loss=0.6990, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6383, acc=58.59% (best=58.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6391, acc=62.34% (best=62.34%)\n",
      "          Fold 2 Epoch 5: loss=0.3430, acc=52.34% (best=54.30%)\n",
      "          Fold 1 Epoch 5: loss=0.4084, acc=49.92% (best=60.08%)\n",
      "          Fold 5 Epoch 5: loss=0.3775, acc=48.98% (best=58.05%)\n",
      "          Fold 3 Epoch 5: loss=0.3477, acc=57.58% (best=58.59%)\n",
      "          Fold 4 Epoch 5: loss=0.4102, acc=55.47% (best=62.34%)\n",
      "          Fold 2 Epoch 10: loss=0.2664, acc=62.50% (best=65.70%)\n",
      "          Fold 1 Epoch 10: loss=0.2858, acc=53.52% (best=60.08%)\n",
      "          Fold 5 Epoch 10: loss=0.2665, acc=53.52% (best=58.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2692, acc=50.62% (best=68.28%)\n",
      "          Fold 4 Epoch 10: loss=0.3106, acc=49.61% (best=62.34%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.34%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.05%\n",
      "          Fold 2 Epoch 15: loss=0.2396, acc=57.27% (best=65.70%)\n",
      "          Fold 1 Epoch 15: loss=0.2423, acc=60.39% (best=68.83%)\n",
      "          Fold 3 Epoch 15: loss=0.2395, acc=52.34% (best=68.28%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 68.28%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 65.70%\n",
      "          Fold 1 Epoch 20: loss=0.2236, acc=55.00% (best=68.83%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cb715bb6:\n",
      "        Fold accuracies: ['68.83%', '65.70%', '68.28%', '62.34%', '58.05%']\n",
      "        Average fitness: 64.64% Â± 4.02%\n",
      "        Best fold: Fold 1 with 68.83%\n",
      "      Fitness obtained: 64.64% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 9afdd621)\n",
      "      Architecture: 8 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9afdd621 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7163, acc=43.36% (best=43.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7271, acc=56.72% (best=56.72%)\n",
      "          Fold 3 Epoch 1: loss=0.7308, acc=51.41% (best=51.41%)\n",
      "          Fold 4 Epoch 1: loss=0.7142, acc=57.89% (best=57.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7384, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.4886, acc=53.20% (best=53.20%)\n",
      "          Fold 3 Epoch 5: loss=0.5843, acc=42.73% (best=59.14%)\n",
      "          Fold 4 Epoch 5: loss=0.6014, acc=36.56% (best=61.64%)\n",
      "          Fold 1 Epoch 5: loss=0.6223, acc=53.98% (best=60.47%)\n",
      "          Fold 5 Epoch 5: loss=0.6963, acc=51.33% (best=51.33%)\n",
      "          Fold 2 Epoch 10: loss=0.3387, acc=55.23% (best=61.48%)\n",
      "          Fold 3 Epoch 10: loss=0.3466, acc=59.84% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.4422, acc=43.05% (best=61.64%)\n",
      "          Fold 1 Epoch 10: loss=0.4194, acc=54.53% (best=60.47%)\n",
      "          Fold 5 Epoch 10: loss=0.5509, acc=44.92% (best=52.34%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 61.64%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 60.47%\n",
      "          Fold 2 Epoch 15: loss=0.2883, acc=51.64% (best=61.48%)\n",
      "          Fold 3 Epoch 15: loss=0.2845, acc=46.72% (best=59.84%)\n",
      "          Fold 5 Epoch 15: loss=0.4009, acc=56.41% (best=56.41%)\n",
      "          Fold 2 Epoch 20: loss=0.2584, acc=48.98% (best=63.12%)\n",
      "          Fold 3 Epoch 20: loss=0.2522, acc=50.47% (best=59.84%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 59.84%\n",
      "          Fold 5 Epoch 20: loss=0.2939, acc=51.02% (best=56.41%)\n",
      "          Fold 2 Epoch 25: loss=0.2474, acc=54.06% (best=63.12%)\n",
      "          Fold 5 Epoch 25: loss=0.2558, acc=40.23% (best=56.41%)\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 56.41%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 63.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9afdd621:\n",
      "        Fold accuracies: ['60.47%', '63.12%', '59.84%', '61.64%', '56.41%']\n",
      "        Average fitness: 60.30% Â± 2.24%\n",
      "        Best fold: Fold 2 with 63.12%\n",
      "      Fitness obtained: 60.30% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 19f2b985)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 19f2b985 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7066, acc=59.06% (best=59.06%)\n",
      "          Fold 3 Epoch 1: loss=0.6925, acc=46.95% (best=46.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6879, acc=38.36% (best=38.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6720, acc=63.05% (best=63.05%)\n",
      "          Fold 1 Epoch 1: loss=0.6981, acc=62.11% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.3852, acc=49.06% (best=59.06%)\n",
      "          Fold 3 Epoch 5: loss=0.3748, acc=46.25% (best=58.83%)\n",
      "          Fold 2 Epoch 5: loss=0.3829, acc=53.36% (best=56.80%)\n",
      "          Fold 4 Epoch 5: loss=0.4505, acc=61.33% (best=68.67%)\n",
      "          Fold 1 Epoch 5: loss=0.5161, acc=59.61% (best=62.11%)\n",
      "          Fold 3 Epoch 10: loss=0.3007, acc=59.14% (best=59.14%)\n",
      "          Fold 5 Epoch 10: loss=0.2818, acc=50.70% (best=61.72%)\n",
      "          Fold 2 Epoch 10: loss=0.2994, acc=46.09% (best=58.44%)\n",
      "          Fold 4 Epoch 10: loss=0.3089, acc=53.75% (best=68.67%)\n",
      "          Fold 1 Epoch 10: loss=0.3382, acc=60.62% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.67%\n",
      "          Fold 3 Epoch 15: loss=0.2644, acc=46.25% (best=59.14%)\n",
      "          Fold 2 Epoch 15: loss=0.2752, acc=42.89% (best=58.44%)\n",
      "          Fold 5 Epoch 15: loss=0.2525, acc=42.58% (best=61.72%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 58.44%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 61.72%\n",
      "          Fold 3 Epoch 20: loss=0.2492, acc=51.72% (best=59.14%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 59.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 19f2b985:\n",
      "        Fold accuracies: ['62.11%', '58.44%', '59.14%', '68.67%', '61.72%']\n",
      "        Average fitness: 62.02% Â± 3.62%\n",
      "        Best fold: Fold 4 with 68.67%\n",
      "      Fitness obtained: 62.02% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 9d30cb55)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9d30cb55 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6697, acc=61.56% (best=61.56%)\n",
      "          Fold 5 Epoch 1: loss=0.7034, acc=50.31% (best=50.31%)\n",
      "          Fold 1 Epoch 1: loss=0.6813, acc=54.77% (best=54.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6672, acc=58.44% (best=58.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6779, acc=47.34% (best=47.34%)\n",
      "          Fold 3 Epoch 5: loss=0.3807, acc=44.77% (best=61.56%)\n",
      "          Fold 5 Epoch 5: loss=0.4616, acc=49.30% (best=55.47%)\n",
      "          Fold 1 Epoch 5: loss=0.4607, acc=54.30% (best=62.42%)\n",
      "          Fold 4 Epoch 5: loss=0.4204, acc=45.70% (best=62.03%)\n",
      "          Fold 2 Epoch 5: loss=0.3681, acc=54.45% (best=54.45%)\n",
      "          Fold 3 Epoch 10: loss=0.2984, acc=48.20% (best=61.56%)\n",
      "          Fold 5 Epoch 10: loss=0.3367, acc=46.48% (best=55.47%)\n",
      "          Fold 1 Epoch 10: loss=0.3370, acc=59.53% (best=62.42%)\n",
      "          Fold 4 Epoch 10: loss=0.3064, acc=44.06% (best=62.03%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 61.56%\n",
      "          Fold 2 Epoch 10: loss=0.2821, acc=45.47% (best=57.89%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.03%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "          Fold 5 Epoch 15: loss=0.2733, acc=57.73% (best=60.23%)\n",
      "          Fold 2 Epoch 15: loss=0.2538, acc=43.91% (best=57.89%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 57.89%\n",
      "          Fold 5 Epoch 20: loss=0.2582, acc=51.25% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9d30cb55:\n",
      "        Fold accuracies: ['62.42%', '57.89%', '61.56%', '62.03%', '60.23%']\n",
      "        Average fitness: 60.83% Â± 1.64%\n",
      "        Best fold: Fold 1 with 62.42%\n",
      "      Fitness obtained: 60.83% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 4d70e5ef)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 4d70e5ef with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6701, acc=50.16% (best=50.16%)\n",
      "          Fold 2 Epoch 1: loss=0.6736, acc=38.44% (best=38.44%)\n",
      "          Fold 3 Epoch 1: loss=0.6898, acc=62.34% (best=62.34%)\n",
      "          Fold 1 Epoch 1: loss=0.6969, acc=54.38% (best=54.38%)\n",
      "          Fold 5 Epoch 1: loss=0.7166, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 5: loss=0.3561, acc=36.64% (best=48.59%)\n",
      "          Fold 4 Epoch 5: loss=0.4099, acc=66.25% (best=66.25%)\n",
      "          Fold 3 Epoch 5: loss=0.3945, acc=61.80% (best=62.34%)\n",
      "          Fold 1 Epoch 5: loss=0.4485, acc=44.14% (best=54.38%)\n",
      "          Fold 5 Epoch 5: loss=0.4493, acc=53.36% (best=61.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2697, acc=46.33% (best=48.59%)\n",
      "          Fold 4 Epoch 10: loss=0.2959, acc=53.52% (best=66.25%)\n",
      "          Fold 3 Epoch 10: loss=0.3058, acc=47.50% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.3292, acc=42.58% (best=55.00%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 48.59%\n",
      "          Fold 5 Epoch 10: loss=0.2878, acc=56.02% (best=61.48%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 4 Epoch 15: loss=0.2564, acc=37.11% (best=66.25%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.25%\n",
      "          Fold 3 Epoch 15: loss=0.2667, acc=54.69% (best=63.20%)\n",
      "          Fold 1 Epoch 15: loss=0.2726, acc=53.67% (best=55.00%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 55.00%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 63.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4d70e5ef:\n",
      "        Fold accuracies: ['55.00%', '48.59%', '63.20%', '66.25%', '61.48%']\n",
      "        Average fitness: 58.91% Â± 6.33%\n",
      "        Best fold: Fold 4 with 66.25%\n",
      "      Fitness obtained: 58.91% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: b2a98531)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model b2a98531 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7096, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 1: loss=0.6908, acc=36.72% (best=36.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6979, acc=55.47% (best=55.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6820, acc=68.05% (best=68.05%)\n",
      "          Fold 5 Epoch 1: loss=0.7183, acc=70.94% (best=70.94%)\n",
      "          Fold 2 Epoch 5: loss=0.6216, acc=30.70% (best=36.72%)\n",
      "          Fold 3 Epoch 5: loss=0.5844, acc=49.61% (best=57.27%)\n",
      "          Fold 1 Epoch 5: loss=0.6312, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 5: loss=0.5977, acc=58.59% (best=68.05%)\n",
      "          Fold 5 Epoch 5: loss=0.6388, acc=51.33% (best=70.94%)\n",
      "          Fold 2 Epoch 10: loss=0.5063, acc=35.55% (best=42.50%)\n",
      "          Fold 3 Epoch 10: loss=0.4720, acc=44.30% (best=57.27%)\n",
      "          Fold 1 Epoch 10: loss=0.5175, acc=69.84% (best=69.84%)\n",
      "          Fold 4 Epoch 10: loss=0.5033, acc=47.89% (best=68.05%)\n",
      "          Fold 5 Epoch 10: loss=0.5262, acc=43.98% (best=70.94%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 57.27%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 70.94%\n",
      "          Fold 2 Epoch 15: loss=0.4050, acc=35.70% (best=42.50%)\n",
      "          Fold 1 Epoch 15: loss=0.4459, acc=70.23% (best=70.23%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 42.50%\n",
      "          Fold 1 Epoch 20: loss=0.4046, acc=69.84% (best=72.89%)\n",
      "          Fold 1 Epoch 25: loss=0.3839, acc=61.48% (best=72.89%)\n",
      "          Fold 1 Epoch 30: loss=0.3668, acc=67.42% (best=73.05%)\n",
      "          Fold 1 Epoch 35: loss=0.3391, acc=67.97% (best=73.05%)\n",
      "          Fold 1: Early stopping at epoch 37\n",
      "      â†’ Fold 1 completed: 73.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b2a98531:\n",
      "        Fold accuracies: ['73.05%', '42.50%', '57.27%', '68.05%', '70.94%']\n",
      "        Average fitness: 62.36% Â± 11.32%\n",
      "        Best fold: Fold 1 with 73.05%\n",
      "      Fitness obtained: 62.36% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 48bbd7e0)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.1\n",
      "      Training/Evaluating model 48bbd7e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7949, acc=42.89% (best=42.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7709, acc=51.48% (best=51.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7707, acc=52.27% (best=52.27%)\n",
      "          Fold 4 Epoch 1: loss=0.7284, acc=51.25% (best=51.25%)\n",
      "          Fold 1 Epoch 1: loss=0.8044, acc=58.98% (best=58.98%)\n",
      "          Fold 2 Epoch 5: loss=0.6266, acc=40.55% (best=53.52%)\n",
      "          Fold 3 Epoch 5: loss=0.5523, acc=50.94% (best=61.25%)\n",
      "          Fold 5 Epoch 5: loss=0.6963, acc=50.00% (best=51.48%)\n",
      "          Fold 4 Epoch 5: loss=0.5399, acc=54.06% (best=56.48%)\n",
      "          Fold 1 Epoch 5: loss=0.6257, acc=50.39% (best=58.98%)\n",
      "          Fold 2 Epoch 10: loss=0.3893, acc=45.86% (best=54.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3278, acc=58.91% (best=64.30%)\n",
      "          Fold 5 Epoch 10: loss=0.6944, acc=50.00% (best=51.48%)\n",
      "          Fold 4 Epoch 10: loss=0.3402, acc=47.58% (best=59.06%)\n",
      "          Fold 1 Epoch 10: loss=0.4822, acc=55.86% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 51.48%\n",
      "          Fold 2 Epoch 15: loss=0.3022, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 15: loss=0.2907, acc=50.00% (best=64.30%)\n",
      "          Fold 4 Epoch 15: loss=0.2709, acc=53.91% (best=59.06%)\n",
      "          Fold 1 Epoch 15: loss=0.3530, acc=44.84% (best=61.41%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 59.06%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 64.30%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 61.41%\n",
      "          Fold 2 Epoch 20: loss=0.2634, acc=59.30% (best=59.30%)\n",
      "          Fold 2 Epoch 25: loss=0.2554, acc=31.56% (best=59.30%)\n",
      "          Fold 2 Epoch 30: loss=0.2551, acc=43.28% (best=59.30%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 59.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 48bbd7e0:\n",
      "        Fold accuracies: ['61.41%', '59.30%', '64.30%', '59.06%', '51.48%']\n",
      "        Average fitness: 59.11% Â± 4.25%\n",
      "        Best fold: Fold 3 with 64.30%\n",
      "      Fitness obtained: 59.11% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 36e87cf7)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 36e87cf7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6763, acc=46.25% (best=46.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6906, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6796, acc=47.89% (best=47.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6485, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7094, acc=42.42% (best=42.42%)\n",
      "          Fold 2 Epoch 5: loss=0.3766, acc=42.73% (best=58.28%)\n",
      "          Fold 3 Epoch 5: loss=0.3843, acc=50.16% (best=60.62%)\n",
      "          Fold 1 Epoch 5: loss=0.3022, acc=54.22% (best=57.58%)\n",
      "          Fold 4 Epoch 5: loss=0.3417, acc=51.41% (best=71.64%)\n",
      "          Fold 5 Epoch 5: loss=0.3531, acc=46.64% (best=48.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2615, acc=44.53% (best=58.28%)\n",
      "          Fold 3 Epoch 10: loss=0.2674, acc=57.97% (best=60.62%)\n",
      "          Fold 1 Epoch 10: loss=0.2238, acc=54.61% (best=57.58%)\n",
      "          Fold 4 Epoch 10: loss=0.2502, acc=57.11% (best=71.64%)\n",
      "          Fold 5 Epoch 10: loss=0.2475, acc=43.12% (best=56.09%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 58.28%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 57.58%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 71.64%\n",
      "          Fold 3 Epoch 15: loss=0.2342, acc=58.91% (best=62.58%)\n",
      "          Fold 5 Epoch 15: loss=0.2125, acc=46.80% (best=56.09%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 56.09%\n",
      "          Fold 3 Epoch 20: loss=0.2240, acc=55.08% (best=65.31%)\n",
      "          Fold 3 Epoch 25: loss=0.2121, acc=61.64% (best=67.81%)\n",
      "          Fold 3 Epoch 30: loss=0.2084, acc=59.69% (best=67.81%)\n",
      "          Fold 3: Early stopping at epoch 33\n",
      "      â†’ Fold 3 completed: 67.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 36e87cf7:\n",
      "        Fold accuracies: ['57.58%', '58.28%', '67.81%', '71.64%', '56.09%']\n",
      "        Average fitness: 62.28% Â± 6.24%\n",
      "        Best fold: Fold 4 with 71.64%\n",
      "      Fitness obtained: 62.28% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 8431f0b4)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 8431f0b4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6209, acc=54.53% (best=54.53%)\n",
      "          Fold 3 Epoch 1: loss=0.6376, acc=58.91% (best=58.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6507, acc=49.38% (best=49.38%)\n",
      "          Fold 1 Epoch 1: loss=0.6584, acc=58.67% (best=58.67%)\n",
      "          Fold 5 Epoch 1: loss=0.6816, acc=62.27% (best=62.27%)\n",
      "          Fold 2 Epoch 5: loss=0.3277, acc=50.78% (best=63.44%)\n",
      "          Fold 3 Epoch 5: loss=0.3684, acc=50.62% (best=58.91%)\n",
      "          Fold 4 Epoch 5: loss=0.3461, acc=36.41% (best=57.50%)\n",
      "          Fold 1 Epoch 5: loss=0.3765, acc=57.66% (best=59.45%)\n",
      "          Fold 5 Epoch 5: loss=0.3412, acc=56.25% (best=62.27%)\n",
      "          Fold 2 Epoch 10: loss=0.2705, acc=53.83% (best=63.44%)\n",
      "          Fold 3 Epoch 10: loss=0.2873, acc=41.48% (best=58.91%)\n",
      "          Fold 4 Epoch 10: loss=0.2632, acc=45.31% (best=57.50%)\n",
      "          Fold 1 Epoch 10: loss=0.2869, acc=48.67% (best=64.92%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "          Fold 5 Epoch 10: loss=0.2645, acc=51.33% (best=62.27%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 63.44%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.27%\n",
      "          Fold 4 Epoch 15: loss=0.2359, acc=47.73% (best=61.56%)\n",
      "          Fold 1 Epoch 15: loss=0.2535, acc=55.16% (best=64.92%)\n",
      "          Fold 4 Epoch 20: loss=0.2204, acc=48.75% (best=61.56%)\n",
      "          Fold 1 Epoch 20: loss=0.2374, acc=70.62% (best=70.62%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 61.56%\n",
      "          Fold 1 Epoch 25: loss=0.2338, acc=63.83% (best=70.62%)\n",
      "          Fold 1 Epoch 30: loss=0.2184, acc=65.23% (best=70.62%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 70.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8431f0b4:\n",
      "        Fold accuracies: ['70.62%', '63.44%', '58.91%', '61.56%', '62.27%']\n",
      "        Average fitness: 63.36% Â± 3.93%\n",
      "        Best fold: Fold 1 with 70.62%\n",
      "      Fitness obtained: 63.36% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 1f8920bf)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1f8920bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7084, acc=58.05% (best=58.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6800, acc=46.48% (best=46.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7022, acc=48.67% (best=48.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6596, acc=51.25% (best=51.25%)\n",
      "          Fold 1 Epoch 1: loss=0.6727, acc=57.27% (best=57.27%)\n",
      "          Fold 5 Epoch 5: loss=0.4144, acc=54.92% (best=66.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4197, acc=62.66% (best=63.20%)\n",
      "          Fold 2 Epoch 5: loss=0.3526, acc=35.08% (best=46.48%)\n",
      "          Fold 1 Epoch 5: loss=0.4168, acc=55.62% (best=59.45%)\n",
      "          Fold 4 Epoch 5: loss=0.4072, acc=48.52% (best=62.03%)\n",
      "          Fold 2 Epoch 10: loss=0.2870, acc=40.55% (best=47.66%)\n",
      "          Fold 3 Epoch 10: loss=0.3210, acc=56.48% (best=71.95%)\n",
      "          Fold 5 Epoch 10: loss=0.3120, acc=48.28% (best=66.88%)\n",
      "          Fold 1 Epoch 10: loss=0.3006, acc=50.08% (best=59.45%)\n",
      "          Fold 4 Epoch 10: loss=0.2867, acc=55.31% (best=69.38%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 66.88%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 2 Epoch 15: loss=0.2501, acc=35.47% (best=47.66%)\n",
      "          Fold 3 Epoch 15: loss=0.2622, acc=58.05% (best=71.95%)\n",
      "          Fold 4 Epoch 15: loss=0.2424, acc=58.83% (best=69.38%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 71.95%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "          Fold 2 Epoch 20: loss=0.2336, acc=52.58% (best=52.58%)\n",
      "          Fold 2 Epoch 25: loss=0.2216, acc=46.17% (best=52.58%)\n",
      "          Fold 2 Epoch 30: loss=0.2143, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 35: loss=0.2186, acc=45.47% (best=56.09%)\n",
      "          Fold 2 Epoch 40: loss=0.2137, acc=46.88% (best=56.09%)\n",
      "          Fold 2: Early stopping at epoch 40\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1f8920bf:\n",
      "        Fold accuracies: ['59.45%', '56.09%', '71.95%', '69.38%', '66.88%']\n",
      "        Average fitness: 64.75% Â± 6.01%\n",
      "        Best fold: Fold 3 with 71.95%\n",
      "      Fitness obtained: 64.75% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 32624301)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 32624301 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6559, acc=46.17% (best=46.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6396, acc=61.95% (best=61.95%)\n",
      "          Fold 1 Epoch 1: loss=0.6898, acc=44.61% (best=44.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7148, acc=47.66% (best=47.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6656, acc=70.70% (best=70.70%)\n",
      "          Fold 2 Epoch 5: loss=0.2999, acc=36.56% (best=59.45%)\n",
      "          Fold 3 Epoch 5: loss=0.2987, acc=56.80% (best=66.02%)\n",
      "          Fold 1 Epoch 5: loss=0.3829, acc=56.56% (best=56.56%)\n",
      "          Fold 4 Epoch 5: loss=0.3899, acc=59.61% (best=70.70%)\n",
      "          Fold 5 Epoch 5: loss=0.3240, acc=46.33% (best=55.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2465, acc=46.48% (best=59.45%)\n",
      "          Fold 3 Epoch 10: loss=0.2450, acc=57.19% (best=66.02%)\n",
      "          Fold 1 Epoch 10: loss=0.2948, acc=54.53% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.2758, acc=51.72% (best=70.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2541, acc=50.55% (best=55.70%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.02%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 59.45%\n",
      "          Fold 1 Epoch 15: loss=0.2519, acc=44.92% (best=60.08%)\n",
      "          Fold 5 Epoch 15: loss=0.2279, acc=41.09% (best=56.25%)\n",
      "          Fold 1 Epoch 20: loss=0.2291, acc=52.03% (best=60.08%)\n",
      "          Fold 5 Epoch 20: loss=0.2133, acc=40.86% (best=56.25%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 56.25%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 60.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 32624301:\n",
      "        Fold accuracies: ['60.08%', '59.45%', '66.02%', '70.70%', '56.25%']\n",
      "        Average fitness: 62.50% Â± 5.17%\n",
      "        Best fold: Fold 4 with 70.70%\n",
      "      Fitness obtained: 62.50% | Best in generation: 66.42% | Global best: 67.50%\n",
      "\n",
      "GENERATION 5 STATISTICS:\n",
      "   Maximum fitness: 66.42%\n",
      "   Average fitness: 59.14%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 13.73%\n",
      "   Best individual: 7b867c19 with 66.42%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=13.73)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 7b867c19 (fitness: 66.42%)\n",
      "   Elite 2: 2a3883b2 (fitness: 65.47%)\n",
      "   Elite 3: 1f8920bf (fitness: 64.75%)\n",
      "   Elite 4: cb715bb6 (fitness: 64.64%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 6\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 6)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 7b867c19)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7b867c19 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6950, acc=66.64% (best=66.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6679, acc=61.95% (best=61.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7035, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6713, acc=40.62% (best=40.62%)\n",
      "          Fold 1 Epoch 1: loss=0.6878, acc=48.05% (best=48.05%)\n",
      "          Fold 3 Epoch 5: loss=0.5146, acc=50.62% (best=66.64%)\n",
      "          Fold 4 Epoch 5: loss=0.4823, acc=48.36% (best=65.47%)\n",
      "          Fold 2 Epoch 5: loss=0.5460, acc=43.05% (best=48.28%)\n",
      "          Fold 5 Epoch 5: loss=0.4967, acc=49.92% (best=55.23%)\n",
      "          Fold 1 Epoch 5: loss=0.5524, acc=50.31% (best=56.09%)\n",
      "          Fold 3 Epoch 10: loss=0.3362, acc=50.86% (best=66.64%)\n",
      "          Fold 4 Epoch 10: loss=0.2958, acc=44.77% (best=65.47%)\n",
      "          Fold 5 Epoch 10: loss=0.3647, acc=49.14% (best=55.23%)\n",
      "          Fold 2 Epoch 10: loss=0.3687, acc=39.84% (best=48.83%)\n",
      "          Fold 1 Epoch 10: loss=0.4059, acc=56.25% (best=61.25%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 66.64%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.23%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.47%\n",
      "          Fold 2 Epoch 15: loss=0.3051, acc=54.84% (best=54.84%)\n",
      "          Fold 1 Epoch 15: loss=0.3270, acc=56.41% (best=61.25%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 61.25%\n",
      "          Fold 2 Epoch 20: loss=0.2837, acc=53.52% (best=54.84%)\n",
      "          Fold 2 Epoch 25: loss=0.2527, acc=53.83% (best=54.84%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7b867c19:\n",
      "        Fold accuracies: ['61.25%', '54.84%', '66.64%', '65.47%', '55.23%']\n",
      "        Average fitness: 60.69% Â± 4.95%\n",
      "        Best fold: Fold 3 with 66.64%\n",
      "      New best fitness in this generation: 60.69%!\n",
      "      Fitness obtained: 60.69% | Best in generation: 60.69% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 2a3883b2)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2a3883b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6961, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6843, acc=43.05% (best=43.05%)\n",
      "          Fold 1 Epoch 1: loss=0.6907, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 1: loss=0.6724, acc=48.67% (best=48.67%)\n",
      "          Fold 5 Epoch 1: loss=0.7023, acc=56.72% (best=56.72%)\n",
      "          Fold 3 Epoch 5: loss=0.4491, acc=56.95% (best=56.95%)\n",
      "          Fold 2 Epoch 5: loss=0.4769, acc=53.44% (best=62.03%)\n",
      "          Fold 1 Epoch 5: loss=0.5654, acc=49.53% (best=53.44%)\n",
      "          Fold 4 Epoch 5: loss=0.5072, acc=50.31% (best=58.12%)\n",
      "          Fold 5 Epoch 5: loss=0.6370, acc=55.78% (best=56.72%)\n",
      "          Fold 3 Epoch 10: loss=0.3485, acc=55.70% (best=56.95%)\n",
      "          Fold 2 Epoch 10: loss=0.3292, acc=50.39% (best=62.03%)\n",
      "          Fold 1 Epoch 10: loss=0.3851, acc=53.83% (best=57.66%)\n",
      "          Fold 4 Epoch 10: loss=0.3339, acc=49.38% (best=62.66%)\n",
      "          Fold 5 Epoch 10: loss=0.4333, acc=48.91% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 62.03%\n",
      "          Fold 3 Epoch 15: loss=0.3008, acc=58.52% (best=69.38%)\n",
      "          Fold 1 Epoch 15: loss=0.3199, acc=52.66% (best=60.00%)\n",
      "          Fold 4 Epoch 15: loss=0.2692, acc=43.20% (best=62.66%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 62.66%\n",
      "          Fold 5 Epoch 15: loss=0.3292, acc=46.09% (best=59.53%)\n",
      "          Fold 3 Epoch 20: loss=0.2713, acc=67.11% (best=69.38%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 59.53%\n",
      "          Fold 1 Epoch 20: loss=0.2773, acc=62.58% (best=68.44%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 69.38%\n",
      "          Fold 1 Epoch 25: loss=0.2506, acc=50.62% (best=68.44%)\n",
      "          Fold 1 Epoch 30: loss=0.2347, acc=57.66% (best=71.64%)\n",
      "          Fold 1 Epoch 35: loss=0.2295, acc=58.12% (best=71.64%)\n",
      "          Fold 1: Early stopping at epoch 36\n",
      "      â†’ Fold 1 completed: 71.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2a3883b2:\n",
      "        Fold accuracies: ['71.64%', '62.03%', '69.38%', '62.66%', '59.53%']\n",
      "        Average fitness: 65.05% Â± 4.64%\n",
      "        Best fold: Fold 1 with 71.64%\n",
      "      New best fitness in this generation: 65.05%!\n",
      "      Fitness obtained: 65.05% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 1f8920bf)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1f8920bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6827, acc=47.58% (best=47.58%)\n",
      "          Fold 1 Epoch 1: loss=0.6958, acc=49.84% (best=49.84%)\n",
      "          Fold 3 Epoch 1: loss=0.6905, acc=61.09% (best=61.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6579, acc=52.81% (best=52.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7052, acc=63.98% (best=63.98%)\n",
      "          Fold 2 Epoch 5: loss=0.3852, acc=41.88% (best=50.78%)\n",
      "          Fold 3 Epoch 5: loss=0.3776, acc=50.08% (best=61.09%)\n",
      "          Fold 1 Epoch 5: loss=0.4345, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 5: loss=0.4273, acc=44.69% (best=69.61%)\n",
      "          Fold 5 Epoch 5: loss=0.4081, acc=53.05% (best=63.98%)\n",
      "          Fold 2 Epoch 10: loss=0.2888, acc=44.84% (best=50.78%)\n",
      "          Fold 3 Epoch 10: loss=0.2854, acc=50.08% (best=61.09%)\n",
      "          Fold 1 Epoch 10: loss=0.2993, acc=54.38% (best=63.59%)\n",
      "          Fold 4 Epoch 10: loss=0.2946, acc=47.11% (best=69.61%)\n",
      "          Fold 5 Epoch 10: loss=0.2815, acc=48.91% (best=63.98%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 61.09%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 2 Epoch 15: loss=0.2582, acc=44.61% (best=57.27%)\n",
      "          Fold 1 Epoch 15: loss=0.2577, acc=60.08% (best=63.59%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 63.59%\n",
      "          Fold 2 Epoch 20: loss=0.2395, acc=55.86% (best=60.55%)\n",
      "          Fold 2 Epoch 25: loss=0.2286, acc=52.58% (best=65.62%)\n",
      "          Fold 2 Epoch 30: loss=0.2268, acc=46.17% (best=65.62%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 65.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1f8920bf:\n",
      "        Fold accuracies: ['63.59%', '65.62%', '61.09%', '69.61%', '63.98%']\n",
      "        Average fitness: 64.78% Â± 2.82%\n",
      "        Best fold: Fold 4 with 69.61%\n",
      "      Fitness obtained: 64.78% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: cb715bb6)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cb715bb6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6725, acc=46.33% (best=46.33%)\n",
      "          Fold 3 Epoch 1: loss=0.6734, acc=54.77% (best=54.77%)\n",
      "          Fold 2 Epoch 1: loss=0.6271, acc=46.64% (best=46.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6364, acc=62.27% (best=62.27%)\n",
      "          Fold 5 Epoch 1: loss=0.6583, acc=62.19% (best=62.19%)\n",
      "          Fold 3 Epoch 5: loss=0.3655, acc=50.70% (best=54.77%)\n",
      "          Fold 1 Epoch 5: loss=0.4252, acc=62.42% (best=63.36%)\n",
      "          Fold 2 Epoch 5: loss=0.3124, acc=54.61% (best=57.81%)\n",
      "          Fold 4 Epoch 5: loss=0.3661, acc=46.02% (best=62.27%)\n",
      "          Fold 5 Epoch 5: loss=0.3435, acc=44.84% (best=62.19%)\n",
      "          Fold 3 Epoch 10: loss=0.2814, acc=41.17% (best=55.00%)\n",
      "          Fold 2 Epoch 10: loss=0.2482, acc=55.08% (best=57.81%)\n",
      "          Fold 1 Epoch 10: loss=0.3057, acc=70.47% (best=70.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2753, acc=47.42% (best=62.27%)\n",
      "          Fold 5 Epoch 10: loss=0.2592, acc=41.72% (best=62.19%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.27%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 3 Epoch 15: loss=0.2409, acc=52.11% (best=58.67%)\n",
      "          Fold 1 Epoch 15: loss=0.2490, acc=69.30% (best=70.86%)\n",
      "          Fold 3 Epoch 20: loss=0.2206, acc=54.61% (best=58.67%)\n",
      "          Fold 1 Epoch 20: loss=0.2294, acc=69.69% (best=73.91%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 58.67%\n",
      "          Fold 1 Epoch 25: loss=0.2233, acc=64.38% (best=73.91%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 73.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cb715bb6:\n",
      "        Fold accuracies: ['73.91%', '57.81%', '58.67%', '62.27%', '62.19%']\n",
      "        Average fitness: 62.97% Â± 5.76%\n",
      "        Best fold: Fold 1 with 73.91%\n",
      "      Fitness obtained: 62.97% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: a230ae4a)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model a230ae4a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6150, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6246, acc=41.33% (best=41.33%)\n",
      "          Fold 5 Epoch 1: loss=0.6912, acc=52.81% (best=52.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6377, acc=54.22% (best=54.22%)\n",
      "          Fold 1 Epoch 1: loss=0.6822, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 5: loss=0.2962, acc=57.03% (best=59.84%)\n",
      "          Fold 2 Epoch 5: loss=0.3052, acc=43.52% (best=55.62%)\n",
      "          Fold 5 Epoch 5: loss=0.3289, acc=50.70% (best=55.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3249, acc=53.52% (best=65.31%)\n",
      "          Fold 1 Epoch 5: loss=0.3909, acc=58.44% (best=58.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2377, acc=50.08% (best=59.84%)\n",
      "          Fold 2 Epoch 10: loss=0.2480, acc=41.02% (best=55.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2624, acc=54.22% (best=55.62%)\n",
      "          Fold 3 Epoch 10: loss=0.2552, acc=54.30% (best=68.36%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 59.84%\n",
      "          Fold 1 Epoch 10: loss=0.2754, acc=62.11% (best=68.36%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 55.62%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 55.62%\n",
      "          Fold 3 Epoch 15: loss=0.2274, acc=59.06% (best=68.36%)\n",
      "          Fold 1 Epoch 15: loss=0.2404, acc=67.03% (best=68.36%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 68.36%\n",
      "          Fold 1 Epoch 20: loss=0.2262, acc=54.61% (best=71.80%)\n",
      "          Fold 1 Epoch 25: loss=0.2198, acc=70.31% (best=71.80%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 71.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a230ae4a:\n",
      "        Fold accuracies: ['71.80%', '55.62%', '68.36%', '59.84%', '55.62%']\n",
      "        Average fitness: 62.25% Â± 6.66%\n",
      "        Best fold: Fold 1 with 71.80%\n",
      "      Fitness obtained: 62.25% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: eabfa98c)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eabfa98c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6598, acc=47.03% (best=47.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6975, acc=45.08% (best=45.08%)\n",
      "          Fold 1 Epoch 1: loss=0.6842, acc=46.95% (best=46.95%)\n",
      "          Fold 4 Epoch 1: loss=0.6494, acc=42.42% (best=42.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6619, acc=59.14% (best=59.14%)\n",
      "          Fold 2 Epoch 5: loss=0.3389, acc=56.80% (best=60.23%)\n",
      "          Fold 5 Epoch 5: loss=0.3738, acc=47.27% (best=56.41%)\n",
      "          Fold 1 Epoch 5: loss=0.4406, acc=48.98% (best=65.39%)\n",
      "          Fold 4 Epoch 5: loss=0.3678, acc=52.58% (best=59.61%)\n",
      "          Fold 3 Epoch 5: loss=0.3904, acc=57.97% (best=59.14%)\n",
      "          Fold 2 Epoch 10: loss=0.2614, acc=50.16% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.2859, acc=54.77% (best=65.39%)\n",
      "          Fold 5 Epoch 10: loss=0.2698, acc=40.00% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.2483, acc=48.83% (best=62.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2935, acc=50.16% (best=59.45%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 65.39%\n",
      "          Fold 2 Epoch 15: loss=0.2410, acc=46.41% (best=63.20%)\n",
      "          Fold 5 Epoch 15: loss=0.2364, acc=44.69% (best=57.03%)\n",
      "          Fold 4 Epoch 15: loss=0.2226, acc=57.19% (best=62.97%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 63.20%\n",
      "          Fold 3 Epoch 15: loss=0.2523, acc=47.34% (best=65.55%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "          Fold 3 Epoch 20: loss=0.2339, acc=35.16% (best=65.55%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 65.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eabfa98c:\n",
      "        Fold accuracies: ['65.39%', '63.20%', '65.55%', '62.97%', '57.03%']\n",
      "        Average fitness: 62.83% Â± 3.09%\n",
      "        Best fold: Fold 3 with 65.55%\n",
      "      Fitness obtained: 62.83% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 8f581f55)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 8f581f55 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6973, acc=49.38% (best=49.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6898, acc=49.45% (best=49.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6750, acc=57.19% (best=57.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6998, acc=49.92% (best=49.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7201, acc=45.39% (best=45.39%)\n",
      "          Fold 2 Epoch 5: loss=0.4102, acc=42.81% (best=54.06%)\n",
      "          Fold 3 Epoch 5: loss=0.3710, acc=53.59% (best=57.27%)\n",
      "          Fold 4 Epoch 5: loss=0.3576, acc=54.84% (best=57.19%)\n",
      "          Fold 1 Epoch 5: loss=0.3954, acc=57.19% (best=57.19%)\n",
      "          Fold 5 Epoch 5: loss=0.4051, acc=47.19% (best=54.14%)\n",
      "          Fold 2 Epoch 10: loss=0.2747, acc=54.14% (best=54.14%)\n",
      "          Fold 3 Epoch 10: loss=0.2757, acc=46.56% (best=57.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2536, acc=55.78% (best=57.19%)\n",
      "          Fold 1 Epoch 10: loss=0.2826, acc=60.62% (best=60.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2806, acc=52.81% (best=60.86%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 57.19%\n",
      "          Fold 2 Epoch 15: loss=0.2421, acc=46.64% (best=54.14%)\n",
      "          Fold 3 Epoch 15: loss=0.2402, acc=46.56% (best=57.89%)\n",
      "          Fold 1 Epoch 15: loss=0.2456, acc=59.30% (best=60.62%)\n",
      "          Fold 5 Epoch 15: loss=0.2369, acc=59.06% (best=60.86%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 57.89%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 60.86%\n",
      "          Fold 2 Epoch 20: loss=0.2243, acc=48.05% (best=59.38%)\n",
      "          Fold 1 Epoch 20: loss=0.2180, acc=53.59% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 60.62%\n",
      "          Fold 2 Epoch 25: loss=0.2139, acc=53.28% (best=61.25%)\n",
      "          Fold 2 Epoch 30: loss=0.2148, acc=49.92% (best=61.25%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 61.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8f581f55:\n",
      "        Fold accuracies: ['60.62%', '61.25%', '57.89%', '57.19%', '60.86%']\n",
      "        Average fitness: 59.56% Â± 1.68%\n",
      "        Best fold: Fold 2 with 61.25%\n",
      "      Fitness obtained: 59.56% | Best in generation: 65.05% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: b152dfee)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b152dfee with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6699, acc=51.72% (best=51.72%)\n",
      "          Fold 2 Epoch 1: loss=0.6523, acc=34.61% (best=34.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6608, acc=63.52% (best=63.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6782, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.6865, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 5: loss=0.3027, acc=55.78% (best=55.78%)\n",
      "          Fold 1 Epoch 5: loss=0.4090, acc=42.11% (best=62.11%)\n",
      "          Fold 4 Epoch 5: loss=0.3654, acc=65.00% (best=68.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3399, acc=53.52% (best=65.16%)\n",
      "          Fold 5 Epoch 5: loss=0.3497, acc=48.75% (best=55.31%)\n",
      "          Fold 2 Epoch 10: loss=0.2496, acc=56.56% (best=60.23%)\n",
      "          Fold 1 Epoch 10: loss=0.2726, acc=48.28% (best=62.11%)\n",
      "          Fold 4 Epoch 10: loss=0.2548, acc=46.72% (best=68.91%)\n",
      "          Fold 3 Epoch 10: loss=0.2602, acc=63.12% (best=65.16%)\n",
      "          Fold 5 Epoch 10: loss=0.2588, acc=50.94% (best=55.31%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.31%\n",
      "          Fold 2 Epoch 15: loss=0.2159, acc=60.31% (best=63.05%)\n",
      "          Fold 3 Epoch 15: loss=0.2301, acc=54.53% (best=70.08%)\n",
      "          Fold 2 Epoch 20: loss=0.2101, acc=59.92% (best=65.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2182, acc=58.75% (best=70.08%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 70.08%\n",
      "          Fold 2 Epoch 25: loss=0.2036, acc=50.55% (best=66.25%)\n",
      "          Fold 2 Epoch 30: loss=0.2015, acc=56.95% (best=78.20%)\n",
      "          Fold 2 Epoch 35: loss=0.1983, acc=69.45% (best=78.20%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 78.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b152dfee:\n",
      "        Fold accuracies: ['62.11%', '78.20%', '70.08%', '68.91%', '55.31%']\n",
      "        Average fitness: 66.92% Â± 7.73%\n",
      "        Best fold: Fold 2 with 78.20%\n",
      "      New best fitness in this generation: 66.92%!\n",
      "      Fitness obtained: 66.92% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: ecaf761a)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model ecaf761a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7019, acc=48.59% (best=48.59%)\n",
      "          Fold 2 Epoch 1: loss=0.6886, acc=46.72% (best=46.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6655, acc=59.77% (best=59.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7035, acc=55.16% (best=55.16%)\n",
      "          Fold 1 Epoch 1: loss=0.6950, acc=56.95% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.4072, acc=56.80% (best=56.80%)\n",
      "          Fold 2 Epoch 5: loss=0.3659, acc=51.33% (best=54.06%)\n",
      "          Fold 4 Epoch 5: loss=0.3635, acc=56.80% (best=60.94%)\n",
      "          Fold 5 Epoch 5: loss=0.4908, acc=51.02% (best=55.16%)\n",
      "          Fold 1 Epoch 5: loss=0.5607, acc=53.83% (best=59.77%)\n",
      "          Fold 3 Epoch 10: loss=0.2790, acc=55.55% (best=56.80%)\n",
      "          Fold 2 Epoch 10: loss=0.2621, acc=53.83% (best=64.38%)\n",
      "          Fold 4 Epoch 10: loss=0.2606, acc=49.61% (best=60.94%)\n",
      "          Fold 5 Epoch 10: loss=0.3246, acc=42.42% (best=55.16%)\n",
      "          Fold 1 Epoch 10: loss=0.3261, acc=55.08% (best=62.19%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.16%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 60.94%\n",
      "          Fold 3 Epoch 15: loss=0.2470, acc=45.94% (best=56.80%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 56.80%\n",
      "          Fold 2 Epoch 15: loss=0.2430, acc=57.11% (best=64.38%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 64.38%\n",
      "          Fold 1 Epoch 15: loss=0.2663, acc=49.06% (best=62.19%)\n",
      "          Fold 1 Epoch 20: loss=0.2456, acc=60.31% (best=63.05%)\n",
      "          Fold 1 Epoch 25: loss=0.2287, acc=56.80% (best=63.05%)\n",
      "          Fold 1 Epoch 30: loss=0.2210, acc=67.11% (best=67.11%)\n",
      "          Fold 1 Epoch 35: loss=0.2178, acc=53.52% (best=67.11%)\n",
      "          Fold 1 Epoch 40: loss=0.2112, acc=63.20% (best=67.11%)\n",
      "          Fold 1: Early stopping at epoch 40\n",
      "      â†’ Fold 1 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ecaf761a:\n",
      "        Fold accuracies: ['67.11%', '64.38%', '56.80%', '60.94%', '55.16%']\n",
      "        Average fitness: 60.88% Â± 4.48%\n",
      "        Best fold: Fold 1 with 67.11%\n",
      "      Fitness obtained: 60.88% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 9df8a01c)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9df8a01c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6871, acc=37.19% (best=37.19%)\n",
      "          Fold 3 Epoch 1: loss=0.6872, acc=56.64% (best=56.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6541, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=0.6814, acc=63.83% (best=63.83%)\n",
      "          Fold 5 Epoch 1: loss=0.6968, acc=48.20% (best=48.20%)\n",
      "          Fold 2 Epoch 5: loss=0.3606, acc=40.39% (best=47.11%)\n",
      "          Fold 3 Epoch 5: loss=0.3895, acc=61.64% (best=61.64%)\n",
      "          Fold 4 Epoch 5: loss=0.4240, acc=38.20% (best=65.47%)\n",
      "          Fold 1 Epoch 5: loss=0.4366, acc=54.77% (best=63.83%)\n",
      "          Fold 5 Epoch 5: loss=0.3436, acc=50.47% (best=52.03%)\n",
      "          Fold 2 Epoch 10: loss=0.2799, acc=42.11% (best=50.78%)\n",
      "          Fold 3 Epoch 10: loss=0.2831, acc=63.59% (best=65.78%)\n",
      "          Fold 4 Epoch 10: loss=0.3080, acc=48.59% (best=65.47%)\n",
      "          Fold 1 Epoch 10: loss=0.3139, acc=60.78% (best=63.83%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 63.83%\n",
      "          Fold 5 Epoch 10: loss=0.2659, acc=43.05% (best=52.03%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.47%\n",
      "          Fold 2 Epoch 15: loss=0.2497, acc=48.28% (best=53.44%)\n",
      "          Fold 3 Epoch 15: loss=0.2592, acc=54.06% (best=65.78%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 52.03%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 65.78%\n",
      "          Fold 2 Epoch 20: loss=0.2327, acc=53.83% (best=55.78%)\n",
      "          Fold 2 Epoch 25: loss=0.2240, acc=52.11% (best=55.78%)\n",
      "          Fold 2 Epoch 30: loss=0.2183, acc=56.48% (best=59.06%)\n",
      "          Fold 2 Epoch 35: loss=0.2141, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 40: loss=0.2101, acc=55.23% (best=60.16%)\n",
      "          Fold 2 Epoch 45: loss=0.2105, acc=53.28% (best=60.16%)\n",
      "          Fold 2: Early stopping at epoch 45\n",
      "      â†’ Fold 2 completed: 60.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9df8a01c:\n",
      "        Fold accuracies: ['63.83%', '60.16%', '65.78%', '65.47%', '52.03%']\n",
      "        Average fitness: 61.45% Â± 5.12%\n",
      "        Best fold: Fold 3 with 65.78%\n",
      "      Fitness obtained: 61.45% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: dd02eb21)\n",
      "      Architecture: 8 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model dd02eb21 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7013, acc=45.55% (best=45.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6660, acc=52.11% (best=52.11%)\n",
      "          Fold 2 Epoch 1: loss=0.6699, acc=37.89% (best=37.89%)\n",
      "          Fold 1 Epoch 1: loss=0.6855, acc=61.88% (best=61.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7071, acc=55.31% (best=55.31%)\n",
      "          Fold 3 Epoch 5: loss=0.3664, acc=54.61% (best=62.11%)\n",
      "          Fold 4 Epoch 5: loss=0.4006, acc=47.11% (best=66.09%)\n",
      "          Fold 1 Epoch 5: loss=0.4341, acc=57.50% (best=61.88%)\n",
      "          Fold 2 Epoch 5: loss=0.3379, acc=40.16% (best=55.62%)\n",
      "          Fold 5 Epoch 5: loss=0.4308, acc=57.50% (best=60.62%)\n",
      "          Fold 3 Epoch 10: loss=0.2682, acc=51.33% (best=62.11%)\n",
      "          Fold 4 Epoch 10: loss=0.2787, acc=59.45% (best=66.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2669, acc=53.44% (best=55.62%)\n",
      "          Fold 1 Epoch 10: loss=0.2969, acc=55.23% (best=61.88%)\n",
      "          Fold 5 Epoch 10: loss=0.2678, acc=36.95% (best=60.62%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.09%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 62.11%\n",
      "          Fold 2 Epoch 15: loss=0.2353, acc=53.05% (best=57.19%)\n",
      "          Fold 1 Epoch 15: loss=0.2499, acc=54.38% (best=62.11%)\n",
      "          Fold 2 Epoch 20: loss=0.2143, acc=55.78% (best=65.23%)\n",
      "          Fold 1 Epoch 20: loss=0.2314, acc=47.81% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 2 Epoch 25: loss=0.2095, acc=70.55% (best=70.55%)\n",
      "          Fold 2 Epoch 30: loss=0.2049, acc=56.09% (best=70.55%)\n",
      "          Fold 2 Epoch 35: loss=0.2030, acc=58.83% (best=70.55%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 70.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dd02eb21:\n",
      "        Fold accuracies: ['62.11%', '70.55%', '62.11%', '66.09%', '60.62%']\n",
      "        Average fitness: 64.30% Â± 3.62%\n",
      "        Best fold: Fold 2 with 70.55%\n",
      "      Fitness obtained: 64.30% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: fcf286bd)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model fcf286bd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7283, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7534, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7016, acc=58.12% (best=58.12%)\n",
      "          Fold 1 Epoch 1: loss=0.7367, acc=57.03% (best=57.03%)\n",
      "          Fold 3 Epoch 1: loss=0.7465, acc=50.08% (best=50.08%)\n",
      "          Fold 2 Epoch 5: loss=0.5398, acc=56.17% (best=56.17%)\n",
      "          Fold 5 Epoch 5: loss=0.7048, acc=50.55% (best=58.59%)\n",
      "          Fold 4 Epoch 5: loss=0.5352, acc=49.30% (best=58.12%)\n",
      "          Fold 1 Epoch 5: loss=0.6894, acc=68.52% (best=68.52%)\n",
      "          Fold 3 Epoch 5: loss=0.5107, acc=43.28% (best=50.08%)\n",
      "          Fold 2 Epoch 10: loss=0.3536, acc=53.28% (best=59.84%)\n",
      "          Fold 5 Epoch 10: loss=0.5495, acc=55.23% (best=58.59%)\n",
      "          Fold 4 Epoch 10: loss=0.3454, acc=53.05% (best=58.12%)\n",
      "          Fold 1 Epoch 10: loss=0.5515, acc=48.52% (best=68.52%)\n",
      "          Fold 3 Epoch 10: loss=0.3564, acc=43.52% (best=53.75%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 58.12%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.59%\n",
      "          Fold 2 Epoch 15: loss=0.2966, acc=62.42% (best=62.42%)\n",
      "          Fold 1 Epoch 15: loss=0.3842, acc=49.45% (best=68.52%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 68.52%\n",
      "          Fold 3 Epoch 15: loss=0.3005, acc=44.84% (best=59.30%)\n",
      "          Fold 2 Epoch 20: loss=0.2653, acc=58.98% (best=65.16%)\n",
      "          Fold 3 Epoch 20: loss=0.2724, acc=50.86% (best=59.30%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 59.30%\n",
      "          Fold 2 Epoch 25: loss=0.2454, acc=66.02% (best=71.56%)\n",
      "          Fold 2 Epoch 30: loss=0.2383, acc=57.50% (best=71.56%)\n",
      "          Fold 2 Epoch 35: loss=0.2275, acc=65.94% (best=73.20%)\n",
      "          Fold 2 Epoch 40: loss=0.2236, acc=59.69% (best=73.20%)\n",
      "          Fold 2: Early stopping at epoch 41\n",
      "      â†’ Fold 2 completed: 73.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fcf286bd:\n",
      "        Fold accuracies: ['68.52%', '73.20%', '59.30%', '58.12%', '58.59%']\n",
      "        Average fitness: 63.55% Â± 6.16%\n",
      "        Best fold: Fold 2 with 73.20%\n",
      "      Fitness obtained: 63.55% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 4bfa61c6)\n",
      "      Architecture: 10 conv + 1 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 4bfa61c6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7217, acc=60.86% (best=60.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7092, acc=52.89% (best=52.89%)\n",
      "          Fold 1 Epoch 1: loss=0.7004, acc=61.88% (best=61.88%)\n",
      "          Fold 2 Epoch 1: loss=0.7063, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6850, acc=64.53% (best=64.53%)\n",
      "          Fold 3 Epoch 5: loss=0.6905, acc=65.62% (best=69.30%)\n",
      "          Fold 2 Epoch 5: loss=0.6712, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 5: loss=0.6839, acc=62.19% (best=62.19%)\n",
      "          Fold 5 Epoch 5: loss=0.6977, acc=59.45% (best=59.45%)\n",
      "          Fold 4 Epoch 5: loss=0.6669, acc=68.12% (best=69.22%)\n",
      "          Fold 2 Epoch 10: loss=0.6526, acc=55.86% (best=58.20%)\n",
      "          Fold 3 Epoch 10: loss=0.6715, acc=55.94% (best=69.30%)\n",
      "          Fold 1 Epoch 10: loss=0.6771, acc=62.03% (best=62.19%)\n",
      "          Fold 5 Epoch 10: loss=0.6832, acc=56.72% (best=60.08%)\n",
      "          Fold 4 Epoch 10: loss=0.6489, acc=62.89% (best=69.22%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 69.30%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 69.22%\n",
      "          Fold 2 Epoch 15: loss=0.6477, acc=55.23% (best=58.20%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 58.20%\n",
      "          Fold 1 Epoch 15: loss=0.6714, acc=61.88% (best=62.19%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 62.19%\n",
      "          Fold 5 Epoch 15: loss=0.6696, acc=56.33% (best=60.08%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4bfa61c6:\n",
      "        Fold accuracies: ['62.19%', '58.20%', '69.30%', '69.22%', '60.08%']\n",
      "        Average fitness: 63.80% Â± 4.63%\n",
      "        Best fold: Fold 3 with 69.30%\n",
      "      Fitness obtained: 63.80% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 27180b05)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 27180b05 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7151, acc=48.28% (best=48.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6617, acc=63.83% (best=63.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6617, acc=51.48% (best=51.48%)\n",
      "          Fold 1 Epoch 1: loss=0.6954, acc=53.20% (best=53.20%)\n",
      "          Fold 2 Epoch 1: loss=0.6867, acc=42.58% (best=42.58%)\n",
      "          Fold 2 Epoch 5: loss=0.3407, acc=29.77% (best=51.88%)\n",
      "          Fold 3 Epoch 5: loss=0.3189, acc=62.42% (best=63.83%)\n",
      "          Fold 4 Epoch 5: loss=0.3264, acc=52.58% (best=60.08%)\n",
      "          Fold 1 Epoch 5: loss=0.3696, acc=53.91% (best=53.91%)\n",
      "          Fold 5 Epoch 5: loss=0.3442, acc=46.48% (best=55.00%)\n",
      "          Fold 2 Epoch 10: loss=0.2542, acc=40.78% (best=53.98%)\n",
      "          Fold 3 Epoch 10: loss=0.2578, acc=52.58% (best=63.83%)\n",
      "          Fold 1 Epoch 10: loss=0.2617, acc=50.39% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2363, acc=57.89% (best=63.52%)\n",
      "          Fold 5 Epoch 10: loss=0.2498, acc=49.92% (best=55.00%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 63.83%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.00%\n",
      "          Fold 2 Epoch 15: loss=0.2306, acc=31.95% (best=53.98%)\n",
      "          Fold 1 Epoch 15: loss=0.2346, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 15: loss=0.2157, acc=50.94% (best=63.52%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 53.98%\n",
      "          Fold 1 Epoch 20: loss=0.2182, acc=51.56% (best=66.80%)\n",
      "          Fold 1 Epoch 25: loss=0.2092, acc=61.56% (best=66.80%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 66.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 27180b05:\n",
      "        Fold accuracies: ['66.80%', '53.98%', '63.83%', '63.52%', '55.00%']\n",
      "        Average fitness: 60.62% Â± 5.15%\n",
      "        Best fold: Fold 1 with 66.80%\n",
      "      Fitness obtained: 60.62% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 4ee90395)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 4ee90395 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6889, acc=56.88% (best=56.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6847, acc=67.97% (best=67.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6561, acc=48.91% (best=48.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6964, acc=49.45% (best=49.45%)\n",
      "          Fold 5 Epoch 1: loss=0.7142, acc=58.59% (best=58.59%)\n",
      "          Fold 4 Epoch 5: loss=0.3546, acc=56.80% (best=56.80%)\n",
      "          Fold 1 Epoch 5: loss=0.3779, acc=44.53% (best=67.97%)\n",
      "          Fold 5 Epoch 5: loss=0.3409, acc=55.47% (best=65.62%)\n",
      "          Fold 2 Epoch 5: loss=0.3743, acc=54.92% (best=58.12%)\n",
      "          Fold 3 Epoch 5: loss=0.3637, acc=55.47% (best=55.94%)\n",
      "          Fold 4 Epoch 10: loss=0.2665, acc=50.39% (best=56.80%)\n",
      "          Fold 1 Epoch 10: loss=0.2743, acc=51.17% (best=67.97%)\n",
      "          Fold 5 Epoch 10: loss=0.2597, acc=56.25% (best=65.62%)\n",
      "          Fold 2 Epoch 10: loss=0.2717, acc=53.44% (best=58.12%)\n",
      "          Fold 3 Epoch 10: loss=0.2660, acc=60.62% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 67.97%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 4 Epoch 15: loss=0.2331, acc=53.05% (best=60.86%)\n",
      "          Fold 2 Epoch 15: loss=0.2388, acc=60.16% (best=61.64%)\n",
      "          Fold 3 Epoch 15: loss=0.2397, acc=56.88% (best=60.62%)\n",
      "          Fold 4 Epoch 20: loss=0.2222, acc=50.00% (best=60.86%)\n",
      "          Fold 2 Epoch 20: loss=0.2247, acc=65.70% (best=66.41%)\n",
      "          Fold 3 Epoch 20: loss=0.2286, acc=56.72% (best=60.62%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 60.62%\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 60.86%\n",
      "          Fold 2 Epoch 25: loss=0.2190, acc=50.94% (best=66.64%)\n",
      "          Fold 2 Epoch 30: loss=0.2154, acc=56.17% (best=66.64%)\n",
      "          Fold 2 Epoch 35: loss=0.2031, acc=56.95% (best=69.30%)\n",
      "          Fold 2 Epoch 40: loss=0.2050, acc=60.70% (best=69.30%)\n",
      "          Fold 2: Early stopping at epoch 41\n",
      "      â†’ Fold 2 completed: 69.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4ee90395:\n",
      "        Fold accuracies: ['67.97%', '69.30%', '60.62%', '60.86%', '65.62%']\n",
      "        Average fitness: 64.88% Â± 3.57%\n",
      "        Best fold: Fold 2 with 69.30%\n",
      "      Fitness obtained: 64.88% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 70088d3f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 70088d3f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6822, acc=37.81% (best=37.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6724, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=0.7022, acc=53.28% (best=53.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6570, acc=41.64% (best=41.64%)\n",
      "          Fold 5 Epoch 1: loss=0.6963, acc=56.25% (best=56.25%)\n",
      "          Fold 2 Epoch 5: loss=0.3404, acc=47.97% (best=53.67%)\n",
      "          Fold 3 Epoch 5: loss=0.3794, acc=56.80% (best=59.06%)\n",
      "          Fold 1 Epoch 5: loss=0.4079, acc=61.17% (best=64.61%)\n",
      "          Fold 4 Epoch 5: loss=0.3810, acc=55.55% (best=67.81%)\n",
      "          Fold 5 Epoch 5: loss=0.3902, acc=44.77% (best=57.27%)\n",
      "          Fold 2 Epoch 10: loss=0.2627, acc=51.33% (best=55.16%)\n",
      "          Fold 3 Epoch 10: loss=0.3081, acc=58.36% (best=59.06%)\n",
      "          Fold 1 Epoch 10: loss=0.2812, acc=65.94% (best=76.56%)\n",
      "          Fold 4 Epoch 10: loss=0.2613, acc=49.38% (best=67.81%)\n",
      "          Fold 5 Epoch 10: loss=0.2758, acc=42.58% (best=57.27%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 59.06%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.81%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 57.27%\n",
      "          Fold 2 Epoch 15: loss=0.2393, acc=53.12% (best=66.56%)\n",
      "          Fold 1 Epoch 15: loss=0.2428, acc=58.05% (best=76.56%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 76.56%\n",
      "          Fold 2 Epoch 20: loss=0.2198, acc=50.55% (best=66.56%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 66.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 70088d3f:\n",
      "        Fold accuracies: ['76.56%', '66.56%', '59.06%', '67.81%', '57.27%']\n",
      "        Average fitness: 65.45% Â± 6.90%\n",
      "        Best fold: Fold 1 with 76.56%\n",
      "      Fitness obtained: 65.45% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: bae8f747)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bae8f747 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6590, acc=54.06% (best=54.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6930, acc=54.38% (best=54.38%)\n",
      "          Fold 3 Epoch 1: loss=0.7008, acc=49.53% (best=49.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7047, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 1: loss=0.6612, acc=45.39% (best=45.39%)\n",
      "          Fold 4 Epoch 5: loss=0.4910, acc=39.84% (best=61.17%)\n",
      "          Fold 1 Epoch 5: loss=0.4900, acc=49.92% (best=58.36%)\n",
      "          Fold 3 Epoch 5: loss=0.4073, acc=60.08% (best=60.08%)\n",
      "          Fold 5 Epoch 5: loss=0.4991, acc=55.00% (best=60.08%)\n",
      "          Fold 2 Epoch 5: loss=0.3613, acc=48.12% (best=49.77%)\n",
      "          Fold 4 Epoch 10: loss=0.2906, acc=53.91% (best=61.17%)\n",
      "          Fold 1 Epoch 10: loss=0.3511, acc=48.20% (best=58.36%)\n",
      "          Fold 3 Epoch 10: loss=0.3004, acc=59.30% (best=61.95%)\n",
      "          Fold 5 Epoch 10: loss=0.2904, acc=39.45% (best=60.08%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 58.36%\n",
      "          Fold 2 Epoch 10: loss=0.2753, acc=51.64% (best=51.80%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 61.17%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.08%\n",
      "          Fold 3 Epoch 15: loss=0.2623, acc=58.83% (best=61.95%)\n",
      "          Fold 2 Epoch 15: loss=0.2472, acc=48.91% (best=55.86%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 61.95%\n",
      "          Fold 2 Epoch 20: loss=0.2341, acc=36.25% (best=55.86%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bae8f747:\n",
      "        Fold accuracies: ['58.36%', '55.86%', '61.95%', '61.17%', '60.08%']\n",
      "        Average fitness: 59.48% Â± 2.18%\n",
      "        Best fold: Fold 3 with 61.95%\n",
      "      Fitness obtained: 59.48% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 598660df)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 598660df with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6737, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6711, acc=56.88% (best=56.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6908, acc=56.64% (best=56.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6664, acc=52.19% (best=52.19%)\n",
      "          Fold 5 Epoch 1: loss=0.6923, acc=47.81% (best=47.81%)\n",
      "          Fold 2 Epoch 5: loss=0.3361, acc=46.88% (best=56.09%)\n",
      "          Fold 3 Epoch 5: loss=0.4232, acc=48.98% (best=56.64%)\n",
      "          Fold 1 Epoch 5: loss=0.3589, acc=38.75% (best=56.88%)\n",
      "          Fold 4 Epoch 5: loss=0.4400, acc=54.53% (best=63.59%)\n",
      "          Fold 5 Epoch 5: loss=0.3103, acc=53.52% (best=53.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2657, acc=44.30% (best=56.09%)\n",
      "          Fold 3 Epoch 10: loss=0.3120, acc=55.00% (best=63.36%)\n",
      "          Fold 1 Epoch 10: loss=0.2678, acc=47.42% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2811, acc=54.53% (best=63.59%)\n",
      "          Fold 5 Epoch 10: loss=0.2497, acc=56.56% (best=58.83%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.88%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 63.59%\n",
      "          Fold 3 Epoch 15: loss=0.2555, acc=57.19% (best=63.36%)\n",
      "          Fold 5 Epoch 15: loss=0.2231, acc=44.22% (best=58.83%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 58.83%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 63.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 598660df:\n",
      "        Fold accuracies: ['56.88%', '56.09%', '63.36%', '63.59%', '58.83%']\n",
      "        Average fitness: 59.75% Â± 3.17%\n",
      "        Best fold: Fold 4 with 63.59%\n",
      "      Fitness obtained: 59.75% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: a3fcf664)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model a3fcf664 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6509, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 1: loss=0.6639, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6827, acc=50.62% (best=50.62%)\n",
      "          Fold 2 Epoch 1: loss=0.6676, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7028, acc=56.33% (best=56.33%)\n",
      "          Fold 4 Epoch 5: loss=0.2953, acc=57.81% (best=67.03%)\n",
      "          Fold 1 Epoch 5: loss=0.3223, acc=55.70% (best=55.70%)\n",
      "          Fold 3 Epoch 5: loss=0.3303, acc=60.39% (best=60.39%)\n",
      "          Fold 2 Epoch 5: loss=0.2980, acc=58.98% (best=62.42%)\n",
      "          Fold 5 Epoch 5: loss=0.3372, acc=49.69% (best=58.91%)\n",
      "          Fold 4 Epoch 10: loss=0.2380, acc=55.23% (best=67.11%)\n",
      "          Fold 3 Epoch 10: loss=0.2557, acc=61.64% (best=68.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2590, acc=59.69% (best=59.69%)\n",
      "          Fold 2 Epoch 10: loss=0.2620, acc=64.45% (best=64.45%)\n",
      "          Fold 5 Epoch 10: loss=0.2585, acc=40.78% (best=58.91%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.91%\n",
      "          Fold 3 Epoch 15: loss=0.2334, acc=50.23% (best=68.28%)\n",
      "          Fold 4 Epoch 15: loss=0.2158, acc=51.41% (best=67.11%)\n",
      "          Fold 1 Epoch 15: loss=0.2345, acc=58.83% (best=69.45%)\n",
      "          Fold 2 Epoch 15: loss=0.2293, acc=52.73% (best=64.45%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 64.45%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 68.28%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "          Fold 1 Epoch 20: loss=0.2160, acc=68.91% (best=69.45%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 69.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a3fcf664:\n",
      "        Fold accuracies: ['69.45%', '64.45%', '68.28%', '67.11%', '58.91%']\n",
      "        Average fitness: 65.64% Â± 3.75%\n",
      "        Best fold: Fold 1 with 69.45%\n",
      "      Fitness obtained: 65.64% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 964a35da)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 964a35da with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6759, acc=52.19% (best=52.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6712, acc=58.91% (best=58.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6409, acc=70.08% (best=70.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6618, acc=47.58% (best=47.58%)\n",
      "          Fold 5 Epoch 1: loss=0.6827, acc=47.34% (best=47.34%)\n",
      "          Fold 2 Epoch 5: loss=0.3327, acc=55.94% (best=67.11%)\n",
      "          Fold 3 Epoch 5: loss=0.3573, acc=52.42% (best=60.55%)\n",
      "          Fold 4 Epoch 5: loss=0.3166, acc=54.22% (best=70.08%)\n",
      "          Fold 1 Epoch 5: loss=0.3774, acc=56.33% (best=58.91%)\n",
      "          Fold 5 Epoch 5: loss=0.3771, acc=48.36% (best=58.91%)\n",
      "          Fold 2 Epoch 10: loss=0.2820, acc=64.14% (best=67.11%)\n",
      "          Fold 3 Epoch 10: loss=0.2746, acc=50.39% (best=60.55%)\n",
      "          Fold 4 Epoch 10: loss=0.2458, acc=59.69% (best=70.08%)\n",
      "          Fold 1 Epoch 10: loss=0.2613, acc=63.59% (best=65.94%)\n",
      "          Fold 5 Epoch 10: loss=0.2747, acc=57.11% (best=62.11%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.08%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 67.11%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 60.55%\n",
      "          Fold 1 Epoch 15: loss=0.2362, acc=60.16% (best=68.75%)\n",
      "          Fold 5 Epoch 15: loss=0.2435, acc=56.56% (best=62.11%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 62.11%\n",
      "          Fold 1 Epoch 20: loss=0.2201, acc=66.72% (best=70.94%)\n",
      "          Fold 1 Epoch 25: loss=0.2183, acc=59.61% (best=70.94%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 70.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 964a35da:\n",
      "        Fold accuracies: ['70.94%', '67.11%', '60.55%', '70.08%', '62.11%']\n",
      "        Average fitness: 66.16% Â± 4.17%\n",
      "        Best fold: Fold 1 with 70.94%\n",
      "      Fitness obtained: 66.16% | Best in generation: 66.92% | Global best: 67.50%\n",
      "\n",
      "GENERATION 6 STATISTICS:\n",
      "   Maximum fitness: 66.92%\n",
      "   Average fitness: 63.05%\n",
      "   Minimum fitness: 59.48%\n",
      "   Standard deviation: 2.29%\n",
      "   Best individual: b152dfee with 66.92%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "Adaptive mutation rate updated to 0.3583 (std_fitness=2.29)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: b152dfee (fitness: 66.92%)\n",
      "   Elite 2: 964a35da (fitness: 66.16%)\n",
      "   Elite 3: a3fcf664 (fitness: 65.64%)\n",
      "   Elite 4: 70088d3f (fitness: 65.45%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 7\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 7)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: b152dfee)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b152dfee with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6876, acc=52.81% (best=52.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6773, acc=57.81% (best=57.81%)\n",
      "          Fold 1 Epoch 1: loss=0.6785, acc=49.06% (best=49.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6580, acc=50.94% (best=50.94%)\n",
      "          Fold 5 Epoch 1: loss=0.7051, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 5: loss=0.3756, acc=34.69% (best=52.81%)\n",
      "          Fold 3 Epoch 5: loss=0.3165, acc=53.05% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4332, acc=54.92% (best=54.92%)\n",
      "          Fold 4 Epoch 5: loss=0.3295, acc=57.27% (best=65.31%)\n",
      "          Fold 5 Epoch 5: loss=0.3460, acc=48.59% (best=58.98%)\n",
      "          Fold 2 Epoch 10: loss=0.2686, acc=47.58% (best=55.16%)\n",
      "          Fold 3 Epoch 10: loss=0.2499, acc=56.25% (best=61.33%)\n",
      "          Fold 1 Epoch 10: loss=0.2777, acc=39.77% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.2528, acc=60.31% (best=65.31%)\n",
      "          Fold 5 Epoch 10: loss=0.2619, acc=55.00% (best=58.98%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.31%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 2 Epoch 15: loss=0.2343, acc=47.50% (best=55.16%)\n",
      "          Fold 3 Epoch 15: loss=0.2297, acc=47.11% (best=62.58%)\n",
      "          Fold 1 Epoch 15: loss=0.2397, acc=58.05% (best=59.84%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 55.16%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 59.84%\n",
      "          Fold 3 Epoch 20: loss=0.2178, acc=52.89% (best=62.58%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b152dfee:\n",
      "        Fold accuracies: ['59.84%', '55.16%', '62.58%', '65.31%', '58.98%']\n",
      "        Average fitness: 60.38% Â± 3.43%\n",
      "        Best fold: Fold 4 with 65.31%\n",
      "      New best fitness in this generation: 60.38%!\n",
      "      Fitness obtained: 60.38% | Best in generation: 60.38% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 964a35da)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 964a35da with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6235, acc=52.50% (best=52.50%)\n",
      "          Fold 4 Epoch 1: loss=0.6499, acc=64.45% (best=64.45%)\n",
      "          Fold 1 Epoch 1: loss=0.6741, acc=46.25% (best=46.25%)\n",
      "          Fold 3 Epoch 1: loss=0.6346, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.6898, acc=33.44% (best=33.44%)\n",
      "          Fold 2 Epoch 5: loss=0.3281, acc=44.53% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.3596, acc=41.17% (best=62.19%)\n",
      "          Fold 4 Epoch 5: loss=0.3925, acc=56.25% (best=65.00%)\n",
      "          Fold 1 Epoch 5: loss=0.3807, acc=60.86% (best=62.58%)\n",
      "          Fold 5 Epoch 5: loss=0.3774, acc=48.75% (best=54.92%)\n",
      "          Fold 2 Epoch 10: loss=0.2698, acc=41.72% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.2777, acc=47.42% (best=62.19%)\n",
      "          Fold 4 Epoch 10: loss=0.2943, acc=60.70% (best=65.00%)\n",
      "          Fold 1 Epoch 10: loss=0.2827, acc=64.38% (best=72.11%)\n",
      "          Fold 5 Epoch 10: loss=0.2649, acc=46.41% (best=54.92%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.19%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.00%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 56.95%\n",
      "          Fold 1 Epoch 15: loss=0.2451, acc=56.25% (best=72.11%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 72.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 964a35da:\n",
      "        Fold accuracies: ['72.11%', '56.95%', '62.19%', '65.00%', '54.92%']\n",
      "        Average fitness: 62.23% Â± 6.11%\n",
      "        Best fold: Fold 1 with 72.11%\n",
      "      New best fitness in this generation: 62.23%!\n",
      "      Fitness obtained: 62.23% | Best in generation: 62.23% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: a3fcf664)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model a3fcf664 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6504, acc=57.89% (best=57.89%)\n",
      "          Fold 3 Epoch 1: loss=0.6774, acc=52.42% (best=52.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6792, acc=44.53% (best=44.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6455, acc=62.11% (best=62.11%)\n",
      "          Fold 5 Epoch 1: loss=0.6753, acc=56.95% (best=56.95%)\n",
      "          Fold 2 Epoch 5: loss=0.3180, acc=66.48% (best=66.48%)\n",
      "          Fold 3 Epoch 5: loss=0.3343, acc=69.45% (best=69.45%)\n",
      "          Fold 1 Epoch 5: loss=0.3467, acc=47.34% (best=53.59%)\n",
      "          Fold 4 Epoch 5: loss=0.2943, acc=50.31% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.3113, acc=47.66% (best=56.95%)\n",
      "          Fold 2 Epoch 10: loss=0.2652, acc=47.42% (best=66.48%)\n",
      "          Fold 3 Epoch 10: loss=0.2543, acc=59.45% (best=69.45%)\n",
      "          Fold 1 Epoch 10: loss=0.2590, acc=60.00% (best=62.11%)\n",
      "          Fold 4 Epoch 10: loss=0.2343, acc=54.06% (best=63.91%)\n",
      "          Fold 5 Epoch 10: loss=0.2396, acc=50.39% (best=57.66%)\n",
      "          Fold 2 Epoch 15: loss=0.2335, acc=52.34% (best=66.48%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "          Fold 3 Epoch 15: loss=0.2332, acc=62.42% (best=69.45%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 69.45%\n",
      "          Fold 1 Epoch 15: loss=0.2334, acc=61.95% (best=64.69%)\n",
      "          Fold 4 Epoch 15: loss=0.2197, acc=42.73% (best=63.91%)\n",
      "          Fold 5 Epoch 15: loss=0.2255, acc=45.39% (best=57.66%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 63.91%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 1 Epoch 20: loss=0.2182, acc=52.66% (best=64.69%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a3fcf664:\n",
      "        Fold accuracies: ['64.69%', '66.48%', '69.45%', '63.91%', '57.66%']\n",
      "        Average fitness: 64.44% Â± 3.89%\n",
      "        Best fold: Fold 3 with 69.45%\n",
      "      New best fitness in this generation: 64.44%!\n",
      "      Fitness obtained: 64.44% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 70088d3f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 70088d3f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6786, acc=57.42% (best=57.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6928, acc=42.73% (best=42.73%)\n",
      "          Fold 1 Epoch 1: loss=0.6761, acc=47.73% (best=47.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6719, acc=51.25% (best=51.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7082, acc=50.55% (best=50.55%)\n",
      "          Fold 2 Epoch 5: loss=0.3733, acc=51.41% (best=57.42%)\n",
      "          Fold 3 Epoch 5: loss=0.3905, acc=46.09% (best=52.89%)\n",
      "          Fold 1 Epoch 5: loss=0.4814, acc=52.89% (best=58.36%)\n",
      "          Fold 4 Epoch 5: loss=0.4101, acc=49.84% (best=65.00%)\n",
      "          Fold 5 Epoch 5: loss=0.4064, acc=48.05% (best=58.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2779, acc=55.94% (best=59.92%)\n",
      "          Fold 3 Epoch 10: loss=0.3026, acc=56.72% (best=56.72%)\n",
      "          Fold 1 Epoch 10: loss=0.3154, acc=40.31% (best=58.36%)\n",
      "          Fold 4 Epoch 10: loss=0.2735, acc=54.84% (best=65.00%)\n",
      "          Fold 5 Epoch 10: loss=0.2927, acc=53.91% (best=58.52%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 65.00%\n",
      "          Fold 2 Epoch 15: loss=0.2400, acc=58.67% (best=59.92%)\n",
      "          Fold 3 Epoch 15: loss=0.2573, acc=56.56% (best=56.72%)\n",
      "          Fold 1 Epoch 15: loss=0.2650, acc=52.50% (best=58.59%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 3 Epoch 20: loss=0.2423, acc=63.91% (best=63.91%)\n",
      "          Fold 1 Epoch 20: loss=0.2412, acc=55.39% (best=61.64%)\n",
      "          Fold 3 Epoch 25: loss=0.2299, acc=49.22% (best=63.91%)\n",
      "          Fold 1 Epoch 25: loss=0.2296, acc=47.11% (best=61.64%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 61.64%\n",
      "          Fold 3 Epoch 30: loss=0.2187, acc=61.80% (best=63.91%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 63.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 70088d3f:\n",
      "        Fold accuracies: ['61.64%', '59.92%', '63.91%', '65.00%', '58.52%']\n",
      "        Average fitness: 61.80% Â± 2.41%\n",
      "        Best fold: Fold 4 with 65.00%\n",
      "      Fitness obtained: 61.80% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 103abc6b)\n",
      "      Architecture: 22 conv + 4 fc, opt=adam, lr=1e-05\n",
      "      Training/Evaluating model 103abc6b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 203, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 103abc6b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 800277b3)\n",
      "      Architecture: 12 conv + 10 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 800277b3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 832, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1899, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7327, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7141, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7328, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6829, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 5: loss=0.6213, acc=48.98% (best=49.22%)\n",
      "          Fold 5 Epoch 5: loss=0.7018, acc=50.00% (best=50.23%)\n",
      "          Fold 2 Epoch 10: loss=0.5596, acc=40.94% (best=50.39%)\n",
      "          Fold 4 Epoch 10: loss=0.5627, acc=49.30% (best=49.92%)\n",
      "          Fold 5 Epoch 10: loss=0.7006, acc=50.00% (best=50.23%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.39%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 50.23%\n",
      "          Fold 4 Epoch 15: loss=0.5122, acc=49.53% (best=49.92%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 49.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 800277b3:\n",
      "        Fold accuracies: ['0.00%', '50.39%', '0.00%', '49.92%', '50.23%']\n",
      "        Average fitness: 30.11% Â± 24.58%\n",
      "        Best fold: Fold 2 with 50.39%\n",
      "      Fitness obtained: 30.11% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: f4aed4d1)\n",
      "      Architecture: 26 conv + 9 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model f4aed4d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 18, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for f4aed4d1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: bf0f6fbb)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bf0f6fbb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6781, acc=43.98% (best=43.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6989, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6695, acc=66.72% (best=66.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6925, acc=53.20% (best=53.20%)\n",
      "          Fold 5 Epoch 1: loss=0.6998, acc=45.08% (best=45.08%)\n",
      "          Fold 2 Epoch 5: loss=0.4366, acc=41.64% (best=56.33%)\n",
      "          Fold 3 Epoch 5: loss=0.4098, acc=52.97% (best=57.34%)\n",
      "          Fold 1 Epoch 5: loss=0.5294, acc=47.66% (best=59.69%)\n",
      "          Fold 5 Epoch 5: loss=0.5297, acc=58.20% (best=62.81%)\n",
      "          Fold 4 Epoch 5: loss=0.4659, acc=69.30% (best=69.30%)\n",
      "          Fold 2 Epoch 10: loss=0.3225, acc=49.53% (best=56.33%)\n",
      "          Fold 3 Epoch 10: loss=0.3246, acc=46.80% (best=57.34%)\n",
      "          Fold 1 Epoch 10: loss=0.3682, acc=57.58% (best=59.69%)\n",
      "          Fold 5 Epoch 10: loss=0.3613, acc=50.00% (best=66.95%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 56.33%\n",
      "          Fold 4 Epoch 10: loss=0.3279, acc=37.34% (best=69.30%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 59.69%\n",
      "          Fold 3 Epoch 15: loss=0.2824, acc=60.94% (best=63.36%)\n",
      "          Fold 5 Epoch 15: loss=0.3145, acc=60.16% (best=66.95%)\n",
      "          Fold 4 Epoch 15: loss=0.2636, acc=57.42% (best=69.30%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 66.95%\n",
      "          Fold 3 Epoch 20: loss=0.2573, acc=47.34% (best=63.36%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 63.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bf0f6fbb:\n",
      "        Fold accuracies: ['59.69%', '56.33%', '63.36%', '69.30%', '66.95%']\n",
      "        Average fitness: 63.12% Â± 4.71%\n",
      "        Best fold: Fold 4 with 69.30%\n",
      "      Fitness obtained: 63.12% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 29411d33)\n",
      "      Architecture: 8 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 29411d33 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6958, acc=51.80% (best=51.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7069, acc=60.23% (best=60.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6786, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 1: loss=0.7139, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7274, acc=58.20% (best=58.20%)\n",
      "          Fold 3 Epoch 5: loss=0.3358, acc=53.44% (best=60.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3584, acc=55.70% (best=62.27%)\n",
      "          Fold 2 Epoch 5: loss=0.3342, acc=54.69% (best=58.36%)\n",
      "          Fold 5 Epoch 5: loss=0.3978, acc=59.45% (best=59.45%)\n",
      "          Fold 1 Epoch 5: loss=0.4466, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 10: loss=0.2592, acc=47.19% (best=60.23%)\n",
      "          Fold 4 Epoch 10: loss=0.2534, acc=52.66% (best=62.27%)\n",
      "          Fold 2 Epoch 10: loss=0.2734, acc=50.55% (best=58.36%)\n",
      "          Fold 5 Epoch 10: loss=0.2758, acc=61.25% (best=61.25%)\n",
      "          Fold 1 Epoch 10: loss=0.3026, acc=55.39% (best=60.47%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 60.23%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 58.36%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 62.27%\n",
      "          Fold 5 Epoch 15: loss=0.2502, acc=62.89% (best=64.92%)\n",
      "          Fold 1 Epoch 15: loss=0.2607, acc=48.28% (best=68.44%)\n",
      "          Fold 5 Epoch 20: loss=0.2324, acc=67.58% (best=67.58%)\n",
      "          Fold 1 Epoch 20: loss=0.2394, acc=53.36% (best=71.33%)\n",
      "          Fold 5 Epoch 25: loss=0.2202, acc=61.33% (best=67.58%)\n",
      "          Fold 1 Epoch 25: loss=0.2297, acc=54.77% (best=71.33%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 71.33%\n",
      "          Fold 5 Epoch 30: loss=0.2103, acc=59.61% (best=67.58%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 29411d33:\n",
      "        Fold accuracies: ['71.33%', '58.36%', '60.23%', '62.27%', '67.58%']\n",
      "        Average fitness: 63.95% Â± 4.81%\n",
      "        Best fold: Fold 1 with 71.33%\n",
      "      Fitness obtained: 63.95% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 2824c5a9)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2824c5a9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6929, acc=37.81% (best=37.81%)\n",
      "          Fold 3 Epoch 1: loss=0.7060, acc=50.70% (best=50.70%)\n",
      "          Fold 1 Epoch 1: loss=0.6994, acc=53.20% (best=53.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6791, acc=59.69% (best=59.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7225, acc=46.09% (best=46.09%)\n",
      "          Fold 2 Epoch 5: loss=0.4406, acc=41.88% (best=55.08%)\n",
      "          Fold 3 Epoch 5: loss=0.4780, acc=48.67% (best=54.14%)\n",
      "          Fold 4 Epoch 5: loss=0.5254, acc=55.31% (best=62.27%)\n",
      "          Fold 1 Epoch 5: loss=0.5939, acc=54.92% (best=54.92%)\n",
      "          Fold 5 Epoch 5: loss=0.5407, acc=52.73% (best=52.73%)\n",
      "          Fold 2 Epoch 10: loss=0.3558, acc=50.62% (best=59.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3651, acc=48.83% (best=56.72%)\n",
      "          Fold 4 Epoch 10: loss=0.3904, acc=53.52% (best=62.27%)\n",
      "          Fold 1 Epoch 10: loss=0.4048, acc=53.59% (best=59.38%)\n",
      "          Fold 5 Epoch 10: loss=0.4167, acc=45.08% (best=65.55%)\n",
      "          Fold 2 Epoch 15: loss=0.3152, acc=50.31% (best=59.45%)\n",
      "          Fold 3 Epoch 15: loss=0.3199, acc=58.67% (best=58.67%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 62.27%\n",
      "          Fold 1 Epoch 15: loss=0.3450, acc=54.61% (best=59.38%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 59.45%\n",
      "          Fold 5 Epoch 15: loss=0.3632, acc=60.39% (best=65.55%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 59.38%\n",
      "          Fold 3 Epoch 20: loss=0.2882, acc=46.33% (best=58.67%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 65.55%\n",
      "          Fold 3 Epoch 25: loss=0.2635, acc=55.78% (best=58.91%)\n",
      "          Fold 3 Epoch 30: loss=0.2574, acc=55.78% (best=58.91%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2824c5a9:\n",
      "        Fold accuracies: ['59.38%', '59.45%', '58.91%', '62.27%', '65.55%']\n",
      "        Average fitness: 61.11% Â± 2.52%\n",
      "        Best fold: Fold 5 with 65.55%\n",
      "      Fitness obtained: 61.11% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: dd1c6e7d)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model dd1c6e7d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6693, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6736, acc=62.50% (best=62.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7039, acc=59.61% (best=59.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6483, acc=61.72% (best=61.72%)\n",
      "          Fold 3 Epoch 5: loss=0.3367, acc=69.06% (best=69.06%)\n",
      "          Fold 1 Epoch 5: loss=0.3197, acc=65.16% (best=65.16%)\n",
      "          Fold 5 Epoch 5: loss=0.2975, acc=45.47% (best=60.70%)\n",
      "          Fold 4 Epoch 5: loss=0.2946, acc=59.92% (best=64.84%)\n",
      "          Fold 3 Epoch 10: loss=0.2500, acc=64.45% (best=69.06%)\n",
      "          Fold 1 Epoch 10: loss=0.2444, acc=62.50% (best=65.16%)\n",
      "          Fold 4 Epoch 10: loss=0.2266, acc=53.05% (best=64.84%)\n",
      "          Fold 5 Epoch 10: loss=0.2361, acc=41.72% (best=60.70%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 60.70%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 3 Epoch 15: loss=0.2342, acc=58.44% (best=69.22%)\n",
      "          Fold 1 Epoch 15: loss=0.2226, acc=63.36% (best=67.50%)\n",
      "          Fold 3 Epoch 20: loss=0.2210, acc=61.72% (best=69.22%)\n",
      "          Fold 1 Epoch 20: loss=0.2151, acc=66.95% (best=72.73%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 69.22%\n",
      "          Fold 1 Epoch 25: loss=0.2092, acc=68.12% (best=72.73%)\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 72.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dd1c6e7d:\n",
      "        Fold accuracies: ['72.73%', '0.00%', '69.22%', '64.84%', '60.70%']\n",
      "        Average fitness: 53.50% Â± 27.05%\n",
      "        Best fold: Fold 1 with 72.73%\n",
      "      Fitness obtained: 53.50% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 62f1611f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 62f1611f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6802, acc=59.14% (best=59.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6437, acc=63.36% (best=63.36%)\n",
      "          Fold 2 Epoch 1: loss=0.6651, acc=36.72% (best=36.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7047, acc=56.56% (best=56.56%)\n",
      "          Fold 3 Epoch 1: loss=0.6671, acc=42.50% (best=42.50%)\n",
      "          Fold 4 Epoch 5: loss=0.3473, acc=67.03% (best=72.27%)\n",
      "          Fold 5 Epoch 5: loss=0.3585, acc=50.31% (best=57.50%)\n",
      "          Fold 2 Epoch 5: loss=0.3387, acc=42.34% (best=49.61%)\n",
      "          Fold 1 Epoch 5: loss=0.3800, acc=48.05% (best=59.14%)\n",
      "          Fold 3 Epoch 5: loss=0.3448, acc=61.56% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.2549, acc=56.17% (best=72.27%)\n",
      "          Fold 5 Epoch 10: loss=0.2547, acc=47.19% (best=57.50%)\n",
      "          Fold 2 Epoch 10: loss=0.2643, acc=51.56% (best=51.88%)\n",
      "          Fold 1 Epoch 10: loss=0.2564, acc=50.70% (best=59.14%)\n",
      "          Fold 3 Epoch 10: loss=0.2531, acc=54.92% (best=61.56%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.14%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 72.27%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 57.50%\n",
      "          Fold 2 Epoch 15: loss=0.2331, acc=60.86% (best=60.86%)\n",
      "          Fold 3 Epoch 15: loss=0.2330, acc=56.56% (best=61.56%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 61.56%\n",
      "          Fold 2 Epoch 20: loss=0.2236, acc=60.78% (best=66.48%)\n",
      "          Fold 2 Epoch 25: loss=0.2080, acc=59.53% (best=66.48%)\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 66.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 62f1611f:\n",
      "        Fold accuracies: ['59.14%', '66.48%', '61.56%', '72.27%', '57.50%']\n",
      "        Average fitness: 63.39% Â± 5.37%\n",
      "        Best fold: Fold 4 with 72.27%\n",
      "      Fitness obtained: 63.39% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 681cc6dd)\n",
      "      Architecture: 8 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 681cc6dd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6679, acc=48.59% (best=48.59%)\n",
      "          Fold 3 Epoch 1: loss=0.6823, acc=47.19% (best=47.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6890, acc=52.19% (best=52.19%)\n",
      "          Fold 4 Epoch 1: loss=0.6448, acc=53.98% (best=53.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7039, acc=51.56% (best=51.56%)\n",
      "          Fold 2 Epoch 5: loss=0.3896, acc=60.70% (best=60.70%)\n",
      "          Fold 3 Epoch 5: loss=0.4342, acc=55.16% (best=55.16%)\n",
      "          Fold 1 Epoch 5: loss=0.4096, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.4542, acc=51.09% (best=64.22%)\n",
      "          Fold 5 Epoch 5: loss=0.4574, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 10: loss=0.2876, acc=56.88% (best=60.70%)\n",
      "          Fold 3 Epoch 10: loss=0.3393, acc=51.95% (best=55.16%)\n",
      "          Fold 4 Epoch 10: loss=0.3072, acc=54.38% (best=64.22%)\n",
      "          Fold 1 Epoch 10: loss=0.2896, acc=46.64% (best=56.48%)\n",
      "          Fold 5 Epoch 10: loss=0.3053, acc=46.33% (best=56.88%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 64.22%\n",
      "          Fold 2 Epoch 15: loss=0.2532, acc=52.27% (best=68.75%)\n",
      "          Fold 3 Epoch 15: loss=0.2899, acc=43.36% (best=57.42%)\n",
      "          Fold 1 Epoch 15: loss=0.2445, acc=45.39% (best=56.48%)\n",
      "          Fold 5 Epoch 15: loss=0.2535, acc=45.08% (best=56.88%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 56.48%\n",
      "          Fold 2 Epoch 20: loss=0.2300, acc=55.94% (best=68.75%)\n",
      "          Fold 3 Epoch 20: loss=0.2482, acc=56.80% (best=60.47%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "          Fold 3 Epoch 25: loss=0.2362, acc=50.00% (best=61.09%)\n",
      "          Fold 3 Epoch 30: loss=0.2261, acc=38.44% (best=61.09%)\n",
      "          Fold 3 Epoch 35: loss=0.2132, acc=54.38% (best=63.59%)\n",
      "          Fold 3 Epoch 40: loss=0.2122, acc=59.38% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 42\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 681cc6dd:\n",
      "        Fold accuracies: ['56.48%', '68.75%', '63.59%', '64.22%', '56.88%']\n",
      "        Average fitness: 61.98% Â± 4.68%\n",
      "        Best fold: Fold 2 with 68.75%\n",
      "      Fitness obtained: 61.98% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 6dc69e7d)\n",
      "      Architecture: 28 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6dc69e7d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6dc69e7d:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: f7daabd4)\n",
      "      Architecture: 8 conv + 4 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model f7daabd4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 220, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6599, acc=37.50% (best=37.50%)\n",
      "          Fold 3 Epoch 1: loss=0.6621, acc=57.89% (best=57.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6381, acc=65.86% (best=65.86%)\n",
      "          Fold 1 Epoch 1: loss=0.6793, acc=60.16% (best=60.16%)\n",
      "          Fold 5 Epoch 1: loss=0.6689, acc=47.50% (best=47.50%)\n",
      "          Fold 2 Epoch 5: loss=0.3137, acc=39.61% (best=54.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3158, acc=59.92% (best=59.92%)\n",
      "          Fold 1 Epoch 5: loss=0.3663, acc=48.52% (best=60.16%)\n",
      "          Fold 4 Epoch 5: loss=0.3015, acc=45.47% (best=65.86%)\n",
      "          Fold 5 Epoch 5: loss=0.3246, acc=46.02% (best=53.05%)\n",
      "          Fold 2 Epoch 10: loss=0.2465, acc=53.83% (best=55.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2560, acc=60.86% (best=60.86%)\n",
      "          Fold 1 Epoch 10: loss=0.2542, acc=39.77% (best=60.16%)\n",
      "          Fold 4 Epoch 10: loss=0.2358, acc=45.31% (best=65.86%)\n",
      "          Fold 5 Epoch 10: loss=0.2431, acc=33.52% (best=53.05%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.16%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.05%\n",
      "          Fold 2 Epoch 15: loss=0.2278, acc=50.94% (best=60.47%)\n",
      "          Fold 3 Epoch 15: loss=0.2271, acc=54.61% (best=60.86%)\n",
      "          Fold 2 Epoch 20: loss=0.2129, acc=58.98% (best=60.47%)\n",
      "          Fold 3 Epoch 20: loss=0.2173, acc=52.81% (best=60.86%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 60.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f7daabd4:\n",
      "        Fold accuracies: ['60.16%', '60.47%', '60.86%', '65.86%', '53.05%']\n",
      "        Average fitness: 60.08% Â± 4.09%\n",
      "        Best fold: Fold 4 with 65.86%\n",
      "      Fitness obtained: 60.08% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 23a338ec)\n",
      "      Architecture: 29 conv + 5 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 23a338ec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 179, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 23a338ec:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.44% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: de19370a)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model de19370a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6884, acc=45.86% (best=45.86%)\n",
      "          Fold 3 Epoch 1: loss=0.6756, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.6862, acc=51.48% (best=51.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6062, acc=64.38% (best=64.38%)\n",
      "          Fold 5 Epoch 1: loss=0.6988, acc=56.48% (best=56.48%)\n",
      "          Fold 2 Epoch 5: loss=0.3169, acc=52.73% (best=55.94%)\n",
      "          Fold 3 Epoch 5: loss=0.3153, acc=57.27% (best=57.27%)\n",
      "          Fold 1 Epoch 5: loss=0.2673, acc=54.30% (best=58.98%)\n",
      "          Fold 4 Epoch 5: loss=0.2549, acc=59.92% (best=64.38%)\n",
      "          Fold 5 Epoch 5: loss=0.3041, acc=47.42% (best=56.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2302, acc=49.45% (best=61.09%)\n",
      "          Fold 3 Epoch 10: loss=0.2413, acc=57.27% (best=60.78%)\n",
      "          Fold 4 Epoch 10: loss=0.2149, acc=56.25% (best=67.66%)\n",
      "          Fold 1 Epoch 10: loss=0.2218, acc=52.81% (best=67.03%)\n",
      "          Fold 5 Epoch 10: loss=0.2314, acc=37.03% (best=56.48%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.48%\n",
      "          Fold 2 Epoch 15: loss=0.2107, acc=48.75% (best=62.19%)\n",
      "          Fold 3 Epoch 15: loss=0.2258, acc=61.17% (best=64.22%)\n",
      "          Fold 4 Epoch 15: loss=0.1992, acc=55.23% (best=67.66%)\n",
      "          Fold 1 Epoch 15: loss=0.2072, acc=59.22% (best=67.03%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 67.66%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 67.03%\n",
      "          Fold 2 Epoch 20: loss=0.2029, acc=61.33% (best=63.52%)\n",
      "          Fold 3 Epoch 20: loss=0.2172, acc=54.77% (best=64.22%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 64.22%\n",
      "          Fold 2 Epoch 25: loss=0.2000, acc=52.66% (best=63.52%)\n",
      "          Fold 2 Epoch 30: loss=0.1961, acc=59.06% (best=68.20%)\n",
      "          Fold 2 Epoch 35: loss=0.1946, acc=67.27% (best=68.20%)\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for de19370a:\n",
      "        Fold accuracies: ['67.03%', '68.20%', '64.22%', '67.66%', '56.48%']\n",
      "        Average fitness: 64.72% Â± 4.34%\n",
      "        Best fold: Fold 2 with 68.20%\n",
      "      New best fitness in this generation: 64.72%!\n",
      "      Fitness obtained: 64.72% | Best in generation: 64.72% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: bd66665a)\n",
      "      Architecture: 30 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bd66665a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 233, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for bd66665a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.72% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 898d6cda)\n",
      "      Architecture: 1 conv + 5 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 898d6cda with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5517, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.5605, acc=48.52% (best=48.52%)\n",
      "          Fold 5 Epoch 1: loss=0.5670, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 1: loss=0.5163, acc=47.81% (best=47.81%)\n",
      "          Fold 3 Epoch 1: loss=0.5680, acc=54.45% (best=54.45%)\n",
      "          Fold 2 Epoch 5: loss=0.2835, acc=50.00% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.2910, acc=49.77% (best=54.45%)\n",
      "          Fold 1 Epoch 5: loss=0.2945, acc=44.30% (best=48.67%)\n",
      "          Fold 4 Epoch 5: loss=0.2742, acc=45.16% (best=47.81%)\n",
      "          Fold 5 Epoch 5: loss=0.2877, acc=59.77% (best=59.77%)\n",
      "          Fold 2 Epoch 10: loss=0.2365, acc=50.16% (best=50.39%)\n",
      "          Fold 3 Epoch 10: loss=0.2436, acc=52.73% (best=54.45%)\n",
      "          Fold 4 Epoch 10: loss=0.2332, acc=45.23% (best=48.44%)\n",
      "          Fold 1 Epoch 10: loss=0.2502, acc=49.45% (best=49.45%)\n",
      "          Fold 5 Epoch 10: loss=0.2457, acc=53.98% (best=59.77%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 54.45%\n",
      "          Fold 2 Epoch 15: loss=0.2286, acc=47.03% (best=53.05%)\n",
      "          Fold 1 Epoch 15: loss=0.2299, acc=44.38% (best=52.34%)\n",
      "          Fold 4 Epoch 15: loss=0.2260, acc=46.95% (best=48.59%)\n",
      "          Fold 5 Epoch 15: loss=0.2301, acc=52.89% (best=59.77%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 59.77%\n",
      "          Fold 2 Epoch 20: loss=0.2190, acc=49.84% (best=53.05%)\n",
      "          Fold 1 Epoch 20: loss=0.2202, acc=49.61% (best=52.97%)\n",
      "          Fold 4 Epoch 20: loss=0.2078, acc=43.59% (best=48.59%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 53.05%\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 48.59%\n",
      "          Fold 1 Epoch 25: loss=0.2121, acc=46.56% (best=52.97%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 52.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 898d6cda:\n",
      "        Fold accuracies: ['52.97%', '53.05%', '54.45%', '48.59%', '59.77%']\n",
      "        Average fitness: 53.77% Â± 3.59%\n",
      "        Best fold: Fold 5 with 59.77%\n",
      "      Fitness obtained: 53.77% | Best in generation: 64.72% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 4869fe0b)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 4869fe0b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6939, acc=62.89% (best=62.89%)\n",
      "          Fold 4 Epoch 5: loss=0.3581, acc=61.80% (best=62.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2579, acc=35.86% (best=62.89%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4869fe0b:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '62.89%', '0.00%']\n",
      "        Average fitness: 12.58% Â± 25.16%\n",
      "        Best fold: Fold 4 with 62.89%\n",
      "      Fitness obtained: 12.58% | Best in generation: 64.72% | Global best: 67.50%\n",
      "\n",
      "GENERATION 7 STATISTICS:\n",
      "   Maximum fitness: 64.72%\n",
      "   Average fitness: 41.86%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 27.14%\n",
      "   Best individual: de19370a with 64.72%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 6/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=27.14)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: de19370a (fitness: 64.72%)\n",
      "   Elite 2: a3fcf664 (fitness: 64.44%)\n",
      "   Elite 3: 29411d33 (fitness: 63.95%)\n",
      "   Elite 4: 62f1611f (fitness: 63.39%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 7/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 8\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 8)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: de19370a)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model de19370a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6012, acc=55.62% (best=55.62%)\n",
      "          Fold 3 Epoch 1: loss=0.5922, acc=46.95% (best=46.95%)\n",
      "          Fold 4 Epoch 1: loss=0.5765, acc=58.83% (best=58.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6534, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 1: loss=0.6741, acc=53.20% (best=53.20%)\n",
      "          Fold 2 Epoch 5: loss=0.2496, acc=63.83% (best=63.83%)\n",
      "          Fold 3 Epoch 5: loss=0.2650, acc=58.98% (best=58.98%)\n",
      "          Fold 4 Epoch 5: loss=0.2372, acc=46.72% (best=58.83%)\n",
      "          Fold 1 Epoch 5: loss=0.2762, acc=62.50% (best=66.17%)\n",
      "          Fold 5 Epoch 5: loss=0.2706, acc=35.31% (best=66.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2168, acc=59.77% (best=63.83%)\n",
      "          Fold 3 Epoch 10: loss=0.2251, acc=53.44% (best=66.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2053, acc=55.00% (best=58.83%)\n",
      "          Fold 1 Epoch 10: loss=0.2195, acc=67.11% (best=67.11%)\n",
      "          Fold 5 Epoch 10: loss=0.2235, acc=40.70% (best=66.48%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 58.83%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 2 Epoch 15: loss=0.2074, acc=52.58% (best=63.83%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.83%\n",
      "          Fold 3 Epoch 15: loss=0.2086, acc=56.56% (best=66.09%)\n",
      "          Fold 1 Epoch 15: loss=0.2150, acc=63.75% (best=69.38%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 66.09%\n",
      "          Fold 1 Epoch 20: loss=0.2026, acc=72.27% (best=72.27%)\n",
      "          Fold 1 Epoch 25: loss=0.1968, acc=60.55% (best=72.27%)\n",
      "          Fold 1 Epoch 30: loss=0.1920, acc=60.70% (best=72.27%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for de19370a:\n",
      "        Fold accuracies: ['72.27%', '63.83%', '66.09%', '58.83%', '66.48%']\n",
      "        Average fitness: 65.50% Â± 4.35%\n",
      "        Best fold: Fold 1 with 72.27%\n",
      "      New best fitness in this generation: 65.50%!\n",
      "      Fitness obtained: 65.50% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: a3fcf664)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model a3fcf664 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6520, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6362, acc=51.41% (best=51.41%)\n",
      "          Fold 3 Epoch 1: loss=0.6756, acc=50.08% (best=50.08%)\n",
      "          Fold 1 Epoch 1: loss=0.6751, acc=59.92% (best=59.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7081, acc=59.61% (best=59.61%)\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 5: loss=0.3143, acc=46.17% (best=53.12%)\n",
      "          Fold 4 Epoch 5: loss=0.2864, acc=65.70% (best=65.70%)\n",
      "          Fold 1 Epoch 5: loss=0.3374, acc=51.64% (best=62.50%)\n",
      "          Fold 5 Epoch 5: loss=0.3277, acc=48.28% (best=59.61%)\n",
      "          Fold 2 Epoch 10: loss=0.2447, acc=50.47% (best=56.95%)\n",
      "          Fold 4 Epoch 10: loss=0.2381, acc=57.66% (best=65.70%)\n",
      "          Fold 1 Epoch 10: loss=0.2587, acc=46.02% (best=62.50%)\n",
      "          Fold 5 Epoch 10: loss=0.2560, acc=53.52% (best=59.61%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.61%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.50%\n",
      "          Fold 2 Epoch 15: loss=0.2212, acc=54.92% (best=64.45%)\n",
      "          Fold 4 Epoch 15: loss=0.2196, acc=53.67% (best=66.41%)\n",
      "          Fold 2 Epoch 20: loss=0.2206, acc=56.09% (best=64.45%)\n",
      "          Fold 4 Epoch 20: loss=0.2093, acc=63.44% (best=66.41%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 64.45%\n",
      "          Fold 4 Epoch 25: loss=0.2100, acc=55.08% (best=68.44%)\n",
      "          Fold 4 Epoch 30: loss=0.2035, acc=51.88% (best=68.44%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a3fcf664:\n",
      "        Fold accuracies: ['62.50%', '64.45%', '0.00%', '68.44%', '59.61%']\n",
      "        Average fitness: 51.00% Â± 25.66%\n",
      "        Best fold: Fold 4 with 68.44%\n",
      "      Fitness obtained: 51.00% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 29411d33)\n",
      "      Architecture: 8 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 29411d33 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7056, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 1: loss=0.6856, acc=52.73% (best=52.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7113, acc=52.97% (best=52.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7263, acc=52.03% (best=52.03%)\n",
      "          Fold 1 Epoch 1: loss=0.7040, acc=58.59% (best=58.59%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 5: loss=0.3237, acc=39.53% (best=60.00%)\n",
      "          Fold 3 Epoch 5: loss=0.3221, acc=55.39% (best=57.27%)\n",
      "          Fold 2 Epoch 10: loss=0.2490, acc=58.28% (best=60.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2615, acc=54.84% (best=57.27%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 57.27%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 60.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 29411d33:\n",
      "        Fold accuracies: ['0.00%', '60.00%', '57.27%', '0.00%', '0.00%']\n",
      "        Average fitness: 23.45% Â± 28.74%\n",
      "        Best fold: Fold 2 with 60.00%\n",
      "      Fitness obtained: 23.45% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 62f1611f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 62f1611f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6679, acc=48.67% (best=48.67%)\n",
      "          Fold 3 Epoch 1: loss=0.6728, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6993, acc=49.14% (best=49.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6565, acc=61.88% (best=61.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6814, acc=48.59% (best=48.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3392, acc=53.36% (best=58.44%)\n",
      "          Fold 5 Epoch 5: loss=0.3085, acc=46.64% (best=53.59%)\n",
      "          Fold 4 Epoch 5: loss=0.3313, acc=47.58% (best=66.33%)\n",
      "          Fold 1 Epoch 5: loss=0.3785, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 5: loss=0.3689, acc=61.56% (best=61.56%)\n",
      "          Fold 2 Epoch 10: loss=0.2656, acc=48.36% (best=58.44%)\n",
      "          Fold 5 Epoch 10: loss=0.2485, acc=50.31% (best=53.59%)\n",
      "          Fold 4 Epoch 10: loss=0.2474, acc=57.27% (best=66.33%)\n",
      "          Fold 1 Epoch 10: loss=0.2736, acc=55.86% (best=56.80%)\n",
      "          Fold 3 Epoch 10: loss=0.2784, acc=51.64% (best=61.56%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 58.44%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.33%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 61.56%\n",
      "          Fold 5 Epoch 15: loss=0.2303, acc=42.50% (best=60.70%)\n",
      "          Fold 1 Epoch 15: loss=0.2390, acc=57.73% (best=62.81%)\n",
      "          Fold 5 Epoch 20: loss=0.2184, acc=43.36% (best=60.70%)\n",
      "          Fold 1 Epoch 20: loss=0.2211, acc=67.11% (best=67.11%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 60.70%\n",
      "          Fold 1 Epoch 25: loss=0.2153, acc=55.00% (best=67.11%)\n",
      "          Fold 1 Epoch 30: loss=0.2106, acc=54.61% (best=67.11%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 62f1611f:\n",
      "        Fold accuracies: ['67.11%', '58.44%', '61.56%', '66.33%', '60.70%']\n",
      "        Average fitness: 62.83% Â± 3.35%\n",
      "        Best fold: Fold 1 with 67.11%\n",
      "      Fitness obtained: 62.83% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 3101da1e)\n",
      "      Architecture: 3 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3101da1e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.4775, acc=44.61% (best=44.61%)\n",
      "          Fold 1 Epoch 5: loss=0.2299, acc=49.69% (best=53.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2092, acc=42.89% (best=53.28%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 53.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3101da1e:\n",
      "        Fold accuracies: ['53.28%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 10.66% Â± 21.31%\n",
      "        Best fold: Fold 1 with 53.28%\n",
      "      Fitness obtained: 10.66% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 46586dec)\n",
      "      Architecture: 21 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 46586dec with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 243, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 46586dec:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 881b104f)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 881b104f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7105, acc=52.50% (best=52.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7148, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 1: loss=0.7000, acc=58.59% (best=58.59%)\n",
      "          Fold 2 Epoch 5: loss=0.6849, acc=49.14% (best=52.50%)\n",
      "          Fold 4 Epoch 5: loss=0.6669, acc=55.31% (best=59.22%)\n",
      "          Fold 5 Epoch 5: loss=0.6992, acc=49.61% (best=56.56%)\n",
      "          Fold 2 Epoch 10: loss=0.6691, acc=57.81% (best=57.89%)\n",
      "          Fold 4 Epoch 10: loss=0.6467, acc=48.91% (best=59.22%)\n",
      "          Fold 5 Epoch 10: loss=0.6974, acc=55.47% (best=56.56%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 59.22%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "          Fold 2 Epoch 15: loss=0.6230, acc=41.02% (best=57.89%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 57.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 881b104f:\n",
      "        Fold accuracies: ['0.00%', '57.89%', '0.00%', '59.22%', '56.56%']\n",
      "        Average fitness: 34.73% Â± 28.37%\n",
      "        Best fold: Fold 4 with 59.22%\n",
      "      Fitness obtained: 34.73% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: cb75f555)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model cb75f555 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7053, acc=41.80% (best=41.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7223, acc=53.91% (best=53.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6775, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6938, acc=37.73% (best=37.73%)\n",
      "          Fold 1 Epoch 1: loss=0.6953, acc=49.69% (best=49.69%)\n",
      "          Fold 3 Epoch 5: loss=0.3938, acc=55.00% (best=55.86%)\n",
      "          Fold 5 Epoch 5: loss=0.4411, acc=51.33% (best=55.16%)\n",
      "          Fold 4 Epoch 5: loss=0.4260, acc=37.97% (best=55.23%)\n",
      "          Fold 2 Epoch 5: loss=0.3606, acc=46.64% (best=51.56%)\n",
      "          Fold 1 Epoch 5: loss=0.4166, acc=54.53% (best=58.91%)\n",
      "          Fold 3 Epoch 10: loss=0.3044, acc=58.28% (best=58.91%)\n",
      "          Fold 4 Epoch 10: loss=0.3149, acc=44.06% (best=55.23%)\n",
      "          Fold 5 Epoch 10: loss=0.2923, acc=46.95% (best=55.16%)\n",
      "          Fold 2 Epoch 10: loss=0.2682, acc=34.53% (best=52.50%)\n",
      "          Fold 1 Epoch 10: loss=0.3195, acc=67.34% (best=67.34%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 55.23%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 55.16%\n",
      "          Fold 3 Epoch 15: loss=0.2651, acc=56.25% (best=58.91%)\n",
      "          Fold 2 Epoch 15: loss=0.2444, acc=41.88% (best=52.50%)\n",
      "          Fold 1 Epoch 15: loss=0.2708, acc=57.97% (best=67.34%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 52.50%\n",
      "          Fold 1 Epoch 20: loss=0.2456, acc=58.12% (best=67.34%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cb75f555:\n",
      "        Fold accuracies: ['67.34%', '52.50%', '58.91%', '55.23%', '55.16%']\n",
      "        Average fitness: 57.83% Â± 5.18%\n",
      "        Best fold: Fold 1 with 67.34%\n",
      "      Fitness obtained: 57.83% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 89bd425e)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 89bd425e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.6447, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6455, acc=66.88% (best=66.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6336, acc=49.30% (best=49.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6688, acc=62.03% (best=62.03%)\n",
      "          Fold 3 Epoch 5: loss=0.2826, acc=62.66% (best=63.91%)\n",
      "          Fold 1 Epoch 5: loss=0.2982, acc=48.52% (best=56.64%)\n",
      "          Fold 4 Epoch 5: loss=0.2977, acc=47.50% (best=66.88%)\n",
      "          Fold 5 Epoch 5: loss=0.2900, acc=45.78% (best=62.03%)\n",
      "          Fold 3 Epoch 10: loss=0.2360, acc=56.88% (best=67.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2355, acc=51.02% (best=68.05%)\n",
      "          Fold 1 Epoch 10: loss=0.2281, acc=60.31% (best=60.55%)\n",
      "          Fold 5 Epoch 10: loss=0.2352, acc=50.08% (best=62.03%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 3 Epoch 15: loss=0.2186, acc=55.94% (best=67.89%)\n",
      "          Fold 1 Epoch 15: loss=0.2230, acc=59.84% (best=60.55%)\n",
      "          Fold 4 Epoch 15: loss=0.2156, acc=54.06% (best=68.05%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 60.55%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 67.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 89bd425e:\n",
      "        Fold accuracies: ['60.55%', '0.00%', '67.89%', '68.05%', '62.03%']\n",
      "        Average fitness: 51.70% Â± 26.03%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      Fitness obtained: 51.70% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 839443b2)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 839443b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.6593, acc=61.64% (best=61.64%)\n",
      "          Fold 1 Epoch 1: loss=0.6813, acc=67.03% (best=67.03%)\n",
      "          Fold 1 Epoch 5: loss=0.4138, acc=53.36% (best=67.03%)\n",
      "          Fold 4 Epoch 5: loss=0.4180, acc=51.72% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3076, acc=48.67% (best=61.64%)\n",
      "          Fold 1 Epoch 10: loss=0.3248, acc=42.97% (best=67.03%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 67.03%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 839443b2:\n",
      "        Fold accuracies: ['67.03%', '0.00%', '0.00%', '61.64%', '0.00%']\n",
      "        Average fitness: 25.73% Â± 31.56%\n",
      "        Best fold: Fold 1 with 67.03%\n",
      "      Fitness obtained: 25.73% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: e52c1ef1)\n",
      "      Architecture: 8 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e52c1ef1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch.       ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6143, acc=50.94% (best=50.94%)\n",
      "          Fold 5 Epoch 1: loss=0.6909, acc=50.86% (best=50.86%)\n",
      "          Fold 3 Epoch 5: loss=0.2923, acc=42.50% (best=63.28%)\n",
      "          Fold 5 Epoch 5: loss=0.3173, acc=49.84% (best=57.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2431, acc=52.81% (best=63.28%)\n",
      "          Fold 5 Epoch 10: loss=0.2438, acc=47.58% (best=57.97%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 57.97%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 63.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e52c1ef1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '63.28%', '0.00%', '57.97%']\n",
      "        Average fitness: 24.25% Â± 29.75%\n",
      "        Best fold: Fold 3 with 63.28%\n",
      "      Fitness obtained: 24.25% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 724b6fa6)\n",
      "      Architecture: 8 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 724b6fa6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7298, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 1: loss=0.7329, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7504, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7244, acc=49.38% (best=49.38%)\n",
      "          Fold 4 Epoch 1: loss=0.7051, acc=42.66% (best=42.66%)\n",
      "          Fold 2 Epoch 5: loss=0.4572, acc=48.67% (best=49.61%)\n",
      "          Fold 3 Epoch 5: loss=0.5497, acc=48.98% (best=55.08%)\n",
      "          Fold 1 Epoch 5: loss=0.5306, acc=50.08% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.5347, acc=52.34% (best=59.92%)\n",
      "          Fold 5 Epoch 5: loss=0.5909, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 10: loss=0.2808, acc=52.19% (best=56.48%)\n",
      "          Fold 3 Epoch 10: loss=0.4112, acc=51.33% (best=59.84%)\n",
      "          Fold 1 Epoch 10: loss=0.2906, acc=47.27% (best=58.28%)\n",
      "          Fold 4 Epoch 10: loss=0.3685, acc=47.66% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3173, acc=46.33% (best=52.34%)\n",
      "          Fold 2 Epoch 15: loss=0.2360, acc=47.19% (best=56.48%)\n",
      "          Fold 3 Epoch 15: loss=0.3238, acc=51.25% (best=60.00%)\n",
      "          Fold 1 Epoch 15: loss=0.2372, acc=41.64% (best=58.28%)\n",
      "          Fold 4 Epoch 15: loss=0.2675, acc=54.77% (best=60.86%)\n",
      "          Fold 5 Epoch 15: loss=0.2413, acc=39.92% (best=52.34%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 52.34%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 60.86%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 58.28%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 56.48%\n",
      "          Fold 3 Epoch 20: loss=0.2747, acc=58.67% (best=64.45%)\n",
      "          Fold 3 Epoch 25: loss=0.2495, acc=65.78% (best=65.78%)\n",
      "          Fold 3 Epoch 30: loss=0.2382, acc=58.28% (best=65.78%)\n",
      "          Fold 3 Epoch 35: loss=0.2307, acc=56.72% (best=71.09%)\n",
      "          Fold 3 Epoch 40: loss=0.2251, acc=55.31% (best=71.09%)\n",
      "          Fold 3: Early stopping at epoch 41\n",
      "      â†’ Fold 3 completed: 71.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 724b6fa6:\n",
      "        Fold accuracies: ['58.28%', '56.48%', '71.09%', '60.86%', '52.34%']\n",
      "        Average fitness: 59.81% Â± 6.29%\n",
      "        Best fold: Fold 3 with 71.09%\n",
      "      Fitness obtained: 59.81% | Best in generation: 65.50% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 6d598049)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6d598049 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6792, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6330, acc=51.64% (best=51.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6375, acc=65.39% (best=65.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6495, acc=54.84% (best=54.84%)\n",
      "          Fold 5 Epoch 1: loss=0.6932, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.3409, acc=51.09% (best=55.94%)\n",
      "          Fold 3 Epoch 5: loss=0.3581, acc=44.14% (best=56.88%)\n",
      "          Fold 1 Epoch 5: loss=0.4090, acc=67.50% (best=67.50%)\n",
      "          Fold 4 Epoch 5: loss=0.4116, acc=57.11% (best=65.39%)\n",
      "          Fold 5 Epoch 5: loss=0.3963, acc=52.97% (best=62.73%)\n",
      "          Fold 2 Epoch 10: loss=0.2755, acc=54.77% (best=56.41%)\n",
      "          Fold 3 Epoch 10: loss=0.2613, acc=58.28% (best=58.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2886, acc=61.95% (best=68.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2856, acc=51.72% (best=65.39%)\n",
      "          Fold 5 Epoch 10: loss=0.2931, acc=45.39% (best=62.73%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 62.73%\n",
      "          Fold 2 Epoch 15: loss=0.2428, acc=65.86% (best=65.86%)\n",
      "          Fold 3 Epoch 15: loss=0.2400, acc=61.17% (best=61.17%)\n",
      "          Fold 1 Epoch 15: loss=0.2514, acc=62.34% (best=68.83%)\n",
      "          Fold 2 Epoch 20: loss=0.2262, acc=50.86% (best=65.86%)\n",
      "          Fold 3 Epoch 20: loss=0.2245, acc=65.62% (best=66.41%)\n",
      "          Fold 1 Epoch 20: loss=0.2335, acc=64.84% (best=71.02%)\n",
      "          Fold 2 Epoch 25: loss=0.2193, acc=52.03% (best=65.86%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 3 Epoch 25: loss=0.2135, acc=60.86% (best=66.41%)\n",
      "          Fold 1 Epoch 25: loss=0.2196, acc=64.45% (best=71.17%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 66.41%\n",
      "          Fold 1 Epoch 30: loss=0.2149, acc=64.69% (best=71.17%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 71.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6d598049:\n",
      "        Fold accuracies: ['71.17%', '65.86%', '66.41%', '65.39%', '62.73%']\n",
      "        Average fitness: 66.31% Â± 2.74%\n",
      "        Best fold: Fold 1 with 71.17%\n",
      "      New best fitness in this generation: 66.31%!\n",
      "      Fitness obtained: 66.31% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6926, acc=45.94% (best=45.94%)\n",
      "          Fold 1 Epoch 1: loss=0.6906, acc=57.11% (best=57.11%)\n",
      "          Fold 3 Epoch 1: loss=0.6821, acc=54.38% (best=54.38%)\n",
      "          Fold 4 Epoch 1: loss=0.6864, acc=60.00% (best=60.00%)\n",
      "          Fold 5 Epoch 1: loss=0.7089, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 5: loss=0.4063, acc=60.55% (best=60.55%)\n",
      "          Fold 1 Epoch 5: loss=0.4535, acc=49.69% (best=57.11%)\n",
      "          Fold 5 Epoch 5: loss=0.4290, acc=53.75% (best=53.75%)\n",
      "          Fold 3 Epoch 5: loss=0.3800, acc=55.70% (best=55.70%)\n",
      "          Fold 4 Epoch 5: loss=0.4057, acc=51.72% (best=62.42%)\n",
      "          Fold 2 Epoch 10: loss=0.2811, acc=64.53% (best=66.02%)\n",
      "          Fold 1 Epoch 10: loss=0.3341, acc=53.91% (best=66.02%)\n",
      "          Fold 5 Epoch 10: loss=0.3095, acc=47.73% (best=58.20%)\n",
      "          Fold 3 Epoch 10: loss=0.2989, acc=53.05% (best=56.80%)\n",
      "          Fold 4 Epoch 10: loss=0.2935, acc=45.00% (best=62.42%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.42%\n",
      "          Fold 2 Epoch 15: loss=0.2595, acc=51.25% (best=66.02%)\n",
      "          Fold 1 Epoch 15: loss=0.2879, acc=59.45% (best=66.95%)\n",
      "          Fold 5 Epoch 15: loss=0.2719, acc=47.11% (best=58.20%)\n",
      "          Fold 3 Epoch 15: loss=0.2675, acc=52.81% (best=56.80%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 66.02%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 58.20%\n",
      "          Fold 1 Epoch 20: loss=0.2666, acc=56.64% (best=66.95%)\n",
      "          Fold 3 Epoch 20: loss=0.2537, acc=52.58% (best=64.22%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 66.95%\n",
      "          Fold 3 Epoch 25: loss=0.2428, acc=59.14% (best=64.22%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 64.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['66.95%', '66.02%', '64.22%', '62.42%', '58.20%']\n",
      "        Average fitness: 63.56% Â± 3.10%\n",
      "        Best fold: Fold 1 with 66.95%\n",
      "      Fitness obtained: 63.56% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: f746090c)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f746090c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6755, acc=42.73% (best=42.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6699, acc=55.23% (best=55.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7003, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 1: loss=0.6663, acc=49.06% (best=49.06%)\n",
      "          Fold 4 Epoch 1: loss=0.6545, acc=66.64% (best=66.64%)\n",
      "          Fold 1 Epoch 5: loss=0.4449, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 5: loss=0.4156, acc=55.70% (best=62.89%)\n",
      "          Fold 2 Epoch 5: loss=0.3837, acc=49.77% (best=52.81%)\n",
      "          Fold 5 Epoch 5: loss=0.4149, acc=54.92% (best=60.23%)\n",
      "          Fold 4 Epoch 5: loss=0.4534, acc=49.84% (best=66.64%)\n",
      "          Fold 1 Epoch 10: loss=0.3758, acc=42.19% (best=59.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3480, acc=64.69% (best=64.69%)\n",
      "          Fold 2 Epoch 10: loss=0.3028, acc=50.31% (best=60.55%)\n",
      "          Fold 5 Epoch 10: loss=0.3028, acc=55.94% (best=67.11%)\n",
      "          Fold 4 Epoch 10: loss=0.3615, acc=55.94% (best=66.64%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.64%\n",
      "          Fold 1 Epoch 15: loss=0.3139, acc=55.16% (best=59.45%)\n",
      "          Fold 3 Epoch 15: loss=0.3038, acc=53.98% (best=64.69%)\n",
      "          Fold 2 Epoch 15: loss=0.2574, acc=58.20% (best=60.55%)\n",
      "          Fold 5 Epoch 15: loss=0.2632, acc=60.16% (best=67.11%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 67.11%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 60.55%\n",
      "          Fold 3 Epoch 20: loss=0.2765, acc=50.39% (best=64.69%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f746090c:\n",
      "        Fold accuracies: ['59.45%', '60.55%', '64.69%', '66.64%', '67.11%']\n",
      "        Average fitness: 63.69% Â± 3.14%\n",
      "        Best fold: Fold 5 with 67.11%\n",
      "      Fitness obtained: 63.69% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 17213825)\n",
      "      Architecture: 12 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 17213825 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6682, acc=51.25% (best=51.25%)\n",
      "          Fold 2 Epoch 1: loss=0.6899, acc=49.38% (best=49.38%)\n",
      "          Fold 3 Epoch 1: loss=0.7061, acc=51.64% (best=51.64%)\n",
      "          Fold 1 Epoch 1: loss=0.6954, acc=62.58% (best=62.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7085, acc=47.58% (best=47.58%)\n",
      "          Fold 4 Epoch 5: loss=0.4276, acc=47.89% (best=61.88%)\n",
      "          Fold 2 Epoch 5: loss=0.4761, acc=53.44% (best=53.44%)\n",
      "          Fold 3 Epoch 5: loss=0.3994, acc=54.84% (best=57.27%)\n",
      "          Fold 5 Epoch 5: loss=0.5221, acc=59.53% (best=59.53%)\n",
      "          Fold 1 Epoch 5: loss=0.6018, acc=49.45% (best=62.58%)\n",
      "          Fold 4 Epoch 10: loss=0.2688, acc=50.23% (best=61.88%)\n",
      "          Fold 2 Epoch 10: loss=0.2723, acc=35.70% (best=53.44%)\n",
      "          Fold 3 Epoch 10: loss=0.2802, acc=57.03% (best=57.27%)\n",
      "          Fold 5 Epoch 10: loss=0.3068, acc=61.95% (best=63.28%)\n",
      "          Fold 1 Epoch 10: loss=0.3394, acc=58.28% (best=66.17%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 61.88%\n",
      "          Fold 2 Epoch 15: loss=0.2419, acc=38.59% (best=56.02%)\n",
      "          Fold 3 Epoch 15: loss=0.2378, acc=58.44% (best=63.44%)\n",
      "          Fold 5 Epoch 15: loss=0.2492, acc=38.59% (best=63.28%)\n",
      "          Fold 1 Epoch 15: loss=0.2618, acc=65.78% (best=66.17%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 63.28%\n",
      "          Fold 2 Epoch 20: loss=0.2307, acc=43.36% (best=56.02%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 66.17%\n",
      "          Fold 3 Epoch 20: loss=0.2278, acc=58.67% (best=63.44%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 56.02%\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 17213825:\n",
      "        Fold accuracies: ['66.17%', '56.02%', '63.44%', '61.88%', '63.28%']\n",
      "        Average fitness: 62.16% Â± 3.37%\n",
      "        Best fold: Fold 1 with 66.17%\n",
      "      Fitness obtained: 62.16% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 4561fe35)\n",
      "      Architecture: 11 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 4561fe35 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6774, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6665, acc=57.19% (best=57.19%)\n",
      "          Fold 3 Epoch 1: loss=0.6808, acc=49.69% (best=49.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7046, acc=50.55% (best=50.55%)\n",
      "          Fold 1 Epoch 1: loss=0.6836, acc=63.59% (best=63.59%)\n",
      "          Fold 2 Epoch 5: loss=0.4669, acc=49.06% (best=62.97%)\n",
      "          Fold 4 Epoch 5: loss=0.4425, acc=57.89% (best=63.67%)\n",
      "          Fold 3 Epoch 5: loss=0.4235, acc=49.22% (best=57.66%)\n",
      "          Fold 5 Epoch 5: loss=0.4747, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 5: loss=0.4481, acc=54.69% (best=63.59%)\n",
      "          Fold 2 Epoch 10: loss=0.2913, acc=49.77% (best=62.97%)\n",
      "          Fold 4 Epoch 10: loss=0.3111, acc=34.77% (best=63.67%)\n",
      "          Fold 3 Epoch 10: loss=0.3150, acc=51.17% (best=57.89%)\n",
      "          Fold 5 Epoch 10: loss=0.3199, acc=55.08% (best=57.03%)\n",
      "          Fold 1 Epoch 10: loss=0.3054, acc=55.23% (best=63.59%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 63.67%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 63.59%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 62.97%\n",
      "          Fold 3 Epoch 15: loss=0.2668, acc=52.34% (best=61.41%)\n",
      "          Fold 5 Epoch 15: loss=0.2689, acc=50.47% (best=57.03%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 3 Epoch 20: loss=0.2465, acc=53.28% (best=61.41%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 61.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4561fe35:\n",
      "        Fold accuracies: ['63.59%', '62.97%', '61.41%', '63.67%', '57.03%']\n",
      "        Average fitness: 61.73% Â± 2.49%\n",
      "        Best fold: Fold 4 with 63.67%\n",
      "      Fitness obtained: 61.73% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: e3203692)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e3203692 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.6745, acc=47.73% (best=47.73%)\n",
      "          Fold 5 Epoch 1: loss=0.6964, acc=44.61% (best=44.61%)\n",
      "          Fold 3 Epoch 5: loss=0.3433, acc=49.22% (best=59.84%)\n",
      "          Fold 5 Epoch 5: loss=0.3428, acc=45.62% (best=52.03%)\n",
      "          Fold 3 Epoch 10: loss=0.2921, acc=56.64% (best=62.66%)\n",
      "          Fold 5 Epoch 10: loss=0.2768, acc=47.19% (best=56.56%)\n",
      "          Fold 3 Epoch 15: loss=0.2527, acc=54.45% (best=66.56%)\n",
      "          Fold 5 Epoch 15: loss=0.2447, acc=47.03% (best=56.56%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "          Fold 3 Epoch 20: loss=0.2443, acc=60.31% (best=68.59%)\n",
      "          Fold 3 Epoch 25: loss=0.2317, acc=66.72% (best=68.59%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 68.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e3203692:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '68.59%', '0.00%', '56.56%']\n",
      "        Average fitness: 25.03% Â± 30.89%\n",
      "        Best fold: Fold 3 with 68.59%\n",
      "      Fitness obtained: 25.03% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 0e2f7825)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 0e2f7825 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 1: loss=0.5669, acc=58.59% (best=58.59%)\n",
      "          Fold 5 Epoch 1: loss=0.5874, acc=63.98% (best=63.98%)\n",
      "          Fold 1 Epoch 1: loss=0.6584, acc=52.73% (best=52.73%)\n",
      "          Fold 4 Epoch 1: loss=0.5583, acc=56.33% (best=56.33%)\n",
      "          Fold 3 Epoch 5: loss=0.2385, acc=52.34% (best=58.59%)\n",
      "          Fold 1 Epoch 5: loss=0.2362, acc=44.92% (best=55.78%)\n",
      "          Fold 5 Epoch 5: loss=0.2298, acc=50.55% (best=63.98%)\n",
      "          Fold 4 Epoch 5: loss=0.2244, acc=63.67% (best=63.67%)\n",
      "          Fold 3 Epoch 10: loss=0.2083, acc=65.23% (best=65.23%)\n",
      "          Fold 1 Epoch 10: loss=0.2013, acc=47.11% (best=58.20%)\n",
      "          Fold 5 Epoch 10: loss=0.2022, acc=51.48% (best=63.98%)\n",
      "          Fold 4 Epoch 10: loss=0.1935, acc=60.47% (best=63.67%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "          Fold 3 Epoch 15: loss=0.2016, acc=58.28% (best=65.23%)\n",
      "          Fold 1 Epoch 15: loss=0.1950, acc=42.11% (best=58.20%)\n",
      "          Fold 4 Epoch 15: loss=0.1912, acc=58.44% (best=63.67%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 63.67%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 58.20%\n",
      "          Fold 3 Epoch 20: loss=0.2115, acc=63.44% (best=65.23%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0e2f7825:\n",
      "        Fold accuracies: ['58.20%', '0.00%', '65.23%', '63.67%', '63.98%']\n",
      "        Average fitness: 50.22% Â± 25.23%\n",
      "        Best fold: Fold 3 with 65.23%\n",
      "      Fitness obtained: 50.22% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 9d5ae115)\n",
      "      Architecture: 10 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 9d5ae115 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6966, acc=61.09% (best=61.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6751, acc=63.12% (best=63.12%)\n",
      "          Fold 5 Epoch 1: loss=0.6831, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 1: loss=0.6767, acc=42.50% (best=42.50%)\n",
      "          Fold 2 Epoch 1: loss=0.6593, acc=51.41% (best=51.41%)\n",
      "          Fold 4 Epoch 5: loss=0.3899, acc=55.70% (best=63.12%)\n",
      "          Fold 3 Epoch 5: loss=0.3569, acc=60.08% (best=63.83%)\n",
      "          Fold 5 Epoch 5: loss=0.3538, acc=50.55% (best=58.20%)\n",
      "          Fold 2 Epoch 5: loss=0.3412, acc=51.80% (best=52.03%)\n",
      "          Fold 1 Epoch 5: loss=0.3781, acc=46.80% (best=53.75%)\n",
      "          Fold 3 Epoch 10: loss=0.2780, acc=55.23% (best=63.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2855, acc=47.66% (best=63.12%)\n",
      "          Fold 5 Epoch 10: loss=0.2879, acc=53.44% (best=62.50%)\n",
      "          Fold 2 Epoch 10: loss=0.2735, acc=65.23% (best=70.39%)\n",
      "          Fold 1 Epoch 10: loss=0.3008, acc=49.06% (best=53.75%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.12%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 63.83%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 53.75%\n",
      "          Fold 5 Epoch 15: loss=0.2602, acc=56.33% (best=62.50%)\n",
      "          Fold 2 Epoch 15: loss=0.2445, acc=67.19% (best=73.83%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 62.50%\n",
      "          Fold 2 Epoch 20: loss=0.2271, acc=70.78% (best=73.83%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 73.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9d5ae115:\n",
      "        Fold accuracies: ['53.75%', '73.83%', '63.83%', '63.12%', '62.50%']\n",
      "        Average fitness: 63.41% Â± 6.37%\n",
      "        Best fold: Fold 2 with 73.83%\n",
      "      Fitness obtained: 63.41% | Best in generation: 66.31% | Global best: 67.50%\n",
      "\n",
      "GENERATION 8 STATISTICS:\n",
      "   Maximum fitness: 66.31%\n",
      "   Average fitness: 46.18%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 20.30%\n",
      "   Best individual: 6d598049 with 66.31%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 8/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=20.30)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 6d598049 (fitness: 66.31%)\n",
      "   Elite 2: de19370a (fitness: 65.50%)\n",
      "   Elite 3: f746090c (fitness: 63.69%)\n",
      "   Elite 4: 59336158 (fitness: 63.56%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 9/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 9\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 9)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 6d598049)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6d598049 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6770, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 1: loss=0.6577, acc=42.03% (best=42.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6996, acc=44.53% (best=44.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6584, acc=63.83% (best=63.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6723, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 5: loss=0.3576, acc=51.02% (best=56.48%)\n",
      "          Fold 3 Epoch 5: loss=0.3888, acc=46.17% (best=53.83%)\n",
      "          Fold 4 Epoch 5: loss=0.4149, acc=45.78% (best=63.83%)\n",
      "          Fold 1 Epoch 5: loss=0.4335, acc=50.16% (best=56.88%)\n",
      "          Fold 5 Epoch 5: loss=0.3451, acc=51.88% (best=58.67%)\n",
      "          Fold 2 Epoch 10: loss=0.2702, acc=42.50% (best=56.48%)\n",
      "          Fold 3 Epoch 10: loss=0.3059, acc=56.41% (best=61.33%)\n",
      "          Fold 4 Epoch 10: loss=0.2810, acc=55.39% (best=63.83%)\n",
      "          Fold 1 Epoch 10: loss=0.3372, acc=52.81% (best=64.61%)\n",
      "          Fold 5 Epoch 10: loss=0.2696, acc=44.14% (best=58.67%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.48%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "          Fold 3 Epoch 15: loss=0.2689, acc=53.36% (best=67.19%)\n",
      "          Fold 1 Epoch 15: loss=0.2766, acc=51.48% (best=64.61%)\n",
      "          Fold 3 Epoch 20: loss=0.2416, acc=49.22% (best=67.19%)\n",
      "          Fold 1 Epoch 20: loss=0.2436, acc=63.12% (best=67.73%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 67.19%\n",
      "          Fold 1 Epoch 25: loss=0.2245, acc=59.14% (best=72.58%)\n",
      "          Fold 1 Epoch 30: loss=0.2169, acc=59.84% (best=72.58%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 72.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6d598049:\n",
      "        Fold accuracies: ['72.58%', '56.48%', '67.19%', '63.83%', '58.67%']\n",
      "        Average fitness: 63.75% Â± 5.80%\n",
      "        Best fold: Fold 1 with 72.58%\n",
      "      New best fitness in this generation: 63.75%!\n",
      "      Fitness obtained: 63.75% | Best in generation: 63.75% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: de19370a)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model de19370a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6766, acc=40.23% (best=40.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6289, acc=57.03% (best=57.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6823, acc=47.19% (best=47.19%)\n",
      "          Fold 4 Epoch 1: loss=0.5983, acc=67.58% (best=67.58%)\n",
      "          Fold 5 Epoch 1: loss=0.6319, acc=51.41% (best=51.41%)\n",
      "          Fold 2 Epoch 5: loss=0.3244, acc=41.95% (best=50.08%)\n",
      "          Fold 3 Epoch 5: loss=0.2900, acc=64.22% (best=64.22%)\n",
      "          Fold 4 Epoch 5: loss=0.2498, acc=52.58% (best=67.58%)\n",
      "          Fold 1 Epoch 5: loss=0.3329, acc=43.67% (best=50.47%)\n",
      "          Fold 5 Epoch 5: loss=0.2680, acc=48.44% (best=57.03%)\n",
      "          Fold 2 Epoch 10: loss=0.2606, acc=41.56% (best=50.08%)\n",
      "          Fold 3 Epoch 10: loss=0.2307, acc=61.09% (best=64.22%)\n",
      "          Fold 1 Epoch 10: loss=0.2463, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2137, acc=50.08% (best=67.58%)\n",
      "          Fold 5 Epoch 10: loss=0.2240, acc=57.89% (best=57.89%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 50.08%\n",
      "          Fold 3 Epoch 15: loss=0.2139, acc=51.80% (best=64.22%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 64.22%\n",
      "          Fold 1 Epoch 15: loss=0.2185, acc=47.73% (best=55.00%)\n",
      "          Fold 5 Epoch 15: loss=0.2074, acc=53.12% (best=57.89%)\n",
      "          Fold 1 Epoch 20: loss=0.2099, acc=60.16% (best=60.16%)\n",
      "          Fold 5 Epoch 20: loss=0.2052, acc=47.73% (best=57.89%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "          Fold 1 Epoch 25: loss=0.2084, acc=55.39% (best=60.16%)\n",
      "          Fold 1 Epoch 30: loss=0.2004, acc=54.53% (best=67.73%)\n",
      "          Fold 1 Epoch 35: loss=0.1986, acc=54.53% (best=67.73%)\n",
      "          Fold 1: Early stopping at epoch 37\n",
      "      â†’ Fold 1 completed: 67.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for de19370a:\n",
      "        Fold accuracies: ['67.73%', '50.08%', '64.22%', '67.58%', '57.89%']\n",
      "        Average fitness: 61.50% Â± 6.73%\n",
      "        Best fold: Fold 1 with 67.73%\n",
      "      Fitness obtained: 61.50% | Best in generation: 63.75% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: f746090c)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f746090c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6591, acc=43.91% (best=43.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6734, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6860, acc=38.36% (best=38.36%)\n",
      "          Fold 5 Epoch 1: loss=0.7065, acc=46.41% (best=46.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6773, acc=41.33% (best=41.33%)\n",
      "          Fold 4 Epoch 5: loss=0.4191, acc=53.75% (best=65.70%)\n",
      "          Fold 3 Epoch 5: loss=0.4137, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 5: loss=0.4013, acc=46.48% (best=55.23%)\n",
      "          Fold 5 Epoch 5: loss=0.4494, acc=51.25% (best=53.67%)\n",
      "          Fold 1 Epoch 5: loss=0.4475, acc=53.75% (best=59.61%)\n",
      "          Fold 3 Epoch 10: loss=0.3362, acc=55.31% (best=59.53%)\n",
      "          Fold 4 Epoch 10: loss=0.3289, acc=47.89% (best=65.70%)\n",
      "          Fold 2 Epoch 10: loss=0.3109, acc=56.41% (best=56.41%)\n",
      "          Fold 5 Epoch 10: loss=0.3258, acc=54.53% (best=59.45%)\n",
      "          Fold 1 Epoch 10: loss=0.3483, acc=51.02% (best=59.61%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 65.70%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 59.61%\n",
      "          Fold 3 Epoch 15: loss=0.2988, acc=48.20% (best=59.61%)\n",
      "          Fold 2 Epoch 15: loss=0.2794, acc=55.94% (best=56.41%)\n",
      "          Fold 5 Epoch 15: loss=0.2744, acc=46.95% (best=64.06%)\n",
      "          Fold 3 Epoch 20: loss=0.2738, acc=41.33% (best=60.00%)\n",
      "          Fold 2 Epoch 20: loss=0.2557, acc=47.42% (best=59.61%)\n",
      "          Fold 5 Epoch 20: loss=0.2525, acc=55.23% (best=64.69%)\n",
      "          Fold 3 Epoch 25: loss=0.2572, acc=54.92% (best=60.00%)\n",
      "          Fold 2 Epoch 25: loss=0.2488, acc=52.03% (best=59.61%)\n",
      "          Fold 5 Epoch 25: loss=0.2332, acc=58.67% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 3 Epoch 30: loss=0.2422, acc=58.67% (best=60.78%)\n",
      "          Fold 2 Epoch 30: loss=0.2335, acc=47.03% (best=62.73%)\n",
      "          Fold 3 Epoch 35: loss=0.2316, acc=45.70% (best=60.78%)\n",
      "          Fold 2 Epoch 35: loss=0.2227, acc=52.42% (best=62.73%)\n",
      "          Fold 3: Early stopping at epoch 38\n",
      "      â†’ Fold 3 completed: 60.78%\n",
      "          Fold 2: Early stopping at epoch 38\n",
      "      â†’ Fold 2 completed: 62.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f746090c:\n",
      "        Fold accuracies: ['59.61%', '62.73%', '60.78%', '65.70%', '64.69%']\n",
      "        Average fitness: 62.70% Â± 2.29%\n",
      "        Best fold: Fold 4 with 65.70%\n",
      "      Fitness obtained: 62.70% | Best in generation: 63.75% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6879, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7112, acc=59.30% (best=59.30%)\n",
      "          Fold 3 Epoch 1: loss=0.7010, acc=46.02% (best=46.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7023, acc=65.86% (best=65.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6663, acc=48.67% (best=48.67%)\n",
      "          Fold 2 Epoch 5: loss=0.4275, acc=51.48% (best=57.58%)\n",
      "          Fold 5 Epoch 5: loss=0.3840, acc=50.39% (best=59.30%)\n",
      "          Fold 3 Epoch 5: loss=0.3535, acc=57.81% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4692, acc=59.38% (best=65.86%)\n",
      "          Fold 4 Epoch 5: loss=0.3743, acc=38.75% (best=64.84%)\n",
      "          Fold 2 Epoch 10: loss=0.3095, acc=55.00% (best=63.75%)\n",
      "          Fold 5 Epoch 10: loss=0.2792, acc=46.72% (best=59.30%)\n",
      "          Fold 3 Epoch 10: loss=0.2822, acc=66.33% (best=66.33%)\n",
      "          Fold 1 Epoch 10: loss=0.3201, acc=41.88% (best=65.86%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.30%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 65.86%\n",
      "          Fold 4 Epoch 10: loss=0.2971, acc=57.73% (best=64.84%)\n",
      "          Fold 2 Epoch 15: loss=0.2677, acc=56.41% (best=66.64%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 3 Epoch 15: loss=0.2576, acc=55.55% (best=66.33%)\n",
      "          Fold 2 Epoch 20: loss=0.2575, acc=62.11% (best=70.62%)\n",
      "          Fold 3 Epoch 20: loss=0.2429, acc=64.06% (best=66.33%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 66.33%\n",
      "          Fold 2 Epoch 25: loss=0.2352, acc=61.09% (best=70.62%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 70.62%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['65.86%', '70.62%', '66.33%', '64.84%', '59.30%']\n",
      "        Average fitness: 65.39% Â± 3.63%\n",
      "        Best fold: Fold 2 with 70.62%\n",
      "      New best fitness in this generation: 65.39%!\n",
      "      Fitness obtained: 65.39% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 376114e0)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 376114e0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6311, acc=46.88% (best=46.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6114, acc=57.19% (best=57.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6483, acc=51.80% (best=51.80%)\n",
      "          Fold 4 Epoch 1: loss=0.6161, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.6542, acc=49.53% (best=49.53%)\n",
      "          Fold 2 Epoch 5: loss=0.2467, acc=50.08% (best=54.14%)\n",
      "          Fold 3 Epoch 5: loss=0.2571, acc=52.34% (best=62.27%)\n",
      "          Fold 1 Epoch 5: loss=0.2500, acc=49.22% (best=55.00%)\n",
      "          Fold 4 Epoch 5: loss=0.2436, acc=59.92% (best=61.41%)\n",
      "          Fold 5 Epoch 5: loss=0.2480, acc=45.70% (best=60.62%)\n",
      "          Fold 2 Epoch 10: loss=0.2089, acc=60.62% (best=60.86%)\n",
      "          Fold 3 Epoch 10: loss=0.2190, acc=44.53% (best=62.27%)\n",
      "          Fold 1 Epoch 10: loss=0.2096, acc=57.42% (best=57.42%)\n",
      "          Fold 4 Epoch 10: loss=0.2025, acc=57.81% (best=61.41%)\n",
      "          Fold 5 Epoch 10: loss=0.2135, acc=49.69% (best=60.62%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.27%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 61.41%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 2 Epoch 15: loss=0.2001, acc=62.11% (best=62.81%)\n",
      "          Fold 1 Epoch 15: loss=0.2010, acc=39.84% (best=57.42%)\n",
      "          Fold 2 Epoch 20: loss=0.2017, acc=53.75% (best=62.81%)\n",
      "          Fold 1 Epoch 20: loss=0.1940, acc=57.19% (best=57.42%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 57.42%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 62.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 376114e0:\n",
      "        Fold accuracies: ['57.42%', '62.81%', '62.27%', '61.41%', '60.62%']\n",
      "        Average fitness: 60.91% Â± 1.89%\n",
      "        Best fold: Fold 2 with 62.81%\n",
      "      Fitness obtained: 60.91% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 660f8134)\n",
      "      Architecture: 10 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 660f8134 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6856, acc=64.06% (best=64.06%)\n",
      "          Fold 5 Epoch 1: loss=0.6701, acc=39.61% (best=39.61%)\n",
      "          Fold 2 Epoch 1: loss=0.6705, acc=53.91% (best=53.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6510, acc=43.12% (best=43.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6504, acc=56.72% (best=56.72%)\n",
      "          Fold 2 Epoch 5: loss=0.3110, acc=44.22% (best=60.00%)\n",
      "          Fold 1 Epoch 5: loss=0.3528, acc=57.03% (best=64.06%)\n",
      "          Fold 5 Epoch 5: loss=0.3051, acc=31.02% (best=58.12%)\n",
      "          Fold 3 Epoch 5: loss=0.3445, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 5: loss=0.3212, acc=46.09% (best=68.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2643, acc=55.94% (best=60.00%)\n",
      "          Fold 1 Epoch 10: loss=0.2699, acc=50.08% (best=64.06%)\n",
      "          Fold 5 Epoch 10: loss=0.2517, acc=45.16% (best=58.12%)\n",
      "          Fold 3 Epoch 10: loss=0.2737, acc=53.05% (best=72.42%)\n",
      "          Fold 4 Epoch 10: loss=0.2552, acc=54.61% (best=68.52%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.06%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.12%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 60.00%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.52%\n",
      "          Fold 3 Epoch 15: loss=0.2434, acc=57.19% (best=72.42%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 72.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 660f8134:\n",
      "        Fold accuracies: ['64.06%', '60.00%', '72.42%', '68.52%', '58.12%']\n",
      "        Average fitness: 64.62% Â± 5.29%\n",
      "        Best fold: Fold 3 with 72.42%\n",
      "      Fitness obtained: 64.62% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 9f7a9f15)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 9f7a9f15 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7095, acc=46.09% (best=46.09%)\n",
      "          Fold 3 Epoch 1: loss=0.7198, acc=48.59% (best=48.59%)\n",
      "          Fold 4 Epoch 1: loss=0.6879, acc=45.08% (best=45.08%)\n",
      "          Fold 1 Epoch 1: loss=0.7124, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7293, acc=45.00% (best=45.00%)\n",
      "          Fold 2 Epoch 5: loss=0.4259, acc=43.36% (best=52.11%)\n",
      "          Fold 4 Epoch 5: loss=0.3742, acc=66.95% (best=66.95%)\n",
      "          Fold 3 Epoch 5: loss=0.3953, acc=54.53% (best=56.80%)\n",
      "          Fold 1 Epoch 5: loss=0.5555, acc=66.48% (best=66.48%)\n",
      "          Fold 5 Epoch 5: loss=0.4201, acc=50.62% (best=55.31%)\n",
      "          Fold 2 Epoch 10: loss=0.2936, acc=52.27% (best=58.52%)\n",
      "          Fold 4 Epoch 10: loss=0.2583, acc=59.14% (best=66.95%)\n",
      "          Fold 1 Epoch 10: loss=0.3213, acc=68.91% (best=71.25%)\n",
      "          Fold 3 Epoch 10: loss=0.2783, acc=56.88% (best=65.00%)\n",
      "          Fold 5 Epoch 10: loss=0.2800, acc=44.84% (best=55.39%)\n",
      "          Fold 2 Epoch 15: loss=0.2530, acc=47.03% (best=58.52%)\n",
      "          Fold 4 Epoch 15: loss=0.2292, acc=51.95% (best=66.95%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.95%\n",
      "          Fold 1 Epoch 15: loss=0.2637, acc=51.48% (best=71.25%)\n",
      "          Fold 3 Epoch 15: loss=0.2511, acc=67.34% (best=69.22%)\n",
      "          Fold 5 Epoch 15: loss=0.2361, acc=48.28% (best=56.56%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 71.25%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 58.52%\n",
      "          Fold 3 Epoch 20: loss=0.2326, acc=64.06% (best=69.22%)\n",
      "          Fold 5 Epoch 20: loss=0.2291, acc=46.48% (best=56.56%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9f7a9f15:\n",
      "        Fold accuracies: ['71.25%', '58.52%', '69.22%', '66.95%', '56.56%']\n",
      "        Average fitness: 64.50% Â± 5.88%\n",
      "        Best fold: Fold 1 with 71.25%\n",
      "      Fitness obtained: 64.50% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: d080d272)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model d080d272 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6632, acc=45.08% (best=45.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6891, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6723, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6655, acc=66.72% (best=66.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6835, acc=55.16% (best=55.16%)\n",
      "          Fold 2 Epoch 5: loss=0.2619, acc=55.31% (best=61.02%)\n",
      "          Fold 3 Epoch 5: loss=0.3038, acc=52.66% (best=66.48%)\n",
      "          Fold 4 Epoch 5: loss=0.3214, acc=49.22% (best=66.72%)\n",
      "          Fold 1 Epoch 5: loss=0.3894, acc=63.20% (best=63.20%)\n",
      "          Fold 5 Epoch 5: loss=0.2962, acc=61.56% (best=61.56%)\n",
      "          Fold 2 Epoch 10: loss=0.2191, acc=49.14% (best=67.19%)\n",
      "          Fold 3 Epoch 10: loss=0.2321, acc=56.33% (best=66.48%)\n",
      "          Fold 4 Epoch 10: loss=0.2284, acc=40.70% (best=66.72%)\n",
      "          Fold 1 Epoch 10: loss=0.2560, acc=51.80% (best=63.20%)\n",
      "          Fold 5 Epoch 10: loss=0.2285, acc=50.08% (best=61.56%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.72%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 66.48%\n",
      "          Fold 2 Epoch 15: loss=0.2215, acc=63.28% (best=67.19%)\n",
      "          Fold 1 Epoch 15: loss=0.2242, acc=52.81% (best=63.20%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.20%\n",
      "          Fold 5 Epoch 15: loss=0.2097, acc=48.67% (best=61.56%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 61.56%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d080d272:\n",
      "        Fold accuracies: ['63.20%', '67.19%', '66.48%', '66.72%', '61.56%']\n",
      "        Average fitness: 65.03% Â± 2.24%\n",
      "        Best fold: Fold 2 with 67.19%\n",
      "      Fitness obtained: 65.03% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: c1b9b94c)\n",
      "      Architecture: 8 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model c1b9b94c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7111, acc=50.55% (best=50.55%)\n",
      "          Fold 3 Epoch 1: loss=0.7218, acc=52.50% (best=52.50%)\n",
      "          Fold 1 Epoch 1: loss=0.7077, acc=52.50% (best=52.50%)\n",
      "          Fold 4 Epoch 1: loss=0.7067, acc=54.77% (best=54.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7194, acc=50.78% (best=50.78%)\n",
      "          Fold 2 Epoch 5: loss=0.6880, acc=51.02% (best=51.56%)\n",
      "          Fold 3 Epoch 5: loss=0.7060, acc=68.12% (best=68.12%)\n",
      "          Fold 4 Epoch 5: loss=0.6715, acc=56.25% (best=68.59%)\n",
      "          Fold 1 Epoch 5: loss=0.6945, acc=55.39% (best=59.53%)\n",
      "          Fold 5 Epoch 5: loss=0.7088, acc=42.66% (best=54.69%)\n",
      "          Fold 2 Epoch 10: loss=0.6711, acc=51.41% (best=51.56%)\n",
      "          Fold 3 Epoch 10: loss=0.6856, acc=54.61% (best=68.12%)\n",
      "          Fold 4 Epoch 10: loss=0.6499, acc=59.30% (best=68.59%)\n",
      "          Fold 1 Epoch 10: loss=0.6851, acc=60.00% (best=60.00%)\n",
      "          Fold 5 Epoch 10: loss=0.6937, acc=48.44% (best=54.69%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.59%\n",
      "          Fold 2 Epoch 15: loss=0.6557, acc=50.62% (best=53.20%)\n",
      "          Fold 3 Epoch 15: loss=0.6611, acc=55.47% (best=68.12%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 68.12%\n",
      "          Fold 1 Epoch 15: loss=0.6720, acc=62.81% (best=62.97%)\n",
      "          Fold 5 Epoch 15: loss=0.6752, acc=51.48% (best=63.75%)\n",
      "          Fold 2 Epoch 20: loss=0.6405, acc=50.39% (best=53.20%)\n",
      "          Fold 1 Epoch 20: loss=0.6534, acc=57.73% (best=64.53%)\n",
      "          Fold 5 Epoch 20: loss=0.6390, acc=56.95% (best=63.75%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 53.20%\n",
      "          Fold 1 Epoch 25: loss=0.6278, acc=54.84% (best=64.53%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c1b9b94c:\n",
      "        Fold accuracies: ['64.53%', '53.20%', '68.12%', '68.59%', '63.75%']\n",
      "        Average fitness: 63.64% Â± 5.56%\n",
      "        Best fold: Fold 4 with 68.59%\n",
      "      Fitness obtained: 63.64% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 237ee4ae)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 237ee4ae with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6738, acc=34.30% (best=34.30%)\n",
      "          Fold 3 Epoch 1: loss=0.6762, acc=57.34% (best=57.34%)\n",
      "          Fold 4 Epoch 1: loss=0.6266, acc=52.97% (best=52.97%)\n",
      "          Fold 1 Epoch 1: loss=0.6673, acc=59.30% (best=59.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6813, acc=44.38% (best=44.38%)\n",
      "          Fold 2 Epoch 5: loss=0.3703, acc=40.86% (best=50.00%)\n",
      "          Fold 3 Epoch 5: loss=0.3846, acc=45.94% (best=57.34%)\n",
      "          Fold 1 Epoch 5: loss=0.3813, acc=51.41% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.3800, acc=62.97% (best=69.61%)\n",
      "          Fold 5 Epoch 5: loss=0.3865, acc=49.53% (best=59.22%)\n",
      "          Fold 2 Epoch 10: loss=0.2854, acc=52.03% (best=53.12%)\n",
      "          Fold 3 Epoch 10: loss=0.3017, acc=65.16% (best=65.16%)\n",
      "          Fold 1 Epoch 10: loss=0.2956, acc=50.78% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.2832, acc=55.08% (best=69.61%)\n",
      "          Fold 5 Epoch 10: loss=0.2906, acc=51.17% (best=59.22%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 59.22%\n",
      "          Fold 2 Epoch 15: loss=0.2506, acc=49.22% (best=54.61%)\n",
      "          Fold 3 Epoch 15: loss=0.2629, acc=46.02% (best=65.16%)\n",
      "          Fold 1 Epoch 15: loss=0.2551, acc=63.91% (best=64.06%)\n",
      "          Fold 2 Epoch 20: loss=0.2396, acc=56.17% (best=56.17%)\n",
      "          Fold 3 Epoch 20: loss=0.2465, acc=54.06% (best=65.16%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 65.16%\n",
      "          Fold 1 Epoch 20: loss=0.2410, acc=49.84% (best=64.06%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 64.06%\n",
      "          Fold 2 Epoch 25: loss=0.2263, acc=59.14% (best=60.94%)\n",
      "          Fold 2 Epoch 30: loss=0.2168, acc=53.05% (best=60.94%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 60.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 237ee4ae:\n",
      "        Fold accuracies: ['64.06%', '60.94%', '65.16%', '69.61%', '59.22%']\n",
      "        Average fitness: 63.80% Â± 3.60%\n",
      "        Best fold: Fold 4 with 69.61%\n",
      "      Fitness obtained: 63.80% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: c783fe3b)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c783fe3b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6915, acc=51.25% (best=51.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6666, acc=63.91% (best=63.91%)\n",
      "          Fold 5 Epoch 1: loss=0.7006, acc=55.86% (best=55.86%)\n",
      "          Fold 2 Epoch 1: loss=0.6870, acc=59.53% (best=59.53%)\n",
      "          Fold 1 Epoch 1: loss=0.6864, acc=52.03% (best=52.03%)\n",
      "          Fold 4 Epoch 5: loss=0.4330, acc=49.77% (best=63.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3320, acc=55.86% (best=58.98%)\n",
      "          Fold 5 Epoch 5: loss=0.5010, acc=53.05% (best=55.86%)\n",
      "          Fold 1 Epoch 5: loss=0.5888, acc=60.86% (best=60.86%)\n",
      "          Fold 2 Epoch 5: loss=0.3564, acc=43.67% (best=59.53%)\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1422, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 3 Epoch 10: loss=0.2571, acc=61.95% (best=69.84%)\n",
      "          Fold 4 Epoch 10: loss=0.2595, acc=52.42% (best=63.91%)\n",
      "          Fold 5 Epoch 10: loss=0.2636, acc=57.34% (best=57.34%)\n",
      "          Fold 1 Epoch 10: loss=0.2763, acc=54.84% (best=60.86%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.91%\n",
      "          Fold 3 Epoch 15: loss=0.2358, acc=37.58% (best=69.84%)\n",
      "          Fold 5 Epoch 15: loss=0.2350, acc=56.33% (best=57.34%)\n",
      "          Fold 1 Epoch 15: loss=0.2423, acc=53.98% (best=60.86%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 60.86%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 69.84%\n",
      "          Fold 5 Epoch 20: loss=0.2189, acc=46.48% (best=58.59%)\n",
      "          Fold 5 Epoch 25: loss=0.2149, acc=45.16% (best=59.84%)\n",
      "          Fold 5 Epoch 30: loss=0.2075, acc=51.88% (best=59.84%)\n",
      "          Fold 5 Epoch 35: loss=0.2025, acc=52.34% (best=60.00%)\n",
      "          Fold 5 Epoch 40: loss=0.1988, acc=54.30% (best=60.00%)\n",
      "          Fold 5 Epoch 45: loss=0.1964, acc=52.27% (best=61.48%)\n",
      "          Fold 5 Epoch 50: loss=0.1971, acc=59.38% (best=61.48%)\n",
      "          Fold 5: Early stopping at epoch 51\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c783fe3b:\n",
      "        Fold accuracies: ['60.86%', '0.00%', '69.84%', '63.91%', '61.48%']\n",
      "        Average fitness: 51.22% Â± 25.81%\n",
      "        Best fold: Fold 3 with 69.84%\n",
      "      Fitness obtained: 51.22% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: eeb527d6)\n",
      "      Architecture: 11 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eeb527d6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6887, acc=39.61% (best=39.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6902, acc=51.95% (best=51.95%)\n",
      "          Fold 3 Epoch 1: loss=0.7058, acc=58.52% (best=58.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6730, acc=49.53% (best=49.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7135, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 5: loss=0.4240, acc=52.58% (best=52.58%)\n",
      "          Fold 1 Epoch 5: loss=0.4962, acc=46.48% (best=51.95%)\n",
      "          Fold 4 Epoch 5: loss=0.5206, acc=48.75% (best=59.38%)\n",
      "          Fold 3 Epoch 5: loss=0.4281, acc=57.81% (best=58.52%)\n",
      "          Fold 5 Epoch 5: loss=0.4857, acc=60.55% (best=60.55%)\n",
      "          Fold 2 Epoch 10: loss=0.3246, acc=41.72% (best=61.95%)\n",
      "          Fold 1 Epoch 10: loss=0.3837, acc=44.53% (best=53.44%)\n",
      "          Fold 4 Epoch 10: loss=0.3977, acc=51.88% (best=59.38%)\n",
      "          Fold 3 Epoch 10: loss=0.3424, acc=49.53% (best=62.11%)\n",
      "          Fold 5 Epoch 10: loss=0.3647, acc=43.36% (best=60.55%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 59.38%\n",
      "          Fold 2 Epoch 15: loss=0.2918, acc=60.62% (best=61.95%)\n",
      "          Fold 1 Epoch 15: loss=0.3357, acc=44.84% (best=53.44%)\n",
      "          Fold 3 Epoch 15: loss=0.3169, acc=58.75% (best=64.53%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 61.95%\n",
      "          Fold 5 Epoch 15: loss=0.3134, acc=48.28% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 1 Epoch 20: loss=0.2984, acc=49.69% (best=63.28%)\n",
      "          Fold 3 Epoch 20: loss=0.2905, acc=54.06% (best=64.53%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 64.53%\n",
      "          Fold 1 Epoch 25: loss=0.2756, acc=50.23% (best=63.28%)\n",
      "          Fold 1 Epoch 30: loss=0.2545, acc=54.30% (best=69.22%)\n",
      "          Fold 1 Epoch 35: loss=0.2423, acc=42.89% (best=69.22%)\n",
      "          Fold 1: Early stopping at epoch 38\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eeb527d6:\n",
      "        Fold accuracies: ['69.22%', '61.95%', '64.53%', '59.38%', '60.55%']\n",
      "        Average fitness: 63.12% Â± 3.50%\n",
      "        Best fold: Fold 1 with 69.22%\n",
      "      Fitness obtained: 63.12% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: a6ce7278)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model a6ce7278 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6735, acc=41.72% (best=41.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6481, acc=60.78% (best=60.78%)\n",
      "          Fold 5 Epoch 1: loss=0.6822, acc=48.83% (best=48.83%)\n",
      "          Fold 2 Epoch 5: loss=0.3437, acc=51.64% (best=63.44%)\n",
      "          Fold 1 Epoch 5: loss=0.3671, acc=57.81% (best=61.56%)\n",
      "          Fold 5 Epoch 5: loss=0.3443, acc=48.44% (best=55.55%)\n",
      "          Fold 2 Epoch 10: loss=0.2646, acc=66.48% (best=66.48%)\n",
      "          Fold 1 Epoch 10: loss=0.2576, acc=68.98% (best=68.98%)\n",
      "          Fold 5 Epoch 10: loss=0.2694, acc=50.39% (best=58.05%)\n",
      "          Fold 2 Epoch 15: loss=0.2373, acc=42.03% (best=66.48%)\n",
      "          Fold 1 Epoch 15: loss=0.2318, acc=65.31% (best=71.95%)\n",
      "          Fold 5 Epoch 15: loss=0.2426, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 20: loss=0.2265, acc=61.88% (best=67.27%)\n",
      "          Fold 1 Epoch 20: loss=0.2143, acc=72.11% (best=74.69%)\n",
      "          Fold 5 Epoch 20: loss=0.2288, acc=42.27% (best=58.52%)\n",
      "          Fold 2 Epoch 25: loss=0.2181, acc=57.11% (best=67.27%)\n",
      "          Fold 1 Epoch 25: loss=0.2064, acc=65.70% (best=74.69%)\n",
      "          Fold 5 Epoch 25: loss=0.2170, acc=48.98% (best=58.52%)\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 74.69%\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a6ce7278:\n",
      "        Fold accuracies: ['74.69%', '67.27%', '0.00%', '0.00%', '58.52%']\n",
      "        Average fitness: 40.09% Â± 33.13%\n",
      "        Best fold: Fold 1 with 74.69%\n",
      "      Fitness obtained: 40.09% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 7fbc932b)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7fbc932b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6879, acc=51.56% (best=51.56%)\n",
      "          Fold 3 Epoch 1: loss=0.7009, acc=50.55% (best=50.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6854, acc=49.06% (best=49.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6884, acc=50.00% (best=50.00%)\n",
      "          Fold 5 Epoch 1: loss=0.7128, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 5: loss=0.4514, acc=42.11% (best=56.72%)\n",
      "          Fold 3 Epoch 5: loss=0.4325, acc=52.81% (best=56.25%)\n",
      "          Fold 4 Epoch 5: loss=0.5559, acc=49.92% (best=58.05%)\n",
      "          Fold 1 Epoch 5: loss=0.4903, acc=45.78% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.4748, acc=44.69% (best=54.22%)\n",
      "          Fold 2 Epoch 10: loss=0.3245, acc=52.81% (best=56.72%)\n",
      "          Fold 3 Epoch 10: loss=0.3379, acc=48.28% (best=62.50%)\n",
      "          Fold 4 Epoch 10: loss=0.3871, acc=53.83% (best=71.25%)\n",
      "          Fold 1 Epoch 10: loss=0.3708, acc=47.66% (best=59.30%)\n",
      "          Fold 5 Epoch 10: loss=0.3358, acc=63.75% (best=63.75%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 56.72%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 59.30%\n",
      "          Fold 3 Epoch 15: loss=0.2832, acc=56.56% (best=62.50%)\n",
      "          Fold 4 Epoch 15: loss=0.3090, acc=43.12% (best=71.25%)\n",
      "          Fold 5 Epoch 15: loss=0.2933, acc=62.11% (best=63.75%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 62.50%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "          Fold 5 Epoch 20: loss=0.2597, acc=53.52% (best=63.75%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7fbc932b:\n",
      "        Fold accuracies: ['59.30%', '56.72%', '62.50%', '71.25%', '63.75%']\n",
      "        Average fitness: 62.70% Â± 4.93%\n",
      "        Best fold: Fold 4 with 71.25%\n",
      "      Fitness obtained: 62.70% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 04b08074)\n",
      "      Architecture: 10 conv + 4 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 04b08074 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7219, acc=47.42% (best=47.42%)\n",
      "          Fold 3 Epoch 1: loss=0.7227, acc=55.94% (best=55.94%)\n",
      "          Fold 1 Epoch 1: loss=0.7102, acc=57.97% (best=57.97%)\n",
      "          Fold 4 Epoch 1: loss=0.7130, acc=62.73% (best=62.73%)\n",
      "          Fold 5 Epoch 1: loss=0.7261, acc=58.75% (best=58.75%)\n",
      "          Fold 3 Epoch 5: loss=0.7053, acc=56.48% (best=60.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7090, acc=58.12% (best=61.56%)\n",
      "          Fold 2 Epoch 5: loss=0.6890, acc=48.67% (best=53.36%)\n",
      "          Fold 4 Epoch 5: loss=0.6860, acc=67.27% (best=70.00%)\n",
      "          Fold 1 Epoch 5: loss=0.6991, acc=62.73% (best=62.73%)\n",
      "          Fold 3 Epoch 10: loss=0.6959, acc=59.06% (best=62.27%)\n",
      "          Fold 2 Epoch 10: loss=0.6724, acc=52.73% (best=55.55%)\n",
      "          Fold 5 Epoch 10: loss=0.7013, acc=56.80% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.6772, acc=65.16% (best=73.36%)\n",
      "          Fold 1 Epoch 10: loss=0.6881, acc=50.23% (best=64.38%)\n",
      "          Fold 3 Epoch 15: loss=0.6884, acc=67.97% (best=67.97%)\n",
      "          Fold 2 Epoch 15: loss=0.6672, acc=51.09% (best=56.33%)\n",
      "          Fold 5 Epoch 15: loss=0.6983, acc=51.41% (best=61.95%)\n",
      "          Fold 4 Epoch 15: loss=0.6639, acc=60.16% (best=73.36%)\n",
      "          Fold 1 Epoch 15: loss=0.6852, acc=61.80% (best=64.38%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "          Fold 3 Epoch 20: loss=0.6757, acc=61.48% (best=70.16%)\n",
      "          Fold 2 Epoch 20: loss=0.6633, acc=51.25% (best=56.33%)\n",
      "          Fold 5 Epoch 20: loss=0.6934, acc=51.25% (best=61.95%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 64.38%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 56.33%\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 61.95%\n",
      "          Fold 3 Epoch 25: loss=0.6616, acc=63.28% (best=70.16%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 04b08074:\n",
      "        Fold accuracies: ['64.38%', '56.33%', '70.16%', '73.36%', '61.95%']\n",
      "        Average fitness: 65.23% Â± 6.02%\n",
      "        Best fold: Fold 4 with 73.36%\n",
      "      Fitness obtained: 65.23% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: b1e746e1)\n",
      "      Architecture: 10 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model b1e746e1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6862, acc=47.97% (best=47.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6936, acc=45.55% (best=45.55%)\n",
      "          Fold 5 Epoch 1: loss=0.7132, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.6985, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 5: loss=0.3531, acc=44.30% (best=52.81%)\n",
      "          Fold 3 Epoch 5: loss=0.4036, acc=53.12% (best=53.12%)\n",
      "          Fold 1 Epoch 5: loss=0.4954, acc=56.48% (best=62.89%)\n",
      "          Fold 5 Epoch 5: loss=0.3781, acc=53.67% (best=55.16%)\n",
      "          Fold 2 Epoch 10: loss=0.2676, acc=56.33% (best=56.33%)\n",
      "          Fold 3 Epoch 10: loss=0.3135, acc=55.08% (best=64.30%)\n",
      "          Fold 1 Epoch 10: loss=0.3306, acc=52.03% (best=62.89%)\n",
      "          Fold 5 Epoch 10: loss=0.2959, acc=42.11% (best=55.16%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.89%\n",
      "          Fold 2 Epoch 15: loss=0.2460, acc=54.45% (best=58.12%)\n",
      "          Fold 3 Epoch 15: loss=0.2707, acc=50.70% (best=64.30%)\n",
      "          Fold 5 Epoch 15: loss=0.2662, acc=52.73% (best=56.80%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 64.30%\n",
      "          Fold 2 Epoch 20: loss=0.2306, acc=47.42% (best=58.12%)\n",
      "          Fold 5 Epoch 20: loss=0.2538, acc=47.81% (best=56.80%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 56.80%\n",
      "          Fold 2 Epoch 25: loss=0.2227, acc=53.91% (best=62.58%)\n",
      "          Fold 2 Epoch 30: loss=0.2187, acc=63.75% (best=63.75%)\n",
      "          Fold 2 Epoch 35: loss=0.2130, acc=56.56% (best=63.75%)\n",
      "          Fold 2 Epoch 40: loss=0.2109, acc=56.09% (best=63.75%)\n",
      "          Fold 2: Early stopping at epoch 40\n",
      "      â†’ Fold 2 completed: 63.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b1e746e1:\n",
      "        Fold accuracies: ['62.89%', '63.75%', '64.30%', '0.00%', '56.80%']\n",
      "        Average fitness: 49.55% Â± 24.92%\n",
      "        Best fold: Fold 3 with 64.30%\n",
      "      Fitness obtained: 49.55% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: b87c465e)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model b87c465e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6426, acc=55.47% (best=55.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6276, acc=55.78% (best=55.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6480, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6409, acc=57.97% (best=57.97%)\n",
      "          Fold 5 Epoch 1: loss=0.6644, acc=47.50% (best=47.50%)\n",
      "          Fold 4 Epoch 5: loss=0.3106, acc=44.38% (best=57.97%)\n",
      "          Fold 1 Epoch 5: loss=0.3168, acc=44.14% (best=61.48%)\n",
      "          Fold 5 Epoch 5: loss=0.2865, acc=47.27% (best=58.44%)\n",
      "          Fold 2 Epoch 5: loss=0.2995, acc=51.25% (best=55.47%)\n",
      "          Fold 3 Epoch 5: loss=0.3078, acc=49.30% (best=55.78%)\n",
      "          Fold 4 Epoch 10: loss=0.2429, acc=56.80% (best=57.97%)\n",
      "          Fold 1 Epoch 10: loss=0.2512, acc=54.92% (best=61.48%)\n",
      "          Fold 5 Epoch 10: loss=0.2449, acc=35.86% (best=58.44%)\n",
      "          Fold 2 Epoch 10: loss=0.2511, acc=60.94% (best=60.94%)\n",
      "          Fold 3 Epoch 10: loss=0.2529, acc=53.59% (best=55.78%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 57.97%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.48%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.44%\n",
      "          Fold 2 Epoch 15: loss=0.2459, acc=37.03% (best=60.94%)\n",
      "          Fold 3 Epoch 15: loss=0.2358, acc=49.38% (best=58.91%)\n",
      "          Fold 2 Epoch 20: loss=0.2223, acc=53.44% (best=60.94%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 60.94%\n",
      "          Fold 3 Epoch 20: loss=0.2228, acc=55.78% (best=58.91%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b87c465e:\n",
      "        Fold accuracies: ['61.48%', '60.94%', '58.91%', '57.97%', '58.44%']\n",
      "        Average fitness: 59.55% Â± 1.40%\n",
      "        Best fold: Fold 1 with 61.48%\n",
      "      Fitness obtained: 59.55% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 372eaabb)\n",
      "      Architecture: 8 conv + 2 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 372eaabb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6877, acc=37.81% (best=37.81%)\n",
      "          Fold 3 Epoch 1: loss=0.7098, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 1: loss=0.6822, acc=62.58% (best=62.58%)\n",
      "          Fold 1 Epoch 1: loss=0.6968, acc=56.25% (best=56.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7116, acc=52.81% (best=52.81%)\n",
      "          Fold 2 Epoch 5: loss=0.6314, acc=42.11% (best=42.66%)\n",
      "          Fold 3 Epoch 5: loss=0.6391, acc=56.17% (best=59.84%)\n",
      "          Fold 4 Epoch 5: loss=0.6283, acc=63.98% (best=66.72%)\n",
      "          Fold 1 Epoch 5: loss=0.6200, acc=57.50% (best=61.33%)\n",
      "          Fold 5 Epoch 5: loss=0.6770, acc=50.70% (best=58.75%)\n",
      "          Fold 2 Epoch 10: loss=0.5610, acc=56.25% (best=56.25%)\n",
      "          Fold 3 Epoch 10: loss=0.5471, acc=57.19% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.5774, acc=53.83% (best=66.72%)\n",
      "          Fold 1 Epoch 10: loss=0.5094, acc=56.09% (best=61.33%)\n",
      "          Fold 5 Epoch 10: loss=0.6074, acc=53.98% (best=58.75%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 66.72%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.75%\n",
      "          Fold 2 Epoch 15: loss=0.4694, acc=51.25% (best=56.25%)\n",
      "          Fold 3 Epoch 15: loss=0.4780, acc=58.83% (best=63.59%)\n",
      "          Fold 1 Epoch 15: loss=0.4149, acc=58.52% (best=61.72%)\n",
      "          Fold 2 Epoch 20: loss=0.3909, acc=51.02% (best=56.25%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 56.25%\n",
      "          Fold 3 Epoch 20: loss=0.4207, acc=54.14% (best=63.59%)\n",
      "          Fold 1 Epoch 20: loss=0.3614, acc=56.25% (best=61.72%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 61.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 372eaabb:\n",
      "        Fold accuracies: ['61.72%', '56.25%', '63.59%', '66.72%', '58.75%']\n",
      "        Average fitness: 61.41% Â± 3.65%\n",
      "        Best fold: Fold 4 with 66.72%\n",
      "      Fitness obtained: 61.41% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 132c921a)\n",
      "      Architecture: 8 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 132c921a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7044, acc=40.08% (best=40.08%)\n",
      "          Fold 3 Epoch 1: loss=0.6751, acc=51.56% (best=51.56%)\n",
      "          Fold 1 Epoch 1: loss=0.7066, acc=55.16% (best=55.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6619, acc=46.72% (best=46.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7211, acc=54.92% (best=54.92%)\n",
      "          Fold 2 Epoch 5: loss=0.3497, acc=48.44% (best=48.44%)\n",
      "          Fold 3 Epoch 5: loss=0.3441, acc=56.72% (best=56.72%)\n",
      "          Fold 4 Epoch 5: loss=0.3589, acc=46.80% (best=56.72%)\n",
      "          Fold 1 Epoch 5: loss=0.3647, acc=53.20% (best=58.83%)\n",
      "          Fold 5 Epoch 5: loss=0.3897, acc=55.94% (best=66.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2642, acc=46.33% (best=48.44%)\n",
      "          Fold 3 Epoch 10: loss=0.2547, acc=55.94% (best=56.72%)\n",
      "          Fold 1 Epoch 10: loss=0.2571, acc=62.89% (best=65.62%)\n",
      "          Fold 4 Epoch 10: loss=0.2433, acc=42.66% (best=56.88%)\n",
      "          Fold 5 Epoch 10: loss=0.2817, acc=57.81% (best=66.09%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 66.09%\n",
      "          Fold 2 Epoch 15: loss=0.2315, acc=50.08% (best=50.70%)\n",
      "          Fold 3 Epoch 15: loss=0.2290, acc=46.56% (best=61.09%)\n",
      "          Fold 1 Epoch 15: loss=0.2273, acc=46.80% (best=65.62%)\n",
      "          Fold 4 Epoch 15: loss=0.2089, acc=40.62% (best=56.88%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 65.62%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 56.88%\n",
      "          Fold 2 Epoch 20: loss=0.2123, acc=43.98% (best=50.70%)\n",
      "          Fold 3 Epoch 20: loss=0.2170, acc=49.30% (best=61.09%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 50.70%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 61.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 132c921a:\n",
      "        Fold accuracies: ['65.62%', '50.70%', '61.09%', '56.88%', '66.09%']\n",
      "        Average fitness: 60.08% Â± 5.76%\n",
      "        Best fold: Fold 5 with 66.09%\n",
      "      Fitness obtained: 60.08% | Best in generation: 65.39% | Global best: 67.50%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 1b39d73a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b39d73a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6780, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6792, acc=53.12% (best=53.12%)\n",
      "          Fold 1 Epoch 1: loss=0.6880, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6657, acc=48.67% (best=48.67%)\n",
      "          Fold 5 Epoch 1: loss=0.7028, acc=52.11% (best=52.11%)\n",
      "          Fold 2 Epoch 5: loss=0.3491, acc=53.20% (best=53.20%)\n",
      "          Fold 3 Epoch 5: loss=0.3769, acc=69.61% (best=69.61%)\n",
      "          Fold 1 Epoch 5: loss=0.4039, acc=46.56% (best=54.06%)\n",
      "          Fold 4 Epoch 5: loss=0.4027, acc=53.44% (best=62.66%)\n",
      "          Fold 5 Epoch 5: loss=0.3350, acc=45.23% (best=63.91%)\n",
      "          Fold 2 Epoch 10: loss=0.2557, acc=54.14% (best=58.20%)\n",
      "          Fold 3 Epoch 10: loss=0.2689, acc=59.14% (best=69.61%)\n",
      "          Fold 1 Epoch 10: loss=0.2822, acc=43.12% (best=55.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2756, acc=49.06% (best=62.66%)\n",
      "          Fold 5 Epoch 10: loss=0.2532, acc=55.94% (best=63.91%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.66%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.91%\n",
      "          Fold 2 Epoch 15: loss=0.2284, acc=52.34% (best=67.89%)\n",
      "          Fold 3 Epoch 15: loss=0.2433, acc=63.83% (best=69.61%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 69.61%\n",
      "          Fold 1 Epoch 15: loss=0.2467, acc=58.36% (best=65.86%)\n",
      "          Fold 2 Epoch 20: loss=0.2219, acc=61.80% (best=67.89%)\n",
      "          Fold 1 Epoch 20: loss=0.2314, acc=61.09% (best=65.86%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 65.86%\n",
      "          Fold 2 Epoch 25: loss=0.2100, acc=59.22% (best=68.75%)\n",
      "          Fold 2 Epoch 30: loss=0.2065, acc=60.08% (best=68.75%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b39d73a:\n",
      "        Fold accuracies: ['65.86%', '68.75%', '69.61%', '62.66%', '63.91%']\n",
      "        Average fitness: 66.16% Â± 2.69%\n",
      "        Best fold: Fold 3 with 69.61%\n",
      "      New best fitness in this generation: 66.16%!\n",
      "      Fitness obtained: 66.16% | Best in generation: 66.16% | Global best: 67.50%\n",
      "\n",
      "GENERATION 9 STATISTICS:\n",
      "   Maximum fitness: 66.16%\n",
      "   Average fitness: 60.75%\n",
      "   Minimum fitness: 40.09%\n",
      "   Standard deviation: 6.34%\n",
      "   Best individual: 1b39d73a with 66.16%\n",
      "   Global best individual: 64530a51 with 67.50%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 10/20\n",
      "Adaptive mutation rate updated to 0.1964 (std_fitness=6.34)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1b39d73a (fitness: 66.16%)\n",
      "   Elite 2: 59336158 (fitness: 65.39%)\n",
      "   Elite 3: 04b08074 (fitness: 65.23%)\n",
      "   Elite 4: d080d272 (fitness: 65.03%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 11/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 10\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 10)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1b39d73a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b39d73a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6569, acc=69.30% (best=69.30%)\n",
      "          Fold 5 Epoch 1: loss=0.7110, acc=49.45% (best=49.45%)\n",
      "          Fold 3 Epoch 1: loss=0.6861, acc=50.70% (best=50.70%)\n",
      "          Fold 2 Epoch 1: loss=0.6686, acc=56.41% (best=56.41%)\n",
      "          Fold 1 Epoch 1: loss=0.6896, acc=54.38% (best=54.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3435, acc=61.80% (best=66.72%)\n",
      "          Fold 4 Epoch 5: loss=0.4080, acc=46.48% (best=69.30%)\n",
      "          Fold 2 Epoch 5: loss=0.3335, acc=46.72% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.3483, acc=53.20% (best=63.67%)\n",
      "          Fold 1 Epoch 5: loss=0.4149, acc=67.97% (best=67.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2633, acc=58.28% (best=66.72%)\n",
      "          Fold 2 Epoch 10: loss=0.2541, acc=56.09% (best=61.02%)\n",
      "          Fold 4 Epoch 10: loss=0.2658, acc=55.47% (best=69.30%)\n",
      "          Fold 5 Epoch 10: loss=0.2582, acc=37.19% (best=63.67%)\n",
      "          Fold 1 Epoch 10: loss=0.2997, acc=64.30% (best=67.97%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.72%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 63.67%\n",
      "          Fold 2 Epoch 15: loss=0.2329, acc=49.22% (best=62.42%)\n",
      "          Fold 1 Epoch 15: loss=0.2510, acc=54.61% (best=72.42%)\n",
      "          Fold 2 Epoch 20: loss=0.2296, acc=60.16% (best=62.42%)\n",
      "          Fold 1 Epoch 20: loss=0.2282, acc=58.67% (best=72.42%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 72.42%\n",
      "          Fold 2 Epoch 25: loss=0.2189, acc=65.39% (best=65.39%)\n",
      "          Fold 2 Epoch 30: loss=0.2029, acc=59.53% (best=65.39%)\n",
      "          Fold 2 Epoch 35: loss=0.2143, acc=68.75% (best=68.75%)\n",
      "          Fold 2 Epoch 40: loss=0.2082, acc=61.09% (best=68.75%)\n",
      "          Fold 2 Epoch 45: loss=0.2018, acc=64.53% (best=75.08%)\n",
      "          Fold 2 Epoch 50: loss=0.1979, acc=66.02% (best=75.08%)\n",
      "          Fold 2: Early stopping at epoch 51\n",
      "      â†’ Fold 2 completed: 75.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b39d73a:\n",
      "        Fold accuracies: ['72.42%', '75.08%', '66.72%', '69.30%', '63.67%']\n",
      "        Average fitness: 69.44% Â± 4.03%\n",
      "        Best fold: Fold 2 with 75.08%\n",
      "      New best fitness in this generation: 69.44%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 69.44% > 67.50%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen4_id64530a51_fitness67.50.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen10_id1b39d73a_fitness69.44.pth\n",
      "        Fitness: 69.44%, ID: 1b39d73a, Gen: 10\n",
      "      Fitness obtained: 69.44% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6887, acc=52.97% (best=52.97%)\n",
      "          Fold 3 Epoch 1: loss=0.6990, acc=48.20% (best=48.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6654, acc=66.64% (best=66.64%)\n",
      "          Fold 1 Epoch 1: loss=0.7017, acc=55.39% (best=55.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7149, acc=44.77% (best=44.77%)\n",
      "          Fold 2 Epoch 5: loss=0.4052, acc=52.34% (best=62.89%)\n",
      "          Fold 4 Epoch 5: loss=0.3613, acc=65.94% (best=66.64%)\n",
      "          Fold 3 Epoch 5: loss=0.4425, acc=52.11% (best=57.73%)\n",
      "          Fold 1 Epoch 5: loss=0.4623, acc=47.97% (best=56.33%)\n",
      "          Fold 5 Epoch 5: loss=0.4404, acc=54.14% (best=57.58%)\n",
      "          Fold 2 Epoch 10: loss=0.3002, acc=35.16% (best=62.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2827, acc=50.70% (best=66.64%)\n",
      "          Fold 3 Epoch 10: loss=0.2962, acc=58.28% (best=63.44%)\n",
      "          Fold 1 Epoch 10: loss=0.3193, acc=65.23% (best=68.75%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.64%\n",
      "          Fold 5 Epoch 10: loss=0.3261, acc=47.66% (best=57.66%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 62.89%\n",
      "          Fold 3 Epoch 15: loss=0.2713, acc=67.89% (best=67.89%)\n",
      "          Fold 1 Epoch 15: loss=0.2842, acc=63.98% (best=68.75%)\n",
      "          Fold 5 Epoch 15: loss=0.2821, acc=53.20% (best=57.66%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 68.75%\n",
      "          Fold 3 Epoch 20: loss=0.2548, acc=58.59% (best=67.89%)\n",
      "          Fold 3 Epoch 25: loss=0.2418, acc=59.77% (best=67.89%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 67.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['68.75%', '62.89%', '67.89%', '66.64%', '57.66%']\n",
      "        Average fitness: 64.77% Â± 4.08%\n",
      "        Best fold: Fold 1 with 68.75%\n",
      "      Fitness obtained: 64.77% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 04b08074)\n",
      "      Architecture: 10 conv + 4 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 04b08074 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7127, acc=61.33% (best=61.33%)\n",
      "          Fold 1 Epoch 1: loss=0.7163, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7325, acc=41.64% (best=41.64%)\n",
      "          Fold 2 Epoch 1: loss=0.7071, acc=43.28% (best=43.28%)\n",
      "          Fold 4 Epoch 1: loss=0.7065, acc=60.16% (best=60.16%)\n",
      "          Fold 3 Epoch 5: loss=0.7037, acc=65.23% (best=65.23%)\n",
      "          Fold 1 Epoch 5: loss=0.6967, acc=50.55% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.7075, acc=40.23% (best=48.12%)\n",
      "          Fold 4 Epoch 5: loss=0.6796, acc=71.48% (best=71.48%)\n",
      "          Fold 2 Epoch 5: loss=0.6862, acc=39.84% (best=43.28%)\n",
      "          Fold 3 Epoch 10: loss=0.6950, acc=61.09% (best=65.23%)\n",
      "          Fold 1 Epoch 10: loss=0.6914, acc=52.81% (best=61.02%)\n",
      "          Fold 5 Epoch 10: loss=0.7010, acc=41.02% (best=48.12%)\n",
      "          Fold 4 Epoch 10: loss=0.6739, acc=67.81% (best=71.48%)\n",
      "          Fold 2 Epoch 10: loss=0.6808, acc=39.30% (best=43.28%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.02%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 48.12%\n",
      "          Fold 3 Epoch 15: loss=0.6839, acc=65.78% (best=65.78%)\n",
      "          Fold 2 Epoch 15: loss=0.6717, acc=39.30% (best=50.47%)\n",
      "          Fold 4 Epoch 15: loss=0.6705, acc=67.58% (best=71.48%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 71.48%\n",
      "          Fold 3 Epoch 20: loss=0.6750, acc=60.86% (best=68.83%)\n",
      "          Fold 2 Epoch 20: loss=0.6611, acc=41.33% (best=53.12%)\n",
      "          Fold 3 Epoch 25: loss=0.6652, acc=58.20% (best=68.83%)\n",
      "          Fold 2 Epoch 25: loss=0.6584, acc=50.70% (best=53.91%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 68.83%\n",
      "          Fold 2 Epoch 30: loss=0.6436, acc=46.25% (best=53.91%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 53.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 04b08074:\n",
      "        Fold accuracies: ['61.02%', '53.91%', '68.83%', '71.48%', '48.12%']\n",
      "        Average fitness: 60.67% Â± 8.79%\n",
      "        Best fold: Fold 4 with 71.48%\n",
      "      Fitness obtained: 60.67% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: d080d272)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model d080d272 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6787, acc=53.52% (best=53.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6639, acc=53.28% (best=53.28%)\n",
      "          Fold 3 Epoch 1: loss=0.6846, acc=55.31% (best=55.31%)\n",
      "          Fold 4 Epoch 1: loss=0.6602, acc=59.92% (best=59.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7089, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 5: loss=0.2649, acc=46.64% (best=61.41%)\n",
      "          Fold 3 Epoch 5: loss=0.2835, acc=56.48% (best=56.48%)\n",
      "          Fold 1 Epoch 5: loss=0.3578, acc=62.58% (best=70.08%)\n",
      "          Fold 4 Epoch 5: loss=0.3521, acc=53.20% (best=63.91%)\n",
      "          Fold 5 Epoch 5: loss=0.3193, acc=40.47% (best=60.31%)\n",
      "          Fold 2 Epoch 10: loss=0.2256, acc=46.56% (best=61.41%)\n",
      "          Fold 3 Epoch 10: loss=0.2291, acc=53.05% (best=58.83%)\n",
      "          Fold 1 Epoch 10: loss=0.2348, acc=58.83% (best=70.08%)\n",
      "          Fold 4 Epoch 10: loss=0.2469, acc=62.11% (best=63.91%)\n",
      "          Fold 5 Epoch 10: loss=0.2292, acc=53.52% (best=60.31%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 61.41%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "          Fold 3 Epoch 15: loss=0.2145, acc=47.73% (best=58.83%)\n",
      "          Fold 1 Epoch 15: loss=0.2131, acc=54.53% (best=70.70%)\n",
      "          Fold 4 Epoch 15: loss=0.2185, acc=50.16% (best=64.92%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 58.83%\n",
      "          Fold 1 Epoch 20: loss=0.2062, acc=62.27% (best=70.70%)\n",
      "          Fold 4 Epoch 20: loss=0.2141, acc=57.03% (best=64.92%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 64.92%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 70.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d080d272:\n",
      "        Fold accuracies: ['70.70%', '61.41%', '58.83%', '64.92%', '60.31%']\n",
      "        Average fitness: 63.23% Â± 4.24%\n",
      "        Best fold: Fold 1 with 70.70%\n",
      "      Fitness obtained: 63.23% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: ffdc7680)\n",
      "      Architecture: 12 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model ffdc7680 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6977, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 1: loss=0.6698, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6538, acc=68.75% (best=68.75%)\n",
      "          Fold 5 Epoch 1: loss=0.7028, acc=41.33% (best=41.33%)\n",
      "          Fold 1 Epoch 1: loss=0.6850, acc=40.78% (best=40.78%)\n",
      "          Fold 3 Epoch 5: loss=0.3654, acc=59.92% (best=62.97%)\n",
      "          Fold 4 Epoch 5: loss=0.4055, acc=53.75% (best=68.75%)\n",
      "          Fold 2 Epoch 5: loss=0.3692, acc=37.81% (best=57.73%)\n",
      "          Fold 5 Epoch 5: loss=0.4095, acc=57.58% (best=57.58%)\n",
      "          Fold 1 Epoch 5: loss=0.4700, acc=54.84% (best=55.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2838, acc=55.39% (best=65.08%)\n",
      "          Fold 4 Epoch 10: loss=0.2793, acc=52.11% (best=70.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2778, acc=36.48% (best=57.73%)\n",
      "          Fold 5 Epoch 10: loss=0.3002, acc=43.67% (best=57.58%)\n",
      "          Fold 1 Epoch 10: loss=0.3211, acc=50.70% (best=55.00%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 57.73%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 55.00%\n",
      "          Fold 3 Epoch 15: loss=0.2603, acc=56.64% (best=65.08%)\n",
      "          Fold 4 Epoch 15: loss=0.2655, acc=57.42% (best=70.70%)\n",
      "          Fold 5 Epoch 15: loss=0.2612, acc=41.25% (best=57.58%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.58%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 65.08%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 70.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ffdc7680:\n",
      "        Fold accuracies: ['55.00%', '57.73%', '65.08%', '70.70%', '57.58%']\n",
      "        Average fitness: 61.22% Â± 5.81%\n",
      "        Best fold: Fold 4 with 70.70%\n",
      "      Fitness obtained: 61.22% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 87af66b6)\n",
      "      Architecture: 24 conv + 8 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 87af66b6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 100, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 87af66b6:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 9fde62b9)\n",
      "      Architecture: 12 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 9fde62b9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1701, in relu\n",
      "    result = torch.relu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6930, acc=48.59% (best=48.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3519, acc=43.36% (best=60.16%)\n",
      "          Fold 2 Epoch 10: loss=0.2768, acc=57.58% (best=60.16%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 60.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fde62b9:\n",
      "        Fold accuracies: ['0.00%', '60.16%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 12.03% Â± 24.06%\n",
      "        Best fold: Fold 2 with 60.16%\n",
      "      Fitness obtained: 12.03% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 9fb19248)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 9fb19248 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6694, acc=57.19% (best=57.19%)\n",
      "          Fold 2 Epoch 1: loss=0.6765, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6676, acc=46.95% (best=46.95%)\n",
      "          Fold 4 Epoch 1: loss=0.6618, acc=40.31% (best=40.31%)\n",
      "          Fold 5 Epoch 1: loss=0.7070, acc=44.14% (best=44.14%)\n",
      "          Fold 3 Epoch 5: loss=0.3387, acc=55.00% (best=58.83%)\n",
      "          Fold 2 Epoch 5: loss=0.3006, acc=63.67% (best=63.67%)\n",
      "          Fold 1 Epoch 5: loss=0.3082, acc=44.77% (best=52.66%)\n",
      "          Fold 4 Epoch 5: loss=0.3327, acc=52.19% (best=55.70%)\n",
      "          Fold 5 Epoch 5: loss=0.3428, acc=43.36% (best=55.62%)\n",
      "          Fold 3 Epoch 10: loss=0.2607, acc=48.91% (best=58.83%)\n",
      "          Fold 2 Epoch 10: loss=0.2479, acc=59.30% (best=63.67%)\n",
      "          Fold 1 Epoch 10: loss=0.2575, acc=62.58% (best=62.58%)\n",
      "          Fold 4 Epoch 10: loss=0.2488, acc=56.41% (best=56.41%)\n",
      "          Fold 5 Epoch 10: loss=0.2615, acc=43.36% (best=59.06%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 58.83%\n",
      "          Fold 2 Epoch 15: loss=0.2238, acc=64.84% (best=64.84%)\n",
      "          Fold 1 Epoch 15: loss=0.2307, acc=59.30% (best=62.58%)\n",
      "          Fold 4 Epoch 15: loss=0.2372, acc=49.45% (best=56.41%)\n",
      "          Fold 5 Epoch 15: loss=0.2318, acc=52.73% (best=59.06%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 59.06%\n",
      "          Fold 2 Epoch 20: loss=0.2156, acc=63.67% (best=70.47%)\n",
      "          Fold 1 Epoch 20: loss=0.2241, acc=50.23% (best=62.58%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 62.58%\n",
      "          Fold 4 Epoch 20: loss=0.2161, acc=52.73% (best=63.83%)\n",
      "          Fold 2 Epoch 25: loss=0.2096, acc=62.42% (best=74.69%)\n",
      "          Fold 4 Epoch 25: loss=0.2256, acc=53.36% (best=63.83%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 2 Epoch 30: loss=0.2067, acc=64.22% (best=74.69%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 74.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9fb19248:\n",
      "        Fold accuracies: ['62.58%', '74.69%', '58.83%', '63.83%', '59.06%']\n",
      "        Average fitness: 63.80% Â± 5.78%\n",
      "        Best fold: Fold 2 with 74.69%\n",
      "      Fitness obtained: 63.80% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: daf197dd)\n",
      "      Architecture: 10 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model daf197dd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7279, acc=68.28% (best=68.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7135, acc=46.25% (best=46.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7234, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 1: loss=0.7057, acc=61.41% (best=61.41%)\n",
      "          Fold 1 Epoch 1: loss=0.7433, acc=53.44% (best=53.44%)\n",
      "          Fold 4 Epoch 5: loss=0.6842, acc=65.23% (best=68.28%)\n",
      "          Fold 3 Epoch 5: loss=0.7046, acc=53.52% (best=56.17%)\n",
      "          Fold 5 Epoch 5: loss=0.7168, acc=53.98% (best=58.83%)\n",
      "          Fold 2 Epoch 5: loss=0.6838, acc=55.23% (best=61.41%)\n",
      "          Fold 1 Epoch 5: loss=0.7051, acc=52.97% (best=60.78%)\n",
      "          Fold 3 Epoch 10: loss=0.6957, acc=50.08% (best=56.17%)\n",
      "          Fold 4 Epoch 10: loss=0.6748, acc=59.45% (best=68.28%)\n",
      "          Fold 5 Epoch 10: loss=0.7098, acc=52.19% (best=58.83%)\n",
      "          Fold 2 Epoch 10: loss=0.6795, acc=51.95% (best=61.41%)\n",
      "          Fold 1 Epoch 10: loss=0.6979, acc=59.14% (best=62.19%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.28%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 61.41%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 56.17%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.83%\n",
      "          Fold 1 Epoch 15: loss=0.6935, acc=55.94% (best=62.19%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 62.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for daf197dd:\n",
      "        Fold accuracies: ['62.19%', '61.41%', '56.17%', '68.28%', '58.83%']\n",
      "        Average fitness: 61.38% Â± 4.05%\n",
      "        Best fold: Fold 4 with 68.28%\n",
      "      Fitness obtained: 61.38% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: c284d7a7)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.001\n",
      "      Training/Evaluating model c284d7a7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6989, acc=44.06% (best=44.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6998, acc=50.86% (best=50.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6795, acc=62.27% (best=62.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6843, acc=54.30% (best=54.30%)\n",
      "          Fold 5 Epoch 1: loss=0.7101, acc=53.44% (best=53.44%)\n",
      "          Fold 2 Epoch 5: loss=0.3413, acc=48.75% (best=53.98%)\n",
      "          Fold 1 Epoch 5: loss=0.3786, acc=51.56% (best=68.83%)\n",
      "          Fold 4 Epoch 5: loss=0.3770, acc=66.56% (best=67.97%)\n",
      "          Fold 3 Epoch 5: loss=0.3977, acc=52.97% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.3742, acc=48.36% (best=53.44%)\n",
      "          Fold 2 Epoch 10: loss=0.2678, acc=45.16% (best=56.48%)\n",
      "          Fold 1 Epoch 10: loss=0.2657, acc=63.28% (best=68.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2836, acc=55.08% (best=67.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2846, acc=41.09% (best=62.11%)\n",
      "          Fold 5 Epoch 10: loss=0.2752, acc=37.58% (best=53.44%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 53.44%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.11%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 68.83%\n",
      "          Fold 2 Epoch 15: loss=0.2601, acc=52.03% (best=58.91%)\n",
      "          Fold 2 Epoch 20: loss=0.2343, acc=61.64% (best=61.64%)\n",
      "          Fold 2 Epoch 25: loss=0.2278, acc=53.91% (best=61.64%)\n",
      "          Fold 2 Epoch 30: loss=0.2115, acc=51.09% (best=61.64%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c284d7a7:\n",
      "        Fold accuracies: ['68.83%', '61.64%', '62.11%', '67.97%', '53.44%']\n",
      "        Average fitness: 62.80% Â± 5.52%\n",
      "        Best fold: Fold 1 with 68.83%\n",
      "      Fitness obtained: 62.80% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 323991fc)\n",
      "      Architecture: 8 conv + 3 fc, opt=adam, lr=0.01\n",
      "      Training/Evaluating model 323991fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6924, acc=42.42% (best=42.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6912, acc=47.11% (best=47.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6959, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 1: loss=0.6694, acc=67.27% (best=67.27%)\n",
      "          Fold 5 Epoch 1: loss=0.7158, acc=42.89% (best=42.89%)\n",
      "          Fold 2 Epoch 5: loss=0.3535, acc=46.25% (best=46.25%)\n",
      "          Fold 3 Epoch 5: loss=0.3616, acc=63.52% (best=67.50%)\n",
      "          Fold 4 Epoch 5: loss=0.4331, acc=43.75% (best=68.05%)\n",
      "          Fold 1 Epoch 5: loss=0.5102, acc=46.72% (best=56.02%)\n",
      "          Fold 5 Epoch 5: loss=0.3790, acc=55.47% (best=55.78%)\n",
      "          Fold 2 Epoch 10: loss=0.2631, acc=48.91% (best=48.91%)\n",
      "          Fold 3 Epoch 10: loss=0.2815, acc=63.75% (best=67.50%)\n",
      "          Fold 1 Epoch 10: loss=0.3480, acc=49.92% (best=59.69%)\n",
      "          Fold 4 Epoch 10: loss=0.2766, acc=63.75% (best=68.05%)\n",
      "          Fold 5 Epoch 10: loss=0.2520, acc=45.00% (best=55.78%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 55.78%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 67.50%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 2 Epoch 15: loss=0.2319, acc=49.69% (best=51.17%)\n",
      "          Fold 1 Epoch 15: loss=0.2626, acc=47.58% (best=59.69%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 59.69%\n",
      "          Fold 2 Epoch 20: loss=0.2215, acc=56.02% (best=56.02%)\n",
      "          Fold 2 Epoch 25: loss=0.2239, acc=51.17% (best=56.64%)\n",
      "          Fold 2 Epoch 30: loss=0.2069, acc=58.75% (best=59.53%)\n",
      "          Fold 2 Epoch 35: loss=0.2453, acc=54.92% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 323991fc:\n",
      "        Fold accuracies: ['59.69%', '59.53%', '67.50%', '68.05%', '55.78%']\n",
      "        Average fitness: 62.11% Â± 4.83%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      Fitness obtained: 62.11% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 60b97f21)\n",
      "      Architecture: 10 conv + 4 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 60b97f21 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7180, acc=51.88% (best=51.88%)\n",
      "          Fold 4 Epoch 1: loss=0.7136, acc=60.86% (best=60.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7130, acc=54.45% (best=54.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7335, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7322, acc=61.41% (best=61.41%)\n",
      "          Fold 1 Epoch 5: loss=0.7009, acc=53.20% (best=59.14%)\n",
      "          Fold 4 Epoch 5: loss=0.6846, acc=63.98% (best=63.98%)\n",
      "          Fold 5 Epoch 5: loss=0.7063, acc=46.88% (best=54.45%)\n",
      "          Fold 3 Epoch 5: loss=0.7017, acc=48.75% (best=48.98%)\n",
      "          Fold 2 Epoch 5: loss=0.6948, acc=49.06% (best=61.41%)\n",
      "          Fold 1 Epoch 10: loss=0.6921, acc=43.98% (best=59.14%)\n",
      "          Fold 4 Epoch 10: loss=0.6749, acc=52.97% (best=63.98%)\n",
      "          Fold 5 Epoch 10: loss=0.7061, acc=53.05% (best=61.80%)\n",
      "          Fold 3 Epoch 10: loss=0.6969, acc=52.42% (best=52.42%)\n",
      "          Fold 2 Epoch 10: loss=0.6845, acc=34.53% (best=61.41%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 61.41%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 59.14%\n",
      "          Fold 4 Epoch 15: loss=0.6574, acc=48.12% (best=63.98%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 63.98%\n",
      "          Fold 5 Epoch 15: loss=0.6979, acc=56.95% (best=61.80%)\n",
      "          Fold 3 Epoch 15: loss=0.6894, acc=46.56% (best=52.42%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "          Fold 3 Epoch 20: loss=0.6792, acc=43.20% (best=52.42%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 52.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 60b97f21:\n",
      "        Fold accuracies: ['59.14%', '61.41%', '52.42%', '63.98%', '61.80%']\n",
      "        Average fitness: 59.75% Â± 3.97%\n",
      "        Best fold: Fold 4 with 63.98%\n",
      "      Fitness obtained: 59.75% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 1142d6fc)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 1142d6fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6918, acc=40.23% (best=40.23%)\n",
      "          Fold 3 Epoch 1: loss=0.7097, acc=58.98% (best=58.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6843, acc=62.81% (best=62.81%)\n",
      "          Fold 1 Epoch 1: loss=0.7133, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7128, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 5: loss=0.5682, acc=44.30% (best=47.03%)\n",
      "          Fold 3 Epoch 5: loss=0.5579, acc=53.36% (best=62.11%)\n",
      "          Fold 4 Epoch 5: loss=0.5200, acc=55.00% (best=66.09%)\n",
      "          Fold 1 Epoch 5: loss=0.6165, acc=49.53% (best=56.95%)\n",
      "          Fold 5 Epoch 5: loss=0.6595, acc=50.00% (best=64.22%)\n",
      "          Fold 2 Epoch 10: loss=0.3239, acc=58.36% (best=58.36%)\n",
      "          Fold 3 Epoch 10: loss=0.3529, acc=59.06% (best=65.23%)\n",
      "          Fold 4 Epoch 10: loss=0.3472, acc=58.91% (best=66.09%)\n",
      "          Fold 1 Epoch 10: loss=0.4216, acc=42.42% (best=60.08%)\n",
      "          Fold 5 Epoch 10: loss=0.4243, acc=51.41% (best=64.22%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 64.22%\n",
      "          Fold 2 Epoch 15: loss=0.2795, acc=56.56% (best=59.53%)\n",
      "          Fold 3 Epoch 15: loss=0.3082, acc=58.36% (best=65.23%)\n",
      "          Fold 4 Epoch 15: loss=0.2943, acc=52.27% (best=67.03%)\n",
      "          Fold 1 Epoch 15: loss=0.3486, acc=53.12% (best=60.08%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 60.08%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "          Fold 2 Epoch 20: loss=0.2651, acc=50.78% (best=59.53%)\n",
      "          Fold 4 Epoch 20: loss=0.2562, acc=64.22% (best=67.03%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "          Fold 4 Epoch 25: loss=0.2379, acc=61.17% (best=70.47%)\n",
      "          Fold 4 Epoch 30: loss=0.2259, acc=67.73% (best=70.47%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1142d6fc:\n",
      "        Fold accuracies: ['60.08%', '59.53%', '65.23%', '70.47%', '64.22%']\n",
      "        Average fitness: 63.91% Â± 3.97%\n",
      "        Best fold: Fold 4 with 70.47%\n",
      "      Fitness obtained: 63.91% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 1808ef0b)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 1808ef0b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6572, acc=55.47% (best=55.47%)\n",
      "          Fold 3 Epoch 1: loss=0.6659, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6370, acc=67.81% (best=67.81%)\n",
      "          Fold 1 Epoch 1: loss=0.6846, acc=52.81% (best=52.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7009, acc=42.89% (best=42.89%)\n",
      "          Fold 2 Epoch 5: loss=0.2957, acc=55.62% (best=55.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3006, acc=60.39% (best=60.39%)\n",
      "          Fold 4 Epoch 5: loss=0.2690, acc=62.34% (best=67.81%)\n",
      "          Fold 1 Epoch 5: loss=0.2889, acc=64.53% (best=64.53%)\n",
      "          Fold 5 Epoch 5: loss=0.2718, acc=43.75% (best=50.62%)\n",
      "          Fold 2 Epoch 10: loss=0.2354, acc=52.73% (best=61.33%)\n",
      "          Fold 3 Epoch 10: loss=0.2341, acc=52.66% (best=60.39%)\n",
      "          Fold 1 Epoch 10: loss=0.2321, acc=63.52% (best=65.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2203, acc=47.58% (best=67.81%)\n",
      "          Fold 5 Epoch 10: loss=0.2243, acc=40.31% (best=50.62%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.81%\n",
      "          Fold 2 Epoch 15: loss=0.2115, acc=55.39% (best=64.84%)\n",
      "          Fold 3 Epoch 15: loss=0.2163, acc=50.08% (best=60.39%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 60.39%\n",
      "          Fold 1 Epoch 15: loss=0.2116, acc=65.86% (best=65.86%)\n",
      "          Fold 5 Epoch 15: loss=0.2107, acc=51.02% (best=51.17%)\n",
      "          Fold 2 Epoch 20: loss=0.2021, acc=51.41% (best=65.00%)\n",
      "          Fold 1 Epoch 20: loss=0.2025, acc=61.80% (best=67.81%)\n",
      "          Fold 5 Epoch 20: loss=0.2013, acc=46.25% (best=53.05%)\n",
      "          Fold 2 Epoch 25: loss=0.2002, acc=52.58% (best=65.00%)\n",
      "          Fold 1 Epoch 25: loss=0.1961, acc=67.11% (best=72.27%)\n",
      "          Fold 5 Epoch 25: loss=0.1955, acc=47.19% (best=53.05%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 65.00%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 53.05%\n",
      "          Fold 1 Epoch 30: loss=0.1964, acc=61.72% (best=72.27%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 72.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1808ef0b:\n",
      "        Fold accuracies: ['72.27%', '65.00%', '60.39%', '67.81%', '53.05%']\n",
      "        Average fitness: 63.70% Â± 6.58%\n",
      "        Best fold: Fold 1 with 72.27%\n",
      "      Fitness obtained: 63.70% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 9da5aa88)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 9da5aa88 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=1.3084, acc=47.19% (best=47.19%)\n",
      "          Fold 3 Epoch 1: loss=1.1391, acc=39.53% (best=39.53%)\n",
      "          Fold 5 Epoch 1: loss=1.4519, acc=50.16% (best=50.16%)\n",
      "          Fold 4 Epoch 1: loss=0.9936, acc=52.11% (best=52.11%)\n",
      "          Fold 1 Epoch 1: loss=1.3325, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 5: loss=0.6477, acc=42.89% (best=50.23%)\n",
      "          Fold 3 Epoch 5: loss=0.5376, acc=58.91% (best=58.91%)\n",
      "          Fold 5 Epoch 5: loss=0.6813, acc=49.92% (best=63.12%)\n",
      "          Fold 4 Epoch 5: loss=0.6350, acc=66.88% (best=66.88%)\n",
      "          Fold 1 Epoch 5: loss=0.6720, acc=60.23% (best=60.23%)\n",
      "          Fold 2 Epoch 10: loss=0.4455, acc=49.14% (best=53.05%)\n",
      "          Fold 3 Epoch 10: loss=0.3290, acc=56.41% (best=58.91%)\n",
      "          Fold 5 Epoch 10: loss=0.4132, acc=43.52% (best=63.12%)\n",
      "          Fold 4 Epoch 10: loss=0.4220, acc=36.48% (best=66.88%)\n",
      "          Fold 1 Epoch 10: loss=0.4349, acc=45.94% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "          Fold 2 Epoch 15: loss=0.2939, acc=47.11% (best=53.05%)\n",
      "          Fold 3 Epoch 15: loss=0.2750, acc=45.39% (best=62.03%)\n",
      "          Fold 4 Epoch 15: loss=0.2826, acc=50.16% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 1 Epoch 15: loss=0.2875, acc=60.39% (best=62.89%)\n",
      "          Fold 2 Epoch 20: loss=0.2572, acc=50.39% (best=55.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2387, acc=56.72% (best=62.03%)\n",
      "          Fold 1 Epoch 20: loss=0.2579, acc=57.42% (best=62.89%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 62.03%\n",
      "          Fold 2 Epoch 25: loss=0.2376, acc=53.20% (best=58.12%)\n",
      "          Fold 1 Epoch 25: loss=0.2350, acc=59.53% (best=69.06%)\n",
      "          Fold 2 Epoch 30: loss=0.2241, acc=49.38% (best=64.45%)\n",
      "          Fold 1 Epoch 30: loss=0.2278, acc=48.98% (best=69.06%)\n",
      "          Fold 2 Epoch 35: loss=0.2161, acc=64.53% (best=64.53%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 69.06%\n",
      "          Fold 2 Epoch 40: loss=0.2227, acc=57.42% (best=64.53%)\n",
      "          Fold 2 Epoch 45: loss=0.2149, acc=52.27% (best=64.53%)\n",
      "          Fold 2: Early stopping at epoch 45\n",
      "      â†’ Fold 2 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9da5aa88:\n",
      "        Fold accuracies: ['69.06%', '64.53%', '62.03%', '66.88%', '63.12%']\n",
      "        Average fitness: 65.12% Â± 2.55%\n",
      "        Best fold: Fold 1 with 69.06%\n",
      "      Fitness obtained: 65.12% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 0135c2c7)\n",
      "      Architecture: 11 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 0135c2c7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7349, acc=43.12% (best=43.12%)\n",
      "          Fold 2 Epoch 1: loss=0.7233, acc=46.17% (best=46.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7132, acc=52.58% (best=52.58%)\n",
      "          Fold 4 Epoch 1: loss=0.7297, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7294, acc=47.58% (best=47.58%)\n",
      "          Fold 3 Epoch 5: loss=0.7051, acc=52.73% (best=53.83%)\n",
      "          Fold 4 Epoch 5: loss=0.6801, acc=53.44% (best=62.73%)\n",
      "          Fold 1 Epoch 5: loss=0.6975, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 5: loss=0.6993, acc=42.19% (best=50.62%)\n",
      "          Fold 5 Epoch 5: loss=0.7165, acc=58.28% (best=58.28%)\n",
      "          Fold 3 Epoch 10: loss=0.7016, acc=44.45% (best=53.83%)\n",
      "          Fold 4 Epoch 10: loss=0.6679, acc=55.94% (best=62.73%)\n",
      "          Fold 1 Epoch 10: loss=0.6847, acc=51.02% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.6819, acc=46.48% (best=52.89%)\n",
      "          Fold 5 Epoch 10: loss=0.7120, acc=55.62% (best=58.91%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 53.83%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 62.73%\n",
      "          Fold 1 Epoch 15: loss=0.6754, acc=65.08% (best=66.88%)\n",
      "          Fold 2 Epoch 15: loss=0.6725, acc=45.70% (best=53.20%)\n",
      "          Fold 5 Epoch 15: loss=0.7011, acc=44.53% (best=61.64%)\n",
      "          Fold 1 Epoch 20: loss=0.6442, acc=61.17% (best=66.88%)\n",
      "          Fold 2 Epoch 20: loss=0.6606, acc=51.88% (best=53.20%)\n",
      "          Fold 5 Epoch 20: loss=0.6969, acc=60.16% (best=66.80%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 66.88%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 53.20%\n",
      "          Fold 5 Epoch 25: loss=0.6859, acc=49.30% (best=66.80%)\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 66.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0135c2c7:\n",
      "        Fold accuracies: ['66.88%', '53.20%', '53.83%', '62.73%', '66.80%']\n",
      "        Average fitness: 60.69% Â± 6.05%\n",
      "        Best fold: Fold 1 with 66.88%\n",
      "      Fitness obtained: 60.69% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 813185ae)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 813185ae with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=2.0517, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 1: loss=2.6778, acc=59.53% (best=59.53%)\n",
      "          Fold 1 Epoch 1: loss=2.4631, acc=58.83% (best=58.83%)\n",
      "          Fold 3 Epoch 1: loss=2.6695, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=3.6166, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6167, acc=55.70% (best=55.70%)\n",
      "          Fold 4 Epoch 5: loss=0.5505, acc=50.78% (best=59.69%)\n",
      "          Fold 1 Epoch 5: loss=0.6588, acc=57.58% (best=58.83%)\n",
      "          Fold 3 Epoch 5: loss=0.6401, acc=50.08% (best=55.39%)\n",
      "          Fold 5 Epoch 5: loss=0.6975, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 10: loss=0.3884, acc=38.05% (best=55.70%)\n",
      "          Fold 4 Epoch 10: loss=0.3868, acc=53.52% (best=59.69%)\n",
      "          Fold 1 Epoch 10: loss=0.6832, acc=49.77% (best=58.83%)\n",
      "          Fold 3 Epoch 10: loss=0.3966, acc=63.91% (best=67.58%)\n",
      "          Fold 5 Epoch 10: loss=0.6983, acc=50.00% (best=50.00%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 58.83%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 59.69%\n",
      "          Fold 2 Epoch 15: loss=0.3336, acc=53.44% (best=55.70%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 55.70%\n",
      "          Fold 3 Epoch 15: loss=0.3535, acc=58.20% (best=67.58%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 813185ae:\n",
      "        Fold accuracies: ['58.83%', '55.70%', '67.58%', '59.69%', '50.00%']\n",
      "        Average fitness: 58.36% Â± 5.73%\n",
      "        Best fold: Fold 3 with 67.58%\n",
      "      Fitness obtained: 58.36% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 332c2fcc)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 332c2fcc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 332c2fcc:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4481e72c)\n",
      "      Architecture: 28 conv + 4 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 4481e72c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 5, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 4481e72c:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: c363899c)\n",
      "      Architecture: 10 conv + 3 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model c363899c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7253, acc=31.02% (best=31.02%)\n",
      "          Fold 3 Epoch 1: loss=0.7237, acc=57.58% (best=57.58%)\n",
      "          Fold 1 Epoch 1: loss=0.7106, acc=58.05% (best=58.05%)\n",
      "          Fold 4 Epoch 1: loss=0.7068, acc=52.27% (best=52.27%)\n",
      "          Fold 5 Epoch 1: loss=0.7239, acc=43.67% (best=43.67%)\n",
      "          Fold 2 Epoch 5: loss=0.6768, acc=42.58% (best=44.84%)\n",
      "          Fold 3 Epoch 5: loss=0.6916, acc=48.05% (best=57.58%)\n",
      "          Fold 5 Epoch 5: loss=0.7053, acc=57.81% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.6888, acc=59.45% (best=60.31%)\n",
      "          Fold 4 Epoch 5: loss=0.6548, acc=53.75% (best=60.78%)\n",
      "          Fold 2 Epoch 10: loss=0.6592, acc=46.48% (best=46.48%)\n",
      "          Fold 3 Epoch 10: loss=0.6591, acc=57.50% (best=59.69%)\n",
      "          Fold 5 Epoch 10: loss=0.6778, acc=61.64% (best=61.64%)\n",
      "          Fold 1 Epoch 10: loss=0.6614, acc=59.45% (best=60.31%)\n",
      "          Fold 4 Epoch 10: loss=0.6313, acc=52.11% (best=60.78%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 60.31%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.78%\n",
      "          Fold 2 Epoch 15: loss=0.6306, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 15: loss=0.6156, acc=56.25% (best=59.69%)\n",
      "          Fold 5 Epoch 15: loss=0.6419, acc=56.09% (best=61.80%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 59.69%\n",
      "          Fold 2 Epoch 20: loss=0.6038, acc=45.47% (best=59.22%)\n",
      "          Fold 5 Epoch 20: loss=0.5932, acc=59.53% (best=61.80%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "          Fold 2 Epoch 25: loss=0.5547, acc=42.50% (best=59.22%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 59.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c363899c:\n",
      "        Fold accuracies: ['60.31%', '59.22%', '59.69%', '60.78%', '61.80%']\n",
      "        Average fitness: 60.36% Â± 0.89%\n",
      "        Best fold: Fold 5 with 61.80%\n",
      "      Fitness obtained: 60.36% | Best in generation: 69.44% | Global best: 69.44%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 10 STATISTICS:\n",
      "   Maximum fitness: 69.44%\n",
      "   Average fitness: 50.67%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 24.05%\n",
      "   Best individual: 1b39d73a with 69.44%\n",
      "   Global best individual: 1b39d73a with 69.44%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.94% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=24.05)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1b39d73a (fitness: 69.44%)\n",
      "   Elite 2: 9da5aa88 (fitness: 65.12%)\n",
      "   Elite 3: 59336158 (fitness: 64.77%)\n",
      "   Elite 4: 1142d6fc (fitness: 63.91%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 11\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 11)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1b39d73a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b39d73a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6771, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.6583, acc=50.55% (best=50.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6525, acc=49.84% (best=49.84%)\n",
      "          Fold 5 Epoch 1: loss=0.7034, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 1: loss=0.6979, acc=56.25% (best=56.25%)\n",
      "          Fold 2 Epoch 5: loss=0.3591, acc=47.97% (best=49.77%)\n",
      "          Fold 3 Epoch 5: loss=0.3676, acc=56.02% (best=63.52%)\n",
      "          Fold 4 Epoch 5: loss=0.4051, acc=57.58% (best=59.77%)\n",
      "          Fold 5 Epoch 5: loss=0.4038, acc=50.00% (best=58.05%)\n",
      "          Fold 1 Epoch 5: loss=0.4618, acc=56.48% (best=67.81%)\n",
      "          Fold 2 Epoch 10: loss=0.2631, acc=54.77% (best=59.53%)\n",
      "          Fold 3 Epoch 10: loss=0.2687, acc=47.03% (best=63.52%)\n",
      "          Fold 4 Epoch 10: loss=0.2805, acc=59.14% (best=64.77%)\n",
      "          Fold 1 Epoch 10: loss=0.3088, acc=65.78% (best=67.81%)\n",
      "          Fold 5 Epoch 10: loss=0.2678, acc=47.11% (best=64.38%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 63.52%\n",
      "          Fold 2 Epoch 15: loss=0.2391, acc=53.67% (best=59.53%)\n",
      "          Fold 4 Epoch 15: loss=0.2350, acc=69.38% (best=69.38%)\n",
      "          Fold 1 Epoch 15: loss=0.2522, acc=57.03% (best=72.03%)\n",
      "          Fold 5 Epoch 15: loss=0.2376, acc=62.50% (best=64.38%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 64.38%\n",
      "          Fold 4 Epoch 20: loss=0.2229, acc=64.69% (best=69.61%)\n",
      "          Fold 1 Epoch 20: loss=0.2364, acc=64.84% (best=72.03%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 72.03%\n",
      "          Fold 4 Epoch 25: loss=0.2145, acc=64.38% (best=69.61%)\n",
      "          Fold 4 Epoch 30: loss=0.2038, acc=70.08% (best=74.92%)\n",
      "          Fold 4 Epoch 35: loss=0.1983, acc=65.00% (best=74.92%)\n",
      "          Fold 4: Early stopping at epoch 36\n",
      "      â†’ Fold 4 completed: 74.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b39d73a:\n",
      "        Fold accuracies: ['72.03%', '59.53%', '63.52%', '74.92%', '64.38%']\n",
      "        Average fitness: 66.88% Â± 5.71%\n",
      "        Best fold: Fold 4 with 74.92%\n",
      "      New best fitness in this generation: 66.88%!\n",
      "      Fitness obtained: 66.88% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 9da5aa88)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 9da5aa88 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=1.4154, acc=56.48% (best=56.48%)\n",
      "          Fold 2 Epoch 1: loss=1.2217, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=1.2487, acc=60.94% (best=60.94%)\n",
      "          Fold 3 Epoch 1: loss=1.3298, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=1.2645, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6509, acc=50.39% (best=53.52%)\n",
      "          Fold 1 Epoch 5: loss=0.6892, acc=62.19% (best=65.23%)\n",
      "          Fold 5 Epoch 5: loss=0.6533, acc=52.81% (best=58.20%)\n",
      "          Fold 3 Epoch 5: loss=0.6791, acc=55.86% (best=55.86%)\n",
      "          Fold 4 Epoch 5: loss=0.6077, acc=56.88% (best=57.66%)\n",
      "          Fold 2 Epoch 10: loss=0.3551, acc=47.03% (best=53.52%)\n",
      "          Fold 1 Epoch 10: loss=0.5764, acc=54.06% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.3588, acc=58.28% (best=59.92%)\n",
      "          Fold 3 Epoch 10: loss=0.4796, acc=60.94% (best=60.94%)\n",
      "          Fold 4 Epoch 10: loss=0.3749, acc=53.67% (best=57.66%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 53.52%\n",
      "          Fold 5 Epoch 15: loss=0.2737, acc=54.22% (best=59.92%)\n",
      "          Fold 3 Epoch 15: loss=0.3707, acc=56.33% (best=60.94%)\n",
      "          Fold 4 Epoch 15: loss=0.2790, acc=55.23% (best=58.12%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 3 Epoch 20: loss=0.3044, acc=52.89% (best=60.94%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 60.94%\n",
      "          Fold 4 Epoch 20: loss=0.2504, acc=42.03% (best=58.12%)\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 58.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9da5aa88:\n",
      "        Fold accuracies: ['65.23%', '53.52%', '60.94%', '58.12%', '59.92%']\n",
      "        Average fitness: 59.55% Â± 3.82%\n",
      "        Best fold: Fold 1 with 65.23%\n",
      "      Fitness obtained: 59.55% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6822, acc=58.52% (best=58.52%)\n",
      "          Fold 5 Epoch 1: loss=0.7061, acc=59.14% (best=59.14%)\n",
      "          Fold 1 Epoch 1: loss=0.7029, acc=54.53% (best=54.53%)\n",
      "          Fold 3 Epoch 1: loss=0.7098, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6704, acc=45.47% (best=45.47%)\n",
      "          Fold 2 Epoch 5: loss=0.3830, acc=53.83% (best=58.52%)\n",
      "          Fold 5 Epoch 5: loss=0.4010, acc=47.50% (best=59.14%)\n",
      "          Fold 1 Epoch 5: loss=0.5418, acc=52.81% (best=62.97%)\n",
      "          Fold 3 Epoch 5: loss=0.4021, acc=40.78% (best=56.02%)\n",
      "          Fold 4 Epoch 5: loss=0.3798, acc=47.27% (best=53.67%)\n",
      "          Fold 2 Epoch 10: loss=0.2839, acc=67.11% (best=70.47%)\n",
      "          Fold 5 Epoch 10: loss=0.3029, acc=45.23% (best=59.14%)\n",
      "          Fold 1 Epoch 10: loss=0.3332, acc=50.39% (best=62.97%)\n",
      "          Fold 3 Epoch 10: loss=0.3105, acc=47.03% (best=63.91%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.14%\n",
      "          Fold 4 Epoch 10: loss=0.2853, acc=57.66% (best=71.02%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.97%\n",
      "          Fold 2 Epoch 15: loss=0.2547, acc=57.19% (best=70.47%)\n",
      "          Fold 3 Epoch 15: loss=0.2757, acc=59.77% (best=64.77%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 70.47%\n",
      "          Fold 4 Epoch 15: loss=0.2592, acc=57.81% (best=71.02%)\n",
      "          Fold 3 Epoch 20: loss=0.2569, acc=60.62% (best=64.77%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 71.02%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 64.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['62.97%', '70.47%', '64.77%', '71.02%', '59.14%']\n",
      "        Average fitness: 65.67% Â± 4.52%\n",
      "        Best fold: Fold 4 with 71.02%\n",
      "      Fitness obtained: 65.67% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 1142d6fc)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 1142d6fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6930, acc=40.39% (best=40.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7089, acc=56.64% (best=56.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6841, acc=70.86% (best=70.86%)\n",
      "          Fold 1 Epoch 1: loss=0.7032, acc=56.41% (best=56.41%)\n",
      "          Fold 5 Epoch 1: loss=0.7121, acc=55.00% (best=55.00%)\n",
      "          Fold 2 Epoch 5: loss=0.5872, acc=48.75% (best=48.75%)\n",
      "          Fold 3 Epoch 5: loss=0.6027, acc=59.38% (best=65.00%)\n",
      "          Fold 4 Epoch 5: loss=0.5411, acc=42.03% (best=70.86%)\n",
      "          Fold 1 Epoch 5: loss=0.5780, acc=47.34% (best=56.41%)\n",
      "          Fold 5 Epoch 5: loss=0.5707, acc=43.98% (best=60.94%)\n",
      "          Fold 2 Epoch 10: loss=0.3418, acc=45.23% (best=55.47%)\n",
      "          Fold 3 Epoch 10: loss=0.3946, acc=66.80% (best=66.80%)\n",
      "          Fold 1 Epoch 10: loss=0.4162, acc=46.41% (best=56.41%)\n",
      "          Fold 4 Epoch 10: loss=0.3488, acc=56.09% (best=70.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3469, acc=46.48% (best=60.94%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.41%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.86%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.94%\n",
      "          Fold 2 Epoch 15: loss=0.2986, acc=57.81% (best=57.81%)\n",
      "          Fold 3 Epoch 15: loss=0.3227, acc=61.88% (best=66.95%)\n",
      "          Fold 2 Epoch 20: loss=0.2662, acc=54.14% (best=57.81%)\n",
      "          Fold 3 Epoch 20: loss=0.2880, acc=61.56% (best=66.95%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 66.95%\n",
      "          Fold 2 Epoch 25: loss=0.2523, acc=60.31% (best=63.52%)\n",
      "          Fold 2 Epoch 30: loss=0.2369, acc=52.97% (best=63.52%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 63.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1142d6fc:\n",
      "        Fold accuracies: ['56.41%', '63.52%', '66.95%', '70.86%', '60.94%']\n",
      "        Average fitness: 63.73% Â± 4.95%\n",
      "        Best fold: Fold 4 with 70.86%\n",
      "      Fitness obtained: 63.73% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 836db64b)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 836db64b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6803, acc=59.53% (best=59.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7247, acc=57.89% (best=57.89%)\n",
      "          Fold 2 Epoch 5: loss=0.3098, acc=36.56% (best=59.53%)\n",
      "          Fold 5 Epoch 5: loss=0.3387, acc=49.38% (best=57.89%)\n",
      "          Fold 2 Epoch 10: loss=0.2542, acc=38.12% (best=59.53%)\n",
      "          Fold 5 Epoch 10: loss=0.2505, acc=55.39% (best=57.89%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "          Fold 5 Epoch 15: loss=0.2314, acc=55.62% (best=59.53%)\n",
      "          Fold 5 Epoch 20: loss=0.2130, acc=53.59% (best=59.53%)\n",
      "          Fold 5 Epoch 25: loss=0.2063, acc=53.59% (best=60.23%)\n",
      "          Fold 5 Epoch 30: loss=0.2025, acc=52.27% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 836db64b:\n",
      "        Fold accuracies: ['0.00%', '59.53%', '0.00%', '0.00%', '60.23%']\n",
      "        Average fitness: 23.95% Â± 29.34%\n",
      "        Best fold: Fold 5 with 60.23%\n",
      "      Fitness obtained: 23.95% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 71cc8bf0)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 71cc8bf0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6299, acc=53.36% (best=53.36%)\n",
      "          Fold 3 Epoch 1: loss=0.6234, acc=57.97% (best=57.97%)\n",
      "          Fold 2 Epoch 5: loss=0.3008, acc=57.66% (best=57.66%)\n",
      "          Fold 3 Epoch 5: loss=0.3049, acc=61.41% (best=61.41%)\n",
      "          Fold 2 Epoch 10: loss=0.2525, acc=51.33% (best=57.66%)\n",
      "          Fold 3 Epoch 10: loss=0.2585, acc=52.97% (best=61.41%)\n",
      "          Fold 2 Epoch 15: loss=0.2349, acc=49.22% (best=57.66%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 57.66%\n",
      "          Fold 3 Epoch 15: loss=0.2413, acc=51.88% (best=61.80%)\n",
      "          Fold 3 Epoch 20: loss=0.2333, acc=61.25% (best=61.80%)\n",
      "          Fold 3 Epoch 25: loss=0.2225, acc=55.31% (best=63.75%)\n",
      "          Fold 3 Epoch 30: loss=0.2143, acc=62.03% (best=63.75%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 63.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 71cc8bf0:\n",
      "        Fold accuracies: ['0.00%', '57.66%', '63.75%', '0.00%', '0.00%']\n",
      "        Average fitness: 24.28% Â± 29.80%\n",
      "        Best fold: Fold 3 with 63.75%\n",
      "      Fitness obtained: 24.28% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 7d6492df)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 7d6492df with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7060, acc=51.48% (best=51.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7116, acc=52.81% (best=52.81%)\n",
      "          Fold 1 Epoch 1: loss=0.7038, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 1: loss=0.7026, acc=61.64% (best=61.64%)\n",
      "          Fold 5 Epoch 1: loss=0.7175, acc=55.08% (best=55.08%)\n",
      "          Fold 2 Epoch 5: loss=0.6564, acc=45.08% (best=51.95%)\n",
      "          Fold 3 Epoch 5: loss=0.6673, acc=58.12% (best=61.64%)\n",
      "          Fold 1 Epoch 5: loss=0.6524, acc=46.72% (best=56.88%)\n",
      "          Fold 4 Epoch 5: loss=0.6116, acc=51.80% (best=66.33%)\n",
      "          Fold 5 Epoch 5: loss=0.6946, acc=56.25% (best=56.25%)\n",
      "          Fold 2 Epoch 10: loss=0.4486, acc=45.47% (best=51.95%)\n",
      "          Fold 3 Epoch 10: loss=0.4298, acc=48.28% (best=61.64%)\n",
      "          Fold 1 Epoch 10: loss=0.4199, acc=58.67% (best=67.58%)\n",
      "          Fold 4 Epoch 10: loss=0.3678, acc=57.89% (best=66.33%)\n",
      "          Fold 5 Epoch 10: loss=0.5570, acc=49.22% (best=56.64%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 66.33%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 61.64%\n",
      "          Fold 2 Epoch 15: loss=0.3320, acc=46.41% (best=53.44%)\n",
      "          Fold 1 Epoch 15: loss=0.3406, acc=58.36% (best=67.58%)\n",
      "          Fold 5 Epoch 15: loss=0.3656, acc=51.56% (best=57.58%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 67.58%\n",
      "          Fold 2 Epoch 20: loss=0.2922, acc=51.48% (best=55.86%)\n",
      "          Fold 5 Epoch 20: loss=0.3136, acc=57.19% (best=59.84%)\n",
      "          Fold 2 Epoch 25: loss=0.2765, acc=48.20% (best=55.94%)\n",
      "          Fold 5 Epoch 25: loss=0.2974, acc=65.86% (best=65.86%)\n",
      "          Fold 2 Epoch 30: loss=0.2695, acc=46.88% (best=60.08%)\n",
      "          Fold 5 Epoch 30: loss=0.2768, acc=54.14% (best=66.41%)\n",
      "          Fold 2 Epoch 35: loss=0.2462, acc=55.16% (best=60.08%)\n",
      "          Fold 5 Epoch 35: loss=0.2723, acc=62.97% (best=66.41%)\n",
      "          Fold 2: Early stopping at epoch 37\n",
      "      â†’ Fold 2 completed: 60.08%\n",
      "          Fold 5: Early stopping at epoch 37\n",
      "      â†’ Fold 5 completed: 66.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7d6492df:\n",
      "        Fold accuracies: ['67.58%', '60.08%', '61.64%', '66.33%', '66.41%']\n",
      "        Average fitness: 64.41% Â± 2.97%\n",
      "        Best fold: Fold 1 with 67.58%\n",
      "      Fitness obtained: 64.41% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 1dab69c0)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 1dab69c0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6813, acc=53.67% (best=53.67%)\n",
      "          Fold 3 Epoch 1: loss=0.6930, acc=58.83% (best=58.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7022, acc=57.19% (best=57.19%)\n",
      "          Fold 4 Epoch 1: loss=0.6924, acc=70.78% (best=70.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7084, acc=47.81% (best=47.81%)\n",
      "          Fold 2 Epoch 5: loss=0.3470, acc=66.02% (best=66.56%)\n",
      "          Fold 3 Epoch 5: loss=0.3335, acc=61.56% (best=61.56%)\n",
      "          Fold 1 Epoch 5: loss=0.4285, acc=43.20% (best=64.38%)\n",
      "          Fold 4 Epoch 5: loss=0.4151, acc=42.73% (best=70.78%)\n",
      "          Fold 5 Epoch 5: loss=0.3247, acc=43.59% (best=52.03%)\n",
      "          Fold 2 Epoch 10: loss=0.2670, acc=65.78% (best=66.56%)\n",
      "          Fold 3 Epoch 10: loss=0.2548, acc=62.81% (best=62.81%)\n",
      "          Fold 1 Epoch 10: loss=0.3016, acc=55.78% (best=64.38%)\n",
      "          Fold 4 Epoch 10: loss=0.2896, acc=40.55% (best=70.78%)\n",
      "          Fold 5 Epoch 10: loss=0.2577, acc=56.80% (best=56.80%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.78%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 64.38%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 66.56%\n",
      "          Fold 3 Epoch 15: loss=0.2450, acc=60.31% (best=62.81%)\n",
      "          Fold 5 Epoch 15: loss=0.2343, acc=47.73% (best=56.80%)\n",
      "          Fold 3 Epoch 20: loss=0.2297, acc=60.16% (best=62.81%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 62.81%\n",
      "          Fold 5 Epoch 20: loss=0.2237, acc=40.39% (best=56.80%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 56.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1dab69c0:\n",
      "        Fold accuracies: ['64.38%', '66.56%', '62.81%', '70.78%', '56.80%']\n",
      "        Average fitness: 64.27% Â± 4.60%\n",
      "        Best fold: Fold 4 with 70.78%\n",
      "      Fitness obtained: 64.27% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 1ae3bddb)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 1ae3bddb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6847, acc=34.30% (best=34.30%)\n",
      "          Fold 3 Epoch 1: loss=0.6939, acc=46.88% (best=46.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6682, acc=52.66% (best=52.66%)\n",
      "          Fold 1 Epoch 1: loss=0.6951, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7025, acc=57.81% (best=57.81%)\n",
      "          Fold 2 Epoch 5: loss=0.3795, acc=37.81% (best=52.73%)\n",
      "          Fold 3 Epoch 5: loss=0.3945, acc=55.78% (best=57.58%)\n",
      "          Fold 1 Epoch 5: loss=0.4596, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 5: loss=0.3891, acc=54.53% (best=54.53%)\n",
      "          Fold 5 Epoch 5: loss=0.4087, acc=58.28% (best=58.28%)\n",
      "          Fold 2 Epoch 10: loss=0.2803, acc=49.14% (best=52.73%)\n",
      "          Fold 3 Epoch 10: loss=0.3013, acc=59.92% (best=60.94%)\n",
      "          Fold 4 Epoch 10: loss=0.2694, acc=50.39% (best=58.75%)\n",
      "          Fold 1 Epoch 10: loss=0.3073, acc=51.80% (best=58.28%)\n",
      "          Fold 5 Epoch 10: loss=0.2874, acc=54.53% (best=58.28%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 52.73%\n",
      "          Fold 3 Epoch 15: loss=0.2679, acc=40.16% (best=60.94%)\n",
      "          Fold 4 Epoch 15: loss=0.2403, acc=60.31% (best=60.31%)\n",
      "          Fold 1 Epoch 15: loss=0.2694, acc=46.56% (best=58.28%)\n",
      "          Fold 5 Epoch 15: loss=0.2553, acc=54.92% (best=58.28%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 58.28%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 58.28%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 60.94%\n",
      "          Fold 4 Epoch 20: loss=0.2256, acc=53.20% (best=60.31%)\n",
      "          Fold 4 Epoch 25: loss=0.2112, acc=55.00% (best=60.31%)\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 60.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1ae3bddb:\n",
      "        Fold accuracies: ['58.28%', '52.73%', '60.94%', '60.31%', '58.28%']\n",
      "        Average fitness: 58.11% Â± 2.89%\n",
      "        Best fold: Fold 3 with 60.94%\n",
      "      Fitness obtained: 58.11% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 24cce0fe)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 24cce0fe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6699, acc=57.03% (best=57.03%)\n",
      "          Fold 4 Epoch 1: loss=0.6814, acc=55.94% (best=55.94%)\n",
      "          Fold 1 Epoch 1: loss=0.6800, acc=64.77% (best=64.77%)\n",
      "          Fold 3 Epoch 1: loss=0.6887, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=0.6958, acc=44.61% (best=44.61%)\n",
      "          Fold 2 Epoch 5: loss=0.2913, acc=60.39% (best=63.83%)\n",
      "          Fold 3 Epoch 5: loss=0.3007, acc=51.25% (best=59.14%)\n",
      "          Fold 1 Epoch 5: loss=0.3545, acc=39.06% (best=64.77%)\n",
      "          Fold 4 Epoch 5: loss=0.4392, acc=53.44% (best=58.52%)\n",
      "          Fold 5 Epoch 5: loss=0.2616, acc=42.89% (best=56.25%)\n",
      "          Fold 2 Epoch 10: loss=0.2238, acc=52.27% (best=66.41%)\n",
      "          Fold 3 Epoch 10: loss=0.2308, acc=63.59% (best=63.59%)\n",
      "          Fold 1 Epoch 10: loss=0.2558, acc=53.59% (best=64.77%)\n",
      "          Fold 4 Epoch 10: loss=0.2861, acc=65.00% (best=65.00%)\n",
      "          Fold 5 Epoch 10: loss=0.2117, acc=37.34% (best=56.25%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.77%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 56.25%\n",
      "          Fold 2 Epoch 15: loss=0.2087, acc=61.56% (best=66.41%)\n",
      "          Fold 3 Epoch 15: loss=0.2170, acc=62.58% (best=63.59%)\n",
      "          Fold 4 Epoch 15: loss=0.2348, acc=47.42% (best=71.25%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "          Fold 3 Epoch 20: loss=0.2119, acc=61.88% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "          Fold 4 Epoch 20: loss=0.2207, acc=55.39% (best=71.25%)\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 24cce0fe:\n",
      "        Fold accuracies: ['64.77%', '66.41%', '63.59%', '71.25%', '56.25%']\n",
      "        Average fitness: 64.45% Â± 4.86%\n",
      "        Best fold: Fold 4 with 71.25%\n",
      "      Fitness obtained: 64.45% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 9c3e3986)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 9c3e3986 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=7.0974, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=3.9259, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 1: loss=4.7458, acc=65.39% (best=65.39%)\n",
      "          Fold 1 Epoch 1: loss=5.2172, acc=62.03% (best=62.03%)\n",
      "          Fold 5 Epoch 1: loss=4.4664, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6774, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 5: loss=0.6372, acc=54.30% (best=65.39%)\n",
      "          Fold 3 Epoch 5: loss=0.6985, acc=48.98% (best=58.36%)\n",
      "          Fold 5 Epoch 5: loss=0.7038, acc=52.42% (best=52.42%)\n",
      "          Fold 1 Epoch 5: loss=0.6684, acc=50.23% (best=62.03%)\n",
      "          Fold 2 Epoch 10: loss=0.6985, acc=49.61% (best=50.39%)\n",
      "          Fold 4 Epoch 10: loss=0.4884, acc=47.73% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.7031, acc=48.98% (best=58.36%)\n",
      "          Fold 5 Epoch 10: loss=0.7056, acc=50.00% (best=52.42%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 50.39%\n",
      "          Fold 1 Epoch 10: loss=0.7351, acc=50.55% (best=62.03%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 58.36%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "          Fold 5 Epoch 15: loss=0.7112, acc=50.00% (best=52.42%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 52.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9c3e3986:\n",
      "        Fold accuracies: ['62.03%', '50.39%', '58.36%', '65.39%', '52.42%']\n",
      "        Average fitness: 57.72% Â± 5.65%\n",
      "        Best fold: Fold 4 with 65.39%\n",
      "      Fitness obtained: 57.72% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: e06d5ef0)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model e06d5ef0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6795, acc=45.86% (best=45.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7011, acc=72.27% (best=72.27%)\n",
      "          Fold 1 Epoch 1: loss=0.6984, acc=59.77% (best=59.77%)\n",
      "          Fold 4 Epoch 1: loss=0.6766, acc=61.72% (best=61.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7064, acc=58.98% (best=58.98%)\n",
      "          Fold 5 Epoch 5: loss=0.4395, acc=49.53% (best=58.98%)\n",
      "          Fold 2 Epoch 5: loss=0.4148, acc=42.11% (best=56.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4275, acc=65.86% (best=72.27%)\n",
      "          Fold 1 Epoch 5: loss=0.4820, acc=55.70% (best=62.03%)\n",
      "          Fold 4 Epoch 5: loss=0.4057, acc=66.17% (best=66.17%)\n",
      "          Fold 2 Epoch 10: loss=0.2914, acc=63.05% (best=63.05%)\n",
      "          Fold 3 Epoch 10: loss=0.3111, acc=52.66% (best=72.27%)\n",
      "          Fold 5 Epoch 10: loss=0.3065, acc=51.17% (best=58.98%)\n",
      "          Fold 1 Epoch 10: loss=0.3164, acc=49.77% (best=62.03%)\n",
      "          Fold 4 Epoch 10: loss=0.2928, acc=68.83% (best=68.83%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 72.27%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "          Fold 2 Epoch 15: loss=0.2617, acc=59.30% (best=63.05%)\n",
      "          Fold 4 Epoch 15: loss=0.2518, acc=59.92% (best=68.83%)\n",
      "          Fold 2 Epoch 20: loss=0.2436, acc=54.38% (best=63.05%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 63.05%\n",
      "          Fold 4 Epoch 20: loss=0.2344, acc=56.09% (best=68.83%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e06d5ef0:\n",
      "        Fold accuracies: ['62.03%', '63.05%', '72.27%', '68.83%', '58.98%']\n",
      "        Average fitness: 65.03% Â± 4.82%\n",
      "        Best fold: Fold 3 with 72.27%\n",
      "      Fitness obtained: 65.03% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: cd1c4251)\n",
      "      Architecture: 2 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model cd1c4251 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6310, acc=47.11% (best=47.11%)\n",
      "          Fold 3 Epoch 1: loss=0.6218, acc=48.59% (best=48.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6558, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 1: loss=0.6385, acc=70.08% (best=70.08%)\n",
      "          Fold 5 Epoch 1: loss=0.6379, acc=51.95% (best=51.95%)\n",
      "          Fold 2 Epoch 5: loss=0.2659, acc=49.45% (best=52.58%)\n",
      "          Fold 3 Epoch 5: loss=0.2847, acc=55.16% (best=58.44%)\n",
      "          Fold 4 Epoch 5: loss=0.2701, acc=53.98% (best=70.08%)\n",
      "          Fold 1 Epoch 5: loss=0.2812, acc=48.36% (best=50.08%)\n",
      "          Fold 5 Epoch 5: loss=0.2747, acc=55.31% (best=65.86%)\n",
      "          Fold 2 Epoch 10: loss=0.2366, acc=52.58% (best=52.97%)\n",
      "          Fold 3 Epoch 10: loss=0.2394, acc=54.92% (best=59.53%)\n",
      "          Fold 4 Epoch 10: loss=0.2374, acc=56.80% (best=70.08%)\n",
      "          Fold 1 Epoch 10: loss=0.2444, acc=45.31% (best=50.08%)\n",
      "          Fold 5 Epoch 10: loss=0.2427, acc=54.69% (best=65.86%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.08%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.08%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.86%\n",
      "          Fold 2 Epoch 15: loss=0.2198, acc=49.69% (best=53.05%)\n",
      "          Fold 3 Epoch 15: loss=0.2274, acc=59.30% (best=59.53%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 59.53%\n",
      "          Fold 2 Epoch 20: loss=0.2164, acc=52.73% (best=53.91%)\n",
      "          Fold 2 Epoch 25: loss=0.2107, acc=49.61% (best=56.17%)\n",
      "          Fold 2 Epoch 30: loss=0.2058, acc=52.73% (best=56.17%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 56.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cd1c4251:\n",
      "        Fold accuracies: ['50.08%', '56.17%', '59.53%', '70.08%', '65.86%']\n",
      "        Average fitness: 60.34% Â± 7.05%\n",
      "        Best fold: Fold 4 with 70.08%\n",
      "      Fitness obtained: 60.34% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 99becb7d)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 99becb7d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6324, acc=48.98% (best=48.98%)\n",
      "          Fold 3 Epoch 1: loss=0.6913, acc=51.72% (best=51.72%)\n",
      "          Fold 5 Epoch 1: loss=0.6710, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 5: loss=0.2841, acc=64.45% (best=70.39%)\n",
      "          Fold 3 Epoch 5: loss=0.3391, acc=49.77% (best=53.28%)\n",
      "          Fold 5 Epoch 5: loss=0.2738, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 10: loss=0.2302, acc=67.50% (best=73.28%)\n",
      "          Fold 3 Epoch 10: loss=0.2518, acc=49.45% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.2350, acc=46.95% (best=55.55%)\n",
      "          Fold 2 Epoch 15: loss=0.2197, acc=51.56% (best=73.28%)\n",
      "          Fold 3 Epoch 15: loss=0.2351, acc=55.47% (best=65.23%)\n",
      "          Fold 5 Epoch 15: loss=0.2217, acc=49.61% (best=55.55%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 55.55%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 73.28%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 99becb7d:\n",
      "        Fold accuracies: ['0.00%', '73.28%', '65.23%', '0.00%', '55.55%']\n",
      "        Average fitness: 38.81% Â± 32.18%\n",
      "        Best fold: Fold 2 with 73.28%\n",
      "      Fitness obtained: 38.81% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: aa1e836a)\n",
      "      Architecture: 27 conv + 4 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model aa1e836a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 23, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for aa1e836a:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: c6339250)\n",
      "      Architecture: 10 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model c6339250 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6539, acc=53.20% (best=53.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6333, acc=63.59% (best=63.59%)\n",
      "          Fold 2 Epoch 5: loss=0.2828, acc=54.61% (best=54.61%)\n",
      "          Fold 4 Epoch 5: loss=0.2849, acc=50.55% (best=63.59%)\n",
      "          Fold 2 Epoch 10: loss=0.2330, acc=62.89% (best=62.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2279, acc=44.14% (best=63.59%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.59%\n",
      "          Fold 2 Epoch 15: loss=0.2212, acc=51.95% (best=65.78%)\n",
      "          Fold 2 Epoch 20: loss=0.2430, acc=59.61% (best=65.78%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 65.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c6339250:\n",
      "        Fold accuracies: ['0.00%', '65.78%', '0.00%', '63.59%', '0.00%']\n",
      "        Average fitness: 25.88% Â± 31.70%\n",
      "        Best fold: Fold 2 with 65.78%\n",
      "      Fitness obtained: 25.88% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 07483a9f)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 07483a9f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6639, acc=53.91% (best=53.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6731, acc=60.55% (best=60.55%)\n",
      "          Fold 3 Epoch 1: loss=0.6976, acc=55.94% (best=55.94%)\n",
      "          Fold 2 Epoch 1: loss=0.6729, acc=40.23% (best=40.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6986, acc=41.09% (best=41.09%)\n",
      "          Fold 1 Epoch 5: loss=0.3232, acc=53.98% (best=62.42%)\n",
      "          Fold 4 Epoch 5: loss=0.4005, acc=56.72% (best=70.47%)\n",
      "          Fold 3 Epoch 5: loss=0.3499, acc=60.62% (best=61.64%)\n",
      "          Fold 2 Epoch 5: loss=0.3458, acc=49.84% (best=49.84%)\n",
      "          Fold 5 Epoch 5: loss=0.3447, acc=45.31% (best=50.62%)\n",
      "          Fold 1 Epoch 10: loss=0.2522, acc=56.17% (best=62.42%)\n",
      "          Fold 4 Epoch 10: loss=0.2988, acc=53.91% (best=70.47%)\n",
      "          Fold 3 Epoch 10: loss=0.2801, acc=66.56% (best=66.56%)\n",
      "          Fold 2 Epoch 10: loss=0.2620, acc=36.80% (best=49.84%)\n",
      "          Fold 5 Epoch 10: loss=0.2626, acc=51.56% (best=52.66%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 70.47%\n",
      "          Fold 3 Epoch 15: loss=0.2524, acc=61.25% (best=66.56%)\n",
      "          Fold 2 Epoch 15: loss=0.2461, acc=39.45% (best=49.84%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 49.84%\n",
      "          Fold 5 Epoch 15: loss=0.2308, acc=46.41% (best=56.72%)\n",
      "          Fold 3 Epoch 20: loss=0.2317, acc=61.02% (best=66.56%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 66.56%\n",
      "          Fold 5 Epoch 20: loss=0.2208, acc=44.61% (best=56.72%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 07483a9f:\n",
      "        Fold accuracies: ['62.42%', '49.84%', '66.56%', '70.47%', '56.72%']\n",
      "        Average fitness: 61.20% Â± 7.28%\n",
      "        Best fold: Fold 4 with 70.47%\n",
      "      Fitness obtained: 61.20% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 5a927ea9)\n",
      "      Architecture: 14 conv + 4 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 5a927ea9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 187, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 5a927ea9:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 56689927)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 56689927 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7109, acc=42.42% (best=42.42%)\n",
      "          Fold 3 Epoch 1: loss=0.7216, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7232, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6912, acc=48.59% (best=48.59%)\n",
      "          Fold 1 Epoch 1: loss=0.7171, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 5: loss=0.5148, acc=53.36% (best=53.36%)\n",
      "          Fold 3 Epoch 5: loss=0.5115, acc=49.77% (best=51.02%)\n",
      "          Fold 5 Epoch 5: loss=0.5814, acc=46.17% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.4776, acc=53.28% (best=55.70%)\n",
      "          Fold 1 Epoch 5: loss=0.5646, acc=47.03% (best=57.03%)\n",
      "          Fold 2 Epoch 10: loss=0.3358, acc=47.42% (best=53.36%)\n",
      "          Fold 3 Epoch 10: loss=0.3669, acc=54.22% (best=54.22%)\n",
      "          Fold 5 Epoch 10: loss=0.3604, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 10: loss=0.3336, acc=49.22% (best=63.44%)\n",
      "          Fold 1 Epoch 10: loss=0.3555, acc=53.20% (best=57.03%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 57.03%\n",
      "          Fold 2 Epoch 15: loss=0.2799, acc=50.70% (best=53.36%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 53.36%\n",
      "          Fold 3 Epoch 15: loss=0.3173, acc=55.16% (best=58.36%)\n",
      "          Fold 5 Epoch 15: loss=0.2887, acc=48.67% (best=53.36%)\n",
      "          Fold 4 Epoch 15: loss=0.2712, acc=55.94% (best=63.44%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 63.44%\n",
      "          Fold 3 Epoch 20: loss=0.2699, acc=60.16% (best=60.16%)\n",
      "          Fold 5 Epoch 20: loss=0.2632, acc=48.12% (best=53.36%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 53.36%\n",
      "          Fold 3 Epoch 25: loss=0.2624, acc=57.27% (best=60.16%)\n",
      "          Fold 3 Epoch 30: loss=0.2577, acc=58.12% (best=67.11%)\n",
      "          Fold 3 Epoch 35: loss=0.2371, acc=55.00% (best=67.11%)\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 56689927:\n",
      "        Fold accuracies: ['57.03%', '53.36%', '67.11%', '63.44%', '53.36%']\n",
      "        Average fitness: 58.86% Â± 5.53%\n",
      "        Best fold: Fold 3 with 67.11%\n",
      "      Fitness obtained: 58.86% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: d43d4e67)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d43d4e67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7080, acc=64.69% (best=64.69%)\n",
      "          Fold 2 Epoch 1: loss=0.7070, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7158, acc=55.08% (best=55.08%)\n",
      "          Fold 3 Epoch 1: loss=0.7143, acc=42.66% (best=42.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7226, acc=46.80% (best=46.80%)\n",
      "          Fold 4 Epoch 5: loss=0.4775, acc=56.41% (best=64.69%)\n",
      "          Fold 1 Epoch 5: loss=0.4336, acc=57.34% (best=61.17%)\n",
      "          Fold 2 Epoch 5: loss=0.4144, acc=49.69% (best=57.73%)\n",
      "          Fold 5 Epoch 5: loss=0.4580, acc=56.25% (best=62.66%)\n",
      "          Fold 3 Epoch 5: loss=0.3978, acc=52.73% (best=64.14%)\n",
      "          Fold 4 Epoch 10: loss=0.3289, acc=52.89% (best=64.69%)\n",
      "          Fold 1 Epoch 10: loss=0.3160, acc=56.25% (best=64.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2946, acc=51.33% (best=57.73%)\n",
      "          Fold 5 Epoch 10: loss=0.3216, acc=52.42% (best=62.66%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.69%\n",
      "          Fold 3 Epoch 10: loss=0.3113, acc=65.47% (best=65.47%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 57.73%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 1 Epoch 15: loss=0.2885, acc=50.00% (best=68.12%)\n",
      "          Fold 3 Epoch 15: loss=0.2892, acc=64.30% (best=67.89%)\n",
      "          Fold 1 Epoch 20: loss=0.2707, acc=55.70% (best=68.12%)\n",
      "          Fold 3 Epoch 20: loss=0.2688, acc=66.25% (best=67.89%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 67.89%\n",
      "          Fold 1 Epoch 25: loss=0.2527, acc=61.95% (best=71.02%)\n",
      "          Fold 1 Epoch 30: loss=0.2444, acc=67.58% (best=71.02%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 71.02%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d43d4e67:\n",
      "        Fold accuracies: ['71.02%', '57.73%', '67.89%', '64.69%', '62.66%']\n",
      "        Average fitness: 64.80% Â± 4.53%\n",
      "        Best fold: Fold 1 with 71.02%\n",
      "      Fitness obtained: 64.80% | Best in generation: 66.88% | Global best: 69.44%\n",
      "\n",
      "GENERATION 11 STATISTICS:\n",
      "   Maximum fitness: 66.88%\n",
      "   Average fitness: 49.40%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 21.62%\n",
      "   Best individual: 1b39d73a with 66.88%\n",
      "   Global best individual: 1b39d73a with 69.44%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=21.62)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 1b39d73a (fitness: 66.88%)\n",
      "   Elite 2: 59336158 (fitness: 65.67%)\n",
      "   Elite 3: e06d5ef0 (fitness: 65.03%)\n",
      "   Elite 4: d43d4e67 (fitness: 64.80%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 12\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 12)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 1b39d73a)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 1b39d73a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6741, acc=53.05% (best=53.05%)\n",
      "          Fold 2 Epoch 1: loss=0.6522, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6695, acc=53.59% (best=53.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6906, acc=58.12% (best=58.12%)\n",
      "          Fold 5 Epoch 1: loss=0.7128, acc=57.66% (best=57.66%)\n",
      "          Fold 2 Epoch 5: loss=0.3088, acc=56.48% (best=64.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3704, acc=46.33% (best=58.28%)\n",
      "          Fold 5 Epoch 5: loss=0.3444, acc=64.69% (best=64.69%)\n",
      "          Fold 1 Epoch 5: loss=0.4403, acc=49.84% (best=58.12%)\n",
      "          Fold 4 Epoch 5: loss=0.4302, acc=65.16% (best=68.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2773, acc=56.17% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2378, acc=44.22% (best=64.38%)\n",
      "          Fold 5 Epoch 10: loss=0.2469, acc=54.84% (best=64.69%)\n",
      "          Fold 1 Epoch 10: loss=0.3156, acc=57.73% (best=58.12%)\n",
      "          Fold 4 Epoch 10: loss=0.2871, acc=53.52% (best=68.05%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 58.12%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 2 Epoch 15: loss=0.2258, acc=48.67% (best=65.39%)\n",
      "          Fold 3 Epoch 15: loss=0.2549, acc=55.39% (best=60.70%)\n",
      "          Fold 5 Epoch 15: loss=0.2335, acc=48.36% (best=64.69%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 64.69%\n",
      "          Fold 2 Epoch 20: loss=0.2148, acc=53.44% (best=65.39%)\n",
      "          Fold 3 Epoch 20: loss=0.2315, acc=61.88% (best=65.39%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "          Fold 3 Epoch 25: loss=0.2218, acc=63.12% (best=67.50%)\n",
      "          Fold 3 Epoch 30: loss=0.2169, acc=57.27% (best=67.50%)\n",
      "          Fold 3: Early stopping at epoch 32\n",
      "      â†’ Fold 3 completed: 67.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1b39d73a:\n",
      "        Fold accuracies: ['58.12%', '65.39%', '67.50%', '68.05%', '64.69%']\n",
      "        Average fitness: 64.75% Â± 3.54%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      New best fitness in this generation: 64.75%!\n",
      "      Fitness obtained: 64.75% | Best in generation: 64.75% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6806, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 1: loss=0.6961, acc=50.94% (best=50.94%)\n",
      "          Fold 1 Epoch 1: loss=0.7043, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6684, acc=64.69% (best=64.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7081, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 5: loss=0.3684, acc=42.66% (best=58.20%)\n",
      "          Fold 2 Epoch 5: loss=0.3661, acc=34.06% (best=50.55%)\n",
      "          Fold 5 Epoch 5: loss=0.4573, acc=58.20% (best=62.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4500, acc=50.47% (best=63.12%)\n",
      "          Fold 4 Epoch 5: loss=0.3937, acc=56.02% (best=71.17%)\n",
      "          Fold 3 Epoch 10: loss=0.2819, acc=51.17% (best=65.00%)\n",
      "          Fold 2 Epoch 10: loss=0.2899, acc=59.84% (best=59.84%)\n",
      "          Fold 5 Epoch 10: loss=0.3254, acc=53.59% (best=62.81%)\n",
      "          Fold 1 Epoch 10: loss=0.3189, acc=53.67% (best=63.12%)\n",
      "          Fold 4 Epoch 10: loss=0.2818, acc=53.67% (best=71.17%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 63.12%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "          Fold 3 Epoch 15: loss=0.2598, acc=51.02% (best=65.00%)\n",
      "          Fold 2 Epoch 15: loss=0.2529, acc=53.91% (best=59.84%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "          Fold 2 Epoch 20: loss=0.2427, acc=62.58% (best=62.58%)\n",
      "          Fold 2 Epoch 25: loss=0.2415, acc=35.39% (best=62.58%)\n",
      "          Fold 2 Epoch 30: loss=0.2287, acc=40.94% (best=62.58%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 62.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['63.12%', '62.58%', '65.00%', '71.17%', '62.81%']\n",
      "        Average fitness: 64.94% Â± 3.23%\n",
      "        Best fold: Fold 4 with 71.17%\n",
      "      New best fitness in this generation: 64.94%!\n",
      "      Fitness obtained: 64.94% | Best in generation: 64.94% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: e06d5ef0)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model e06d5ef0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7018, acc=58.20% (best=58.20%)\n",
      "          Fold 2 Epoch 1: loss=0.6867, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 1: loss=0.6970, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6758, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7049, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 5: loss=0.4755, acc=62.19% (best=62.19%)\n",
      "          Fold 3 Epoch 5: loss=0.4028, acc=52.89% (best=60.00%)\n",
      "          Fold 4 Epoch 5: loss=0.4182, acc=65.94% (best=65.94%)\n",
      "          Fold 2 Epoch 5: loss=0.4596, acc=47.27% (best=52.42%)\n",
      "          Fold 5 Epoch 5: loss=0.4841, acc=53.20% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.3283, acc=51.33% (best=64.06%)\n",
      "          Fold 3 Epoch 10: loss=0.3079, acc=53.36% (best=60.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2941, acc=56.64% (best=65.94%)\n",
      "          Fold 2 Epoch 10: loss=0.3087, acc=64.22% (best=64.22%)\n",
      "          Fold 5 Epoch 10: loss=0.2932, acc=45.62% (best=63.20%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 60.00%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 1 Epoch 15: loss=0.2745, acc=49.69% (best=64.92%)\n",
      "          Fold 4 Epoch 15: loss=0.2554, acc=65.86% (best=66.02%)\n",
      "          Fold 2 Epoch 15: loss=0.2624, acc=62.89% (best=68.36%)\n",
      "          Fold 1 Epoch 20: loss=0.2458, acc=47.11% (best=64.92%)\n",
      "          Fold 4 Epoch 20: loss=0.2349, acc=52.97% (best=68.75%)\n",
      "          Fold 2 Epoch 20: loss=0.2426, acc=67.19% (best=68.36%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "          Fold 2 Epoch 25: loss=0.2349, acc=57.34% (best=69.14%)\n",
      "          Fold 4 Epoch 25: loss=0.2294, acc=63.28% (best=69.61%)\n",
      "          Fold 2 Epoch 30: loss=0.2236, acc=63.12% (best=69.14%)\n",
      "          Fold 4 Epoch 30: loss=0.2144, acc=57.66% (best=69.61%)\n",
      "          Fold 4: Early stopping at epoch 31\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 69.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e06d5ef0:\n",
      "        Fold accuracies: ['64.92%', '69.14%', '60.00%', '69.61%', '63.20%']\n",
      "        Average fitness: 65.38% Â± 3.63%\n",
      "        Best fold: Fold 4 with 69.61%\n",
      "      New best fitness in this generation: 65.38%!\n",
      "      Fitness obtained: 65.38% | Best in generation: 65.38% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: d43d4e67)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d43d4e67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7016, acc=46.48% (best=46.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7288, acc=44.53% (best=44.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7300, acc=50.86% (best=50.86%)\n",
      "          Fold 4 Epoch 1: loss=0.7047, acc=59.61% (best=59.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7091, acc=47.89% (best=47.89%)\n",
      "          Fold 5 Epoch 5: loss=0.4505, acc=50.78% (best=50.86%)\n",
      "          Fold 3 Epoch 5: loss=0.4564, acc=41.17% (best=53.83%)\n",
      "          Fold 2 Epoch 5: loss=0.3938, acc=52.03% (best=52.03%)\n",
      "          Fold 1 Epoch 5: loss=0.4465, acc=54.45% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.4070, acc=63.83% (best=72.42%)\n",
      "          Fold 5 Epoch 10: loss=0.3490, acc=46.88% (best=50.86%)\n",
      "          Fold 3 Epoch 10: loss=0.3526, acc=48.83% (best=61.64%)\n",
      "          Fold 2 Epoch 10: loss=0.3265, acc=54.77% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.3358, acc=67.50% (best=67.50%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.86%\n",
      "          Fold 4 Epoch 10: loss=0.2898, acc=57.58% (best=72.42%)\n",
      "          Fold 3 Epoch 15: loss=0.2995, acc=59.06% (best=61.64%)\n",
      "          Fold 2 Epoch 15: loss=0.2860, acc=52.42% (best=62.58%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 72.42%\n",
      "          Fold 1 Epoch 15: loss=0.2985, acc=57.97% (best=69.84%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 61.64%\n",
      "          Fold 2 Epoch 20: loss=0.2640, acc=54.77% (best=62.58%)\n",
      "          Fold 1 Epoch 20: loss=0.2741, acc=68.12% (best=69.84%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 69.84%\n",
      "          Fold 2 Epoch 25: loss=0.2537, acc=44.30% (best=64.22%)\n",
      "          Fold 2 Epoch 30: loss=0.2433, acc=68.83% (best=68.83%)\n",
      "          Fold 2 Epoch 35: loss=0.2334, acc=56.56% (best=74.45%)\n",
      "          Fold 2 Epoch 40: loss=0.2270, acc=53.36% (best=74.45%)\n",
      "          Fold 2: Early stopping at epoch 41\n",
      "      â†’ Fold 2 completed: 74.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d43d4e67:\n",
      "        Fold accuracies: ['69.84%', '74.45%', '61.64%', '72.42%', '50.86%']\n",
      "        Average fitness: 65.84% Â± 8.67%\n",
      "        Best fold: Fold 2 with 74.45%\n",
      "      New best fitness in this generation: 65.84%!\n",
      "      Fitness obtained: 65.84% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: a74c0038)\n",
      "      Architecture: 10 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model a74c0038 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6463, acc=41.72% (best=41.72%)\n",
      "          Fold 3 Epoch 1: loss=0.6697, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 1: loss=0.6776, acc=61.80% (best=61.80%)\n",
      "          Fold 5 Epoch 1: loss=0.6752, acc=59.84% (best=59.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6401, acc=56.72% (best=56.72%)\n",
      "          Fold 2 Epoch 5: loss=0.2944, acc=43.98% (best=59.77%)\n",
      "          Fold 3 Epoch 5: loss=0.3421, acc=45.94% (best=60.16%)\n",
      "          Fold 1 Epoch 5: loss=0.3221, acc=46.25% (best=61.80%)\n",
      "          Fold 4 Epoch 5: loss=0.2943, acc=47.89% (best=58.36%)\n",
      "          Fold 5 Epoch 5: loss=0.3131, acc=49.14% (best=62.58%)\n",
      "          Fold 2 Epoch 10: loss=0.2297, acc=50.62% (best=59.77%)\n",
      "          Fold 3 Epoch 10: loss=0.2509, acc=45.16% (best=60.16%)\n",
      "          Fold 1 Epoch 10: loss=0.2465, acc=67.89% (best=67.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2293, acc=48.91% (best=58.36%)\n",
      "          Fold 5 Epoch 10: loss=0.2390, acc=45.78% (best=62.58%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 59.77%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 60.16%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 58.36%\n",
      "          Fold 1 Epoch 15: loss=0.2202, acc=71.17% (best=71.41%)\n",
      "          Fold 1 Epoch 20: loss=0.2154, acc=65.16% (best=71.41%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 71.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a74c0038:\n",
      "        Fold accuracies: ['71.41%', '59.77%', '60.16%', '58.36%', '62.58%']\n",
      "        Average fitness: 62.45% Â± 4.68%\n",
      "        Best fold: Fold 1 with 71.41%\n",
      "      Fitness obtained: 62.45% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: faae4684)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model faae4684 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7360, acc=50.70% (best=50.70%)\n",
      "          Fold 5 Epoch 1: loss=0.7442, acc=46.88% (best=46.88%)\n",
      "          Fold 2 Epoch 1: loss=0.7302, acc=54.14% (best=54.14%)\n",
      "          Fold 1 Epoch 1: loss=0.7370, acc=37.42% (best=37.42%)\n",
      "          Fold 4 Epoch 1: loss=0.7244, acc=50.78% (best=50.78%)\n",
      "          Fold 3 Epoch 5: loss=0.4106, acc=65.00% (best=65.00%)\n",
      "          Fold 5 Epoch 5: loss=0.5374, acc=55.70% (best=55.70%)\n",
      "          Fold 1 Epoch 5: loss=0.5100, acc=61.64% (best=61.64%)\n",
      "          Fold 4 Epoch 5: loss=0.4807, acc=54.45% (best=60.70%)\n",
      "          Fold 2 Epoch 5: loss=0.4302, acc=58.20% (best=64.69%)\n",
      "          Fold 3 Epoch 10: loss=0.3174, acc=57.19% (best=65.00%)\n",
      "          Fold 5 Epoch 10: loss=0.3526, acc=47.27% (best=55.70%)\n",
      "          Fold 1 Epoch 10: loss=0.3495, acc=61.17% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3252, acc=62.81% (best=62.81%)\n",
      "          Fold 2 Epoch 10: loss=0.3333, acc=67.19% (best=67.19%)\n",
      "          Fold 3 Epoch 15: loss=0.2924, acc=64.61% (best=65.00%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "          Fold 5 Epoch 15: loss=0.3065, acc=55.47% (best=55.70%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 55.70%\n",
      "          Fold 1 Epoch 15: loss=0.3036, acc=52.89% (best=61.64%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 61.64%\n",
      "          Fold 4 Epoch 15: loss=0.2800, acc=46.25% (best=62.81%)\n",
      "          Fold 2 Epoch 15: loss=0.2879, acc=60.55% (best=67.19%)\n",
      "          Fold 4 Epoch 20: loss=0.2604, acc=55.39% (best=62.81%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 62.81%\n",
      "          Fold 2 Epoch 20: loss=0.2532, acc=65.62% (best=71.56%)\n",
      "          Fold 2 Epoch 25: loss=0.2571, acc=60.78% (best=71.56%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 71.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for faae4684:\n",
      "        Fold accuracies: ['61.64%', '71.56%', '65.00%', '62.81%', '55.70%']\n",
      "        Average fitness: 63.34% Â± 5.14%\n",
      "        Best fold: Fold 2 with 71.56%\n",
      "      Fitness obtained: 63.34% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 0d6ab854)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 0d6ab854 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7180, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 1: loss=0.7241, acc=59.53% (best=59.53%)\n",
      "          Fold 4 Epoch 1: loss=0.7063, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7336, acc=49.06% (best=49.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7122, acc=47.89% (best=47.89%)\n",
      "          Fold 1 Epoch 5: loss=0.6265, acc=62.42% (best=62.42%)\n",
      "          Fold 2 Epoch 5: loss=0.4808, acc=44.77% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.5176, acc=45.47% (best=52.03%)\n",
      "          Fold 4 Epoch 5: loss=0.4691, acc=59.61% (best=60.94%)\n",
      "          Fold 3 Epoch 5: loss=0.4437, acc=43.91% (best=55.55%)\n",
      "          Fold 1 Epoch 10: loss=0.4342, acc=51.95% (best=62.42%)\n",
      "          Fold 2 Epoch 10: loss=0.3448, acc=60.55% (best=60.55%)\n",
      "          Fold 5 Epoch 10: loss=0.3753, acc=47.19% (best=52.03%)\n",
      "          Fold 4 Epoch 10: loss=0.3179, acc=58.05% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.3684, acc=47.89% (best=55.55%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 52.03%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 55.55%\n",
      "          Fold 1 Epoch 15: loss=0.3635, acc=53.28% (best=62.42%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "          Fold 2 Epoch 15: loss=0.3139, acc=61.25% (best=61.25%)\n",
      "          Fold 4 Epoch 15: loss=0.2864, acc=62.42% (best=65.39%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 2 Epoch 20: loss=0.2839, acc=48.52% (best=61.25%)\n",
      "          Fold 2 Epoch 25: loss=0.2662, acc=51.72% (best=61.25%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 61.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0d6ab854:\n",
      "        Fold accuracies: ['62.42%', '61.25%', '55.55%', '65.39%', '52.03%']\n",
      "        Average fitness: 59.33% Â± 4.85%\n",
      "        Best fold: Fold 4 with 65.39%\n",
      "      Fitness obtained: 59.33% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 5885350c)\n",
      "      Architecture: 18 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 5885350c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 221, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 5885350c:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: a39193c5)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model a39193c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 658, in forward\n",
      "    return F.selu(input, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 1832, in selu\n",
      "    result = torch.selu(input)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for a39193c5:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: b21149b8)\n",
      "      Architecture: 2 conv + 5 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model b21149b8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6380, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.6664, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.6853, acc=60.47% (best=60.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6078, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7071, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.2688, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.2954, acc=57.19% (best=66.72%)\n",
      "          Fold 1 Epoch 5: loss=0.2862, acc=50.16% (best=50.31%)\n",
      "          Fold 4 Epoch 5: loss=0.2674, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 5: loss=0.2944, acc=58.12% (best=58.12%)\n",
      "          Fold 2 Epoch 10: loss=0.2463, acc=53.59% (best=53.59%)\n",
      "          Fold 3 Epoch 10: loss=0.2574, acc=58.28% (best=66.72%)\n",
      "          Fold 1 Epoch 10: loss=0.2575, acc=50.78% (best=53.91%)\n",
      "          Fold 4 Epoch 10: loss=0.2475, acc=49.45% (best=49.45%)\n",
      "          Fold 5 Epoch 10: loss=0.2597, acc=57.58% (best=59.92%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 66.72%\n",
      "          Fold 2 Epoch 15: loss=0.2372, acc=53.83% (best=53.83%)\n",
      "          Fold 1 Epoch 15: loss=0.2460, acc=55.94% (best=56.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2363, acc=46.80% (best=49.45%)\n",
      "          Fold 5 Epoch 15: loss=0.2381, acc=55.70% (best=61.48%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 49.45%\n",
      "          Fold 2 Epoch 20: loss=0.2316, acc=52.58% (best=53.83%)\n",
      "          Fold 1 Epoch 20: loss=0.2371, acc=56.80% (best=56.88%)\n",
      "          Fold 5 Epoch 20: loss=0.2303, acc=59.84% (best=61.64%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 53.83%\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 56.88%\n",
      "          Fold 5 Epoch 25: loss=0.2216, acc=59.53% (best=63.12%)\n",
      "          Fold 5 Epoch 30: loss=0.2134, acc=59.06% (best=63.12%)\n",
      "          Fold 5: Early stopping at epoch 33\n",
      "      â†’ Fold 5 completed: 63.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b21149b8:\n",
      "        Fold accuracies: ['56.88%', '53.83%', '66.72%', '49.45%', '63.12%']\n",
      "        Average fitness: 58.00% Â± 6.23%\n",
      "        Best fold: Fold 3 with 66.72%\n",
      "      Fitness obtained: 58.00% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 4d373e08)\n",
      "      Architecture: 8 conv + 4 fc, opt=adamw, lr=0.01\n",
      "      Training/Evaluating model 4d373e08 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7670, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.8216, acc=46.09% (best=46.09%)\n",
      "          Fold 4 Epoch 1: loss=0.7547, acc=51.33% (best=51.33%)\n",
      "          Fold 1 Epoch 1: loss=0.8293, acc=50.47% (best=50.47%)\n",
      "          Fold 5 Epoch 1: loss=0.7935, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 5: loss=0.5796, acc=43.59% (best=60.39%)\n",
      "          Fold 3 Epoch 5: loss=0.4609, acc=52.50% (best=59.84%)\n",
      "          Fold 4 Epoch 5: loss=0.5732, acc=31.33% (best=61.56%)\n",
      "          Fold 1 Epoch 5: loss=0.5732, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 5: loss=0.5962, acc=48.20% (best=48.98%)\n",
      "          Fold 2 Epoch 10: loss=0.3519, acc=56.41% (best=60.39%)\n",
      "          Fold 3 Epoch 10: loss=0.2966, acc=52.66% (best=61.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2736, acc=63.52% (best=63.52%)\n",
      "          Fold 1 Epoch 10: loss=0.4550, acc=52.34% (best=56.64%)\n",
      "          Fold 5 Epoch 10: loss=0.2898, acc=53.52% (best=53.52%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 60.39%\n",
      "          Fold 3 Epoch 15: loss=0.2582, acc=46.80% (best=61.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2272, acc=53.59% (best=63.52%)\n",
      "          Fold 1 Epoch 15: loss=0.3764, acc=55.16% (best=56.64%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 56.64%\n",
      "          Fold 5 Epoch 15: loss=0.2389, acc=43.44% (best=53.52%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 61.88%\n",
      "          Fold 4 Epoch 20: loss=0.2216, acc=60.23% (best=63.52%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 5 Epoch 20: loss=0.2235, acc=43.44% (best=53.59%)\n",
      "          Fold 5 Epoch 25: loss=0.2174, acc=50.62% (best=53.59%)\n",
      "          Fold 5 Epoch 30: loss=0.2093, acc=44.30% (best=53.91%)\n",
      "          Fold 5 Epoch 35: loss=0.2088, acc=50.86% (best=55.08%)\n",
      "          Fold 5 Epoch 40: loss=0.2054, acc=42.34% (best=55.08%)\n",
      "          Fold 5: Early stopping at epoch 41\n",
      "      â†’ Fold 5 completed: 55.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4d373e08:\n",
      "        Fold accuracies: ['56.64%', '60.39%', '61.88%', '63.52%', '55.08%']\n",
      "        Average fitness: 59.50% Â± 3.17%\n",
      "        Best fold: Fold 4 with 63.52%\n",
      "      Fitness obtained: 59.50% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: e173b7d6)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model e173b7d6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6782, acc=57.81% (best=57.81%)\n",
      "          Fold 5 Epoch 1: loss=0.6918, acc=45.70% (best=45.70%)\n",
      "          Fold 1 Epoch 1: loss=0.6955, acc=57.58% (best=57.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6482, acc=48.05% (best=48.05%)\n",
      "          Fold 3 Epoch 1: loss=0.6531, acc=47.11% (best=47.11%)\n",
      "          Fold 2 Epoch 5: loss=0.3896, acc=36.09% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4137, acc=49.06% (best=57.58%)\n",
      "          Fold 5 Epoch 5: loss=0.3554, acc=44.38% (best=52.89%)\n",
      "          Fold 4 Epoch 5: loss=0.3641, acc=59.38% (best=59.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3692, acc=48.36% (best=56.02%)\n",
      "          Fold 2 Epoch 10: loss=0.3038, acc=40.47% (best=57.81%)\n",
      "          Fold 1 Epoch 10: loss=0.3133, acc=56.64% (best=57.58%)\n",
      "          Fold 5 Epoch 10: loss=0.2840, acc=45.31% (best=52.89%)\n",
      "          Fold 4 Epoch 10: loss=0.2830, acc=52.34% (best=68.44%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 3 Epoch 10: loss=0.2929, acc=55.23% (best=56.02%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 57.58%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 52.89%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 56.02%\n",
      "          Fold 4 Epoch 15: loss=0.2459, acc=56.80% (best=68.44%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e173b7d6:\n",
      "        Fold accuracies: ['57.58%', '57.81%', '56.02%', '68.44%', '52.89%']\n",
      "        Average fitness: 58.55% Â± 5.25%\n",
      "        Best fold: Fold 4 with 68.44%\n",
      "      Fitness obtained: 58.55% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: bf76e2f9)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model bf76e2f9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.8729, acc=45.62% (best=45.62%)\n",
      "          Fold 2 Epoch 1: loss=0.8607, acc=48.67% (best=48.67%)\n",
      "          Fold 1 Epoch 1: loss=0.8961, acc=51.80% (best=51.80%)\n",
      "          Fold 5 Epoch 1: loss=0.8382, acc=54.38% (best=54.38%)\n",
      "          Fold 4 Epoch 1: loss=0.8296, acc=37.66% (best=37.66%)\n",
      "          Fold 3 Epoch 5: loss=0.4744, acc=43.98% (best=56.72%)\n",
      "          Fold 1 Epoch 5: loss=0.5194, acc=52.81% (best=56.41%)\n",
      "          Fold 5 Epoch 5: loss=0.5379, acc=57.81% (best=68.36%)\n",
      "          Fold 2 Epoch 5: loss=0.4665, acc=63.59% (best=63.59%)\n",
      "          Fold 4 Epoch 5: loss=0.5430, acc=49.92% (best=59.30%)\n",
      "          Fold 3 Epoch 10: loss=0.3326, acc=47.42% (best=56.72%)\n",
      "          Fold 1 Epoch 10: loss=0.3347, acc=52.58% (best=56.41%)\n",
      "          Fold 2 Epoch 10: loss=0.3132, acc=42.42% (best=63.59%)\n",
      "          Fold 5 Epoch 10: loss=0.3180, acc=51.09% (best=68.36%)\n",
      "          Fold 4 Epoch 10: loss=0.3842, acc=59.30% (best=64.45%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 68.36%\n",
      "          Fold 3 Epoch 15: loss=0.2879, acc=46.56% (best=58.67%)\n",
      "          Fold 1 Epoch 15: loss=0.2852, acc=39.22% (best=56.48%)\n",
      "          Fold 2 Epoch 15: loss=0.2756, acc=46.80% (best=63.59%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.59%\n",
      "          Fold 4 Epoch 15: loss=0.2893, acc=63.98% (best=64.45%)\n",
      "          Fold 3 Epoch 20: loss=0.2667, acc=61.80% (best=61.80%)\n",
      "          Fold 1 Epoch 20: loss=0.2664, acc=57.66% (best=58.98%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 64.45%\n",
      "          Fold 3 Epoch 25: loss=0.2514, acc=60.31% (best=61.80%)\n",
      "          Fold 1 Epoch 25: loss=0.2472, acc=51.64% (best=58.98%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 58.98%\n",
      "          Fold 3 Epoch 30: loss=0.2391, acc=63.44% (best=63.44%)\n",
      "          Fold 3 Epoch 35: loss=0.2320, acc=60.94% (best=63.44%)\n",
      "          Fold 3 Epoch 40: loss=0.2268, acc=47.19% (best=63.44%)\n",
      "          Fold 3: Early stopping at epoch 40\n",
      "      â†’ Fold 3 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bf76e2f9:\n",
      "        Fold accuracies: ['58.98%', '63.59%', '63.44%', '64.45%', '68.36%']\n",
      "        Average fitness: 63.77% Â± 2.99%\n",
      "        Best fold: Fold 5 with 68.36%\n",
      "      Fitness obtained: 63.77% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 5d804207)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 5d804207 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7489, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7555, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 1: loss=0.7104, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7363, acc=47.19% (best=47.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7503, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6161, acc=55.47% (best=55.47%)\n",
      "          Fold 3 Epoch 5: loss=0.6605, acc=47.66% (best=53.12%)\n",
      "          Fold 5 Epoch 5: loss=0.6819, acc=46.95% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.5705, acc=58.83% (best=58.83%)\n",
      "          Fold 1 Epoch 5: loss=0.5901, acc=63.05% (best=63.05%)\n",
      "          Fold 2 Epoch 10: loss=0.3300, acc=63.91% (best=63.91%)\n",
      "          Fold 3 Epoch 10: loss=0.3714, acc=51.25% (best=55.08%)\n",
      "          Fold 5 Epoch 10: loss=0.3472, acc=46.95% (best=50.00%)\n",
      "          Fold 4 Epoch 10: loss=0.3815, acc=42.34% (best=58.83%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 1 Epoch 10: loss=0.3491, acc=57.66% (best=63.05%)\n",
      "          Fold 2 Epoch 15: loss=0.2834, acc=62.81% (best=63.91%)\n",
      "          Fold 3 Epoch 15: loss=0.2900, acc=54.38% (best=56.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2866, acc=43.12% (best=58.83%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 58.83%\n",
      "          Fold 1 Epoch 15: loss=0.2795, acc=53.59% (best=63.05%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.05%\n",
      "          Fold 2 Epoch 20: loss=0.2655, acc=53.67% (best=65.16%)\n",
      "          Fold 3 Epoch 20: loss=0.2601, acc=55.70% (best=68.52%)\n",
      "          Fold 2 Epoch 25: loss=0.2439, acc=51.88% (best=65.16%)\n",
      "          Fold 3 Epoch 25: loss=0.2403, acc=61.25% (best=68.52%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 68.52%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5d804207:\n",
      "        Fold accuracies: ['63.05%', '65.16%', '68.52%', '58.83%', '50.00%']\n",
      "        Average fitness: 61.11% Â± 6.38%\n",
      "        Best fold: Fold 3 with 68.52%\n",
      "      Fitness obtained: 61.11% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 6dfdaa19)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 6dfdaa19 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7131, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.7085, acc=62.97% (best=62.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7224, acc=55.86% (best=55.86%)\n",
      "          Fold 2 Epoch 1: loss=0.6943, acc=40.78% (best=40.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6731, acc=55.31% (best=55.31%)\n",
      "          Fold 3 Epoch 5: loss=0.3830, acc=57.81% (best=59.92%)\n",
      "          Fold 1 Epoch 5: loss=0.4295, acc=59.61% (best=62.97%)\n",
      "          Fold 5 Epoch 5: loss=0.3732, acc=40.16% (best=55.86%)\n",
      "          Fold 2 Epoch 5: loss=0.3654, acc=63.75% (best=64.61%)\n",
      "          Fold 4 Epoch 5: loss=0.3828, acc=54.30% (best=56.02%)\n",
      "          Fold 3 Epoch 10: loss=0.3042, acc=48.12% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.2905, acc=60.62% (best=62.97%)\n",
      "          Fold 5 Epoch 10: loss=0.2693, acc=39.22% (best=55.86%)\n",
      "          Fold 2 Epoch 10: loss=0.2812, acc=41.17% (best=64.61%)\n",
      "          Fold 4 Epoch 10: loss=0.2751, acc=51.56% (best=56.88%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.97%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.86%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 64.61%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 59.92%\n",
      "          Fold 4 Epoch 15: loss=0.2401, acc=51.48% (best=56.88%)\n",
      "          Fold 4 Epoch 20: loss=0.2358, acc=59.38% (best=61.09%)\n",
      "          Fold 4 Epoch 25: loss=0.2244, acc=48.05% (best=61.09%)\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 61.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6dfdaa19:\n",
      "        Fold accuracies: ['62.97%', '64.61%', '59.92%', '61.09%', '55.86%']\n",
      "        Average fitness: 60.89% Â± 2.98%\n",
      "        Best fold: Fold 2 with 64.61%\n",
      "      Fitness obtained: 60.89% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 34211d6f)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 34211d6f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6842, acc=55.39% (best=55.39%)\n",
      "          Fold 3 Epoch 1: loss=0.6931, acc=53.12% (best=53.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6756, acc=61.48% (best=61.48%)\n",
      "          Fold 1 Epoch 1: loss=0.6975, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7052, acc=46.64% (best=46.64%)\n",
      "          Fold 2 Epoch 5: loss=0.4151, acc=47.19% (best=57.58%)\n",
      "          Fold 3 Epoch 5: loss=0.3888, acc=50.70% (best=53.12%)\n",
      "          Fold 4 Epoch 5: loss=0.3282, acc=47.89% (best=68.52%)\n",
      "          Fold 1 Epoch 5: loss=0.4291, acc=52.11% (best=58.20%)\n",
      "          Fold 5 Epoch 5: loss=0.4261, acc=55.39% (best=60.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2762, acc=48.59% (best=57.58%)\n",
      "          Fold 3 Epoch 10: loss=0.2738, acc=49.69% (best=60.62%)\n",
      "          Fold 4 Epoch 10: loss=0.2488, acc=57.03% (best=68.52%)\n",
      "          Fold 1 Epoch 10: loss=0.2772, acc=60.55% (best=60.55%)\n",
      "          Fold 5 Epoch 10: loss=0.2766, acc=48.52% (best=60.23%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 57.58%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.52%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 3 Epoch 15: loss=0.2392, acc=62.27% (best=62.27%)\n",
      "          Fold 1 Epoch 15: loss=0.2477, acc=64.38% (best=64.38%)\n",
      "          Fold 3 Epoch 20: loss=0.2259, acc=58.12% (best=62.97%)\n",
      "          Fold 1 Epoch 20: loss=0.2289, acc=68.44% (best=68.44%)\n",
      "          Fold 3 Epoch 25: loss=0.2223, acc=58.67% (best=62.97%)\n",
      "          Fold 1 Epoch 25: loss=0.2185, acc=59.22% (best=68.44%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 62.97%\n",
      "          Fold 1 Epoch 30: loss=0.2131, acc=63.28% (best=68.44%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 68.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 34211d6f:\n",
      "        Fold accuracies: ['68.44%', '57.58%', '62.97%', '68.52%', '60.23%']\n",
      "        Average fitness: 63.55% Â± 4.37%\n",
      "        Best fold: Fold 4 with 68.52%\n",
      "      Fitness obtained: 63.55% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: d22c88a4)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model d22c88a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6525, acc=45.86% (best=45.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7016, acc=57.42% (best=57.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6631, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6595, acc=57.73% (best=57.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6367, acc=67.58% (best=67.58%)\n",
      "          Fold 2 Epoch 5: loss=0.3093, acc=40.55% (best=49.77%)\n",
      "          Fold 5 Epoch 5: loss=0.3378, acc=50.55% (best=58.98%)\n",
      "          Fold 1 Epoch 5: loss=0.2987, acc=53.98% (best=67.50%)\n",
      "          Fold 4 Epoch 5: loss=0.3059, acc=54.06% (best=63.59%)\n",
      "          Fold 3 Epoch 5: loss=0.3024, acc=64.45% (best=67.58%)\n",
      "          Fold 2 Epoch 10: loss=0.2568, acc=63.05% (best=63.05%)\n",
      "          Fold 5 Epoch 10: loss=0.2623, acc=46.02% (best=58.98%)\n",
      "          Fold 1 Epoch 10: loss=0.2440, acc=48.59% (best=67.50%)\n",
      "          Fold 4 Epoch 10: loss=0.2506, acc=58.05% (best=68.52%)\n",
      "          Fold 3 Epoch 10: loss=0.2551, acc=60.78% (best=67.58%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 67.50%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "          Fold 2 Epoch 15: loss=0.2305, acc=54.06% (best=63.05%)\n",
      "          Fold 4 Epoch 15: loss=0.2249, acc=58.52% (best=68.52%)\n",
      "          Fold 2 Epoch 20: loss=0.2175, acc=45.62% (best=63.05%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 63.05%\n",
      "          Fold 4 Epoch 20: loss=0.2185, acc=60.16% (best=69.84%)\n",
      "          Fold 4 Epoch 25: loss=0.2161, acc=67.66% (best=71.25%)\n",
      "          Fold 4 Epoch 30: loss=0.2104, acc=57.42% (best=71.25%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 71.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d22c88a4:\n",
      "        Fold accuracies: ['67.50%', '63.05%', '67.58%', '71.25%', '58.98%']\n",
      "        Average fitness: 65.67% Â± 4.24%\n",
      "        Best fold: Fold 4 with 71.25%\n",
      "      Fitness obtained: 65.67% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: b1849cb5)\n",
      "      Architecture: 8 conv + 2 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model b1849cb5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6974, acc=56.72% (best=56.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6753, acc=59.61% (best=59.61%)\n",
      "          Fold 3 Epoch 1: loss=0.6805, acc=55.78% (best=55.78%)\n",
      "          Fold 2 Epoch 1: loss=0.6577, acc=38.75% (best=38.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6502, acc=64.61% (best=64.61%)\n",
      "          Fold 2 Epoch 5: loss=0.3502, acc=65.00% (best=65.00%)\n",
      "          Fold 3 Epoch 5: loss=0.4027, acc=62.42% (best=62.42%)\n",
      "          Fold 1 Epoch 5: loss=0.3978, acc=55.94% (best=59.61%)\n",
      "          Fold 5 Epoch 5: loss=0.3863, acc=50.78% (best=56.72%)\n",
      "          Fold 4 Epoch 5: loss=0.3869, acc=67.11% (best=67.11%)\n",
      "          Fold 2 Epoch 10: loss=0.2856, acc=54.14% (best=66.88%)\n",
      "          Fold 3 Epoch 10: loss=0.3097, acc=60.00% (best=62.42%)\n",
      "          Fold 1 Epoch 10: loss=0.3046, acc=54.84% (best=63.52%)\n",
      "          Fold 5 Epoch 10: loss=0.2981, acc=47.50% (best=56.72%)\n",
      "          Fold 4 Epoch 10: loss=0.2812, acc=57.11% (best=67.11%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 2 Epoch 15: loss=0.2561, acc=60.70% (best=66.88%)\n",
      "          Fold 3 Epoch 15: loss=0.2830, acc=51.56% (best=62.42%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 62.42%\n",
      "          Fold 1 Epoch 15: loss=0.2784, acc=58.44% (best=63.52%)\n",
      "          Fold 4 Epoch 15: loss=0.2550, acc=56.56% (best=67.11%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 66.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b1849cb5:\n",
      "        Fold accuracies: ['63.52%', '66.88%', '62.42%', '67.11%', '56.72%']\n",
      "        Average fitness: 63.33% Â± 3.78%\n",
      "        Best fold: Fold 4 with 67.11%\n",
      "      Fitness obtained: 63.33% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 72c1f989)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 72c1f989 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6866, acc=43.36% (best=43.36%)\n",
      "          Fold 4 Epoch 1: loss=0.6778, acc=67.03% (best=67.03%)\n",
      "          Fold 1 Epoch 1: loss=0.6934, acc=56.72% (best=56.72%)\n",
      "          Fold 3 Epoch 1: loss=0.7042, acc=52.11% (best=52.11%)\n",
      "          Fold 5 Epoch 1: loss=0.7076, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 5: loss=0.3735, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 5: loss=0.3809, acc=45.94% (best=67.03%)\n",
      "          Fold 1 Epoch 5: loss=0.4764, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 5: loss=0.3897, acc=61.25% (best=64.45%)\n",
      "          Fold 5 Epoch 5: loss=0.4455, acc=38.52% (best=54.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2740, acc=47.03% (best=59.92%)\n",
      "          Fold 4 Epoch 10: loss=0.2694, acc=53.20% (best=67.03%)\n",
      "          Fold 1 Epoch 10: loss=0.3266, acc=55.78% (best=62.11%)\n",
      "          Fold 3 Epoch 10: loss=0.2883, acc=54.22% (best=69.69%)\n",
      "          Fold 5 Epoch 10: loss=0.2845, acc=40.78% (best=54.53%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.03%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 54.53%\n",
      "          Fold 2 Epoch 15: loss=0.2393, acc=56.56% (best=59.92%)\n",
      "          Fold 1 Epoch 15: loss=0.2726, acc=54.53% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 3 Epoch 15: loss=0.2605, acc=61.88% (best=69.69%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 69.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 72c1f989:\n",
      "        Fold accuracies: ['62.11%', '59.92%', '69.69%', '67.03%', '54.53%']\n",
      "        Average fitness: 62.66% Â± 5.34%\n",
      "        Best fold: Fold 3 with 69.69%\n",
      "      Fitness obtained: 62.66% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 7ce3c4fc)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 7ce3c4fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6861, acc=46.72% (best=46.72%)\n",
      "          Fold 3 Epoch 1: loss=0.6926, acc=54.61% (best=54.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6815, acc=52.11% (best=52.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6961, acc=44.77% (best=44.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7091, acc=51.80% (best=51.80%)\n",
      "          Fold 2 Epoch 5: loss=0.3909, acc=39.69% (best=59.69%)\n",
      "          Fold 3 Epoch 5: loss=0.3652, acc=56.64% (best=62.42%)\n",
      "          Fold 4 Epoch 5: loss=0.3640, acc=46.72% (best=55.47%)\n",
      "          Fold 1 Epoch 5: loss=0.4263, acc=60.31% (best=60.31%)\n",
      "          Fold 5 Epoch 5: loss=0.3987, acc=40.70% (best=60.39%)\n",
      "          Fold 2 Epoch 10: loss=0.2759, acc=50.39% (best=59.69%)\n",
      "          Fold 3 Epoch 10: loss=0.2930, acc=57.11% (best=62.42%)\n",
      "          Fold 4 Epoch 10: loss=0.2820, acc=55.39% (best=74.38%)\n",
      "          Fold 1 Epoch 10: loss=0.3043, acc=63.44% (best=63.44%)\n",
      "          Fold 5 Epoch 10: loss=0.3003, acc=42.34% (best=60.39%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 62.42%\n",
      "          Fold 4 Epoch 15: loss=0.2529, acc=58.20% (best=74.38%)\n",
      "          Fold 1 Epoch 15: loss=0.2606, acc=64.77% (best=64.77%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 74.38%\n",
      "          Fold 1 Epoch 20: loss=0.2468, acc=61.41% (best=64.77%)\n",
      "          Fold 1 Epoch 25: loss=0.2274, acc=61.56% (best=64.77%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 64.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7ce3c4fc:\n",
      "        Fold accuracies: ['64.77%', '59.69%', '62.42%', '74.38%', '60.39%']\n",
      "        Average fitness: 64.33% Â± 5.33%\n",
      "        Best fold: Fold 4 with 74.38%\n",
      "      Fitness obtained: 64.33% | Best in generation: 65.84% | Global best: 69.44%\n",
      "\n",
      "GENERATION 12 STATISTICS:\n",
      "   Maximum fitness: 65.84%\n",
      "   Average fitness: 56.37%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 18.93%\n",
      "   Best individual: d43d4e67 with 65.84%\n",
      "   Global best individual: 1b39d73a with 69.44%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=18.93)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: d43d4e67 (fitness: 65.84%)\n",
      "   Elite 2: d22c88a4 (fitness: 65.67%)\n",
      "   Elite 3: e06d5ef0 (fitness: 65.38%)\n",
      "   Elite 4: 59336158 (fitness: 64.94%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 13\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 13)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: d43d4e67)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d43d4e67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7085, acc=47.58% (best=47.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6951, acc=45.62% (best=45.62%)\n",
      "          Fold 1 Epoch 1: loss=0.7190, acc=61.48% (best=61.48%)\n",
      "          Fold 5 Epoch 1: loss=0.7353, acc=65.00% (best=65.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6931, acc=58.05% (best=58.05%)\n",
      "          Fold 2 Epoch 5: loss=0.3871, acc=55.78% (best=68.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3841, acc=57.50% (best=61.80%)\n",
      "          Fold 1 Epoch 5: loss=0.4375, acc=57.58% (best=61.48%)\n",
      "          Fold 4 Epoch 5: loss=0.5027, acc=62.03% (best=68.91%)\n",
      "          Fold 5 Epoch 5: loss=0.5402, acc=58.05% (best=65.00%)\n",
      "          Fold 3 Epoch 10: loss=0.3092, acc=56.48% (best=62.19%)\n",
      "          Fold 1 Epoch 10: loss=0.3089, acc=55.94% (best=61.48%)\n",
      "          Fold 2 Epoch 10: loss=0.3052, acc=61.17% (best=68.91%)\n",
      "          Fold 5 Epoch 10: loss=0.3354, acc=43.28% (best=65.00%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.48%\n",
      "          Fold 4 Epoch 10: loss=0.3497, acc=61.95% (best=68.91%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 65.00%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 68.91%\n",
      "          Fold 3 Epoch 15: loss=0.2719, acc=59.69% (best=66.80%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 3 Epoch 20: loss=0.2553, acc=55.39% (best=67.19%)\n",
      "          Fold 3 Epoch 25: loss=0.2463, acc=58.20% (best=67.19%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d43d4e67:\n",
      "        Fold accuracies: ['61.48%', '68.91%', '67.19%', '68.91%', '65.00%']\n",
      "        Average fitness: 66.30% Â± 2.80%\n",
      "        Best fold: Fold 2 with 68.91%\n",
      "      New best fitness in this generation: 66.30%!\n",
      "      Fitness obtained: 66.30% | Best in generation: 66.30% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: d22c88a4)\n",
      "      Architecture: 11 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model d22c88a4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6767, acc=53.83% (best=53.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6533, acc=50.70% (best=50.70%)\n",
      "          Fold 1 Epoch 1: loss=0.6911, acc=57.03% (best=57.03%)\n",
      "          Fold 5 Epoch 1: loss=0.6826, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6693, acc=61.48% (best=61.48%)\n",
      "          Fold 2 Epoch 5: loss=0.3077, acc=38.20% (best=53.83%)\n",
      "          Fold 3 Epoch 5: loss=0.3136, acc=53.28% (best=60.86%)\n",
      "          Fold 1 Epoch 5: loss=0.3397, acc=54.84% (best=62.50%)\n",
      "          Fold 5 Epoch 5: loss=0.3296, acc=50.70% (best=66.17%)\n",
      "          Fold 4 Epoch 5: loss=0.2975, acc=43.44% (best=61.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2493, acc=45.94% (best=53.83%)\n",
      "          Fold 3 Epoch 10: loss=0.2548, acc=52.50% (best=60.86%)\n",
      "          Fold 1 Epoch 10: loss=0.2830, acc=65.86% (best=65.86%)\n",
      "          Fold 5 Epoch 10: loss=0.2625, acc=46.25% (best=66.17%)\n",
      "          Fold 4 Epoch 10: loss=0.2457, acc=51.02% (best=61.48%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 53.83%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.48%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 66.17%\n",
      "          Fold 1 Epoch 15: loss=0.2539, acc=49.22% (best=67.66%)\n",
      "          Fold 1 Epoch 20: loss=0.2310, acc=57.89% (best=67.66%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 67.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d22c88a4:\n",
      "        Fold accuracies: ['67.66%', '53.83%', '60.86%', '61.48%', '66.17%']\n",
      "        Average fitness: 62.00% Â± 4.85%\n",
      "        Best fold: Fold 1 with 67.66%\n",
      "      Fitness obtained: 62.00% | Best in generation: 66.30% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: e06d5ef0)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model e06d5ef0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6841, acc=62.42% (best=62.42%)\n",
      "          Fold 2 Epoch 1: loss=0.6806, acc=43.36% (best=43.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7005, acc=53.83% (best=53.83%)\n",
      "          Fold 3 Epoch 1: loss=0.7013, acc=56.72% (best=56.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7117, acc=47.50% (best=47.50%)\n",
      "          Fold 4 Epoch 5: loss=0.4101, acc=53.91% (best=62.42%)\n",
      "          Fold 2 Epoch 5: loss=0.4318, acc=56.17% (best=56.17%)\n",
      "          Fold 1 Epoch 5: loss=0.5421, acc=44.06% (best=55.70%)\n",
      "          Fold 3 Epoch 5: loss=0.4596, acc=55.62% (best=59.61%)\n",
      "          Fold 5 Epoch 5: loss=0.5813, acc=54.53% (best=62.19%)\n",
      "          Fold 4 Epoch 10: loss=0.2873, acc=58.28% (best=62.42%)\n",
      "          Fold 2 Epoch 10: loss=0.3010, acc=62.66% (best=62.66%)\n",
      "          Fold 1 Epoch 10: loss=0.3368, acc=52.19% (best=56.33%)\n",
      "          Fold 3 Epoch 10: loss=0.3359, acc=54.92% (best=59.61%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.42%\n",
      "          Fold 5 Epoch 10: loss=0.3406, acc=51.56% (best=62.19%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 59.61%\n",
      "          Fold 2 Epoch 15: loss=0.2647, acc=55.47% (best=65.86%)\n",
      "          Fold 1 Epoch 15: loss=0.2934, acc=51.09% (best=57.03%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 2 Epoch 20: loss=0.2435, acc=59.30% (best=65.86%)\n",
      "          Fold 1 Epoch 20: loss=0.2671, acc=55.16% (best=57.03%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 65.86%\n",
      "          Fold 1 Epoch 25: loss=0.2483, acc=50.47% (best=60.47%)\n",
      "          Fold 1 Epoch 30: loss=0.2376, acc=56.72% (best=60.47%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 60.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e06d5ef0:\n",
      "        Fold accuracies: ['60.47%', '65.86%', '59.61%', '62.42%', '62.19%']\n",
      "        Average fitness: 62.11% Â± 2.15%\n",
      "        Best fold: Fold 2 with 65.86%\n",
      "      Fitness obtained: 62.11% | Best in generation: 66.30% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 59336158)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 59336158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6693, acc=63.52% (best=63.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6890, acc=51.48% (best=51.48%)\n",
      "          Fold 1 Epoch 1: loss=0.6982, acc=52.89% (best=52.89%)\n",
      "          Fold 3 Epoch 1: loss=0.7071, acc=47.42% (best=47.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7106, acc=51.56% (best=51.56%)\n",
      "          Fold 4 Epoch 5: loss=0.3508, acc=55.08% (best=64.84%)\n",
      "          Fold 1 Epoch 5: loss=0.4259, acc=40.55% (best=53.75%)\n",
      "          Fold 2 Epoch 5: loss=0.3884, acc=44.61% (best=58.05%)\n",
      "          Fold 3 Epoch 5: loss=0.3855, acc=61.48% (best=61.48%)\n",
      "          Fold 5 Epoch 5: loss=0.4266, acc=49.84% (best=55.00%)\n",
      "          Fold 4 Epoch 10: loss=0.2727, acc=52.97% (best=64.84%)\n",
      "          Fold 1 Epoch 10: loss=0.3067, acc=45.70% (best=53.75%)\n",
      "          Fold 2 Epoch 10: loss=0.2740, acc=47.27% (best=58.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2962, acc=62.50% (best=62.50%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 64.84%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 53.75%\n",
      "          Fold 5 Epoch 10: loss=0.3288, acc=41.41% (best=55.00%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 58.05%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 55.00%\n",
      "          Fold 3 Epoch 15: loss=0.2637, acc=64.06% (best=69.53%)\n",
      "          Fold 3 Epoch 20: loss=0.2561, acc=60.08% (best=69.53%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 69.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 59336158:\n",
      "        Fold accuracies: ['53.75%', '58.05%', '69.53%', '64.84%', '55.00%']\n",
      "        Average fitness: 60.23% Â± 6.03%\n",
      "        Best fold: Fold 3 with 69.53%\n",
      "      Fitness obtained: 60.23% | Best in generation: 66.30% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 6182ad6c)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 6182ad6c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.8811, acc=45.70% (best=45.70%)\n",
      "          Fold 4 Epoch 1: loss=0.8496, acc=43.44% (best=43.44%)\n",
      "          Fold 5 Epoch 1: loss=0.8601, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 1: loss=0.8817, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.8870, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 5: loss=0.5812, acc=61.17% (best=61.17%)\n",
      "          Fold 4 Epoch 5: loss=0.4418, acc=47.50% (best=66.41%)\n",
      "          Fold 5 Epoch 5: loss=0.4587, acc=50.16% (best=56.64%)\n",
      "          Fold 2 Epoch 5: loss=0.4862, acc=46.80% (best=58.75%)\n",
      "          Fold 1 Epoch 5: loss=0.5323, acc=56.25% (best=64.06%)\n",
      "          Fold 3 Epoch 10: loss=0.3662, acc=71.17% (best=71.17%)\n",
      "          Fold 4 Epoch 10: loss=0.2921, acc=48.83% (best=66.41%)\n",
      "          Fold 5 Epoch 10: loss=0.2842, acc=52.27% (best=60.39%)\n",
      "          Fold 1 Epoch 10: loss=0.3240, acc=61.56% (best=64.06%)\n",
      "          Fold 2 Epoch 10: loss=0.3153, acc=46.25% (best=65.62%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 66.41%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 64.06%\n",
      "          Fold 3 Epoch 15: loss=0.2853, acc=65.78% (best=71.17%)\n",
      "          Fold 5 Epoch 15: loss=0.2452, acc=51.02% (best=64.53%)\n",
      "          Fold 2 Epoch 15: loss=0.2720, acc=46.88% (best=65.62%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 65.62%\n",
      "          Fold 3 Epoch 20: loss=0.2628, acc=42.97% (best=71.17%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 71.17%\n",
      "          Fold 5 Epoch 20: loss=0.2442, acc=55.47% (best=64.53%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6182ad6c:\n",
      "        Fold accuracies: ['64.06%', '65.62%', '71.17%', '66.41%', '64.53%']\n",
      "        Average fitness: 66.36% Â± 2.54%\n",
      "        Best fold: Fold 3 with 71.17%\n",
      "      New best fitness in this generation: 66.36%!\n",
      "      Fitness obtained: 66.36% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 507a994c)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 507a994c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7130, acc=48.67% (best=48.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7102, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6921, acc=59.77% (best=59.77%)\n",
      "          Fold 1 Epoch 1: loss=0.7180, acc=53.20% (best=53.20%)\n",
      "          Fold 5 Epoch 1: loss=0.7121, acc=50.31% (best=50.31%)\n",
      "          Fold 2 Epoch 5: loss=0.6674, acc=31.88% (best=48.67%)\n",
      "          Fold 3 Epoch 5: loss=0.6855, acc=50.08% (best=50.08%)\n",
      "          Fold 4 Epoch 5: loss=0.6461, acc=62.66% (best=62.66%)\n",
      "          Fold 1 Epoch 5: loss=0.6867, acc=52.42% (best=60.70%)\n",
      "          Fold 5 Epoch 5: loss=0.7002, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 10: loss=0.6434, acc=39.61% (best=48.67%)\n",
      "          Fold 3 Epoch 10: loss=0.6103, acc=52.97% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.5747, acc=57.97% (best=62.66%)\n",
      "          Fold 1 Epoch 10: loss=0.6592, acc=54.30% (best=60.70%)\n",
      "          Fold 5 Epoch 10: loss=0.6738, acc=53.75% (best=54.14%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 48.67%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 60.70%\n",
      "          Fold 3 Epoch 15: loss=0.5113, acc=48.20% (best=59.84%)\n",
      "          Fold 4 Epoch 15: loss=0.5104, acc=55.55% (best=62.66%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 62.66%\n",
      "          Fold 5 Epoch 15: loss=0.5852, acc=51.09% (best=58.12%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 59.84%\n",
      "          Fold 5 Epoch 20: loss=0.5231, acc=58.59% (best=58.59%)\n",
      "          Fold 5 Epoch 25: loss=0.4773, acc=48.67% (best=58.59%)\n",
      "          Fold 5 Epoch 30: loss=0.4375, acc=55.62% (best=58.59%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 58.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 507a994c:\n",
      "        Fold accuracies: ['60.70%', '48.67%', '59.84%', '62.66%', '58.59%']\n",
      "        Average fitness: 58.09% Â± 4.89%\n",
      "        Best fold: Fold 4 with 62.66%\n",
      "      Fitness obtained: 58.09% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 1c545b62)\n",
      "      Architecture: 29 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 1c545b62 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 94, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 1c545b62:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: c8194aca)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model c8194aca with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7230, acc=48.83% (best=48.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7146, acc=55.39% (best=55.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7066, acc=54.61% (best=54.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7058, acc=64.77% (best=64.77%)\n",
      "          Fold 1 Epoch 1: loss=0.7142, acc=43.91% (best=43.91%)\n",
      "          Fold 3 Epoch 5: loss=0.6865, acc=44.30% (best=49.45%)\n",
      "          Fold 5 Epoch 5: loss=0.7029, acc=49.06% (best=65.08%)\n",
      "          Fold 4 Epoch 5: loss=0.6591, acc=37.97% (best=64.77%)\n",
      "          Fold 1 Epoch 5: loss=0.6879, acc=39.30% (best=59.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6677, acc=60.55% (best=60.55%)\n",
      "          Fold 3 Epoch 10: loss=0.4906, acc=48.75% (best=55.86%)\n",
      "          Fold 5 Epoch 10: loss=0.6681, acc=51.17% (best=65.08%)\n",
      "          Fold 4 Epoch 10: loss=0.4543, acc=59.06% (best=64.77%)\n",
      "          Fold 1 Epoch 10: loss=0.5852, acc=61.09% (best=61.09%)\n",
      "          Fold 2 Epoch 10: loss=0.4674, acc=53.75% (best=60.55%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.77%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.08%\n",
      "          Fold 3 Epoch 15: loss=0.3529, acc=45.70% (best=61.17%)\n",
      "          Fold 1 Epoch 15: loss=0.3937, acc=46.72% (best=61.09%)\n",
      "          Fold 2 Epoch 15: loss=0.3465, acc=55.23% (best=60.55%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 60.55%\n",
      "          Fold 3 Epoch 20: loss=0.3223, acc=46.09% (best=61.17%)\n",
      "          Fold 1 Epoch 20: loss=0.3255, acc=46.88% (best=61.09%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 61.09%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 61.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c8194aca:\n",
      "        Fold accuracies: ['61.09%', '60.55%', '61.17%', '64.77%', '65.08%']\n",
      "        Average fitness: 62.53% Â± 1.97%\n",
      "        Best fold: Fold 5 with 65.08%\n",
      "      Fitness obtained: 62.53% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 5a8c5780)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 5a8c5780 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7145, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 1: loss=0.7174, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 1: loss=0.7240, acc=50.31% (best=50.31%)\n",
      "          Fold 3 Epoch 1: loss=0.7252, acc=49.14% (best=49.14%)\n",
      "          Fold 5 Epoch 1: loss=0.7212, acc=54.38% (best=54.38%)\n",
      "          Fold 4 Epoch 5: loss=0.6936, acc=57.03% (best=61.56%)\n",
      "          Fold 1 Epoch 5: loss=0.7019, acc=50.23% (best=50.31%)\n",
      "          Fold 5 Epoch 5: loss=0.7106, acc=47.34% (best=54.38%)\n",
      "          Fold 2 Epoch 5: loss=0.7038, acc=51.09% (best=54.45%)\n",
      "          Fold 3 Epoch 5: loss=0.7123, acc=58.20% (best=58.20%)\n",
      "          Fold 4 Epoch 10: loss=0.6743, acc=49.84% (best=61.56%)\n",
      "          Fold 1 Epoch 10: loss=0.6971, acc=50.31% (best=50.39%)\n",
      "          Fold 5 Epoch 10: loss=0.7069, acc=50.78% (best=54.38%)\n",
      "          Fold 2 Epoch 10: loss=0.6884, acc=46.64% (best=54.45%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 54.38%\n",
      "          Fold 3 Epoch 10: loss=0.7047, acc=52.50% (best=58.20%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 54.45%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 61.56%\n",
      "          Fold 1 Epoch 15: loss=0.6852, acc=49.69% (best=53.20%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 58.20%\n",
      "          Fold 1 Epoch 20: loss=0.6698, acc=49.84% (best=53.20%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 53.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5a8c5780:\n",
      "        Fold accuracies: ['53.20%', '54.45%', '58.20%', '61.56%', '54.38%']\n",
      "        Average fitness: 56.36% Â± 3.10%\n",
      "        Best fold: Fold 4 with 61.56%\n",
      "      Fitness obtained: 56.36% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: d4ac3307)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d4ac3307 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6809, acc=52.81% (best=52.81%)\n",
      "          Fold 2 Epoch 1: loss=0.6606, acc=57.42% (best=57.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6149, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=0.6879, acc=51.80% (best=51.80%)\n",
      "          Fold 5 Epoch 1: loss=0.6893, acc=47.11% (best=47.11%)\n",
      "          Fold 2 Epoch 5: loss=0.3510, acc=50.86% (best=57.42%)\n",
      "          Fold 1 Epoch 5: loss=0.3643, acc=37.97% (best=58.05%)\n",
      "          Fold 4 Epoch 5: loss=0.3475, acc=51.56% (best=51.56%)\n",
      "          Fold 5 Epoch 5: loss=0.3769, acc=48.75% (best=54.14%)\n",
      "          Fold 3 Epoch 5: loss=0.3639, acc=56.72% (best=61.95%)\n",
      "          Fold 2 Epoch 10: loss=0.2909, acc=68.28% (best=68.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2787, acc=59.06% (best=59.06%)\n",
      "          Fold 4 Epoch 10: loss=0.2789, acc=43.83% (best=63.59%)\n",
      "          Fold 5 Epoch 10: loss=0.2992, acc=49.38% (best=54.14%)\n",
      "          Fold 3 Epoch 10: loss=0.2970, acc=56.48% (best=61.95%)\n",
      "          Fold 2 Epoch 15: loss=0.2670, acc=57.03% (best=68.28%)\n",
      "          Fold 1 Epoch 15: loss=0.2604, acc=66.02% (best=66.95%)\n",
      "          Fold 4 Epoch 15: loss=0.2567, acc=57.97% (best=63.59%)\n",
      "          Fold 5 Epoch 15: loss=0.2619, acc=44.69% (best=58.67%)\n",
      "          Fold 3 Epoch 15: loss=0.2717, acc=56.95% (best=63.20%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 63.59%\n",
      "          Fold 2 Epoch 20: loss=0.2500, acc=54.77% (best=68.28%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 68.28%\n",
      "          Fold 1 Epoch 20: loss=0.2430, acc=65.86% (best=68.52%)\n",
      "          Fold 5 Epoch 20: loss=0.2490, acc=49.92% (best=59.92%)\n",
      "          Fold 3 Epoch 20: loss=0.2444, acc=51.64% (best=63.20%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 63.20%\n",
      "          Fold 1 Epoch 25: loss=0.2328, acc=60.55% (best=68.52%)\n",
      "          Fold 5 Epoch 25: loss=0.2416, acc=52.19% (best=59.92%)\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 1 Epoch 30: loss=0.2255, acc=66.25% (best=71.80%)\n",
      "          Fold 1 Epoch 35: loss=0.2258, acc=55.55% (best=71.80%)\n",
      "          Fold 1: Early stopping at epoch 36\n",
      "      â†’ Fold 1 completed: 71.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d4ac3307:\n",
      "        Fold accuracies: ['71.80%', '68.28%', '63.20%', '63.59%', '59.92%']\n",
      "        Average fitness: 65.36% Â± 4.18%\n",
      "        Best fold: Fold 1 with 71.80%\n",
      "      Fitness obtained: 65.36% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 1d6c68e5)\n",
      "      Architecture: 10 conv + 8 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 1d6c68e5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=1.1208, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=1.1163, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.9638, acc=52.27% (best=52.27%)\n",
      "          Fold 3 Epoch 1: loss=1.0010, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=1.0711, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 5: loss=0.6949, acc=48.28% (best=50.78%)\n",
      "          Fold 2 Epoch 5: loss=0.6654, acc=49.92% (best=56.41%)\n",
      "          Fold 4 Epoch 5: loss=0.6304, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 5: loss=0.6750, acc=57.42% (best=57.42%)\n",
      "          Fold 1 Epoch 5: loss=0.6770, acc=55.94% (best=57.34%)\n",
      "          Fold 5 Epoch 10: loss=0.6964, acc=54.22% (best=54.22%)\n",
      "          Fold 4 Epoch 10: loss=0.3788, acc=51.56% (best=55.08%)\n",
      "          Fold 2 Epoch 10: loss=0.5591, acc=45.86% (best=57.58%)\n",
      "          Fold 3 Epoch 10: loss=0.3713, acc=54.92% (best=66.64%)\n",
      "          Fold 1 Epoch 10: loss=0.4978, acc=58.05% (best=58.05%)\n",
      "          Fold 5 Epoch 15: loss=0.6762, acc=48.52% (best=54.45%)\n",
      "          Fold 4 Epoch 15: loss=0.2760, acc=52.89% (best=60.16%)\n",
      "          Fold 2 Epoch 15: loss=0.3224, acc=41.48% (best=57.58%)\n",
      "          Fold 3 Epoch 15: loss=0.2940, acc=54.69% (best=66.64%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 66.64%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 57.58%\n",
      "          Fold 1 Epoch 15: loss=0.3003, acc=46.56% (best=58.05%)\n",
      "          Fold 5 Epoch 20: loss=0.4072, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 20: loss=0.2515, acc=50.31% (best=60.16%)\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 60.16%\n",
      "          Fold 1 Epoch 20: loss=0.2675, acc=48.20% (best=59.22%)\n",
      "          Fold 5 Epoch 25: loss=0.2914, acc=51.95% (best=56.88%)\n",
      "          Fold 1 Epoch 25: loss=0.2464, acc=39.14% (best=62.66%)\n",
      "          Fold 5 Epoch 30: loss=0.2586, acc=50.94% (best=56.88%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 1 Epoch 30: loss=0.2363, acc=51.56% (best=62.66%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 62.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1d6c68e5:\n",
      "        Fold accuracies: ['62.66%', '57.58%', '66.64%', '60.16%', '56.88%']\n",
      "        Average fitness: 60.78% Â± 3.57%\n",
      "        Best fold: Fold 3 with 66.64%\n",
      "      Fitness obtained: 60.78% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 0bba893b)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 0bba893b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6970, acc=40.47% (best=40.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7064, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6859, acc=62.27% (best=62.27%)\n",
      "          Fold 1 Epoch 1: loss=0.7083, acc=62.50% (best=62.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7123, acc=56.56% (best=56.56%)\n",
      "          Fold 3 Epoch 5: loss=0.4211, acc=43.05% (best=61.09%)\n",
      "          Fold 2 Epoch 5: loss=0.4375, acc=57.11% (best=60.47%)\n",
      "          Fold 4 Epoch 5: loss=0.4586, acc=48.52% (best=66.88%)\n",
      "          Fold 1 Epoch 5: loss=0.5732, acc=48.59% (best=62.50%)\n",
      "          Fold 5 Epoch 5: loss=0.5099, acc=48.12% (best=56.56%)\n",
      "          Fold 3 Epoch 10: loss=0.3322, acc=51.80% (best=61.09%)\n",
      "          Fold 1 Epoch 10: loss=0.3627, acc=37.19% (best=66.33%)\n",
      "          Fold 4 Epoch 10: loss=0.3135, acc=53.98% (best=66.88%)\n",
      "          Fold 2 Epoch 10: loss=0.3147, acc=55.86% (best=65.47%)\n",
      "          Fold 5 Epoch 10: loss=0.3573, acc=52.58% (best=61.41%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 3 Epoch 15: loss=0.2675, acc=54.53% (best=70.39%)\n",
      "          Fold 1 Epoch 15: loss=0.2872, acc=34.22% (best=66.33%)\n",
      "          Fold 2 Epoch 15: loss=0.2731, acc=51.33% (best=65.47%)\n",
      "          Fold 5 Epoch 15: loss=0.2909, acc=52.03% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 61.41%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 66.33%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 65.47%\n",
      "          Fold 3 Epoch 20: loss=0.2418, acc=59.61% (best=70.39%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0bba893b:\n",
      "        Fold accuracies: ['66.33%', '65.47%', '70.39%', '66.88%', '61.41%']\n",
      "        Average fitness: 66.09% Â± 2.88%\n",
      "        Best fold: Fold 3 with 70.39%\n",
      "      Fitness obtained: 66.09% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 52030646)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 52030646 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7147, acc=46.64% (best=46.64%)\n",
      "          Fold 3 Epoch 1: loss=0.7164, acc=60.55% (best=60.55%)\n",
      "          Fold 1 Epoch 1: loss=0.7213, acc=46.25% (best=46.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7221, acc=42.58% (best=42.58%)\n",
      "          Fold 4 Epoch 1: loss=0.7129, acc=61.95% (best=61.95%)\n",
      "          Fold 5 Epoch 5: loss=0.7165, acc=54.14% (best=63.83%)\n",
      "          Fold 1 Epoch 5: loss=0.7040, acc=56.72% (best=58.44%)\n",
      "          Fold 3 Epoch 5: loss=0.7133, acc=52.11% (best=60.55%)\n",
      "          Fold 2 Epoch 5: loss=0.6961, acc=45.55% (best=53.52%)\n",
      "          Fold 4 Epoch 5: loss=0.6971, acc=66.64% (best=66.64%)\n",
      "          Fold 5 Epoch 10: loss=0.7112, acc=52.42% (best=63.83%)\n",
      "          Fold 1 Epoch 10: loss=0.7031, acc=56.72% (best=59.06%)\n",
      "          Fold 3 Epoch 10: loss=0.7052, acc=54.45% (best=60.55%)\n",
      "          Fold 2 Epoch 10: loss=0.6857, acc=39.06% (best=53.52%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 60.55%\n",
      "          Fold 4 Epoch 10: loss=0.6695, acc=61.56% (best=66.64%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 53.52%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 63.83%\n",
      "          Fold 1 Epoch 15: loss=0.6895, acc=56.95% (best=59.30%)\n",
      "          Fold 4 Epoch 15: loss=0.6539, acc=56.95% (best=66.64%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.64%\n",
      "          Fold 1 Epoch 20: loss=0.6880, acc=51.41% (best=59.30%)\n",
      "          Fold 1: Early stopping at epoch 23\n",
      "      â†’ Fold 1 completed: 59.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 52030646:\n",
      "        Fold accuracies: ['59.30%', '53.52%', '60.55%', '66.64%', '63.83%']\n",
      "        Average fitness: 60.77% Â± 4.44%\n",
      "        Best fold: Fold 4 with 66.64%\n",
      "      Fitness obtained: 60.77% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 101c8aa7)\n",
      "      Architecture: 10 conv + 2 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 101c8aa7 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7190, acc=53.75% (best=53.75%)\n",
      "          Fold 3 Epoch 1: loss=0.7331, acc=39.38% (best=39.38%)\n",
      "          Fold 1 Epoch 1: loss=0.7422, acc=46.02% (best=46.02%)\n",
      "          Fold 4 Epoch 1: loss=0.7061, acc=52.81% (best=52.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7366, acc=53.59% (best=53.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3618, acc=46.88% (best=53.75%)\n",
      "          Fold 3 Epoch 5: loss=0.3766, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 5: loss=0.3962, acc=30.94% (best=46.02%)\n",
      "          Fold 4 Epoch 5: loss=0.3260, acc=43.20% (best=53.98%)\n",
      "          Fold 5 Epoch 5: loss=0.3406, acc=52.42% (best=55.62%)\n",
      "          Fold 2 Epoch 10: loss=0.2745, acc=50.16% (best=53.75%)\n",
      "          Fold 3 Epoch 10: loss=0.2700, acc=50.47% (best=63.91%)\n",
      "          Fold 1 Epoch 10: loss=0.2928, acc=43.52% (best=54.77%)\n",
      "          Fold 4 Epoch 10: loss=0.2581, acc=46.02% (best=58.12%)\n",
      "          Fold 5 Epoch 10: loss=0.2573, acc=57.50% (best=57.50%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 53.75%\n",
      "          Fold 3 Epoch 15: loss=0.2363, acc=61.33% (best=73.12%)\n",
      "          Fold 1 Epoch 15: loss=0.2544, acc=44.84% (best=54.77%)\n",
      "          Fold 4 Epoch 15: loss=0.2328, acc=51.48% (best=58.12%)\n",
      "          Fold 5 Epoch 15: loss=0.2388, acc=39.45% (best=57.50%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 58.12%\n",
      "          Fold 3 Epoch 20: loss=0.2246, acc=64.92% (best=73.12%)\n",
      "          Fold 1 Epoch 20: loss=0.2387, acc=39.92% (best=57.03%)\n",
      "          Fold 5 Epoch 20: loss=0.2240, acc=47.50% (best=57.50%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 57.50%\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 73.12%\n",
      "          Fold 1 Epoch 25: loss=0.2311, acc=45.47% (best=57.03%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 57.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 101c8aa7:\n",
      "        Fold accuracies: ['57.03%', '53.75%', '73.12%', '58.12%', '57.50%']\n",
      "        Average fitness: 59.91% Â± 6.78%\n",
      "        Best fold: Fold 3 with 73.12%\n",
      "      Fitness obtained: 59.91% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: c652c387)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model c652c387 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6844, acc=47.50% (best=47.50%)\n",
      "          Fold 3 Epoch 1: loss=0.6989, acc=52.42% (best=52.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6746, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 1: loss=0.6971, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7094, acc=57.42% (best=57.42%)\n",
      "          Fold 2 Epoch 5: loss=0.3823, acc=39.14% (best=55.78%)\n",
      "          Fold 3 Epoch 5: loss=0.4229, acc=58.98% (best=64.61%)\n",
      "          Fold 4 Epoch 5: loss=0.3678, acc=49.61% (best=65.78%)\n",
      "          Fold 1 Epoch 5: loss=0.4530, acc=43.83% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.3935, acc=57.66% (best=63.44%)\n",
      "          Fold 2 Epoch 10: loss=0.2809, acc=45.62% (best=55.78%)\n",
      "          Fold 3 Epoch 10: loss=0.2970, acc=55.70% (best=64.61%)\n",
      "          Fold 4 Epoch 10: loss=0.2686, acc=62.34% (best=65.78%)\n",
      "          Fold 1 Epoch 10: loss=0.3002, acc=50.23% (best=54.06%)\n",
      "          Fold 5 Epoch 10: loss=0.2841, acc=47.89% (best=63.44%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 55.78%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 64.61%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 65.78%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "          Fold 1 Epoch 15: loss=0.2581, acc=56.56% (best=56.56%)\n",
      "          Fold 1 Epoch 20: loss=0.2372, acc=57.66% (best=58.20%)\n",
      "          Fold 1 Epoch 25: loss=0.2245, acc=58.75% (best=65.47%)\n",
      "          Fold 1 Epoch 30: loss=0.2185, acc=62.81% (best=65.47%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 65.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c652c387:\n",
      "        Fold accuracies: ['65.47%', '55.78%', '64.61%', '65.78%', '63.44%']\n",
      "        Average fitness: 63.02% Â± 3.71%\n",
      "        Best fold: Fold 4 with 65.78%\n",
      "      Fitness obtained: 63.02% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 1c284f7e)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 1c284f7e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7104, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 1: loss=0.7025, acc=48.28% (best=48.28%)\n",
      "          Fold 2 Epoch 1: loss=0.6915, acc=47.81% (best=47.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6858, acc=62.81% (best=62.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7071, acc=46.95% (best=46.95%)\n",
      "          Fold 3 Epoch 5: loss=0.5891, acc=60.86% (best=60.86%)\n",
      "          Fold 2 Epoch 5: loss=0.6373, acc=63.05% (best=63.05%)\n",
      "          Fold 1 Epoch 5: loss=0.6297, acc=44.30% (best=48.28%)\n",
      "          Fold 4 Epoch 5: loss=0.5588, acc=44.38% (best=62.81%)\n",
      "          Fold 5 Epoch 5: loss=0.5931, acc=50.78% (best=55.08%)\n",
      "          Fold 2 Epoch 10: loss=0.4041, acc=48.75% (best=63.05%)\n",
      "          Fold 3 Epoch 10: loss=0.3858, acc=52.66% (best=60.86%)\n",
      "          Fold 1 Epoch 10: loss=0.3915, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 10: loss=0.3630, acc=56.41% (best=62.81%)\n",
      "          Fold 5 Epoch 10: loss=0.3564, acc=52.27% (best=55.08%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.08%\n",
      "          Fold 2 Epoch 15: loss=0.3232, acc=56.56% (best=63.05%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.05%\n",
      "          Fold 3 Epoch 15: loss=0.3116, acc=53.44% (best=60.86%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 1 Epoch 15: loss=0.3220, acc=56.56% (best=56.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2832, acc=59.84% (best=64.45%)\n",
      "          Fold 1 Epoch 20: loss=0.2729, acc=52.97% (best=59.30%)\n",
      "          Fold 4 Epoch 20: loss=0.2512, acc=57.11% (best=64.45%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 64.45%\n",
      "          Fold 1 Epoch 25: loss=0.2544, acc=51.95% (best=59.30%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 59.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1c284f7e:\n",
      "        Fold accuracies: ['59.30%', '63.05%', '60.86%', '64.45%', '55.08%']\n",
      "        Average fitness: 60.55% Â± 3.26%\n",
      "        Best fold: Fold 4 with 64.45%\n",
      "      Fitness obtained: 60.55% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 89088407)\n",
      "      Architecture: 15 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 89088407 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 49, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 89088407:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 1eeb5e37)\n",
      "      Architecture: 8 conv + 3 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model 1eeb5e37 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6481, acc=56.09% (best=56.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6429, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.6374, acc=51.56% (best=51.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6374, acc=54.30% (best=54.30%)\n",
      "          Fold 5 Epoch 1: loss=0.6522, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 5: loss=0.2829, acc=46.41% (best=56.09%)\n",
      "          Fold 3 Epoch 5: loss=0.3097, acc=59.69% (best=59.69%)\n",
      "          Fold 4 Epoch 5: loss=0.2740, acc=55.08% (best=59.45%)\n",
      "          Fold 1 Epoch 5: loss=0.2954, acc=65.55% (best=65.55%)\n",
      "          Fold 5 Epoch 5: loss=0.2937, acc=47.50% (best=50.86%)\n",
      "          Fold 2 Epoch 10: loss=0.2473, acc=50.39% (best=56.09%)\n",
      "          Fold 3 Epoch 10: loss=0.2526, acc=56.33% (best=61.33%)\n",
      "          Fold 1 Epoch 10: loss=0.2460, acc=62.89% (best=68.05%)\n",
      "          Fold 4 Epoch 10: loss=0.2348, acc=59.30% (best=61.41%)\n",
      "          Fold 5 Epoch 10: loss=0.2498, acc=47.19% (best=50.86%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.86%\n",
      "          Fold 3 Epoch 15: loss=0.2299, acc=60.08% (best=61.33%)\n",
      "          Fold 1 Epoch 15: loss=0.2266, acc=64.92% (best=68.05%)\n",
      "          Fold 4 Epoch 15: loss=0.2162, acc=55.78% (best=61.41%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 61.41%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 61.33%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 68.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1eeb5e37:\n",
      "        Fold accuracies: ['68.05%', '56.09%', '61.33%', '61.41%', '50.86%']\n",
      "        Average fitness: 59.55% Â± 5.77%\n",
      "        Best fold: Fold 1 with 68.05%\n",
      "      Fitness obtained: 59.55% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: bbba5e2f)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bbba5e2f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6933, acc=54.77% (best=54.77%)\n",
      "          Fold 1 Epoch 1: loss=0.7028, acc=49.53% (best=49.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6762, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 1: loss=0.6930, acc=44.06% (best=44.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7179, acc=62.42% (best=62.42%)\n",
      "          Fold 3 Epoch 5: loss=0.3741, acc=49.61% (best=57.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4297, acc=49.77% (best=52.34%)\n",
      "          Fold 4 Epoch 5: loss=0.3840, acc=46.33% (best=59.69%)\n",
      "          Fold 5 Epoch 5: loss=0.3734, acc=56.25% (best=62.42%)\n",
      "          Fold 2 Epoch 5: loss=0.4115, acc=45.55% (best=59.14%)\n",
      "          Fold 3 Epoch 10: loss=0.3028, acc=52.03% (best=57.81%)\n",
      "          Fold 1 Epoch 10: loss=0.3197, acc=47.03% (best=56.80%)\n",
      "          Fold 4 Epoch 10: loss=0.2954, acc=57.34% (best=64.61%)\n",
      "          Fold 5 Epoch 10: loss=0.2917, acc=53.12% (best=62.42%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.42%\n",
      "          Fold 2 Epoch 10: loss=0.3049, acc=68.44% (best=68.44%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 57.81%\n",
      "          Fold 1 Epoch 15: loss=0.2847, acc=50.16% (best=66.02%)\n",
      "          Fold 4 Epoch 15: loss=0.2675, acc=52.58% (best=68.12%)\n",
      "          Fold 2 Epoch 15: loss=0.2724, acc=58.28% (best=68.44%)\n",
      "          Fold 1 Epoch 20: loss=0.2602, acc=50.78% (best=66.02%)\n",
      "          Fold 4 Epoch 20: loss=0.2364, acc=50.70% (best=68.12%)\n",
      "          Fold 2 Epoch 20: loss=0.2489, acc=65.08% (best=71.41%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 66.02%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 68.12%\n",
      "          Fold 2 Epoch 25: loss=0.2383, acc=58.91% (best=71.41%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 71.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bbba5e2f:\n",
      "        Fold accuracies: ['66.02%', '71.41%', '57.81%', '68.12%', '62.42%']\n",
      "        Average fitness: 65.16% Â± 4.69%\n",
      "        Best fold: Fold 2 with 71.41%\n",
      "      Fitness obtained: 65.16% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 15375bd5)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 15375bd5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6853, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 1: loss=0.6927, acc=44.22% (best=44.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7096, acc=45.62% (best=45.62%)\n",
      "          Fold 1 Epoch 1: loss=0.7012, acc=55.39% (best=55.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6707, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 5: loss=0.4046, acc=59.53% (best=59.53%)\n",
      "          Fold 3 Epoch 5: loss=0.4016, acc=51.02% (best=52.03%)\n",
      "          Fold 5 Epoch 5: loss=0.5514, acc=49.45% (best=51.56%)\n",
      "          Fold 1 Epoch 5: loss=0.6464, acc=40.08% (best=65.16%)\n",
      "          Fold 4 Epoch 5: loss=0.4488, acc=57.19% (best=57.19%)\n",
      "          Fold 2 Epoch 10: loss=0.3034, acc=53.52% (best=59.53%)\n",
      "          Fold 3 Epoch 10: loss=0.3351, acc=52.19% (best=54.14%)\n",
      "          Fold 5 Epoch 10: loss=0.3388, acc=49.06% (best=51.56%)\n",
      "          Fold 1 Epoch 10: loss=0.3148, acc=46.72% (best=65.16%)\n",
      "          Fold 4 Epoch 10: loss=0.3321, acc=70.08% (best=70.08%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 65.16%\n",
      "          Fold 2 Epoch 15: loss=0.2613, acc=58.83% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.53%\n",
      "          Fold 3 Epoch 15: loss=0.2916, acc=52.34% (best=54.14%)\n",
      "          Fold 5 Epoch 15: loss=0.2810, acc=45.47% (best=59.61%)\n",
      "          Fold 4 Epoch 15: loss=0.2911, acc=56.64% (best=70.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2807, acc=55.55% (best=55.86%)\n",
      "          Fold 5 Epoch 20: loss=0.2552, acc=45.16% (best=59.61%)\n",
      "          Fold 4 Epoch 20: loss=0.2625, acc=58.52% (best=70.78%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 59.61%\n",
      "          Fold 3 Epoch 25: loss=0.2678, acc=54.69% (best=55.86%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 55.86%\n",
      "          Fold 4 Epoch 25: loss=0.2419, acc=59.14% (best=70.78%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 70.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15375bd5:\n",
      "        Fold accuracies: ['65.16%', '59.53%', '55.86%', '70.78%', '59.61%']\n",
      "        Average fitness: 62.19% Â± 5.22%\n",
      "        Best fold: Fold 4 with 70.78%\n",
      "      Fitness obtained: 62.19% | Best in generation: 66.36% | Global best: 69.44%\n",
      "\n",
      "GENERATION 13 STATISTICS:\n",
      "   Maximum fitness: 66.36%\n",
      "   Average fitness: 55.87%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 18.81%\n",
      "   Best individual: 6182ad6c with 66.36%\n",
      "   Global best individual: 1b39d73a with 69.44%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 6/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=18.81)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 6182ad6c (fitness: 66.36%)\n",
      "   Elite 2: d43d4e67 (fitness: 66.30%)\n",
      "   Elite 3: 0bba893b (fitness: 66.09%)\n",
      "   Elite 4: d4ac3307 (fitness: 65.36%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 7/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 14\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 14)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 6182ad6c)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model 6182ad6c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.9143, acc=52.50% (best=52.50%)\n",
      "          Fold 1 Epoch 1: loss=0.8534, acc=46.88% (best=46.88%)\n",
      "          Fold 5 Epoch 1: loss=0.8646, acc=41.80% (best=41.80%)\n",
      "          Fold 4 Epoch 1: loss=0.8974, acc=48.12% (best=48.12%)\n",
      "          Fold 2 Epoch 1: loss=0.8355, acc=50.62% (best=50.62%)\n",
      "          Fold 3 Epoch 5: loss=0.5145, acc=57.19% (best=57.19%)\n",
      "          Fold 1 Epoch 5: loss=0.5291, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 5: loss=0.5005, acc=44.14% (best=54.92%)\n",
      "          Fold 2 Epoch 5: loss=0.5494, acc=50.39% (best=57.11%)\n",
      "          Fold 4 Epoch 5: loss=0.4715, acc=36.56% (best=50.23%)\n",
      "          Fold 3 Epoch 10: loss=0.3506, acc=59.14% (best=62.34%)\n",
      "          Fold 1 Epoch 10: loss=0.3433, acc=60.70% (best=70.55%)\n",
      "          Fold 5 Epoch 10: loss=0.3067, acc=54.45% (best=54.92%)\n",
      "          Fold 2 Epoch 10: loss=0.3568, acc=42.89% (best=57.11%)\n",
      "          Fold 4 Epoch 10: loss=0.2937, acc=52.97% (best=54.77%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 57.11%\n",
      "          Fold 3 Epoch 15: loss=0.2787, acc=52.19% (best=67.11%)\n",
      "          Fold 1 Epoch 15: loss=0.2917, acc=52.42% (best=70.55%)\n",
      "          Fold 4 Epoch 15: loss=0.2515, acc=46.09% (best=54.77%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 70.55%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 54.77%\n",
      "          Fold 3 Epoch 20: loss=0.2534, acc=55.08% (best=67.11%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 67.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6182ad6c:\n",
      "        Fold accuracies: ['70.55%', '57.11%', '67.11%', '54.77%', '54.92%']\n",
      "        Average fitness: 60.89% Â± 6.62%\n",
      "        Best fold: Fold 1 with 70.55%\n",
      "      New best fitness in this generation: 60.89%!\n",
      "      Fitness obtained: 60.89% | Best in generation: 60.89% | Global best: 69.44%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: d43d4e67)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d43d4e67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7147, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7077, acc=57.11% (best=57.11%)\n",
      "          Fold 3 Epoch 1: loss=0.7319, acc=64.84% (best=64.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6812, acc=53.59% (best=53.59%)\n",
      "          Fold 5 Epoch 1: loss=0.7268, acc=54.38% (best=54.38%)\n",
      "          Fold 1 Epoch 5: loss=0.4734, acc=55.70% (best=55.70%)\n",
      "          Fold 3 Epoch 5: loss=0.3823, acc=72.97% (best=72.97%)\n",
      "          Fold 2 Epoch 5: loss=0.4388, acc=57.11% (best=61.09%)\n",
      "          Fold 5 Epoch 5: loss=0.4275, acc=41.41% (best=54.38%)\n",
      "          Fold 4 Epoch 5: loss=0.3746, acc=50.31% (best=63.44%)\n",
      "          Fold 1 Epoch 10: loss=0.3365, acc=56.72% (best=58.20%)\n",
      "          Fold 3 Epoch 10: loss=0.2942, acc=68.98% (best=72.97%)\n",
      "          Fold 2 Epoch 10: loss=0.3161, acc=50.47% (best=61.09%)\n",
      "          Fold 5 Epoch 10: loss=0.3263, acc=55.47% (best=55.94%)\n",
      "          Fold 4 Epoch 10: loss=0.2789, acc=48.91% (best=66.72%)\n",
      "          Fold 1 Epoch 15: loss=0.2991, acc=76.41% (best=76.41%)\n",
      "          Fold 3 Epoch 15: loss=0.2692, acc=62.81% (best=72.97%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 72.97%\n",
      "          Fold 2 Epoch 15: loss=0.2751, acc=42.11% (best=62.97%)\n",
      "          Fold 5 Epoch 15: loss=0.2928, acc=55.16% (best=56.80%)\n",
      "          Fold 4 Epoch 15: loss=0.2551, acc=50.08% (best=66.72%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 66.72%\n",
      "          Fold 1 Epoch 20: loss=0.2726, acc=64.77% (best=76.41%)\n",
      "          Fold 2 Epoch 20: loss=0.2566, acc=52.11% (best=64.06%)\n",
      "          Fold 5 Epoch 20: loss=0.2656, acc=55.08% (best=56.80%)\n",
      "          Fold 1 Epoch 25: loss=0.2569, acc=67.34% (best=76.41%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 76.41%\n",
      "          Fold 2 Epoch 25: loss=0.2533, acc=67.27% (best=70.31%)\n",
      "          Fold 5 Epoch 25: loss=0.2488, acc=53.20% (best=60.47%)\n",
      "          Fold 2 Epoch 30: loss=0.2425, acc=64.22% (best=70.31%)\n",
      "          Fold 5 Epoch 30: loss=0.2431, acc=50.00% (best=60.47%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 60.47%\n",
      "          Fold 2 Epoch 35: loss=0.2321, acc=57.81% (best=70.94%)\n",
      "          Fold 2 Epoch 40: loss=0.2231, acc=64.30% (best=70.94%)\n",
      "          Fold 2: Early stopping at epoch 43\n",
      "      â†’ Fold 2 completed: 70.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d43d4e67:\n",
      "        Fold accuracies: ['76.41%', '70.94%', '72.97%', '66.72%', '60.47%']\n",
      "        Average fitness: 69.50% Â± 5.50%\n",
      "        Best fold: Fold 1 with 76.41%\n",
      "      New best fitness in this generation: 69.50%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 69.50% > 69.44%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen10_id1b39d73a_fitness69.44.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen14_idd43d4e67_fitness69.50.pth\n",
      "        Fitness: 69.50%, ID: d43d4e67, Gen: 14\n",
      "      Fitness obtained: 69.50% | Best in generation: 69.50% | Global best: 69.50%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 0bba893b)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 0bba893b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6992, acc=43.98% (best=43.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7127, acc=51.17% (best=51.17%)\n",
      "          Fold 4 Epoch 1: loss=0.6938, acc=65.47% (best=65.47%)\n",
      "          Fold 1 Epoch 1: loss=0.7026, acc=59.06% (best=59.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7087, acc=45.31% (best=45.31%)\n",
      "          Fold 2 Epoch 5: loss=0.4268, acc=40.78% (best=47.27%)\n",
      "          Fold 5 Epoch 5: loss=0.5456, acc=50.55% (best=61.41%)\n",
      "          Fold 4 Epoch 5: loss=0.4811, acc=66.56% (best=67.58%)\n",
      "          Fold 1 Epoch 5: loss=0.5855, acc=55.78% (best=59.06%)\n",
      "          Fold 3 Epoch 5: loss=0.4722, acc=56.72% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2957, acc=48.83% (best=55.08%)\n",
      "          Fold 5 Epoch 10: loss=0.3448, acc=43.52% (best=61.41%)\n",
      "          Fold 4 Epoch 10: loss=0.2874, acc=47.42% (best=69.77%)\n",
      "          Fold 1 Epoch 10: loss=0.3865, acc=62.81% (best=62.81%)\n",
      "          Fold 3 Epoch 10: loss=0.3152, acc=59.69% (best=65.62%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.41%\n",
      "          Fold 2 Epoch 15: loss=0.2623, acc=51.72% (best=63.28%)\n",
      "          Fold 4 Epoch 15: loss=0.2454, acc=59.61% (best=69.77%)\n",
      "          Fold 1 Epoch 15: loss=0.2921, acc=62.34% (best=63.59%)\n",
      "          Fold 3 Epoch 15: loss=0.2703, acc=69.14% (best=69.14%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 69.77%\n",
      "          Fold 2 Epoch 20: loss=0.2393, acc=51.88% (best=63.28%)\n",
      "          Fold 1 Epoch 20: loss=0.2590, acc=63.36% (best=63.59%)\n",
      "          Fold 3 Epoch 20: loss=0.2472, acc=62.97% (best=69.14%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 63.28%\n",
      "          Fold 1 Epoch 25: loss=0.2450, acc=58.44% (best=65.00%)\n",
      "          Fold 3 Epoch 25: loss=0.2336, acc=62.81% (best=69.14%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 69.14%\n",
      "          Fold 1 Epoch 30: loss=0.2319, acc=59.84% (best=73.67%)\n",
      "          Fold 1 Epoch 35: loss=0.2223, acc=43.67% (best=73.67%)\n",
      "          Fold 1: Early stopping at epoch 39\n",
      "      â†’ Fold 1 completed: 73.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0bba893b:\n",
      "        Fold accuracies: ['73.67%', '63.28%', '69.14%', '69.77%', '61.41%']\n",
      "        Average fitness: 67.45% Â± 4.49%\n",
      "        Best fold: Fold 1 with 73.67%\n",
      "      Fitness obtained: 67.45% | Best in generation: 69.50% | Global best: 69.50%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: d4ac3307)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d4ac3307 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6583, acc=48.20% (best=48.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6599, acc=63.83% (best=63.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7000, acc=53.36% (best=53.36%)\n",
      "          Fold 1 Epoch 1: loss=0.6794, acc=59.77% (best=59.77%)\n",
      "          Fold 3 Epoch 1: loss=0.6492, acc=59.53% (best=59.53%)\n",
      "          Fold 2 Epoch 5: loss=0.3480, acc=52.81% (best=62.66%)\n",
      "          Fold 4 Epoch 5: loss=0.3238, acc=54.92% (best=64.61%)\n",
      "          Fold 5 Epoch 5: loss=0.3704, acc=40.16% (best=56.88%)\n",
      "          Fold 1 Epoch 5: loss=0.3685, acc=66.48% (best=66.48%)\n",
      "          Fold 3 Epoch 5: loss=0.3762, acc=49.84% (best=59.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2980, acc=52.27% (best=69.61%)\n",
      "          Fold 4 Epoch 10: loss=0.2664, acc=53.67% (best=64.61%)\n",
      "          Fold 5 Epoch 10: loss=0.3048, acc=56.64% (best=56.88%)\n",
      "          Fold 1 Epoch 10: loss=0.2962, acc=58.28% (best=66.48%)\n",
      "          Fold 3 Epoch 10: loss=0.3023, acc=52.34% (best=59.53%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 59.53%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 64.61%\n",
      "          Fold 2 Epoch 15: loss=0.2685, acc=55.00% (best=69.61%)\n",
      "          Fold 1 Epoch 15: loss=0.2603, acc=51.09% (best=66.48%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 66.48%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 69.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d4ac3307:\n",
      "        Fold accuracies: ['66.48%', '69.61%', '59.53%', '64.61%', '56.88%']\n",
      "        Average fitness: 63.42% Â± 4.63%\n",
      "        Best fold: Fold 2 with 69.61%\n",
      "      Fitness obtained: 63.42% | Best in generation: 69.50% | Global best: 69.50%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 2121b7ef)\n",
      "      Architecture: 2 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 2121b7ef with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5283, acc=46.33% (best=46.33%)\n",
      "          Fold 3 Epoch 1: loss=0.5257, acc=46.09% (best=46.09%)\n",
      "          Fold 4 Epoch 1: loss=0.5280, acc=55.86% (best=55.86%)\n",
      "          Fold 1 Epoch 1: loss=0.5277, acc=40.31% (best=40.31%)\n",
      "          Fold 5 Epoch 1: loss=0.5203, acc=60.55% (best=60.55%)\n",
      "          Fold 2 Epoch 5: loss=0.2460, acc=55.94% (best=55.94%)\n",
      "          Fold 3 Epoch 5: loss=0.2472, acc=44.38% (best=54.06%)\n",
      "          Fold 4 Epoch 5: loss=0.2330, acc=44.06% (best=55.86%)\n",
      "          Fold 1 Epoch 5: loss=0.2427, acc=43.67% (best=53.28%)\n",
      "          Fold 5 Epoch 5: loss=0.2434, acc=54.06% (best=60.55%)\n",
      "          Fold 2 Epoch 10: loss=0.2166, acc=58.91% (best=58.91%)\n",
      "          Fold 3 Epoch 10: loss=0.2238, acc=47.58% (best=54.06%)\n",
      "          Fold 4 Epoch 10: loss=0.2072, acc=47.73% (best=55.86%)\n",
      "          Fold 1 Epoch 10: loss=0.2122, acc=54.14% (best=54.14%)\n",
      "          Fold 5 Epoch 10: loss=0.2191, acc=57.27% (best=60.55%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 55.86%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 54.06%\n",
      "          Fold 2 Epoch 15: loss=0.2090, acc=55.86% (best=59.14%)\n",
      "          Fold 1 Epoch 15: loss=0.2040, acc=51.02% (best=56.72%)\n",
      "          Fold 2 Epoch 20: loss=0.2012, acc=56.56% (best=59.14%)\n",
      "          Fold 1 Epoch 20: loss=0.1985, acc=48.36% (best=56.72%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 56.72%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 59.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2121b7ef:\n",
      "        Fold accuracies: ['56.72%', '59.14%', '54.06%', '55.86%', '60.55%']\n",
      "        Average fitness: 57.27% Â± 2.32%\n",
      "        Best fold: Fold 5 with 60.55%\n",
      "      Fitness obtained: 57.27% | Best in generation: 69.50% | Global best: 69.50%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: bff27bda)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model bff27bda with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=1.6227, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=1.8245, acc=63.52% (best=63.52%)\n",
      "          Fold 5 Epoch 1: loss=1.7262, acc=40.70% (best=40.70%)\n",
      "          Fold 1 Epoch 1: loss=1.8566, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 1: loss=1.2959, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.5915, acc=50.39% (best=58.83%)\n",
      "          Fold 4 Epoch 5: loss=0.6722, acc=50.78% (best=63.52%)\n",
      "          Fold 5 Epoch 5: loss=0.5799, acc=47.97% (best=50.31%)\n",
      "          Fold 1 Epoch 5: loss=0.6321, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 5: loss=0.7068, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 10: loss=0.3847, acc=44.53% (best=68.12%)\n",
      "          Fold 4 Epoch 10: loss=0.6776, acc=63.67% (best=63.67%)\n",
      "          Fold 5 Epoch 10: loss=0.3658, acc=55.78% (best=55.78%)\n",
      "          Fold 1 Epoch 10: loss=0.7090, acc=45.86% (best=62.11%)\n",
      "          Fold 3 Epoch 10: loss=0.6984, acc=51.02% (best=54.14%)\n",
      "          Fold 2 Epoch 15: loss=0.3369, acc=46.33% (best=68.12%)\n",
      "          Fold 4 Epoch 15: loss=0.6423, acc=50.78% (best=69.69%)\n",
      "          Fold 5 Epoch 15: loss=0.3211, acc=48.75% (best=55.78%)\n",
      "          Fold 1 Epoch 15: loss=0.7374, acc=50.23% (best=62.11%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 68.12%\n",
      "          Fold 3 Epoch 15: loss=0.6957, acc=48.98% (best=54.14%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 54.14%\n",
      "          Fold 4 Epoch 20: loss=0.5681, acc=50.94% (best=69.69%)\n",
      "          Fold 5 Epoch 20: loss=0.3126, acc=56.80% (best=59.92%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 69.69%\n",
      "          Fold 5 Epoch 25: loss=0.2818, acc=55.39% (best=61.41%)\n",
      "          Fold 5 Epoch 30: loss=0.2845, acc=48.67% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 33\n",
      "      â†’ Fold 5 completed: 61.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bff27bda:\n",
      "        Fold accuracies: ['62.11%', '68.12%', '54.14%', '69.69%', '61.41%']\n",
      "        Average fitness: 63.09% Â± 5.53%\n",
      "        Best fold: Fold 4 with 69.69%\n",
      "      Fitness obtained: 63.09% | Best in generation: 69.50% | Global best: 69.50%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 7cf1d714)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7cf1d714 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6977, acc=47.11% (best=47.11%)\n",
      "          Fold 4 Epoch 1: loss=0.6841, acc=73.12% (best=73.12%)\n",
      "          Fold 3 Epoch 1: loss=0.7068, acc=53.36% (best=53.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7024, acc=43.05% (best=43.05%)\n",
      "          Fold 5 Epoch 1: loss=0.7171, acc=43.91% (best=43.91%)\n",
      "          Fold 2 Epoch 5: loss=0.3528, acc=38.05% (best=49.45%)\n",
      "          Fold 4 Epoch 5: loss=0.3740, acc=51.25% (best=73.12%)\n",
      "          Fold 3 Epoch 5: loss=0.3803, acc=55.47% (best=57.66%)\n",
      "          Fold 1 Epoch 5: loss=0.4272, acc=56.09% (best=64.69%)\n",
      "          Fold 5 Epoch 5: loss=0.5319, acc=44.61% (best=54.69%)\n",
      "          Fold 2 Epoch 10: loss=0.2769, acc=51.02% (best=56.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2658, acc=62.34% (best=73.12%)\n",
      "          Fold 3 Epoch 10: loss=0.2954, acc=57.58% (best=66.09%)\n",
      "          Fold 1 Epoch 10: loss=0.3109, acc=70.00% (best=70.00%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 5 Epoch 10: loss=0.2920, acc=54.45% (best=57.11%)\n",
      "          Fold 2 Epoch 15: loss=0.2401, acc=52.73% (best=58.59%)\n",
      "          Fold 3 Epoch 15: loss=0.2616, acc=57.03% (best=66.09%)\n",
      "          Fold 1 Epoch 15: loss=0.2702, acc=67.66% (best=70.00%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 66.09%\n",
      "          Fold 5 Epoch 15: loss=0.2580, acc=49.61% (best=62.03%)\n",
      "          Fold 2 Epoch 20: loss=0.2324, acc=57.34% (best=58.59%)\n",
      "          Fold 1 Epoch 20: loss=0.2456, acc=69.69% (best=71.95%)\n",
      "          Fold 5 Epoch 20: loss=0.2401, acc=50.31% (best=62.03%)\n",
      "          Fold 2 Epoch 25: loss=0.2283, acc=60.00% (best=75.39%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 1 Epoch 25: loss=0.2324, acc=69.69% (best=73.20%)\n",
      "          Fold 2 Epoch 30: loss=0.2204, acc=58.20% (best=75.39%)\n",
      "          Fold 1 Epoch 30: loss=0.2270, acc=65.78% (best=77.97%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 75.39%\n",
      "          Fold 1 Epoch 35: loss=0.2212, acc=62.11% (best=77.97%)\n",
      "          Fold 1: Early stopping at epoch 38\n",
      "      â†’ Fold 1 completed: 77.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7cf1d714:\n",
      "        Fold accuracies: ['77.97%', '75.39%', '66.09%', '73.12%', '62.03%']\n",
      "        Average fitness: 70.92% Â± 5.95%\n",
      "        Best fold: Fold 1 with 77.97%\n",
      "      New best fitness in this generation: 70.92%!\n",
      "      ðŸŒŸ NEW GLOBAL BEST! 70.92% > 69.50%\n",
      "      âœ“ Checkpoint anterior eliminado: checkpoints/best_model_gen14_idd43d4e67_fitness69.50.pth\n",
      "      âœ“ Nuevo checkpoint guardado: checkpoints/best_model_gen14_id7cf1d714_fitness70.92.pth\n",
      "        Fitness: 70.92%, ID: 7cf1d714, Gen: 14\n",
      "      Fitness obtained: 70.92% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: f9f4ba22)\n",
      "      Architecture: 12 conv + 5 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model f9f4ba22 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7066, acc=55.55% (best=55.55%)\n",
      "          Fold 3 Epoch 1: loss=0.7261, acc=58.44% (best=58.44%)\n",
      "          Fold 4 Epoch 1: loss=0.7011, acc=48.98% (best=48.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7265, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.4177, acc=43.75% (best=55.55%)\n",
      "          Fold 3 Epoch 5: loss=0.4381, acc=52.27% (best=58.44%)\n",
      "          Fold 4 Epoch 5: loss=0.5092, acc=48.98% (best=59.92%)\n",
      "          Fold 5 Epoch 5: loss=0.5996, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 10: loss=0.3112, acc=54.38% (best=55.55%)\n",
      "          Fold 3 Epoch 10: loss=0.3437, acc=50.31% (best=58.44%)\n",
      "          Fold 4 Epoch 10: loss=0.3731, acc=54.45% (best=59.92%)\n",
      "          Fold 5 Epoch 10: loss=0.3217, acc=52.73% (best=56.88%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 58.44%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 59.92%\n",
      "          Fold 2 Epoch 15: loss=0.2864, acc=56.09% (best=56.48%)\n",
      "          Fold 5 Epoch 15: loss=0.2761, acc=40.55% (best=56.88%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 2 Epoch 20: loss=0.2612, acc=53.52% (best=63.05%)\n",
      "          Fold 2 Epoch 25: loss=0.2600, acc=55.39% (best=63.52%)\n",
      "          Fold 2 Epoch 30: loss=0.2472, acc=51.95% (best=70.23%)\n",
      "          Fold 2 Epoch 35: loss=0.2457, acc=56.80% (best=70.23%)\n",
      "          Fold 2: Early stopping at epoch 39\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f9f4ba22:\n",
      "        Fold accuracies: ['0.00%', '70.23%', '58.44%', '59.92%', '56.88%']\n",
      "        Average fitness: 49.09% Â± 24.99%\n",
      "        Best fold: Fold 2 with 70.23%\n",
      "      Fitness obtained: 49.09% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: b291bef6)\n",
      "      Architecture: 10 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b291bef6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6718, acc=44.30% (best=44.30%)\n",
      "          Fold 2 Epoch 1: loss=0.6621, acc=54.14% (best=54.14%)\n",
      "          Fold 1 Epoch 1: loss=0.6960, acc=53.44% (best=53.44%)\n",
      "          Fold 5 Epoch 1: loss=0.6523, acc=41.80% (best=41.80%)\n",
      "          Fold 4 Epoch 1: loss=0.6682, acc=56.25% (best=56.25%)\n",
      "          Fold 3 Epoch 5: loss=0.3547, acc=46.48% (best=62.58%)\n",
      "          Fold 5 Epoch 5: loss=0.3353, acc=52.97% (best=52.97%)\n",
      "          Fold 1 Epoch 5: loss=0.3384, acc=46.33% (best=54.06%)\n",
      "          Fold 2 Epoch 5: loss=0.3472, acc=46.64% (best=54.14%)\n",
      "          Fold 4 Epoch 5: loss=0.3513, acc=54.06% (best=56.64%)\n",
      "          Fold 3 Epoch 10: loss=0.2854, acc=47.50% (best=62.58%)\n",
      "          Fold 1 Epoch 10: loss=0.2705, acc=48.28% (best=54.06%)\n",
      "          Fold 5 Epoch 10: loss=0.2735, acc=46.64% (best=55.62%)\n",
      "          Fold 2 Epoch 10: loss=0.2826, acc=37.89% (best=56.64%)\n",
      "          Fold 4 Epoch 10: loss=0.2826, acc=51.25% (best=58.20%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "          Fold 1 Epoch 15: loss=0.2495, acc=47.50% (best=60.23%)\n",
      "          Fold 5 Epoch 15: loss=0.2445, acc=50.16% (best=56.72%)\n",
      "          Fold 2 Epoch 15: loss=0.2613, acc=48.36% (best=57.58%)\n",
      "          Fold 4 Epoch 15: loss=0.2515, acc=59.92% (best=59.92%)\n",
      "          Fold 1 Epoch 20: loss=0.2309, acc=53.75% (best=60.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2375, acc=44.14% (best=57.58%)\n",
      "          Fold 5 Epoch 20: loss=0.2404, acc=49.06% (best=56.72%)\n",
      "          Fold 4 Epoch 20: loss=0.2339, acc=53.44% (best=60.31%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 57.58%\n",
      "          Fold 1 Epoch 25: loss=0.2210, acc=45.39% (best=60.31%)\n",
      "          Fold 4 Epoch 25: loss=0.2217, acc=56.95% (best=60.31%)\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 60.31%\n",
      "          Fold 1 Epoch 30: loss=0.2170, acc=47.34% (best=60.31%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 60.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b291bef6:\n",
      "        Fold accuracies: ['60.31%', '57.58%', '62.58%', '60.31%', '56.72%']\n",
      "        Average fitness: 59.50% Â± 2.11%\n",
      "        Best fold: Fold 3 with 62.58%\n",
      "      Fitness obtained: 59.50% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: be5ff8de)\n",
      "      Architecture: 12 conv + 8 fc, opt=sgd, lr=0.01\n",
      "      Training/Evaluating model be5ff8de with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7162, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7160, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 1: loss=0.7191, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 1: loss=0.7152, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 1: loss=0.7131, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 5: loss=0.7023, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 5: loss=0.7027, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 5: loss=0.6480, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6903, acc=49.77% (best=50.23%)\n",
      "          Fold 2 Epoch 5: loss=0.6605, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 10: loss=0.6829, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 10: loss=0.7008, acc=50.00% (best=57.34%)\n",
      "          Fold 4 Epoch 10: loss=0.5008, acc=50.78% (best=50.78%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 50.78%\n",
      "          Fold 1 Epoch 10: loss=0.5985, acc=49.77% (best=50.23%)\n",
      "          Fold 2 Epoch 10: loss=0.5586, acc=49.61% (best=49.61%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.23%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.61%\n",
      "          Fold 5 Epoch 15: loss=0.7002, acc=50.00% (best=57.34%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 57.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for be5ff8de:\n",
      "        Fold accuracies: ['50.23%', '49.61%', '51.02%', '50.78%', '57.34%']\n",
      "        Average fitness: 51.80% Â± 2.82%\n",
      "        Best fold: Fold 5 with 57.34%\n",
      "      Fitness obtained: 51.80% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: bd9a5b89)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model bd9a5b89 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7025, acc=44.06% (best=44.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7120, acc=50.23% (best=50.23%)\n",
      "          Fold 1 Epoch 1: loss=0.7197, acc=59.38% (best=59.38%)\n",
      "          Fold 4 Epoch 1: loss=0.7102, acc=55.23% (best=55.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7132, acc=47.81% (best=47.81%)\n",
      "          Fold 3 Epoch 5: loss=0.6540, acc=50.94% (best=55.00%)\n",
      "          Fold 5 Epoch 5: loss=0.6802, acc=46.88% (best=52.27%)\n",
      "          Fold 1 Epoch 5: loss=0.6831, acc=47.19% (best=62.34%)\n",
      "          Fold 4 Epoch 5: loss=0.6343, acc=44.14% (best=55.23%)\n",
      "          Fold 2 Epoch 5: loss=0.6512, acc=44.22% (best=48.98%)\n",
      "          Fold 3 Epoch 10: loss=0.4238, acc=61.33% (best=61.33%)\n",
      "          Fold 5 Epoch 10: loss=0.4499, acc=41.72% (best=54.06%)\n",
      "          Fold 1 Epoch 10: loss=0.4679, acc=44.84% (best=62.34%)\n",
      "          Fold 4 Epoch 10: loss=0.3979, acc=60.86% (best=60.86%)\n",
      "          Fold 2 Epoch 10: loss=0.4680, acc=50.55% (best=53.98%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 62.34%\n",
      "          Fold 3 Epoch 15: loss=0.3492, acc=57.58% (best=61.33%)\n",
      "          Fold 5 Epoch 15: loss=0.3491, acc=46.17% (best=54.06%)\n",
      "          Fold 4 Epoch 15: loss=0.3344, acc=55.00% (best=60.86%)\n",
      "          Fold 2 Epoch 15: loss=0.3541, acc=49.61% (best=53.98%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 54.06%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 53.98%\n",
      "          Fold 3 Epoch 20: loss=0.3069, acc=50.78% (best=61.33%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 61.33%\n",
      "          Fold 4 Epoch 20: loss=0.3025, acc=57.03% (best=60.86%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 60.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd9a5b89:\n",
      "        Fold accuracies: ['62.34%', '53.98%', '61.33%', '60.86%', '54.06%']\n",
      "        Average fitness: 58.52% Â± 3.70%\n",
      "        Best fold: Fold 1 with 62.34%\n",
      "      Fitness obtained: 58.52% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: e543e801)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model e543e801 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7125, acc=47.03% (best=47.03%)\n",
      "          Fold 1 Epoch 1: loss=0.7069, acc=61.48% (best=61.48%)\n",
      "          Fold 2 Epoch 1: loss=0.7049, acc=54.14% (best=54.14%)\n",
      "          Fold 3 Epoch 1: loss=0.7126, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7050, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 5: loss=0.7013, acc=46.33% (best=56.56%)\n",
      "          Fold 1 Epoch 5: loss=0.6684, acc=50.86% (best=61.48%)\n",
      "          Fold 4 Epoch 5: loss=0.6293, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 5: loss=0.6692, acc=61.25% (best=61.25%)\n",
      "          Fold 2 Epoch 5: loss=0.6700, acc=46.64% (best=54.14%)\n",
      "          Fold 5 Epoch 10: loss=0.6159, acc=47.50% (best=60.31%)\n",
      "          Fold 1 Epoch 10: loss=0.4485, acc=56.88% (best=61.48%)\n",
      "          Fold 4 Epoch 10: loss=0.4089, acc=38.75% (best=56.80%)\n",
      "          Fold 3 Epoch 10: loss=0.4288, acc=44.14% (best=61.25%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.48%\n",
      "          Fold 2 Epoch 10: loss=0.5281, acc=46.02% (best=58.12%)\n",
      "          Fold 5 Epoch 15: loss=0.4089, acc=48.20% (best=60.31%)\n",
      "          Fold 4 Epoch 15: loss=0.3258, acc=42.89% (best=56.80%)\n",
      "          Fold 3 Epoch 15: loss=0.3441, acc=51.88% (best=61.25%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 61.25%\n",
      "          Fold 2 Epoch 15: loss=0.3691, acc=52.66% (best=58.12%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "          Fold 4 Epoch 20: loss=0.2920, acc=54.69% (best=59.45%)\n",
      "          Fold 2 Epoch 20: loss=0.3251, acc=50.62% (best=58.36%)\n",
      "          Fold 4 Epoch 25: loss=0.2737, acc=59.69% (best=59.69%)\n",
      "          Fold 2 Epoch 25: loss=0.3003, acc=56.72% (best=62.73%)\n",
      "          Fold 4 Epoch 30: loss=0.2572, acc=60.00% (best=65.86%)\n",
      "          Fold 2 Epoch 30: loss=0.2857, acc=55.78% (best=62.73%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 62.73%\n",
      "          Fold 4 Epoch 35: loss=0.2442, acc=54.45% (best=65.86%)\n",
      "          Fold 4: Early stopping at epoch 39\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e543e801:\n",
      "        Fold accuracies: ['61.48%', '62.73%', '61.25%', '65.86%', '60.31%']\n",
      "        Average fitness: 62.33% Â± 1.93%\n",
      "        Best fold: Fold 4 with 65.86%\n",
      "      Fitness obtained: 62.33% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: c0528496)\n",
      "      Architecture: 10 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model c0528496 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6758, acc=61.17% (best=61.17%)\n",
      "          Fold 3 Epoch 1: loss=0.6899, acc=49.69% (best=49.69%)\n",
      "          Fold 1 Epoch 1: loss=0.6900, acc=43.12% (best=43.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6703, acc=65.47% (best=65.47%)\n",
      "          Fold 5 Epoch 1: loss=0.7123, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 5: loss=0.3894, acc=48.36% (best=61.17%)\n",
      "          Fold 1 Epoch 5: loss=0.4125, acc=64.53% (best=64.53%)\n",
      "          Fold 5 Epoch 5: loss=0.3861, acc=50.94% (best=58.83%)\n",
      "          Fold 4 Epoch 5: loss=0.3747, acc=47.73% (best=73.52%)\n",
      "          Fold 3 Epoch 5: loss=0.4041, acc=55.16% (best=61.25%)\n",
      "          Fold 2 Epoch 10: loss=0.3175, acc=57.42% (best=61.17%)\n",
      "          Fold 1 Epoch 10: loss=0.3243, acc=58.67% (best=64.53%)\n",
      "          Fold 5 Epoch 10: loss=0.2782, acc=44.38% (best=58.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2898, acc=57.50% (best=73.52%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 61.17%\n",
      "          Fold 3 Epoch 10: loss=0.3072, acc=60.70% (best=61.25%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.52%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.83%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 61.25%\n",
      "          Fold 1 Epoch 15: loss=0.2823, acc=58.83% (best=64.53%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c0528496:\n",
      "        Fold accuracies: ['64.53%', '61.17%', '61.25%', '73.52%', '58.83%']\n",
      "        Average fitness: 63.86% Â± 5.16%\n",
      "        Best fold: Fold 4 with 73.52%\n",
      "      Fitness obtained: 63.86% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 963c2baf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 963c2baf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6993, acc=52.27% (best=52.27%)\n",
      "          Fold 3 Epoch 1: loss=0.7096, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6998, acc=58.44% (best=58.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7094, acc=48.36% (best=48.36%)\n",
      "          Fold 1 Epoch 1: loss=0.7038, acc=63.52% (best=63.52%)\n",
      "          Fold 3 Epoch 5: loss=0.6222, acc=52.89% (best=57.66%)\n",
      "          Fold 2 Epoch 5: loss=0.6037, acc=46.48% (best=52.27%)\n",
      "          Fold 5 Epoch 5: loss=0.6101, acc=50.31% (best=57.03%)\n",
      "          Fold 4 Epoch 5: loss=0.5775, acc=46.64% (best=58.44%)\n",
      "          Fold 1 Epoch 5: loss=0.6471, acc=64.53% (best=64.53%)\n",
      "          Fold 3 Epoch 10: loss=0.3882, acc=58.44% (best=65.00%)\n",
      "          Fold 5 Epoch 10: loss=0.3645, acc=45.23% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.4035, acc=58.12% (best=64.61%)\n",
      "          Fold 2 Epoch 10: loss=0.3915, acc=48.52% (best=59.38%)\n",
      "          Fold 1 Epoch 10: loss=0.4188, acc=49.14% (best=64.53%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 57.03%\n",
      "          Fold 3 Epoch 15: loss=0.3283, acc=49.61% (best=65.00%)\n",
      "          Fold 4 Epoch 15: loss=0.3240, acc=64.77% (best=64.84%)\n",
      "          Fold 2 Epoch 15: loss=0.3274, acc=56.56% (best=59.38%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "          Fold 1 Epoch 15: loss=0.3359, acc=52.97% (best=64.53%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 64.53%\n",
      "          Fold 2 Epoch 20: loss=0.3016, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 20: loss=0.2980, acc=53.75% (best=65.23%)\n",
      "          Fold 2 Epoch 25: loss=0.2847, acc=66.09% (best=66.09%)\n",
      "          Fold 4 Epoch 25: loss=0.2669, acc=47.58% (best=65.23%)\n",
      "          Fold 4: Early stopping at epoch 28\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "          Fold 2 Epoch 30: loss=0.2581, acc=62.81% (best=66.72%)\n",
      "          Fold 2 Epoch 35: loss=0.2461, acc=64.84% (best=66.72%)\n",
      "          Fold 2 Epoch 40: loss=0.2367, acc=73.98% (best=75.94%)\n",
      "          Fold 2 Epoch 45: loss=0.2345, acc=64.53% (best=75.94%)\n",
      "          Fold 2: Early stopping at epoch 48\n",
      "      â†’ Fold 2 completed: 75.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 963c2baf:\n",
      "        Fold accuracies: ['64.53%', '75.94%', '65.00%', '65.23%', '57.03%']\n",
      "        Average fitness: 65.55% Â± 6.03%\n",
      "        Best fold: Fold 2 with 75.94%\n",
      "      Fitness obtained: 65.55% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 0e77457f)\n",
      "      Architecture: 12 conv + 4 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model 0e77457f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7110, acc=53.75% (best=53.75%)\n",
      "          Fold 3 Epoch 1: loss=0.7350, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7176, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.7032, acc=60.08% (best=60.08%)\n",
      "          Fold 5 Epoch 1: loss=0.7223, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 5: loss=0.6786, acc=46.80% (best=53.75%)\n",
      "          Fold 3 Epoch 5: loss=0.6997, acc=52.27% (best=52.27%)\n",
      "          Fold 5 Epoch 5: loss=0.7036, acc=43.05% (best=55.00%)\n",
      "          Fold 1 Epoch 5: loss=0.6911, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 5: loss=0.6564, acc=48.28% (best=60.08%)\n",
      "          Fold 2 Epoch 10: loss=0.6483, acc=49.69% (best=53.75%)\n",
      "          Fold 3 Epoch 10: loss=0.6418, acc=49.06% (best=54.77%)\n",
      "          Fold 5 Epoch 10: loss=0.6859, acc=49.53% (best=55.00%)\n",
      "          Fold 1 Epoch 10: loss=0.6665, acc=49.77% (best=55.78%)\n",
      "          Fold 4 Epoch 10: loss=0.6075, acc=58.59% (best=60.08%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.08%\n",
      "          Fold 2 Epoch 15: loss=0.6001, acc=56.17% (best=56.17%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 55.00%\n",
      "          Fold 3 Epoch 15: loss=0.5149, acc=50.08% (best=54.77%)\n",
      "          Fold 1 Epoch 15: loss=0.6299, acc=49.92% (best=55.78%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 55.78%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 54.77%\n",
      "          Fold 2 Epoch 20: loss=0.5010, acc=52.81% (best=61.88%)\n",
      "          Fold 2 Epoch 25: loss=0.4085, acc=48.83% (best=61.88%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 61.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0e77457f:\n",
      "        Fold accuracies: ['55.78%', '61.88%', '54.77%', '60.08%', '55.00%']\n",
      "        Average fitness: 57.50% Â± 2.91%\n",
      "        Best fold: Fold 2 with 61.88%\n",
      "      Fitness obtained: 57.50% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: f7feb287)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model f7feb287 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=1.0144, acc=46.64% (best=46.64%)\n",
      "          Fold 3 Epoch 1: loss=0.9977, acc=62.89% (best=62.89%)\n",
      "          Fold 4 Epoch 1: loss=0.9141, acc=49.14% (best=49.14%)\n",
      "          Fold 1 Epoch 1: loss=1.0232, acc=51.56% (best=51.56%)\n",
      "          Fold 5 Epoch 1: loss=1.0559, acc=56.17% (best=56.17%)\n",
      "          Fold 2 Epoch 5: loss=0.4205, acc=54.38% (best=57.58%)\n",
      "          Fold 3 Epoch 5: loss=0.3832, acc=51.95% (best=62.89%)\n",
      "          Fold 4 Epoch 5: loss=0.4099, acc=42.03% (best=59.61%)\n",
      "          Fold 5 Epoch 5: loss=0.5404, acc=40.62% (best=61.72%)\n",
      "          Fold 1 Epoch 5: loss=0.4508, acc=47.50% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2805, acc=39.69% (best=57.58%)\n",
      "          Fold 3 Epoch 10: loss=0.2815, acc=58.75% (best=64.69%)\n",
      "          Fold 4 Epoch 10: loss=0.2806, acc=48.75% (best=59.61%)\n",
      "          Fold 5 Epoch 10: loss=0.3352, acc=52.81% (best=61.72%)\n",
      "          Fold 1 Epoch 10: loss=0.3125, acc=48.59% (best=65.23%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.72%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 59.61%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 57.58%\n",
      "          Fold 3 Epoch 15: loss=0.2535, acc=46.41% (best=64.69%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f7feb287:\n",
      "        Fold accuracies: ['65.23%', '57.58%', '64.69%', '59.61%', '61.72%']\n",
      "        Average fitness: 61.77% Â± 2.92%\n",
      "        Best fold: Fold 1 with 65.23%\n",
      "      Fitness obtained: 61.77% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: bd819486)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bd819486 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6685, acc=49.53% (best=49.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7049, acc=56.64% (best=56.64%)\n",
      "          Fold 3 Epoch 1: loss=0.6709, acc=57.34% (best=57.34%)\n",
      "          Fold 4 Epoch 1: loss=0.6586, acc=68.83% (best=68.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6826, acc=60.78% (best=60.78%)\n",
      "          Fold 2 Epoch 5: loss=0.3924, acc=56.95% (best=56.95%)\n",
      "          Fold 3 Epoch 5: loss=0.4225, acc=54.06% (best=64.53%)\n",
      "          Fold 5 Epoch 5: loss=0.4457, acc=48.05% (best=56.64%)\n",
      "          Fold 4 Epoch 5: loss=0.4408, acc=46.41% (best=68.83%)\n",
      "          Fold 1 Epoch 5: loss=0.4512, acc=56.02% (best=66.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2872, acc=49.92% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.3472, acc=47.03% (best=64.53%)\n",
      "          Fold 5 Epoch 10: loss=0.2950, acc=41.95% (best=56.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3312, acc=57.81% (best=68.83%)\n",
      "          Fold 1 Epoch 10: loss=0.3061, acc=56.41% (best=66.48%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.64%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 64.53%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 66.48%\n",
      "          Fold 2 Epoch 15: loss=0.2499, acc=60.08% (best=60.08%)\n",
      "          Fold 2 Epoch 20: loss=0.2337, acc=63.44% (best=63.44%)\n",
      "          Fold 2 Epoch 25: loss=0.2227, acc=58.28% (best=63.44%)\n",
      "          Fold 2 Epoch 30: loss=0.2156, acc=54.84% (best=63.91%)\n",
      "          Fold 2 Epoch 35: loss=0.2087, acc=59.06% (best=63.91%)\n",
      "          Fold 2 Epoch 40: loss=0.2062, acc=63.83% (best=64.61%)\n",
      "          Fold 2 Epoch 45: loss=0.2060, acc=68.52% (best=68.52%)\n",
      "          Fold 2 Epoch 50: loss=0.2023, acc=57.81% (best=68.52%)\n",
      "          Fold 2 Epoch 55: loss=0.1996, acc=58.59% (best=68.52%)\n",
      "          Fold 2: Early stopping at epoch 55\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bd819486:\n",
      "        Fold accuracies: ['66.48%', '68.52%', '64.53%', '68.83%', '56.64%']\n",
      "        Average fitness: 65.00% Â± 4.46%\n",
      "        Best fold: Fold 4 with 68.83%\n",
      "      Fitness obtained: 65.00% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 0d939084)\n",
      "      Architecture: 10 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 0d939084 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6791, acc=63.44% (best=63.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7209, acc=59.69% (best=59.69%)\n",
      "          Fold 3 Epoch 1: loss=0.7047, acc=58.75% (best=58.75%)\n",
      "          Fold 2 Epoch 1: loss=0.6957, acc=52.81% (best=52.81%)\n",
      "          Fold 1 Epoch 1: loss=0.7057, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3896, acc=47.73% (best=63.44%)\n",
      "          Fold 3 Epoch 5: loss=0.3667, acc=65.78% (best=67.19%)\n",
      "          Fold 5 Epoch 5: loss=0.3845, acc=51.02% (best=59.69%)\n",
      "          Fold 2 Epoch 5: loss=0.3690, acc=49.30% (best=55.39%)\n",
      "          Fold 1 Epoch 5: loss=0.3676, acc=52.81% (best=57.27%)\n",
      "          Fold 3 Epoch 10: loss=0.3026, acc=56.64% (best=68.75%)\n",
      "          Fold 4 Epoch 10: loss=0.2995, acc=48.59% (best=63.44%)\n",
      "          Fold 5 Epoch 10: loss=0.3060, acc=50.94% (best=59.69%)\n",
      "          Fold 2 Epoch 10: loss=0.3079, acc=52.66% (best=55.39%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.44%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.69%\n",
      "          Fold 1 Epoch 10: loss=0.2874, acc=52.66% (best=61.41%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 55.39%\n",
      "          Fold 3 Epoch 15: loss=0.2781, acc=59.69% (best=68.75%)\n",
      "          Fold 1 Epoch 15: loss=0.2664, acc=58.52% (best=61.95%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 68.75%\n",
      "          Fold 1 Epoch 20: loss=0.2492, acc=52.11% (best=61.95%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 61.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0d939084:\n",
      "        Fold accuracies: ['61.95%', '55.39%', '68.75%', '63.44%', '59.69%']\n",
      "        Average fitness: 61.84% Â± 4.39%\n",
      "        Best fold: Fold 3 with 68.75%\n",
      "      Fitness obtained: 61.84% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: aacc1ff5)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model aacc1ff5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6652, acc=49.45% (best=49.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6515, acc=69.14% (best=69.14%)\n",
      "          Fold 2 Epoch 1: loss=0.6696, acc=45.00% (best=45.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6951, acc=57.58% (best=57.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7078, acc=53.52% (best=53.52%)\n",
      "          Fold 2 Epoch 5: loss=0.3289, acc=42.50% (best=49.92%)\n",
      "          Fold 3 Epoch 5: loss=0.3237, acc=68.12% (best=68.12%)\n",
      "          Fold 4 Epoch 5: loss=0.3794, acc=70.00% (best=70.00%)\n",
      "          Fold 1 Epoch 5: loss=0.3503, acc=51.17% (best=58.67%)\n",
      "          Fold 5 Epoch 5: loss=0.3508, acc=50.55% (best=53.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2662, acc=48.28% (best=57.11%)\n",
      "          Fold 3 Epoch 10: loss=0.2593, acc=70.86% (best=71.41%)\n",
      "          Fold 4 Epoch 10: loss=0.2623, acc=64.45% (best=70.00%)\n",
      "          Fold 1 Epoch 10: loss=0.2719, acc=58.67% (best=63.28%)\n",
      "          Fold 5 Epoch 10: loss=0.2643, acc=43.91% (best=56.56%)\n",
      "          Fold 2 Epoch 15: loss=0.2415, acc=50.78% (best=57.11%)\n",
      "          Fold 3 Epoch 15: loss=0.2363, acc=62.42% (best=71.41%)\n",
      "          Fold 4 Epoch 15: loss=0.2381, acc=49.30% (best=70.00%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 70.00%\n",
      "          Fold 1 Epoch 15: loss=0.2458, acc=67.34% (best=67.34%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 57.11%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 71.41%\n",
      "          Fold 5 Epoch 15: loss=0.2423, acc=51.02% (best=56.56%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "          Fold 1 Epoch 20: loss=0.2263, acc=58.83% (best=67.34%)\n",
      "          Fold 1 Epoch 25: loss=0.2254, acc=62.11% (best=69.22%)\n",
      "          Fold 1 Epoch 30: loss=0.2185, acc=56.09% (best=69.22%)\n",
      "          Fold 1: Early stopping at epoch 31\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for aacc1ff5:\n",
      "        Fold accuracies: ['69.22%', '57.11%', '71.41%', '70.00%', '56.56%']\n",
      "        Average fitness: 64.86% Â± 6.59%\n",
      "        Best fold: Fold 3 with 71.41%\n",
      "      Fitness obtained: 64.86% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 79e6dcbd)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 79e6dcbd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6738, acc=43.52% (best=43.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6671, acc=56.88% (best=56.88%)\n",
      "          Fold 1 Epoch 1: loss=0.6711, acc=59.92% (best=59.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6532, acc=59.53% (best=59.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7027, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 5: loss=0.3646, acc=39.92% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.3641, acc=47.19% (best=60.16%)\n",
      "          Fold 1 Epoch 5: loss=0.4105, acc=64.92% (best=64.92%)\n",
      "          Fold 4 Epoch 5: loss=0.3598, acc=45.70% (best=67.42%)\n",
      "          Fold 3 Epoch 5: loss=0.3449, acc=58.91% (best=59.38%)\n",
      "          Fold 2 Epoch 10: loss=0.2788, acc=47.73% (best=59.30%)\n",
      "          Fold 5 Epoch 10: loss=0.2746, acc=46.88% (best=60.16%)\n",
      "          Fold 1 Epoch 10: loss=0.2976, acc=56.25% (best=66.48%)\n",
      "          Fold 4 Epoch 10: loss=0.2701, acc=48.67% (best=67.42%)\n",
      "          Fold 3 Epoch 10: loss=0.2795, acc=56.64% (best=67.27%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 59.30%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.42%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.16%\n",
      "          Fold 1 Epoch 15: loss=0.2636, acc=59.22% (best=66.56%)\n",
      "          Fold 3 Epoch 15: loss=0.2549, acc=56.72% (best=67.27%)\n",
      "          Fold 1 Epoch 20: loss=0.2466, acc=58.44% (best=70.08%)\n",
      "          Fold 3 Epoch 20: loss=0.2377, acc=59.84% (best=68.59%)\n",
      "          Fold 1 Epoch 25: loss=0.2350, acc=53.52% (best=70.08%)\n",
      "          Fold 3 Epoch 25: loss=0.2295, acc=65.47% (best=68.59%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 68.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 79e6dcbd:\n",
      "        Fold accuracies: ['70.08%', '59.30%', '68.59%', '67.42%', '60.16%']\n",
      "        Average fitness: 65.11% Â± 4.48%\n",
      "        Best fold: Fold 1 with 70.08%\n",
      "      Fitness obtained: 65.11% | Best in generation: 70.92% | Global best: 70.92%\n",
      "\n",
      "New global best individual found!\n",
      "\n",
      "GENERATION 14 STATISTICS:\n",
      "   Maximum fitness: 70.92%\n",
      "   Average fitness: 61.96%\n",
      "   Minimum fitness: 49.09%\n",
      "   Standard deviation: 5.22%\n",
      "   Best individual: 7cf1d714 with 70.92%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "ðŸ”„ Improvement detected: 1.48% | Generations without improvement: 0\n",
      "Adaptive mutation rate updated to 0.2412 (std_fitness=5.22)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 7cf1d714 (fitness: 70.92%)\n",
      "   Elite 2: d43d4e67 (fitness: 69.50%)\n",
      "   Elite 3: 0bba893b (fitness: 67.45%)\n",
      "   Elite 4: 963c2baf (fitness: 65.55%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 1/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 15\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 15)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 7cf1d714)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7cf1d714 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6881, acc=39.45% (best=39.45%)\n",
      "          Fold 1 Epoch 1: loss=0.6998, acc=56.72% (best=56.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6932, acc=60.16% (best=60.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7072, acc=48.91% (best=48.91%)\n",
      "          Fold 5 Epoch 1: loss=0.7167, acc=49.06% (best=49.06%)\n",
      "          Fold 2 Epoch 5: loss=0.3353, acc=46.41% (best=61.56%)\n",
      "          Fold 4 Epoch 5: loss=0.3425, acc=38.98% (best=61.95%)\n",
      "          Fold 1 Epoch 5: loss=0.4335, acc=58.83% (best=60.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3759, acc=55.70% (best=62.66%)\n",
      "          Fold 5 Epoch 5: loss=0.4993, acc=44.53% (best=53.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2646, acc=45.78% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.2727, acc=39.14% (best=63.75%)\n",
      "          Fold 1 Epoch 10: loss=0.3118, acc=46.88% (best=67.11%)\n",
      "          Fold 3 Epoch 10: loss=0.2695, acc=67.50% (best=67.50%)\n",
      "          Fold 5 Epoch 10: loss=0.2998, acc=50.94% (best=53.52%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 61.56%\n",
      "          Fold 4 Epoch 15: loss=0.2493, acc=50.16% (best=63.75%)\n",
      "          Fold 1 Epoch 15: loss=0.2821, acc=56.56% (best=67.11%)\n",
      "          Fold 3 Epoch 15: loss=0.2484, acc=65.00% (best=67.58%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 53.52%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 63.75%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 67.11%\n",
      "          Fold 3 Epoch 20: loss=0.2287, acc=55.31% (best=67.58%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7cf1d714:\n",
      "        Fold accuracies: ['67.11%', '61.56%', '67.58%', '63.75%', '53.52%']\n",
      "        Average fitness: 62.70% Â± 5.10%\n",
      "        Best fold: Fold 3 with 67.58%\n",
      "      New best fitness in this generation: 62.70%!\n",
      "      Fitness obtained: 62.70% | Best in generation: 62.70% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: d43d4e67)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d43d4e67 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7162, acc=47.11% (best=47.11%)\n",
      "          Fold 2 Epoch 1: loss=0.7033, acc=44.45% (best=44.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7194, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 1: loss=0.7162, acc=58.36% (best=58.36%)\n",
      "          Fold 5 Epoch 1: loss=0.7107, acc=54.30% (best=54.30%)\n",
      "          Fold 1 Epoch 5: loss=0.4485, acc=43.36% (best=58.52%)\n",
      "          Fold 2 Epoch 5: loss=0.3789, acc=46.48% (best=59.06%)\n",
      "          Fold 4 Epoch 5: loss=0.4666, acc=64.69% (best=68.44%)\n",
      "          Fold 3 Epoch 5: loss=0.4126, acc=43.67% (best=57.73%)\n",
      "          Fold 5 Epoch 5: loss=0.3987, acc=52.89% (best=55.70%)\n",
      "          Fold 1 Epoch 10: loss=0.3218, acc=51.09% (best=58.52%)\n",
      "          Fold 2 Epoch 10: loss=0.3190, acc=59.92% (best=70.23%)\n",
      "          Fold 4 Epoch 10: loss=0.3250, acc=59.77% (best=68.44%)\n",
      "          Fold 3 Epoch 10: loss=0.3433, acc=53.98% (best=58.36%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 58.52%\n",
      "          Fold 5 Epoch 10: loss=0.3007, acc=53.75% (best=55.70%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.44%\n",
      "          Fold 2 Epoch 15: loss=0.2853, acc=64.69% (best=70.23%)\n",
      "          Fold 3 Epoch 15: loss=0.2882, acc=54.84% (best=60.16%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 70.23%\n",
      "          Fold 5 Epoch 15: loss=0.2679, acc=54.14% (best=56.56%)\n",
      "          Fold 3 Epoch 20: loss=0.2621, acc=56.33% (best=60.16%)\n",
      "          Fold 5 Epoch 20: loss=0.2445, acc=46.25% (best=56.56%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 60.16%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 56.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d43d4e67:\n",
      "        Fold accuracies: ['58.52%', '70.23%', '60.16%', '68.44%', '56.56%']\n",
      "        Average fitness: 62.78% Â± 5.50%\n",
      "        Best fold: Fold 2 with 70.23%\n",
      "      New best fitness in this generation: 62.78%!\n",
      "      Fitness obtained: 62.78% | Best in generation: 62.78% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 0bba893b)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 0bba893b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7036, acc=40.70% (best=40.70%)\n",
      "          Fold 3 Epoch 1: loss=0.7090, acc=54.84% (best=54.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6904, acc=48.28% (best=48.28%)\n",
      "          Fold 1 Epoch 1: loss=0.7082, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7200, acc=47.66% (best=47.66%)\n",
      "          Fold 2 Epoch 5: loss=0.5615, acc=51.95% (best=51.95%)\n",
      "          Fold 3 Epoch 5: loss=0.5215, acc=58.12% (best=59.84%)\n",
      "          Fold 5 Epoch 5: loss=0.7014, acc=48.28% (best=62.03%)\n",
      "          Fold 4 Epoch 5: loss=0.4935, acc=62.34% (best=62.34%)\n",
      "          Fold 1 Epoch 5: loss=0.5724, acc=65.70% (best=65.70%)\n",
      "          Fold 2 Epoch 10: loss=0.3528, acc=44.06% (best=52.42%)\n",
      "          Fold 3 Epoch 10: loss=0.3555, acc=61.25% (best=61.25%)\n",
      "          Fold 5 Epoch 10: loss=0.4508, acc=42.97% (best=62.03%)\n",
      "          Fold 4 Epoch 10: loss=0.3065, acc=63.20% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.3866, acc=45.08% (best=65.70%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 2 Epoch 15: loss=0.2869, acc=53.20% (best=53.28%)\n",
      "          Fold 3 Epoch 15: loss=0.2887, acc=56.80% (best=62.58%)\n",
      "          Fold 4 Epoch 15: loss=0.2622, acc=63.44% (best=63.44%)\n",
      "          Fold 1 Epoch 15: loss=0.3011, acc=55.16% (best=65.70%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 65.70%\n",
      "          Fold 2 Epoch 20: loss=0.2740, acc=55.39% (best=55.39%)\n",
      "          Fold 3 Epoch 20: loss=0.2552, acc=54.30% (best=62.58%)\n",
      "          Fold 4 Epoch 20: loss=0.2308, acc=62.27% (best=63.44%)\n",
      "          Fold 2 Epoch 25: loss=0.2573, acc=47.89% (best=55.39%)\n",
      "          Fold 3 Epoch 25: loss=0.2496, acc=60.70% (best=64.77%)\n",
      "          Fold 4 Epoch 25: loss=0.2293, acc=55.78% (best=63.44%)\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 63.44%\n",
      "          Fold 2 Epoch 30: loss=0.2424, acc=45.23% (best=55.39%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 55.39%\n",
      "          Fold 3 Epoch 30: loss=0.2394, acc=69.53% (best=69.53%)\n",
      "          Fold 3 Epoch 35: loss=0.2309, acc=60.55% (best=69.53%)\n",
      "          Fold 3 Epoch 40: loss=0.2214, acc=51.56% (best=69.53%)\n",
      "          Fold 3: Early stopping at epoch 40\n",
      "      â†’ Fold 3 completed: 69.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0bba893b:\n",
      "        Fold accuracies: ['65.70%', '55.39%', '69.53%', '63.44%', '62.03%']\n",
      "        Average fitness: 63.22% Â± 4.66%\n",
      "        Best fold: Fold 3 with 69.53%\n",
      "      New best fitness in this generation: 63.22%!\n",
      "      Fitness obtained: 63.22% | Best in generation: 63.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 963c2baf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 963c2baf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7056, acc=57.19% (best=57.19%)\n",
      "          Fold 4 Epoch 1: loss=0.7019, acc=66.48% (best=66.48%)\n",
      "          Fold 2 Epoch 1: loss=0.6943, acc=43.98% (best=43.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7105, acc=59.53% (best=59.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7075, acc=65.23% (best=65.23%)\n",
      "          Fold 3 Epoch 5: loss=0.5974, acc=61.17% (best=61.17%)\n",
      "          Fold 5 Epoch 5: loss=0.6477, acc=57.27% (best=59.53%)\n",
      "          Fold 4 Epoch 5: loss=0.6261, acc=50.00% (best=66.48%)\n",
      "          Fold 1 Epoch 5: loss=0.6636, acc=62.73% (best=65.23%)\n",
      "          Fold 2 Epoch 5: loss=0.5985, acc=57.11% (best=60.62%)\n",
      "          Fold 3 Epoch 10: loss=0.3856, acc=55.39% (best=61.17%)\n",
      "          Fold 5 Epoch 10: loss=0.3932, acc=50.00% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.3868, acc=55.62% (best=66.48%)\n",
      "          Fold 1 Epoch 10: loss=0.4315, acc=52.03% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.4138, acc=54.84% (best=60.62%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.48%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 60.62%\n",
      "          Fold 3 Epoch 15: loss=0.3184, acc=55.86% (best=61.17%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 61.17%\n",
      "          Fold 5 Epoch 15: loss=0.3320, acc=51.02% (best=61.64%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 963c2baf:\n",
      "        Fold accuracies: ['65.23%', '60.62%', '61.17%', '66.48%', '61.64%']\n",
      "        Average fitness: 63.03% Â± 2.36%\n",
      "        Best fold: Fold 4 with 66.48%\n",
      "      Fitness obtained: 63.03% | Best in generation: 63.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: af7c9260)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model af7c9260 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6209, acc=51.09% (best=51.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6157, acc=65.31% (best=65.31%)\n",
      "          Fold 1 Epoch 1: loss=0.6857, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 1: loss=0.6176, acc=65.39% (best=65.39%)\n",
      "          Fold 5 Epoch 1: loss=0.6571, acc=47.03% (best=47.03%)\n",
      "          Fold 3 Epoch 5: loss=0.3040, acc=41.02% (best=51.95%)\n",
      "          Fold 4 Epoch 5: loss=0.2714, acc=45.47% (best=65.31%)\n",
      "          Fold 1 Epoch 5: loss=0.3199, acc=57.19% (best=57.19%)\n",
      "          Fold 5 Epoch 5: loss=0.2901, acc=54.06% (best=55.62%)\n",
      "          Fold 2 Epoch 5: loss=0.3018, acc=50.39% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.2504, acc=41.80% (best=58.91%)\n",
      "          Fold 4 Epoch 10: loss=0.2258, acc=43.67% (best=65.31%)\n",
      "          Fold 1 Epoch 10: loss=0.2465, acc=48.59% (best=60.16%)\n",
      "          Fold 5 Epoch 10: loss=0.2439, acc=50.39% (best=64.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2494, acc=43.20% (best=65.39%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.31%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "          Fold 3 Epoch 15: loss=0.2274, acc=53.52% (best=58.91%)\n",
      "          Fold 1 Epoch 15: loss=0.2274, acc=56.17% (best=60.16%)\n",
      "          Fold 5 Epoch 15: loss=0.2259, acc=45.16% (best=64.53%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "          Fold 1 Epoch 20: loss=0.2195, acc=46.56% (best=60.70%)\n",
      "          Fold 1 Epoch 25: loss=0.2099, acc=50.00% (best=60.70%)\n",
      "          Fold 1 Epoch 30: loss=0.2068, acc=54.38% (best=63.91%)\n",
      "          Fold 1 Epoch 35: loss=0.2004, acc=52.42% (best=63.98%)\n",
      "          Fold 1 Epoch 40: loss=0.2017, acc=49.22% (best=63.98%)\n",
      "          Fold 1: Early stopping at epoch 44\n",
      "      â†’ Fold 1 completed: 63.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for af7c9260:\n",
      "        Fold accuracies: ['63.98%', '65.39%', '58.91%', '65.31%', '64.53%']\n",
      "        Average fitness: 63.62% Â± 2.42%\n",
      "        Best fold: Fold 2 with 65.39%\n",
      "      New best fitness in this generation: 63.62%!\n",
      "      Fitness obtained: 63.62% | Best in generation: 63.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: b7947a9a)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=5e-05\n",
      "      Training/Evaluating model b7947a9a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7118, acc=55.78% (best=55.78%)\n",
      "          Fold 3 Epoch 1: loss=0.7149, acc=44.53% (best=44.53%)\n",
      "          Fold 4 Epoch 1: loss=0.7120, acc=57.34% (best=57.34%)\n",
      "          Fold 5 Epoch 1: loss=0.7145, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7177, acc=60.08% (best=60.08%)\n",
      "          Fold 2 Epoch 5: loss=0.6680, acc=51.48% (best=55.78%)\n",
      "          Fold 3 Epoch 5: loss=0.6999, acc=53.67% (best=58.44%)\n",
      "          Fold 4 Epoch 5: loss=0.6505, acc=57.73% (best=57.73%)\n",
      "          Fold 5 Epoch 5: loss=0.7039, acc=50.23% (best=54.92%)\n",
      "          Fold 1 Epoch 5: loss=0.6893, acc=47.03% (best=60.08%)\n",
      "          Fold 3 Epoch 10: loss=0.6741, acc=58.44% (best=58.44%)\n",
      "          Fold 2 Epoch 10: loss=0.6212, acc=45.55% (best=58.91%)\n",
      "          Fold 4 Epoch 10: loss=0.5776, acc=52.50% (best=57.97%)\n",
      "          Fold 5 Epoch 10: loss=0.6912, acc=46.95% (best=54.92%)\n",
      "          Fold 1 Epoch 10: loss=0.6567, acc=51.25% (best=60.08%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.08%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 58.44%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 2 Epoch 15: loss=0.5410, acc=45.55% (best=58.91%)\n",
      "          Fold 4 Epoch 15: loss=0.5007, acc=56.48% (best=59.45%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 58.91%\n",
      "          Fold 4 Epoch 20: loss=0.4427, acc=49.45% (best=59.45%)\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 59.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b7947a9a:\n",
      "        Fold accuracies: ['60.08%', '58.91%', '58.44%', '59.45%', '54.92%']\n",
      "        Average fitness: 58.36% Â± 1.80%\n",
      "        Best fold: Fold 1 with 60.08%\n",
      "      Fitness obtained: 58.36% | Best in generation: 63.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 8288bd35)\n",
      "      Architecture: 12 conv + 9 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 8288bd35 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7202, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7125, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7135, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7165, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.7078, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.7011, acc=49.77% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7057, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.6803, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 5: loss=0.7054, acc=48.98% (best=51.02%)\n",
      "          Fold 2 Epoch 10: loss=0.7016, acc=54.45% (best=54.45%)\n",
      "          Fold 1 Epoch 10: loss=0.6998, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 10: loss=0.7015, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 10: loss=0.6340, acc=49.22% (best=49.22%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.22%\n",
      "          Fold 3 Epoch 10: loss=0.7039, acc=51.02% (best=52.03%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 50.23%\n",
      "          Fold 2 Epoch 15: loss=0.6996, acc=50.39% (best=60.39%)\n",
      "          Fold 3 Epoch 15: loss=0.7000, acc=51.02% (best=52.03%)\n",
      "          Fold 2 Epoch 20: loss=0.6889, acc=49.61% (best=60.39%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 52.03%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 60.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8288bd35:\n",
      "        Fold accuracies: ['50.23%', '60.39%', '52.03%', '49.22%', '50.00%']\n",
      "        Average fitness: 52.38% Â± 4.11%\n",
      "        Best fold: Fold 2 with 60.39%\n",
      "      Fitness obtained: 52.38% | Best in generation: 63.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: c78ff7fd)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model c78ff7fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7897, acc=48.28% (best=48.28%)\n",
      "          Fold 1 Epoch 1: loss=0.7374, acc=51.64% (best=51.64%)\n",
      "          Fold 3 Epoch 1: loss=0.7289, acc=47.58% (best=47.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7270, acc=57.19% (best=57.19%)\n",
      "          Fold 4 Epoch 1: loss=0.7242, acc=51.17% (best=51.17%)\n",
      "          Fold 2 Epoch 5: loss=0.7431, acc=49.53% (best=52.27%)\n",
      "          Fold 1 Epoch 5: loss=0.7247, acc=47.11% (best=60.55%)\n",
      "          Fold 3 Epoch 5: loss=0.7201, acc=47.19% (best=52.81%)\n",
      "          Fold 5 Epoch 5: loss=0.7232, acc=43.83% (best=57.19%)\n",
      "          Fold 4 Epoch 5: loss=0.7162, acc=64.14% (best=64.14%)\n",
      "          Fold 2 Epoch 10: loss=0.7220, acc=52.19% (best=53.28%)\n",
      "          Fold 1 Epoch 10: loss=0.7161, acc=57.19% (best=60.55%)\n",
      "          Fold 3 Epoch 10: loss=0.7220, acc=59.61% (best=59.61%)\n",
      "          Fold 5 Epoch 10: loss=0.7227, acc=46.33% (best=57.19%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.19%\n",
      "          Fold 4 Epoch 10: loss=0.7107, acc=62.89% (best=66.09%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 60.55%\n",
      "          Fold 2 Epoch 15: loss=0.7123, acc=53.83% (best=55.31%)\n",
      "          Fold 3 Epoch 15: loss=0.7150, acc=59.84% (best=59.84%)\n",
      "          Fold 4 Epoch 15: loss=0.7066, acc=65.94% (best=71.64%)\n",
      "          Fold 2 Epoch 20: loss=0.7087, acc=56.48% (best=59.38%)\n",
      "          Fold 3 Epoch 20: loss=0.7163, acc=54.77% (best=59.84%)\n",
      "          Fold 4 Epoch 20: loss=0.7082, acc=75.31% (best=77.19%)\n",
      "          Fold 2 Epoch 25: loss=0.7118, acc=47.03% (best=59.38%)\n",
      "          Fold 3 Epoch 25: loss=0.7155, acc=59.92% (best=59.92%)\n",
      "          Fold 4 Epoch 25: loss=0.7086, acc=82.81% (best=82.81%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 59.38%\n",
      "          Fold 3 Epoch 30: loss=0.7135, acc=56.02% (best=59.92%)\n",
      "          Fold 4 Epoch 30: loss=0.7002, acc=72.81% (best=82.81%)\n",
      "          Fold 3 Epoch 35: loss=0.7109, acc=56.25% (best=59.92%)\n",
      "          Fold 3: Early stopping at epoch 35\n",
      "      â†’ Fold 3 completed: 59.92%\n",
      "          Fold 4 Epoch 35: loss=0.6993, acc=74.06% (best=82.81%)\n",
      "          Fold 4: Early stopping at epoch 35\n",
      "      â†’ Fold 4 completed: 82.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c78ff7fd:\n",
      "        Fold accuracies: ['60.55%', '59.38%', '59.92%', '82.81%', '57.19%']\n",
      "        Average fitness: 63.97% Â± 9.49%\n",
      "        Best fold: Fold 4 with 82.81%\n",
      "      New best fitness in this generation: 63.97%!\n",
      "      Fitness obtained: 63.97% | Best in generation: 63.97% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 362a3acf)\n",
      "      Architecture: 27 conv + 4 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 362a3acf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 246, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 362a3acf:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.97% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: b30f77bf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model b30f77bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7108, acc=48.12% (best=48.12%)\n",
      "          Fold 2 Epoch 1: loss=0.6933, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 1: loss=0.6990, acc=46.56% (best=46.56%)\n",
      "          Fold 1 Epoch 1: loss=0.7094, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7143, acc=49.30% (best=49.30%)\n",
      "          Fold 3 Epoch 5: loss=0.6153, acc=42.97% (best=57.34%)\n",
      "          Fold 2 Epoch 5: loss=0.6368, acc=58.67% (best=58.67%)\n",
      "          Fold 4 Epoch 5: loss=0.5485, acc=58.44% (best=58.44%)\n",
      "          Fold 5 Epoch 5: loss=0.6640, acc=46.56% (best=62.58%)\n",
      "          Fold 1 Epoch 5: loss=0.6536, acc=62.50% (best=62.50%)\n",
      "          Fold 3 Epoch 10: loss=0.4079, acc=62.58% (best=62.58%)\n",
      "          Fold 2 Epoch 10: loss=0.4092, acc=49.30% (best=62.27%)\n",
      "          Fold 4 Epoch 10: loss=0.3578, acc=62.73% (best=62.73%)\n",
      "          Fold 5 Epoch 10: loss=0.4238, acc=53.67% (best=62.58%)\n",
      "          Fold 1 Epoch 10: loss=0.4598, acc=56.56% (best=62.50%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "          Fold 3 Epoch 15: loss=0.3405, acc=56.25% (best=62.58%)\n",
      "          Fold 2 Epoch 15: loss=0.3294, acc=55.08% (best=64.45%)\n",
      "          Fold 4 Epoch 15: loss=0.3000, acc=65.23% (best=68.91%)\n",
      "          Fold 1 Epoch 15: loss=0.3496, acc=67.58% (best=67.58%)\n",
      "          Fold 3 Epoch 20: loss=0.2843, acc=55.94% (best=64.06%)\n",
      "          Fold 2 Epoch 20: loss=0.2986, acc=50.47% (best=64.45%)\n",
      "          Fold 4 Epoch 20: loss=0.2728, acc=65.78% (best=68.91%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 64.45%\n",
      "          Fold 1 Epoch 20: loss=0.3157, acc=61.95% (best=72.19%)\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 3 Epoch 25: loss=0.2626, acc=52.03% (best=64.06%)\n",
      "          Fold 1 Epoch 25: loss=0.2761, acc=50.16% (best=72.19%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 72.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30f77bf:\n",
      "        Fold accuracies: ['72.19%', '64.45%', '64.06%', '68.91%', '62.58%']\n",
      "        Average fitness: 66.44% Â± 3.57%\n",
      "        Best fold: Fold 1 with 72.19%\n",
      "      New best fitness in this generation: 66.44%!\n",
      "      Fitness obtained: 66.44% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 3c8674ad)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3c8674ad with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7228, acc=43.59% (best=43.59%)\n",
      "          Fold 3 Epoch 1: loss=0.7174, acc=44.92% (best=44.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7092, acc=52.58% (best=52.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6964, acc=49.38% (best=49.38%)\n",
      "          Fold 5 Epoch 1: loss=0.7317, acc=64.53% (best=64.53%)\n",
      "          Fold 2 Epoch 5: loss=0.4550, acc=55.31% (best=55.31%)\n",
      "          Fold 1 Epoch 5: loss=0.4416, acc=60.62% (best=60.62%)\n",
      "          Fold 3 Epoch 5: loss=0.4439, acc=53.98% (best=65.78%)\n",
      "          Fold 5 Epoch 5: loss=0.4571, acc=47.19% (best=64.53%)\n",
      "          Fold 4 Epoch 5: loss=0.4341, acc=58.36% (best=64.38%)\n",
      "          Fold 2 Epoch 10: loss=0.3097, acc=52.11% (best=58.52%)\n",
      "          Fold 1 Epoch 10: loss=0.3041, acc=41.95% (best=60.62%)\n",
      "          Fold 3 Epoch 10: loss=0.3405, acc=53.20% (best=65.78%)\n",
      "          Fold 5 Epoch 10: loss=0.3087, acc=41.09% (best=64.53%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 65.78%\n",
      "          Fold 4 Epoch 10: loss=0.3108, acc=59.53% (best=66.64%)\n",
      "          Fold 2 Epoch 15: loss=0.2823, acc=62.19% (best=62.19%)\n",
      "          Fold 1 Epoch 15: loss=0.2623, acc=54.22% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 60.62%\n",
      "          Fold 4 Epoch 15: loss=0.2694, acc=50.78% (best=68.98%)\n",
      "          Fold 2 Epoch 20: loss=0.2564, acc=44.30% (best=62.19%)\n",
      "          Fold 4 Epoch 20: loss=0.2384, acc=55.94% (best=68.98%)\n",
      "          Fold 2 Epoch 25: loss=0.2435, acc=58.28% (best=62.19%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 62.19%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 68.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3c8674ad:\n",
      "        Fold accuracies: ['60.62%', '62.19%', '65.78%', '68.98%', '64.53%']\n",
      "        Average fitness: 64.42% Â± 2.90%\n",
      "        Best fold: Fold 4 with 68.98%\n",
      "      Fitness obtained: 64.42% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: f09b22e8)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f09b22e8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6712, acc=50.86% (best=50.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7065, acc=61.95% (best=61.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6922, acc=38.44% (best=38.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7060, acc=62.81% (best=62.81%)\n",
      "          Fold 1 Epoch 1: loss=0.7025, acc=59.77% (best=59.77%)\n",
      "          Fold 4 Epoch 5: loss=0.3586, acc=46.41% (best=65.47%)\n",
      "          Fold 3 Epoch 5: loss=0.3657, acc=33.67% (best=61.95%)\n",
      "          Fold 5 Epoch 5: loss=0.3704, acc=41.64% (best=62.81%)\n",
      "          Fold 2 Epoch 5: loss=0.3778, acc=57.89% (best=60.62%)\n",
      "          Fold 1 Epoch 5: loss=0.4949, acc=61.33% (best=61.33%)\n",
      "          Fold 4 Epoch 10: loss=0.2908, acc=58.75% (best=65.47%)\n",
      "          Fold 5 Epoch 10: loss=0.2822, acc=45.94% (best=62.81%)\n",
      "          Fold 3 Epoch 10: loss=0.2878, acc=54.38% (best=61.95%)\n",
      "          Fold 2 Epoch 10: loss=0.2931, acc=47.11% (best=60.62%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 62.81%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 61.95%\n",
      "          Fold 1 Epoch 10: loss=0.3200, acc=54.61% (best=61.33%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.47%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 60.62%\n",
      "          Fold 1 Epoch 15: loss=0.2703, acc=58.12% (best=61.33%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 61.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f09b22e8:\n",
      "        Fold accuracies: ['61.33%', '60.62%', '61.95%', '65.47%', '62.81%']\n",
      "        Average fitness: 62.44% Â± 1.68%\n",
      "        Best fold: Fold 4 with 65.47%\n",
      "      Fitness obtained: 62.44% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 127e5262)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 127e5262 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 394, in forward\n",
      "    return torch.tanh(input)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6931, acc=46.72% (best=46.72%)\n",
      "          Fold 1 Epoch 1: loss=0.6997, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 1: loss=0.7139, acc=47.50% (best=47.50%)\n",
      "          Fold 2 Epoch 5: loss=0.6420, acc=54.45% (best=54.45%)\n",
      "          Fold 1 Epoch 5: loss=0.6129, acc=55.62% (best=72.50%)\n",
      "          Fold 5 Epoch 5: loss=0.6990, acc=47.11% (best=54.92%)\n",
      "          Fold 2 Epoch 10: loss=0.4338, acc=49.61% (best=54.45%)\n",
      "          Fold 1 Epoch 10: loss=0.3852, acc=57.03% (best=72.50%)\n",
      "          Fold 5 Epoch 10: loss=0.5682, acc=37.42% (best=54.92%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 72.50%\n",
      "          Fold 2 Epoch 15: loss=0.3354, acc=46.95% (best=59.06%)\n",
      "          Fold 2 Epoch 20: loss=0.3037, acc=50.31% (best=59.06%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 59.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 127e5262:\n",
      "        Fold accuracies: ['72.50%', '59.06%', '0.00%', '0.00%', '54.92%']\n",
      "        Average fitness: 37.30% Â± 31.00%\n",
      "        Best fold: Fold 1 with 72.50%\n",
      "      Fitness obtained: 37.30% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 887e4987)\n",
      "      Architecture: 10 conv + 2 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 887e4987 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6960, acc=55.70% (best=55.70%)\n",
      "          Fold 3 Epoch 1: loss=0.7108, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7207, acc=59.30% (best=59.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6853, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 1: loss=0.7165, acc=41.80% (best=41.80%)\n",
      "          Fold 2 Epoch 5: loss=0.6492, acc=35.39% (best=55.70%)\n",
      "          Fold 3 Epoch 5: loss=0.6610, acc=60.78% (best=60.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6868, acc=52.89% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.6764, acc=52.19% (best=60.47%)\n",
      "          Fold 4 Epoch 5: loss=0.6421, acc=61.95% (best=61.95%)\n",
      "          Fold 2 Epoch 10: loss=0.5846, acc=53.28% (best=55.70%)\n",
      "          Fold 1 Epoch 10: loss=0.6367, acc=46.25% (best=59.30%)\n",
      "          Fold 5 Epoch 10: loss=0.5897, acc=50.00% (best=60.47%)\n",
      "          Fold 3 Epoch 10: loss=0.5862, acc=62.58% (best=63.12%)\n",
      "          Fold 4 Epoch 10: loss=0.5899, acc=56.41% (best=63.52%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 55.70%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.30%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.47%\n",
      "          Fold 3 Epoch 15: loss=0.5250, acc=60.16% (best=63.12%)\n",
      "          Fold 4 Epoch 15: loss=0.5201, acc=56.72% (best=63.52%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 63.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 887e4987:\n",
      "        Fold accuracies: ['59.30%', '55.70%', '63.12%', '63.52%', '60.47%']\n",
      "        Average fitness: 60.42% Â± 2.84%\n",
      "        Best fold: Fold 4 with 63.52%\n",
      "      Fitness obtained: 60.42% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 1e9ac3d1)\n",
      "      Architecture: 23 conv + 4 fc, opt=sgd, lr=0.1\n",
      "      Training/Evaluating model 1e9ac3d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e9ac3d1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: ab7456ba)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model ab7456ba with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 70, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7259, acc=43.91% (best=43.91%)\n",
      "          Fold 3 Epoch 1: loss=0.7317, acc=52.27% (best=52.27%)\n",
      "          Fold 1 Epoch 1: loss=0.7349, acc=53.05% (best=53.05%)\n",
      "          Fold 4 Epoch 1: loss=0.7372, acc=54.53% (best=54.53%)\n",
      "          Fold 5 Epoch 1: loss=0.7155, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 5: loss=0.7202, acc=49.92% (best=52.66%)\n",
      "          Fold 5 Epoch 5: loss=0.7131, acc=50.08% (best=53.36%)\n",
      "          Fold 4 Epoch 5: loss=0.6812, acc=48.83% (best=54.53%)\n",
      "          Fold 2 Epoch 5: loss=0.6927, acc=40.86% (best=43.91%)\n",
      "          Fold 1 Epoch 5: loss=0.7039, acc=58.91% (best=62.42%)\n",
      "          Fold 3 Epoch 10: loss=0.7098, acc=40.55% (best=52.66%)\n",
      "          Fold 5 Epoch 10: loss=0.7043, acc=50.70% (best=53.36%)\n",
      "          Fold 4 Epoch 10: loss=0.6711, acc=48.98% (best=54.53%)\n",
      "          Fold 2 Epoch 10: loss=0.6866, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 10: loss=0.6886, acc=62.03% (best=62.42%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 54.53%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 53.36%\n",
      "          Fold 3 Epoch 15: loss=0.7008, acc=52.11% (best=53.98%)\n",
      "          Fold 2 Epoch 15: loss=0.6736, acc=49.61% (best=49.69%)\n",
      "          Fold 3 Epoch 20: loss=0.6878, acc=50.08% (best=56.41%)\n",
      "          Fold 2 Epoch 20: loss=0.6730, acc=46.33% (best=49.69%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 49.69%\n",
      "          Fold 3 Epoch 25: loss=0.6748, acc=60.16% (best=60.16%)\n",
      "          Fold 3 Epoch 30: loss=0.6610, acc=58.05% (best=61.64%)\n",
      "          Fold 3 Epoch 35: loss=0.6361, acc=51.33% (best=61.64%)\n",
      "          Fold 3: Early stopping at epoch 37\n",
      "      â†’ Fold 3 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ab7456ba:\n",
      "        Fold accuracies: ['62.42%', '49.69%', '61.64%', '54.53%', '53.36%']\n",
      "        Average fitness: 56.33% Â± 4.93%\n",
      "        Best fold: Fold 1 with 62.42%\n",
      "      Fitness obtained: 56.33% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 5105911f)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 5105911f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7305, acc=46.48% (best=46.48%)\n",
      "          Fold 4 Epoch 1: loss=0.7225, acc=58.98% (best=58.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7353, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7231, acc=49.84% (best=49.84%)\n",
      "          Fold 3 Epoch 1: loss=0.7173, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 5: loss=0.3850, acc=53.83% (best=53.83%)\n",
      "          Fold 4 Epoch 5: loss=0.4091, acc=42.11% (best=63.52%)\n",
      "          Fold 1 Epoch 5: loss=0.4189, acc=61.64% (best=61.64%)\n",
      "          Fold 5 Epoch 5: loss=0.3923, acc=51.95% (best=53.36%)\n",
      "          Fold 3 Epoch 5: loss=0.4016, acc=53.05% (best=56.02%)\n",
      "          Fold 2 Epoch 10: loss=0.3200, acc=50.00% (best=53.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2985, acc=46.64% (best=65.55%)\n",
      "          Fold 1 Epoch 10: loss=0.3256, acc=54.14% (best=67.03%)\n",
      "          Fold 5 Epoch 10: loss=0.3104, acc=53.83% (best=53.83%)\n",
      "          Fold 3 Epoch 10: loss=0.3295, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 15: loss=0.2863, acc=49.45% (best=59.45%)\n",
      "          Fold 4 Epoch 15: loss=0.2714, acc=67.11% (best=72.81%)\n",
      "          Fold 1 Epoch 15: loss=0.2934, acc=65.47% (best=67.03%)\n",
      "          Fold 5 Epoch 15: loss=0.2713, acc=48.36% (best=53.83%)\n",
      "          Fold 3 Epoch 15: loss=0.2943, acc=48.83% (best=61.17%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 67.03%\n",
      "          Fold 2 Epoch 20: loss=0.2646, acc=61.02% (best=61.02%)\n",
      "          Fold 4 Epoch 20: loss=0.2485, acc=57.81% (best=72.81%)\n",
      "          Fold 5 Epoch 20: loss=0.2577, acc=43.83% (best=53.83%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 53.83%\n",
      "          Fold 3 Epoch 20: loss=0.2738, acc=61.56% (best=61.56%)\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 72.81%\n",
      "          Fold 2 Epoch 25: loss=0.2483, acc=46.88% (best=61.02%)\n",
      "          Fold 3 Epoch 25: loss=0.2540, acc=50.55% (best=61.56%)\n",
      "          Fold 2 Epoch 30: loss=0.2417, acc=46.80% (best=61.02%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 61.02%\n",
      "          Fold 3 Epoch 30: loss=0.2510, acc=51.72% (best=63.52%)\n",
      "          Fold 3 Epoch 35: loss=0.2419, acc=59.38% (best=63.52%)\n",
      "          Fold 3: Early stopping at epoch 37\n",
      "      â†’ Fold 3 completed: 63.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5105911f:\n",
      "        Fold accuracies: ['67.03%', '61.02%', '63.52%', '72.81%', '53.83%']\n",
      "        Average fitness: 63.64% Â± 6.31%\n",
      "        Best fold: Fold 4 with 72.81%\n",
      "      Fitness obtained: 63.64% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 86ef9987)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 86ef9987 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6596, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.6904, acc=52.81% (best=52.81%)\n",
      "          Fold 1 Epoch 1: loss=0.6614, acc=64.45% (best=64.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6246, acc=64.61% (best=64.61%)\n",
      "          Fold 5 Epoch 1: loss=0.6982, acc=43.28% (best=43.28%)\n",
      "          Fold 5 Epoch 5: loss=0.3898, acc=55.00% (best=55.39%)\n",
      "          Fold 4 Epoch 5: loss=0.4164, acc=56.48% (best=64.61%)\n",
      "          Fold 1 Epoch 5: loss=0.4481, acc=53.36% (best=64.45%)\n",
      "          Fold 3 Epoch 5: loss=0.3970, acc=44.53% (best=61.72%)\n",
      "          Fold 2 Epoch 5: loss=0.3453, acc=50.62% (best=62.89%)\n",
      "          Fold 5 Epoch 10: loss=0.2789, acc=50.16% (best=55.39%)\n",
      "          Fold 4 Epoch 10: loss=0.2643, acc=53.83% (best=64.61%)\n",
      "          Fold 1 Epoch 10: loss=0.2917, acc=51.41% (best=64.45%)\n",
      "          Fold 3 Epoch 10: loss=0.2958, acc=48.83% (best=61.72%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.61%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 64.45%\n",
      "          Fold 2 Epoch 10: loss=0.2766, acc=55.23% (best=62.89%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 61.72%\n",
      "          Fold 5 Epoch 15: loss=0.2515, acc=52.89% (best=57.03%)\n",
      "          Fold 2 Epoch 15: loss=0.2474, acc=58.59% (best=64.77%)\n",
      "          Fold 5 Epoch 20: loss=0.2357, acc=50.94% (best=57.73%)\n",
      "          Fold 2 Epoch 20: loss=0.2373, acc=57.50% (best=64.77%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 64.77%\n",
      "          Fold 5 Epoch 25: loss=0.2307, acc=52.42% (best=57.73%)\n",
      "          Fold 5: Early stopping at epoch 26\n",
      "      â†’ Fold 5 completed: 57.73%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 86ef9987:\n",
      "        Fold accuracies: ['64.45%', '64.77%', '61.72%', '64.61%', '57.73%']\n",
      "        Average fitness: 62.66% Â± 2.71%\n",
      "        Best fold: Fold 2 with 64.77%\n",
      "      Fitness obtained: 62.66% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: dad7e231)\n",
      "      Architecture: 10 conv + 7 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model dad7e231 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7196, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.7255, acc=48.98% (best=48.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7325, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7162, acc=60.16% (best=60.16%)\n",
      "          Fold 2 Epoch 1: loss=0.7180, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 5: loss=0.5185, acc=49.84% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.4363, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 5: loss=0.4857, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.4681, acc=54.61% (best=60.16%)\n",
      "          Fold 2 Epoch 5: loss=0.4250, acc=47.81% (best=50.86%)\n",
      "          Fold 1 Epoch 10: loss=0.3632, acc=56.95% (best=64.38%)\n",
      "          Fold 3 Epoch 10: loss=0.3412, acc=57.89% (best=60.31%)\n",
      "          Fold 5 Epoch 10: loss=0.3406, acc=64.77% (best=64.77%)\n",
      "          Fold 4 Epoch 10: loss=0.3308, acc=48.91% (best=60.16%)\n",
      "          Fold 2 Epoch 10: loss=0.3229, acc=48.59% (best=61.25%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.16%\n",
      "          Fold 1 Epoch 15: loss=0.3061, acc=50.16% (best=64.38%)\n",
      "          Fold 3 Epoch 15: loss=0.2944, acc=54.38% (best=60.31%)\n",
      "          Fold 5 Epoch 15: loss=0.2935, acc=55.94% (best=64.77%)\n",
      "          Fold 2 Epoch 15: loss=0.2936, acc=48.52% (best=61.25%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 64.38%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 60.31%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 61.25%\n",
      "          Fold 5 Epoch 20: loss=0.2713, acc=62.81% (best=64.77%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dad7e231:\n",
      "        Fold accuracies: ['64.38%', '61.25%', '60.31%', '60.16%', '64.77%']\n",
      "        Average fitness: 62.17% Â± 2.00%\n",
      "        Best fold: Fold 5 with 64.77%\n",
      "      Fitness obtained: 62.17% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: d271ca69)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.01\n",
      "      Training/Evaluating model d271ca69 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.8078, acc=52.97% (best=52.97%)\n",
      "          Fold 3 Epoch 1: loss=0.8654, acc=56.48% (best=56.48%)\n",
      "          Fold 4 Epoch 1: loss=0.8293, acc=56.33% (best=56.33%)          Fold 1 Epoch 1: loss=0.8111, acc=49.61% (best=49.61%)\n",
      "\n",
      "          Fold 5 Epoch 1: loss=0.8836, acc=55.62% (best=55.62%)\n",
      "          Fold 2 Epoch 5: loss=0.5234, acc=38.20% (best=52.97%)\n",
      "          Fold 3 Epoch 5: loss=0.5242, acc=47.81% (best=56.48%)\n",
      "          Fold 5 Epoch 5: loss=0.6862, acc=50.78% (best=56.09%)\n",
      "          Fold 4 Epoch 5: loss=0.6033, acc=61.33% (best=61.33%)\n",
      "          Fold 1 Epoch 5: loss=0.6257, acc=55.70% (best=55.70%)\n",
      "          Fold 2 Epoch 10: loss=0.3120, acc=61.56% (best=61.56%)\n",
      "          Fold 3 Epoch 10: loss=0.3337, acc=56.09% (best=56.48%)\n",
      "          Fold 5 Epoch 10: loss=0.4290, acc=54.61% (best=56.09%)\n",
      "          Fold 4 Epoch 10: loss=0.3823, acc=57.66% (best=61.33%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 56.48%\n",
      "          Fold 1 Epoch 10: loss=0.3718, acc=52.50% (best=59.38%)\n",
      "          Fold 2 Epoch 15: loss=0.2632, acc=53.52% (best=61.56%)\n",
      "          Fold 5 Epoch 15: loss=0.2763, acc=54.92% (best=57.27%)\n",
      "          Fold 4 Epoch 15: loss=0.2633, acc=51.17% (best=61.33%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 61.33%\n",
      "          Fold 1 Epoch 15: loss=0.2780, acc=51.88% (best=59.38%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 59.38%\n",
      "          Fold 2 Epoch 20: loss=0.2459, acc=61.56% (best=69.84%)\n",
      "          Fold 5 Epoch 20: loss=0.2517, acc=53.67% (best=57.27%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 57.27%\n",
      "          Fold 2 Epoch 25: loss=0.2308, acc=53.20% (best=69.84%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 69.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d271ca69:\n",
      "        Fold accuracies: ['59.38%', '69.84%', '56.48%', '61.33%', '57.27%']\n",
      "        Average fitness: 60.86% Â± 4.80%\n",
      "        Best fold: Fold 2 with 69.84%\n",
      "      Fitness obtained: 60.86% | Best in generation: 66.44% | Global best: 70.92%\n",
      "\n",
      "GENERATION 15 STATISTICS:\n",
      "   Maximum fitness: 66.44%\n",
      "   Average fitness: 54.34%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 19.11%\n",
      "   Best individual: b30f77bf with 66.44%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 2/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=19.11)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: b30f77bf (fitness: 66.44%)\n",
      "   Elite 2: 3c8674ad (fitness: 64.42%)\n",
      "   Elite 3: c78ff7fd (fitness: 63.97%)\n",
      "   Elite 4: 5105911f (fitness: 63.64%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 3/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 16\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 16)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: b30f77bf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model b30f77bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7183, acc=43.67% (best=43.67%)\n",
      "          Fold 1 Epoch 1: loss=0.7060, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6963, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 1: loss=0.7146, acc=47.42% (best=47.42%)\n",
      "          Fold 2 Epoch 1: loss=0.7002, acc=43.28% (best=43.28%)\n",
      "          Fold 2 Epoch 5: loss=0.6510, acc=53.36% (best=53.36%)\n",
      "          Fold 3 Epoch 5: loss=0.6202, acc=49.61% (best=59.69%)\n",
      "          Fold 4 Epoch 5: loss=0.5936, acc=60.31% (best=60.31%)\n",
      "          Fold 1 Epoch 5: loss=0.6111, acc=55.23% (best=62.03%)\n",
      "          Fold 5 Epoch 5: loss=0.6917, acc=59.92% (best=61.09%)\n",
      "          Fold 1 Epoch 10: loss=0.4040, acc=52.11% (best=62.03%)\n",
      "          Fold 5 Epoch 10: loss=0.4506, acc=50.94% (best=63.98%)\n",
      "          Fold 4 Epoch 10: loss=0.3942, acc=55.86% (best=60.31%)\n",
      "          Fold 3 Epoch 10: loss=0.4037, acc=60.55% (best=60.55%)\n",
      "          Fold 2 Epoch 10: loss=0.4332, acc=44.92% (best=56.56%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "          Fold 5 Epoch 15: loss=0.3557, acc=53.05% (best=63.98%)\n",
      "          Fold 4 Epoch 15: loss=0.3246, acc=55.94% (best=60.31%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 60.31%\n",
      "          Fold 3 Epoch 15: loss=0.3439, acc=57.73% (best=67.50%)\n",
      "          Fold 2 Epoch 15: loss=0.3279, acc=56.02% (best=58.67%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 63.98%\n",
      "          Fold 3 Epoch 20: loss=0.3002, acc=69.38% (best=69.38%)\n",
      "          Fold 2 Epoch 20: loss=0.2939, acc=60.47% (best=60.47%)\n",
      "          Fold 3 Epoch 25: loss=0.2647, acc=58.28% (best=69.38%)\n",
      "          Fold 2 Epoch 25: loss=0.2713, acc=63.75% (best=63.75%)\n",
      "          Fold 3 Epoch 30: loss=0.2471, acc=62.11% (best=69.38%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 69.38%\n",
      "          Fold 2 Epoch 30: loss=0.2494, acc=59.92% (best=63.75%)\n",
      "          Fold 2 Epoch 35: loss=0.2323, acc=59.61% (best=73.91%)\n",
      "          Fold 2 Epoch 40: loss=0.2266, acc=58.28% (best=76.09%)\n",
      "          Fold 2 Epoch 45: loss=0.2328, acc=61.41% (best=76.09%)\n",
      "          Fold 2: Early stopping at epoch 49\n",
      "      â†’ Fold 2 completed: 76.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30f77bf:\n",
      "        Fold accuracies: ['62.03%', '76.09%', '69.38%', '60.31%', '63.98%']\n",
      "        Average fitness: 66.36% Â± 5.74%\n",
      "        Best fold: Fold 2 with 76.09%\n",
      "      New best fitness in this generation: 66.36%!\n",
      "      Fitness obtained: 66.36% | Best in generation: 66.36% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 3c8674ad)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3c8674ad with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7072, acc=40.62% (best=40.62%)\n",
      "          Fold 4 Epoch 1: loss=0.7035, acc=63.12% (best=63.12%)\n",
      "          Fold 1 Epoch 1: loss=0.7135, acc=48.05% (best=48.05%)\n",
      "          Fold 5 Epoch 1: loss=0.7433, acc=58.20% (best=58.20%)\n",
      "          Fold 3 Epoch 1: loss=0.7181, acc=48.91% (best=48.91%)\n",
      "          Fold 2 Epoch 5: loss=0.3662, acc=55.08% (best=55.08%)\n",
      "          Fold 4 Epoch 5: loss=0.3690, acc=55.16% (best=63.12%)\n",
      "          Fold 1 Epoch 5: loss=0.4393, acc=59.06% (best=59.06%)\n",
      "          Fold 5 Epoch 5: loss=0.4153, acc=47.03% (best=61.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4084, acc=57.89% (best=59.45%)\n",
      "          Fold 2 Epoch 10: loss=0.2834, acc=52.89% (best=76.72%)\n",
      "          Fold 4 Epoch 10: loss=0.2805, acc=49.92% (best=63.12%)\n",
      "          Fold 1 Epoch 10: loss=0.3257, acc=54.84% (best=63.91%)\n",
      "          Fold 5 Epoch 10: loss=0.3227, acc=54.14% (best=61.88%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.12%\n",
      "          Fold 3 Epoch 10: loss=0.3227, acc=67.19% (best=67.19%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 2 Epoch 15: loss=0.2560, acc=58.20% (best=76.72%)\n",
      "          Fold 1 Epoch 15: loss=0.2684, acc=63.75% (best=67.34%)\n",
      "          Fold 3 Epoch 15: loss=0.2834, acc=61.41% (best=67.19%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 76.72%\n",
      "          Fold 1 Epoch 20: loss=0.2536, acc=63.28% (best=67.34%)\n",
      "          Fold 3 Epoch 20: loss=0.2597, acc=46.95% (best=67.34%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 67.34%\n",
      "          Fold 3 Epoch 25: loss=0.2432, acc=56.25% (best=71.48%)\n",
      "          Fold 3 Epoch 30: loss=0.2275, acc=61.25% (best=71.48%)\n",
      "          Fold 3: Early stopping at epoch 33\n",
      "      â†’ Fold 3 completed: 71.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3c8674ad:\n",
      "        Fold accuracies: ['67.34%', '76.72%', '71.48%', '63.12%', '61.88%']\n",
      "        Average fitness: 68.11% Â± 5.47%\n",
      "        Best fold: Fold 2 with 76.72%\n",
      "      New best fitness in this generation: 68.11%!\n",
      "      Fitness obtained: 68.11% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: c78ff7fd)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model c78ff7fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.8108, acc=48.44% (best=48.44%)\n",
      "          Fold 2 Epoch 1: loss=0.7278, acc=51.09% (best=51.09%)\n",
      "          Fold 1 Epoch 1: loss=0.7272, acc=33.91% (best=33.91%)\n",
      "          Fold 4 Epoch 1: loss=0.7199, acc=48.28% (best=48.28%)\n",
      "          Fold 5 Epoch 1: loss=0.7361, acc=48.20% (best=48.20%)\n",
      "          Fold 3 Epoch 5: loss=0.7510, acc=41.80% (best=49.14%)\n",
      "          Fold 1 Epoch 5: loss=0.7205, acc=43.44% (best=45.55%)\n",
      "          Fold 2 Epoch 5: loss=0.7185, acc=52.50% (best=52.50%)\n",
      "          Fold 4 Epoch 5: loss=0.7132, acc=50.23% (best=56.41%)\n",
      "          Fold 5 Epoch 5: loss=0.7272, acc=50.94% (best=50.94%)\n",
      "          Fold 3 Epoch 10: loss=0.7191, acc=47.81% (best=49.22%)\n",
      "          Fold 1 Epoch 10: loss=0.7159, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 10: loss=0.7150, acc=42.89% (best=53.67%)\n",
      "          Fold 4 Epoch 10: loss=0.7140, acc=55.55% (best=56.41%)\n",
      "          Fold 5 Epoch 10: loss=0.7221, acc=52.89% (best=52.89%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 56.41%\n",
      "          Fold 3 Epoch 15: loss=0.7106, acc=55.78% (best=56.80%)\n",
      "          Fold 1 Epoch 15: loss=0.7142, acc=51.48% (best=58.28%)\n",
      "          Fold 2 Epoch 15: loss=0.7126, acc=47.81% (best=53.67%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 53.67%\n",
      "          Fold 5 Epoch 15: loss=0.7182, acc=50.86% (best=55.55%)\n",
      "          Fold 3 Epoch 20: loss=0.7114, acc=54.30% (best=56.80%)\n",
      "          Fold 1 Epoch 20: loss=0.7120, acc=52.42% (best=58.28%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 58.28%\n",
      "          Fold 5 Epoch 20: loss=0.7155, acc=52.42% (best=55.55%)\n",
      "          Fold 3 Epoch 25: loss=0.7067, acc=57.58% (best=65.00%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 55.55%\n",
      "          Fold 3 Epoch 30: loss=0.7077, acc=48.75% (best=65.00%)\n",
      "          Fold 3: Early stopping at epoch 34\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c78ff7fd:\n",
      "        Fold accuracies: ['58.28%', '53.67%', '65.00%', '56.41%', '55.55%']\n",
      "        Average fitness: 57.78% Â± 3.90%\n",
      "        Best fold: Fold 3 with 65.00%\n",
      "      Fitness obtained: 57.78% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 5105911f)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 5105911f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7361, acc=53.59% (best=53.59%)\n",
      "          Fold 2 Epoch 1: loss=0.7061, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7431, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7311, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7186, acc=48.05% (best=48.05%)\n",
      "          Fold 3 Epoch 5: loss=0.4253, acc=53.75% (best=53.83%)\n",
      "          Fold 2 Epoch 5: loss=0.4060, acc=67.81% (best=67.81%)\n",
      "          Fold 5 Epoch 5: loss=0.4297, acc=49.38% (best=56.64%)\n",
      "          Fold 1 Epoch 5: loss=0.4303, acc=56.25% (best=56.25%)\n",
      "          Fold 4 Epoch 5: loss=0.4776, acc=55.55% (best=60.23%)\n",
      "          Fold 2 Epoch 10: loss=0.3153, acc=56.09% (best=67.81%)\n",
      "          Fold 3 Epoch 10: loss=0.3453, acc=54.53% (best=62.42%)\n",
      "          Fold 5 Epoch 10: loss=0.3398, acc=48.75% (best=61.88%)\n",
      "          Fold 1 Epoch 10: loss=0.3156, acc=53.20% (best=60.62%)\n",
      "          Fold 4 Epoch 10: loss=0.3629, acc=49.84% (best=62.89%)\n",
      "          Fold 3 Epoch 15: loss=0.2971, acc=51.95% (best=62.42%)\n",
      "          Fold 2 Epoch 15: loss=0.2874, acc=49.69% (best=67.81%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 67.81%\n",
      "          Fold 5 Epoch 15: loss=0.2953, acc=46.17% (best=61.88%)\n",
      "          Fold 1 Epoch 15: loss=0.2776, acc=56.88% (best=62.27%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 62.42%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 61.88%\n",
      "          Fold 4 Epoch 15: loss=0.3038, acc=62.34% (best=62.89%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 62.89%\n",
      "          Fold 1 Epoch 20: loss=0.2653, acc=58.36% (best=62.27%)\n",
      "          Fold 1 Epoch 25: loss=0.2459, acc=52.66% (best=64.92%)\n",
      "          Fold 1 Epoch 30: loss=0.2401, acc=54.14% (best=64.92%)\n",
      "          Fold 1 Epoch 35: loss=0.2298, acc=57.19% (best=69.30%)\n",
      "          Fold 1 Epoch 40: loss=0.2182, acc=59.53% (best=69.30%)\n",
      "          Fold 1: Early stopping at epoch 42\n",
      "      â†’ Fold 1 completed: 69.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5105911f:\n",
      "        Fold accuracies: ['69.30%', '67.81%', '62.42%', '62.89%', '61.88%']\n",
      "        Average fitness: 64.86% Â± 3.07%\n",
      "        Best fold: Fold 1 with 69.30%\n",
      "      Fitness obtained: 64.86% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 5e00132d)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 5e00132d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7258, acc=60.31% (best=60.31%)\n",
      "          Fold 4 Epoch 1: loss=0.6822, acc=51.88% (best=51.88%)\n",
      "          Fold 1 Epoch 1: loss=0.7138, acc=62.27% (best=62.27%)\n",
      "          Fold 3 Epoch 1: loss=0.7184, acc=46.95% (best=46.95%)\n",
      "          Fold 2 Epoch 1: loss=0.7061, acc=42.73% (best=42.73%)\n",
      "          Fold 5 Epoch 5: loss=0.4140, acc=42.34% (best=60.31%)\n",
      "          Fold 4 Epoch 5: loss=0.4160, acc=56.09% (best=66.17%)\n",
      "          Fold 1 Epoch 5: loss=0.4375, acc=55.23% (best=62.27%)\n",
      "          Fold 3 Epoch 5: loss=0.3629, acc=65.23% (best=65.23%)\n",
      "          Fold 2 Epoch 5: loss=0.5136, acc=46.25% (best=53.75%)\n",
      "          Fold 4 Epoch 10: loss=0.2632, acc=52.19% (best=66.17%)\n",
      "          Fold 5 Epoch 10: loss=0.2800, acc=49.22% (best=60.31%)\n",
      "          Fold 1 Epoch 10: loss=0.2577, acc=59.92% (best=62.27%)\n",
      "          Fold 3 Epoch 10: loss=0.2628, acc=59.22% (best=66.09%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 62.27%\n",
      "          Fold 2 Epoch 10: loss=0.2935, acc=51.64% (best=53.75%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.17%\n",
      "          Fold 3 Epoch 15: loss=0.2348, acc=61.17% (best=66.09%)\n",
      "          Fold 2 Epoch 15: loss=0.2576, acc=50.39% (best=56.72%)\n",
      "          Fold 3 Epoch 20: loss=0.2234, acc=58.36% (best=66.56%)\n",
      "          Fold 2 Epoch 20: loss=0.2316, acc=45.78% (best=56.72%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 56.72%\n",
      "          Fold 3 Epoch 25: loss=0.2177, acc=58.36% (best=66.56%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 66.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 5e00132d:\n",
      "        Fold accuracies: ['62.27%', '56.72%', '66.56%', '66.17%', '60.31%']\n",
      "        Average fitness: 62.41% Â± 3.69%\n",
      "        Best fold: Fold 3 with 66.56%\n",
      "      Fitness obtained: 62.41% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: fbef1ba6)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model fbef1ba6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7179, acc=56.72% (best=56.72%)\n",
      "          Fold 1 Epoch 1: loss=0.7077, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7073, acc=62.73% (best=62.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7218, acc=52.19% (best=52.19%)\n",
      "          Fold 2 Epoch 1: loss=0.6999, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 5: loss=0.6174, acc=52.19% (best=52.27%)\n",
      "          Fold 5 Epoch 5: loss=0.6935, acc=51.17% (best=56.72%)\n",
      "          Fold 4 Epoch 5: loss=0.6352, acc=54.77% (best=62.73%)\n",
      "          Fold 3 Epoch 5: loss=0.6912, acc=57.27% (best=57.58%)\n",
      "          Fold 2 Epoch 5: loss=0.6040, acc=49.61% (best=50.16%)\n",
      "          Fold 1 Epoch 10: loss=0.4714, acc=61.80% (best=61.80%)\n",
      "          Fold 5 Epoch 10: loss=0.4860, acc=46.33% (best=56.72%)\n",
      "          Fold 4 Epoch 10: loss=0.4683, acc=53.36% (best=67.81%)\n",
      "          Fold 3 Epoch 10: loss=0.5423, acc=51.95% (best=57.58%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.72%\n",
      "          Fold 2 Epoch 10: loss=0.4418, acc=56.25% (best=56.25%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 57.58%\n",
      "          Fold 1 Epoch 15: loss=0.3781, acc=64.77% (best=65.47%)\n",
      "          Fold 4 Epoch 15: loss=0.3830, acc=57.11% (best=67.81%)\n",
      "          Fold 2 Epoch 15: loss=0.3720, acc=52.58% (best=56.25%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 67.81%\n",
      "          Fold 1 Epoch 20: loss=0.3488, acc=65.70% (best=65.86%)\n",
      "          Fold 2 Epoch 20: loss=0.3415, acc=50.00% (best=56.25%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 56.25%\n",
      "          Fold 1 Epoch 25: loss=0.3291, acc=65.31% (best=65.94%)\n",
      "          Fold 1 Epoch 30: loss=0.3096, acc=66.02% (best=66.02%)\n",
      "          Fold 1 Epoch 35: loss=0.2923, acc=67.34% (best=67.34%)\n",
      "          Fold 1 Epoch 40: loss=0.2821, acc=62.73% (best=67.34%)\n",
      "          Fold 1 Epoch 45: loss=0.2759, acc=61.95% (best=67.34%)\n",
      "          Fold 1: Early stopping at epoch 45\n",
      "      â†’ Fold 1 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fbef1ba6:\n",
      "        Fold accuracies: ['67.34%', '56.25%', '57.58%', '67.81%', '56.72%']\n",
      "        Average fitness: 61.14% Â± 5.28%\n",
      "        Best fold: Fold 4 with 67.81%\n",
      "      Fitness obtained: 61.14% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: f4f2860c)\n",
      "      Architecture: 28 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model f4f2860c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 29, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for f4f2860c:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: b2bb8b1d)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model b2bb8b1d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7167, acc=52.97% (best=52.97%)\n",
      "          Fold 1 Epoch 1: loss=0.7207, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7128, acc=31.88% (best=31.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7141, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7438, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.6920, acc=62.42% (best=71.72%)\n",
      "          Fold 1 Epoch 5: loss=0.6959, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 5: loss=0.7053, acc=50.39% (best=50.39%)\n",
      "          Fold 2 Epoch 5: loss=0.6979, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 5: loss=0.7057, acc=48.98% (best=63.98%)\n",
      "          Fold 4 Epoch 10: loss=0.6190, acc=59.06% (best=71.72%)\n",
      "          Fold 1 Epoch 10: loss=0.6617, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 10: loss=0.7001, acc=62.89% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.6214, acc=49.61% (best=52.81%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 49.77%\n",
      "          Fold 3 Epoch 10: loss=0.6928, acc=48.98% (best=63.98%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 71.72%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 63.98%\n",
      "          Fold 2 Epoch 15: loss=0.4704, acc=49.53% (best=52.81%)\n",
      "          Fold 5 Epoch 15: loss=0.6994, acc=53.75% (best=62.89%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 52.81%\n",
      "          Fold 5 Epoch 20: loss=0.7003, acc=50.00% (best=62.89%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 62.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b2bb8b1d:\n",
      "        Fold accuracies: ['49.77%', '52.81%', '63.98%', '71.72%', '62.89%']\n",
      "        Average fitness: 60.23% Â± 7.97%\n",
      "        Best fold: Fold 4 with 71.72%\n",
      "      Fitness obtained: 60.23% | Best in generation: 68.11% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: e5bf30b2)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e5bf30b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7077, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7281, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6894, acc=46.95% (best=46.95%)\n",
      "          Fold 3 Epoch 1: loss=0.7442, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7196, acc=67.89% (best=67.89%)\n",
      "          Fold 1 Epoch 5: loss=0.4563, acc=51.09% (best=64.45%)\n",
      "          Fold 4 Epoch 5: loss=0.4147, acc=61.88% (best=61.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4061, acc=71.64% (best=71.64%)\n",
      "          Fold 2 Epoch 5: loss=0.3874, acc=51.80% (best=56.41%)\n",
      "          Fold 5 Epoch 5: loss=0.4423, acc=64.06% (best=67.89%)\n",
      "          Fold 1 Epoch 10: loss=0.3411, acc=61.48% (best=66.41%)\n",
      "          Fold 4 Epoch 10: loss=0.3222, acc=60.08% (best=64.30%)\n",
      "          Fold 3 Epoch 10: loss=0.3339, acc=48.20% (best=71.64%)\n",
      "          Fold 2 Epoch 10: loss=0.3144, acc=49.53% (best=56.41%)\n",
      "          Fold 5 Epoch 10: loss=0.3369, acc=64.69% (best=67.89%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 67.89%\n",
      "          Fold 1 Epoch 15: loss=0.3063, acc=58.83% (best=66.41%)\n",
      "          Fold 4 Epoch 15: loss=0.2992, acc=47.73% (best=64.30%)\n",
      "          Fold 3 Epoch 15: loss=0.2932, acc=52.03% (best=71.64%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 71.64%\n",
      "          Fold 2 Epoch 15: loss=0.2834, acc=64.61% (best=64.61%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 64.30%\n",
      "          Fold 1 Epoch 20: loss=0.2798, acc=66.80% (best=68.98%)\n",
      "          Fold 2 Epoch 20: loss=0.2748, acc=55.08% (best=64.61%)\n",
      "          Fold 1 Epoch 25: loss=0.2549, acc=76.88% (best=76.88%)\n",
      "          Fold 2 Epoch 25: loss=0.2585, acc=53.75% (best=67.42%)\n",
      "          Fold 1 Epoch 30: loss=0.2457, acc=63.44% (best=76.88%)\n",
      "          Fold 2 Epoch 30: loss=0.2401, acc=55.94% (best=67.42%)\n",
      "          Fold 2: Early stopping at epoch 31\n",
      "      â†’ Fold 2 completed: 67.42%\n",
      "          Fold 1 Epoch 35: loss=0.2385, acc=72.89% (best=76.88%)\n",
      "          Fold 1: Early stopping at epoch 35\n",
      "      â†’ Fold 1 completed: 76.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e5bf30b2:\n",
      "        Fold accuracies: ['76.88%', '67.42%', '71.64%', '64.30%', '67.89%']\n",
      "        Average fitness: 69.62% Â± 4.31%\n",
      "        Best fold: Fold 1 with 76.88%\n",
      "      New best fitness in this generation: 69.62%!\n",
      "      Fitness obtained: 69.62% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 7e40563d)\n",
      "      Architecture: 10 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 7e40563d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7144, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7165, acc=51.17% (best=51.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7227, acc=46.25% (best=46.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7507, acc=57.81% (best=57.81%)\n",
      "          Fold 4 Epoch 1: loss=0.6990, acc=52.42% (best=52.42%)\n",
      "          Fold 1 Epoch 5: loss=0.5066, acc=58.67% (best=60.23%)\n",
      "          Fold 3 Epoch 5: loss=0.3853, acc=50.70% (best=61.80%)\n",
      "          Fold 2 Epoch 5: loss=0.3960, acc=48.05% (best=53.52%)\n",
      "          Fold 5 Epoch 5: loss=0.4408, acc=50.55% (best=57.81%)\n",
      "          Fold 4 Epoch 5: loss=0.4101, acc=54.53% (best=61.02%)\n",
      "          Fold 1 Epoch 10: loss=0.3352, acc=41.80% (best=60.23%)\n",
      "          Fold 3 Epoch 10: loss=0.3003, acc=58.36% (best=63.05%)\n",
      "          Fold 5 Epoch 10: loss=0.3351, acc=53.20% (best=58.05%)\n",
      "          Fold 2 Epoch 10: loss=0.2956, acc=55.86% (best=55.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2863, acc=53.44% (best=61.02%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 60.23%\n",
      "          Fold 3 Epoch 15: loss=0.2592, acc=68.20% (best=68.20%)\n",
      "          Fold 5 Epoch 15: loss=0.2840, acc=57.27% (best=58.20%)\n",
      "          Fold 2 Epoch 15: loss=0.2594, acc=55.16% (best=55.86%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 61.02%\n",
      "          Fold 3 Epoch 20: loss=0.2397, acc=55.39% (best=68.20%)\n",
      "          Fold 5 Epoch 20: loss=0.2501, acc=53.75% (best=58.28%)\n",
      "          Fold 2 Epoch 20: loss=0.2458, acc=49.61% (best=55.86%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 3 Epoch 25: loss=0.2266, acc=54.22% (best=68.20%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 68.20%\n",
      "          Fold 5 Epoch 25: loss=0.2474, acc=51.80% (best=60.23%)\n",
      "          Fold 5 Epoch 30: loss=0.2310, acc=52.66% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 31\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 7e40563d:\n",
      "        Fold accuracies: ['60.23%', '55.86%', '68.20%', '61.02%', '60.23%']\n",
      "        Average fitness: 61.11% Â± 3.99%\n",
      "        Best fold: Fold 3 with 68.20%\n",
      "      Fitness obtained: 61.11% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 4003469d)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 4003469d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.6369, acc=57.27% (best=57.27%)\n",
      "          Fold 1 Epoch 1: loss=0.6901, acc=58.12% (best=58.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6479, acc=65.70% (best=65.70%)\n",
      "          Fold 3 Epoch 1: loss=0.6102, acc=57.50% (best=57.50%)\n",
      "          Fold 2 Epoch 1: loss=0.6612, acc=47.03% (best=47.03%)\n",
      "          Fold 1 Epoch 5: loss=0.3037, acc=53.67% (best=59.38%)\n",
      "          Fold 5 Epoch 5: loss=0.2776, acc=51.88% (best=58.44%)\n",
      "          Fold 4 Epoch 5: loss=0.2769, acc=55.78% (best=65.70%)\n",
      "          Fold 3 Epoch 5: loss=0.2991, acc=58.67% (best=59.53%)\n",
      "          Fold 2 Epoch 5: loss=0.2822, acc=38.12% (best=51.95%)\n",
      "          Fold 1 Epoch 10: loss=0.2434, acc=51.09% (best=59.38%)\n",
      "          Fold 5 Epoch 10: loss=0.2279, acc=46.95% (best=58.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2196, acc=49.84% (best=65.86%)\n",
      "          Fold 3 Epoch 10: loss=0.2458, acc=56.41% (best=68.59%)\n",
      "          Fold 2 Epoch 10: loss=0.2340, acc=45.39% (best=52.89%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 59.38%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.44%\n",
      "          Fold 4 Epoch 15: loss=0.2087, acc=44.84% (best=65.86%)\n",
      "          Fold 3 Epoch 15: loss=0.2263, acc=50.39% (best=68.59%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 68.59%\n",
      "          Fold 2 Epoch 15: loss=0.2163, acc=60.78% (best=60.78%)\n",
      "          Fold 2 Epoch 20: loss=0.2040, acc=60.62% (best=60.78%)\n",
      "          Fold 2 Epoch 25: loss=0.2033, acc=53.20% (best=63.91%)\n",
      "          Fold 2 Epoch 30: loss=0.1991, acc=50.16% (best=63.91%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 63.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4003469d:\n",
      "        Fold accuracies: ['59.38%', '63.91%', '68.59%', '65.86%', '58.44%']\n",
      "        Average fitness: 63.23% Â± 3.85%\n",
      "        Best fold: Fold 3 with 68.59%\n",
      "      Fitness obtained: 63.23% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 95ae1fbb)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 95ae1fbb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7097, acc=45.86% (best=45.86%)\n",
      "          Fold 2 Epoch 1: loss=0.7009, acc=48.75% (best=48.75%)\n",
      "          Fold 1 Epoch 1: loss=0.7002, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6909, acc=52.81% (best=52.81%)\n",
      "          Fold 5 Epoch 1: loss=0.7073, acc=41.80% (best=41.80%)\n",
      "          Fold 2 Epoch 5: loss=0.5402, acc=50.78% (best=55.08%)\n",
      "          Fold 3 Epoch 5: loss=0.4918, acc=52.89% (best=56.41%)\n",
      "          Fold 1 Epoch 5: loss=0.5971, acc=53.12% (best=62.03%)\n",
      "          Fold 4 Epoch 5: loss=0.5509, acc=63.83% (best=63.83%)\n",
      "          Fold 5 Epoch 5: loss=0.5408, acc=46.88% (best=62.03%)\n",
      "          Fold 2 Epoch 10: loss=0.3573, acc=43.59% (best=55.08%)\n",
      "          Fold 3 Epoch 10: loss=0.3425, acc=56.09% (best=56.41%)\n",
      "          Fold 1 Epoch 10: loss=0.3849, acc=48.28% (best=62.03%)\n",
      "          Fold 4 Epoch 10: loss=0.3686, acc=60.55% (best=63.83%)\n",
      "          Fold 5 Epoch 10: loss=0.3635, acc=52.58% (best=62.03%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "          Fold 3 Epoch 15: loss=0.2998, acc=51.41% (best=58.75%)\n",
      "          Fold 2 Epoch 15: loss=0.3112, acc=49.92% (best=60.94%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "          Fold 4 Epoch 15: loss=0.3097, acc=57.42% (best=63.83%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 2 Epoch 20: loss=0.2802, acc=48.91% (best=60.94%)\n",
      "          Fold 3 Epoch 20: loss=0.2645, acc=59.92% (best=67.81%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 60.94%\n",
      "          Fold 3 Epoch 25: loss=0.2475, acc=63.28% (best=67.81%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 67.81%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 95ae1fbb:\n",
      "        Fold accuracies: ['62.03%', '60.94%', '67.81%', '63.83%', '62.03%']\n",
      "        Average fitness: 63.33% Â± 2.43%\n",
      "        Best fold: Fold 3 with 67.81%\n",
      "      Fitness obtained: 63.33% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: acacd4a1)\n",
      "      Architecture: 20 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model acacd4a1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 56, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for acacd4a1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: bfd7fa01)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model bfd7fa01 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7284, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 1: loss=0.7206, acc=48.59% (best=48.59%)\n",
      "          Fold 4 Epoch 1: loss=0.7145, acc=52.34% (best=52.34%)\n",
      "          Fold 5 Epoch 1: loss=0.7659, acc=49.53% (best=49.53%)\n",
      "          Fold 1 Epoch 1: loss=0.7305, acc=51.88% (best=51.88%)\n",
      "          Fold 4 Epoch 5: loss=0.7010, acc=42.89% (best=54.92%)\n",
      "          Fold 3 Epoch 5: loss=0.7203, acc=50.00% (best=51.80%)\n",
      "          Fold 5 Epoch 5: loss=0.7456, acc=52.73% (best=54.84%)\n",
      "          Fold 2 Epoch 5: loss=0.7093, acc=47.66% (best=55.78%)\n",
      "          Fold 1 Epoch 5: loss=0.7133, acc=45.39% (best=55.31%)\n",
      "          Fold 4 Epoch 10: loss=0.6914, acc=45.86% (best=54.92%)\n",
      "          Fold 5 Epoch 10: loss=0.7317, acc=50.78% (best=55.78%)\n",
      "          Fold 3 Epoch 10: loss=0.7136, acc=46.25% (best=51.80%)\n",
      "          Fold 2 Epoch 10: loss=0.7062, acc=48.59% (best=55.78%)\n",
      "          Fold 1 Epoch 10: loss=0.7117, acc=53.67% (best=55.39%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 54.92%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 55.78%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 51.80%\n",
      "          Fold 5 Epoch 15: loss=0.7265, acc=48.44% (best=55.86%)\n",
      "          Fold 1 Epoch 15: loss=0.7007, acc=56.33% (best=66.25%)\n",
      "          Fold 5 Epoch 20: loss=0.7229, acc=54.84% (best=62.97%)\n",
      "          Fold 1 Epoch 20: loss=0.6977, acc=52.97% (best=66.25%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 66.25%\n",
      "          Fold 5 Epoch 25: loss=0.7182, acc=49.69% (best=62.97%)\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 62.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bfd7fa01:\n",
      "        Fold accuracies: ['66.25%', '55.78%', '51.80%', '54.92%', '62.97%']\n",
      "        Average fitness: 58.34% Â± 5.39%\n",
      "        Best fold: Fold 1 with 66.25%\n",
      "      Fitness obtained: 58.34% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: ce6a5b00)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model ce6a5b00 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6963, acc=40.94% (best=40.94%)\n",
      "          Fold 3 Epoch 1: loss=0.7137, acc=46.41% (best=46.41%)\n",
      "          Fold 1 Epoch 1: loss=0.7056, acc=61.88% (best=61.88%)\n",
      "          Fold 4 Epoch 1: loss=0.6940, acc=61.80% (best=61.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7124, acc=37.58% (best=37.58%)\n",
      "          Fold 2 Epoch 5: loss=0.6712, acc=43.44% (best=46.56%)\n",
      "          Fold 3 Epoch 5: loss=0.6644, acc=52.66% (best=55.86%)\n",
      "          Fold 5 Epoch 5: loss=0.7018, acc=62.19% (best=62.19%)\n",
      "          Fold 4 Epoch 5: loss=0.6561, acc=60.16% (best=61.80%)\n",
      "          Fold 1 Epoch 5: loss=0.6803, acc=58.20% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.6073, acc=46.64% (best=46.64%)\n",
      "          Fold 3 Epoch 10: loss=0.5621, acc=61.95% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.6910, acc=54.69% (best=62.97%)\n",
      "          Fold 4 Epoch 10: loss=0.5887, acc=50.62% (best=61.80%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.80%\n",
      "          Fold 1 Epoch 10: loss=0.5961, acc=59.30% (best=64.30%)\n",
      "          Fold 2 Epoch 15: loss=0.4732, acc=52.50% (best=52.50%)\n",
      "          Fold 3 Epoch 15: loss=0.4579, acc=59.06% (best=65.23%)\n",
      "          Fold 5 Epoch 15: loss=0.6372, acc=53.20% (best=65.78%)\n",
      "          Fold 1 Epoch 15: loss=0.4754, acc=71.64% (best=71.64%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "          Fold 2 Epoch 20: loss=0.3980, acc=44.38% (best=54.77%)\n",
      "          Fold 5 Epoch 20: loss=0.5078, acc=49.61% (best=65.78%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 65.78%\n",
      "          Fold 1 Epoch 20: loss=0.3924, acc=73.05% (best=77.50%)\n",
      "          Fold 2 Epoch 25: loss=0.3554, acc=49.77% (best=64.14%)\n",
      "          Fold 1 Epoch 25: loss=0.3502, acc=70.00% (best=77.50%)\n",
      "          Fold 2 Epoch 30: loss=0.3211, acc=47.27% (best=64.14%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 77.50%\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 64.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ce6a5b00:\n",
      "        Fold accuracies: ['77.50%', '64.14%', '65.23%', '61.80%', '65.78%']\n",
      "        Average fitness: 66.89% Â± 5.48%\n",
      "        Best fold: Fold 1 with 77.50%\n",
      "      Fitness obtained: 66.89% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 57d5e974)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 57d5e974 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7192, acc=50.16% (best=50.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7224, acc=49.45% (best=49.45%)\n",
      "          Fold 4 Epoch 1: loss=0.7076, acc=54.92% (best=54.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7251, acc=55.70% (best=55.70%)\n",
      "          Fold 5 Epoch 1: loss=0.7338, acc=46.88% (best=46.88%)\n",
      "          Fold 3 Epoch 5: loss=0.3994, acc=62.89% (best=62.89%)\n",
      "          Fold 4 Epoch 5: loss=0.4300, acc=51.64% (best=56.88%)\n",
      "          Fold 2 Epoch 5: loss=0.4820, acc=40.94% (best=55.94%)\n",
      "          Fold 1 Epoch 5: loss=0.5017, acc=60.39% (best=62.11%)\n",
      "          Fold 5 Epoch 5: loss=0.5169, acc=51.09% (best=51.09%)\n",
      "          Fold 4 Epoch 10: loss=0.3121, acc=48.36% (best=68.12%)\n",
      "          Fold 5 Epoch 10: loss=0.3165, acc=56.33% (best=56.33%)\n",
      "          Fold 1 Epoch 10: loss=0.3483, acc=62.50% (best=62.50%)\n",
      "          Fold 3 Epoch 10: loss=0.3055, acc=53.20% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.3036, acc=57.81% (best=57.81%)\n",
      "          Fold 4 Epoch 15: loss=0.2706, acc=54.38% (best=68.12%)\n",
      "          Fold 5 Epoch 15: loss=0.2655, acc=65.39% (best=65.39%)\n",
      "          Fold 1 Epoch 15: loss=0.2968, acc=52.11% (best=65.31%)\n",
      "          Fold 3 Epoch 15: loss=0.2722, acc=64.22% (best=65.47%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.12%\n",
      "          Fold 2 Epoch 15: loss=0.2586, acc=40.47% (best=57.81%)\n",
      "          Fold 5 Epoch 20: loss=0.2433, acc=41.56% (best=65.39%)\n",
      "          Fold 1 Epoch 20: loss=0.2699, acc=46.25% (best=65.31%)\n",
      "          Fold 3 Epoch 20: loss=0.2482, acc=57.81% (best=65.47%)\n",
      "          Fold 2 Epoch 20: loss=0.2462, acc=41.41% (best=57.81%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 65.47%\n",
      "          Fold 5 Epoch 25: loss=0.2365, acc=44.77% (best=65.39%)\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 65.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 57d5e974:\n",
      "        Fold accuracies: ['65.31%', '57.81%', '65.47%', '68.12%', '65.39%']\n",
      "        Average fitness: 64.42% Â± 3.47%\n",
      "        Best fold: Fold 4 with 68.12%\n",
      "      Fitness obtained: 64.42% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: acbe44bc)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model acbe44bc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7158, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7471, acc=47.73% (best=47.73%)\n",
      "          Fold 1 Epoch 1: loss=0.7390, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 1: loss=0.7263, acc=58.28% (best=58.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7359, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.3953, acc=56.17% (best=59.14%)\n",
      "          Fold 1 Epoch 5: loss=0.4199, acc=59.14% (best=60.08%)\n",
      "          Fold 5 Epoch 5: loss=0.4437, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 5: loss=0.4289, acc=57.73% (best=58.28%)\n",
      "          Fold 3 Epoch 5: loss=0.3774, acc=58.12% (best=58.12%)\n",
      "          Fold 2 Epoch 10: loss=0.3359, acc=47.42% (best=59.14%)\n",
      "          Fold 1 Epoch 10: loss=0.3269, acc=52.19% (best=62.11%)\n",
      "          Fold 5 Epoch 10: loss=0.3572, acc=53.05% (best=62.66%)\n",
      "          Fold 4 Epoch 10: loss=0.3263, acc=39.14% (best=58.98%)\n",
      "          Fold 3 Epoch 10: loss=0.3183, acc=52.66% (best=58.12%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 59.14%\n",
      "          Fold 1 Epoch 15: loss=0.2915, acc=53.91% (best=62.11%)\n",
      "          Fold 5 Epoch 15: loss=0.3044, acc=44.84% (best=62.66%)\n",
      "          Fold 4 Epoch 15: loss=0.2914, acc=51.88% (best=58.98%)\n",
      "          Fold 3 Epoch 15: loss=0.2862, acc=53.91% (best=62.58%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 62.66%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 4 Epoch 20: loss=0.2804, acc=48.36% (best=59.45%)\n",
      "          Fold 3 Epoch 20: loss=0.2708, acc=44.45% (best=62.58%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "          Fold 4 Epoch 25: loss=0.2608, acc=49.84% (best=59.45%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 59.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for acbe44bc:\n",
      "        Fold accuracies: ['62.11%', '59.14%', '62.58%', '59.45%', '62.66%']\n",
      "        Average fitness: 61.19% Â± 1.56%\n",
      "        Best fold: Fold 5 with 62.66%\n",
      "      Fitness obtained: 61.19% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: e28fff8f)\n",
      "      Architecture: 10 conv + 4 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model e28fff8f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7066, acc=55.39% (best=55.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7030, acc=61.80% (best=61.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7052, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7159, acc=55.86% (best=55.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6811, acc=59.61% (best=59.61%)\n",
      "          Fold 3 Epoch 5: loss=0.3531, acc=61.64% (best=61.64%)\n",
      "          Fold 2 Epoch 5: loss=0.3371, acc=56.56% (best=61.80%)\n",
      "          Fold 5 Epoch 5: loss=0.3387, acc=41.17% (best=55.31%)\n",
      "          Fold 1 Epoch 5: loss=0.3739, acc=40.00% (best=56.88%)\n",
      "          Fold 4 Epoch 5: loss=0.3305, acc=49.92% (best=59.61%)\n",
      "          Fold 3 Epoch 10: loss=0.2783, acc=62.66% (best=62.66%)\n",
      "          Fold 2 Epoch 10: loss=0.2529, acc=66.48% (best=66.48%)\n",
      "          Fold 5 Epoch 10: loss=0.2667, acc=42.97% (best=55.31%)\n",
      "          Fold 1 Epoch 10: loss=0.2916, acc=53.28% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2586, acc=38.05% (best=59.61%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 55.31%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 59.61%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 56.88%\n",
      "          Fold 2 Epoch 15: loss=0.2417, acc=57.50% (best=66.48%)\n",
      "          Fold 3 Epoch 15: loss=0.2516, acc=58.83% (best=62.66%)\n",
      "          Fold 2 Epoch 20: loss=0.2205, acc=55.55% (best=68.20%)\n",
      "          Fold 3 Epoch 20: loss=0.2392, acc=62.27% (best=62.66%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 62.66%\n",
      "          Fold 2 Epoch 25: loss=0.2143, acc=52.89% (best=68.20%)\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 68.20%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e28fff8f:\n",
      "        Fold accuracies: ['56.88%', '68.20%', '62.66%', '59.61%', '55.31%']\n",
      "        Average fitness: 60.53% Â± 4.58%\n",
      "        Best fold: Fold 2 with 68.20%\n",
      "      Fitness obtained: 60.53% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 6ba24570)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6ba24570 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7461, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7388, acc=46.80% (best=46.80%)\n",
      "          Fold 4 Epoch 1: loss=0.7191, acc=52.19% (best=52.19%)\n",
      "          Fold 1 Epoch 1: loss=0.7354, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7446, acc=47.58% (best=47.58%)\n",
      "          Fold 1 Epoch 5: loss=0.6520, acc=50.94% (best=52.89%)\n",
      "          Fold 4 Epoch 5: loss=0.6256, acc=53.91% (best=63.59%)\n",
      "          Fold 3 Epoch 5: loss=0.6421, acc=49.53% (best=50.94%)\n",
      "          Fold 5 Epoch 5: loss=0.6647, acc=55.31% (best=55.31%)\n",
      "          Fold 2 Epoch 5: loss=0.6744, acc=46.41% (best=53.44%)\n",
      "          Fold 1 Epoch 10: loss=0.5642, acc=61.02% (best=61.02%)\n",
      "          Fold 4 Epoch 10: loss=0.5733, acc=57.03% (best=63.59%)\n",
      "          Fold 3 Epoch 10: loss=0.5192, acc=55.62% (best=58.59%)\n",
      "          Fold 5 Epoch 10: loss=0.5168, acc=43.67% (best=55.31%)\n",
      "          Fold 2 Epoch 10: loss=0.5296, acc=47.03% (best=53.44%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.59%\n",
      "          Fold 1 Epoch 15: loss=0.5437, acc=47.27% (best=67.03%)\n",
      "          Fold 3 Epoch 15: loss=0.4564, acc=64.22% (best=66.17%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 53.44%\n",
      "          Fold 5 Epoch 15: loss=0.4371, acc=46.41% (best=55.31%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 55.31%\n",
      "          Fold 1 Epoch 20: loss=0.4503, acc=61.48% (best=68.52%)\n",
      "          Fold 3 Epoch 20: loss=0.4140, acc=60.23% (best=66.17%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 66.17%\n",
      "          Fold 1 Epoch 25: loss=0.4198, acc=48.91% (best=68.52%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 68.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6ba24570:\n",
      "        Fold accuracies: ['68.52%', '53.44%', '66.17%', '63.59%', '55.31%']\n",
      "        Average fitness: 61.41% Â± 5.98%\n",
      "        Best fold: Fold 1 with 68.52%\n",
      "      Fitness obtained: 61.41% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 3bf6e0fc)\n",
      "      Architecture: 20 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3bf6e0fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 44, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 3bf6e0fc:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 69.62% | Global best: 70.92%\n",
      "\n",
      "GENERATION 16 STATISTICS:\n",
      "   Maximum fitness: 69.62%\n",
      "   Average fitness: 53.55%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 22.69%\n",
      "   Best individual: e5bf30b2 with 69.62%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 4/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=22.69)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: e5bf30b2 (fitness: 69.62%)\n",
      "   Elite 2: 3c8674ad (fitness: 68.11%)\n",
      "   Elite 3: ce6a5b00 (fitness: 66.89%)\n",
      "   Elite 4: b30f77bf (fitness: 66.36%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 5/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 17\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 17)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: e5bf30b2)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e5bf30b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7313, acc=53.05% (best=53.05%)\n",
      "          Fold 1 Epoch 1: loss=0.7284, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7200, acc=41.95% (best=41.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7434, acc=60.55% (best=60.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6952, acc=45.55% (best=45.55%)\n",
      "          Fold 3 Epoch 5: loss=0.4205, acc=55.55% (best=56.17%)\n",
      "          Fold 1 Epoch 5: loss=0.4319, acc=49.61% (best=65.62%)\n",
      "          Fold 2 Epoch 5: loss=0.3978, acc=47.34% (best=53.83%)\n",
      "          Fold 5 Epoch 5: loss=0.4461, acc=49.14% (best=60.55%)\n",
      "          Fold 4 Epoch 5: loss=0.3860, acc=50.70% (best=50.70%)\n",
      "          Fold 3 Epoch 10: loss=0.3340, acc=55.31% (best=63.28%)\n",
      "          Fold 1 Epoch 10: loss=0.3288, acc=61.41% (best=65.62%)\n",
      "          Fold 2 Epoch 10: loss=0.3011, acc=55.00% (best=56.48%)\n",
      "          Fold 5 Epoch 10: loss=0.3345, acc=42.58% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 4 Epoch 10: loss=0.3133, acc=50.86% (best=63.52%)\n",
      "          Fold 3 Epoch 15: loss=0.2997, acc=55.94% (best=67.58%)\n",
      "          Fold 1 Epoch 15: loss=0.2858, acc=69.45% (best=69.45%)\n",
      "          Fold 2 Epoch 15: loss=0.2658, acc=57.42% (best=61.48%)\n",
      "          Fold 4 Epoch 15: loss=0.2670, acc=45.62% (best=63.52%)\n",
      "          Fold 3 Epoch 20: loss=0.2691, acc=50.62% (best=67.58%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 2 Epoch 20: loss=0.2564, acc=57.73% (best=67.34%)\n",
      "          Fold 1 Epoch 20: loss=0.2570, acc=64.22% (best=69.45%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "          Fold 2 Epoch 25: loss=0.2413, acc=61.25% (best=67.34%)\n",
      "          Fold 1 Epoch 25: loss=0.2458, acc=56.72% (best=69.45%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 69.45%\n",
      "          Fold 2: Early stopping at epoch 29\n",
      "      â†’ Fold 2 completed: 67.34%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e5bf30b2:\n",
      "        Fold accuracies: ['69.45%', '67.34%', '67.58%', '63.52%', '60.55%']\n",
      "        Average fitness: 65.69% Â± 3.21%\n",
      "        Best fold: Fold 1 with 69.45%\n",
      "      New best fitness in this generation: 65.69%!\n",
      "      Fitness obtained: 65.69% | Best in generation: 65.69% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 3c8674ad)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3c8674ad with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7172, acc=51.72% (best=51.72%)\n",
      "          Fold 4 Epoch 1: loss=0.6918, acc=51.95% (best=51.95%)\n",
      "          Fold 3 Epoch 1: loss=0.7149, acc=56.72% (best=56.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7368, acc=59.92% (best=59.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7018, acc=59.38% (best=59.38%)\n",
      "          Fold 4 Epoch 5: loss=0.4244, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 5: loss=0.3867, acc=49.45% (best=59.92%)\n",
      "          Fold 2 Epoch 5: loss=0.3782, acc=42.50% (best=51.72%)\n",
      "          Fold 1 Epoch 5: loss=0.5009, acc=57.42% (best=68.28%)\n",
      "          Fold 3 Epoch 5: loss=0.3728, acc=69.61% (best=69.61%)\n",
      "          Fold 4 Epoch 10: loss=0.3099, acc=53.75% (best=56.88%)\n",
      "          Fold 5 Epoch 10: loss=0.2815, acc=50.08% (best=59.92%)\n",
      "          Fold 2 Epoch 10: loss=0.2947, acc=48.83% (best=51.72%)\n",
      "          Fold 1 Epoch 10: loss=0.3629, acc=46.02% (best=68.28%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 51.72%\n",
      "          Fold 3 Epoch 10: loss=0.2930, acc=51.41% (best=69.61%)\n",
      "          Fold 4 Epoch 15: loss=0.2677, acc=54.61% (best=56.88%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 56.88%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 68.28%\n",
      "          Fold 3 Epoch 15: loss=0.2500, acc=64.61% (best=69.61%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 69.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3c8674ad:\n",
      "        Fold accuracies: ['68.28%', '51.72%', '69.61%', '56.88%', '59.92%']\n",
      "        Average fitness: 61.28% Â± 6.80%\n",
      "        Best fold: Fold 3 with 69.61%\n",
      "      Fitness obtained: 61.28% | Best in generation: 65.69% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: ce6a5b00)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model ce6a5b00 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7005, acc=40.55% (best=40.55%)\n",
      "          Fold 3 Epoch 1: loss=0.7142, acc=56.64% (best=56.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6932, acc=62.50% (best=62.50%)\n",
      "          Fold 1 Epoch 1: loss=0.7093, acc=56.80% (best=56.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7184, acc=55.55% (best=55.55%)\n",
      "          Fold 2 Epoch 5: loss=0.6712, acc=43.36% (best=43.36%)\n",
      "          Fold 3 Epoch 5: loss=0.6909, acc=57.19% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.6912, acc=58.44% (best=58.44%)\n",
      "          Fold 4 Epoch 5: loss=0.6519, acc=63.67% (best=64.14%)\n",
      "          Fold 1 Epoch 5: loss=0.6792, acc=58.91% (best=60.00%)\n",
      "          Fold 2 Epoch 10: loss=0.6388, acc=42.81% (best=50.47%)\n",
      "          Fold 3 Epoch 10: loss=0.6192, acc=47.42% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.5721, acc=52.81% (best=58.44%)\n",
      "          Fold 4 Epoch 10: loss=0.5915, acc=63.28% (best=67.27%)\n",
      "          Fold 1 Epoch 10: loss=0.5981, acc=59.45% (best=61.09%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 2 Epoch 15: loss=0.5325, acc=48.59% (best=50.47%)\n",
      "          Fold 5 Epoch 15: loss=0.4232, acc=61.95% (best=62.97%)\n",
      "          Fold 4 Epoch 15: loss=0.5030, acc=58.59% (best=67.73%)\n",
      "          Fold 1 Epoch 15: loss=0.4616, acc=55.39% (best=61.09%)\n",
      "          Fold 2 Epoch 20: loss=0.4295, acc=55.55% (best=55.55%)\n",
      "          Fold 5 Epoch 20: loss=0.3501, acc=58.75% (best=62.97%)\n",
      "          Fold 4 Epoch 20: loss=0.4220, acc=63.36% (best=67.73%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 61.09%\n",
      "          Fold 2 Epoch 25: loss=0.3509, acc=49.61% (best=55.55%)\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 62.97%\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 67.73%\n",
      "          Fold 2 Epoch 30: loss=0.3249, acc=52.19% (best=55.55%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 55.55%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ce6a5b00:\n",
      "        Fold accuracies: ['61.09%', '55.55%', '60.86%', '67.73%', '62.97%']\n",
      "        Average fitness: 61.64% Â± 3.92%\n",
      "        Best fold: Fold 4 with 67.73%\n",
      "      Fitness obtained: 61.64% | Best in generation: 65.69% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: b30f77bf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model b30f77bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6983, acc=45.70% (best=45.70%)\n",
      "          Fold 1 Epoch 1: loss=0.7045, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6957, acc=60.23% (best=60.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7196, acc=48.28% (best=48.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7127, acc=57.66% (best=57.66%)\n",
      "          Fold 2 Epoch 5: loss=0.6168, acc=47.19% (best=48.75%)\n",
      "          Fold 1 Epoch 5: loss=0.6255, acc=46.33% (best=63.20%)\n",
      "          Fold 4 Epoch 5: loss=0.5384, acc=69.38% (best=69.38%)\n",
      "          Fold 5 Epoch 5: loss=0.6453, acc=47.42% (best=60.70%)\n",
      "          Fold 3 Epoch 5: loss=0.5953, acc=38.28% (best=62.97%)\n",
      "          Fold 2 Epoch 10: loss=0.4104, acc=59.69% (best=60.78%)\n",
      "          Fold 1 Epoch 10: loss=0.4067, acc=59.92% (best=64.30%)\n",
      "          Fold 4 Epoch 10: loss=0.3455, acc=67.42% (best=69.38%)\n",
      "          Fold 5 Epoch 10: loss=0.4147, acc=49.38% (best=60.70%)\n",
      "          Fold 3 Epoch 10: loss=0.3867, acc=47.81% (best=62.97%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.70%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 62.97%\n",
      "          Fold 2 Epoch 15: loss=0.3297, acc=72.50% (best=74.77%)\n",
      "          Fold 1 Epoch 15: loss=0.3276, acc=60.39% (best=64.30%)\n",
      "          Fold 4 Epoch 15: loss=0.2880, acc=65.08% (best=69.38%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 64.30%\n",
      "          Fold 2 Epoch 20: loss=0.2853, acc=54.61% (best=74.77%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 74.77%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30f77bf:\n",
      "        Fold accuracies: ['64.30%', '74.77%', '62.97%', '69.38%', '60.70%']\n",
      "        Average fitness: 66.42% Â± 5.05%\n",
      "        Best fold: Fold 2 with 74.77%\n",
      "      New best fitness in this generation: 66.42%!\n",
      "      Fitness obtained: 66.42% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 960339d4)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 960339d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7135, acc=57.89% (best=57.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7181, acc=59.14% (best=59.14%)\n",
      "          Fold 2 Epoch 1: loss=0.7055, acc=46.56% (best=46.56%)\n",
      "          Fold 3 Epoch 1: loss=0.7178, acc=39.06% (best=39.06%)\n",
      "          Fold 4 Epoch 1: loss=0.7085, acc=62.66% (best=62.66%)\n",
      "          Fold 1 Epoch 5: loss=0.6992, acc=58.44% (best=62.19%)\n",
      "          Fold 5 Epoch 5: loss=0.7091, acc=55.08% (best=59.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6772, acc=38.52% (best=46.56%)\n",
      "          Fold 4 Epoch 5: loss=0.6882, acc=67.11% (best=68.44%)\n",
      "          Fold 3 Epoch 5: loss=0.7051, acc=48.12% (best=48.12%)\n",
      "          Fold 1 Epoch 10: loss=0.6895, acc=59.38% (best=62.50%)\n",
      "          Fold 5 Epoch 10: loss=0.7046, acc=56.80% (best=59.22%)\n",
      "          Fold 2 Epoch 10: loss=0.6661, acc=43.98% (best=50.47%)\n",
      "          Fold 4 Epoch 10: loss=0.6816, acc=66.33% (best=68.67%)\n",
      "          Fold 3 Epoch 10: loss=0.6950, acc=54.69% (best=54.69%)\n",
      "          Fold 1 Epoch 15: loss=0.6715, acc=52.97% (best=62.50%)\n",
      "          Fold 5 Epoch 15: loss=0.6871, acc=44.14% (best=60.31%)\n",
      "          Fold 2 Epoch 15: loss=0.6433, acc=53.59% (best=53.59%)\n",
      "          Fold 4 Epoch 15: loss=0.6656, acc=71.88% (best=71.88%)\n",
      "          Fold 3 Epoch 15: loss=0.6875, acc=46.72% (best=54.69%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.50%\n",
      "          Fold 5 Epoch 20: loss=0.6797, acc=51.02% (best=60.31%)\n",
      "          Fold 2 Epoch 20: loss=0.6189, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 20: loss=0.6540, acc=66.80% (best=71.88%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 60.31%\n",
      "          Fold 3 Epoch 20: loss=0.6687, acc=52.34% (best=54.69%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 54.69%\n",
      "          Fold 2 Epoch 25: loss=0.5861, acc=50.23% (best=61.95%)\n",
      "          Fold 4 Epoch 25: loss=0.6340, acc=63.52% (best=71.88%)\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 71.88%\n",
      "          Fold 2 Epoch 30: loss=0.5427, acc=58.20% (best=61.95%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 61.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 960339d4:\n",
      "        Fold accuracies: ['62.50%', '61.95%', '54.69%', '71.88%', '60.31%']\n",
      "        Average fitness: 62.27% Â± 5.55%\n",
      "        Best fold: Fold 4 with 71.88%\n",
      "      Fitness obtained: 62.27% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 8a841d6e)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8a841d6e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6896, acc=48.83% (best=48.83%)\n",
      "          Fold 3 Epoch 1: loss=0.7266, acc=60.62% (best=60.62%)\n",
      "          Fold 1 Epoch 1: loss=0.7270, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 1: loss=0.7118, acc=31.09% (best=31.09%)\n",
      "          Fold 5 Epoch 1: loss=0.7348, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 5: loss=0.3831, acc=57.34% (best=58.91%)\n",
      "          Fold 1 Epoch 5: loss=0.4802, acc=39.45% (best=60.00%)\n",
      "          Fold 3 Epoch 5: loss=0.3883, acc=44.84% (best=60.62%)\n",
      "          Fold 5 Epoch 5: loss=0.3960, acc=54.69% (best=54.69%)\n",
      "          Fold 2 Epoch 5: loss=0.5023, acc=51.33% (best=51.33%)\n",
      "          Fold 4 Epoch 10: loss=0.2970, acc=50.70% (best=65.00%)\n",
      "          Fold 1 Epoch 10: loss=0.2848, acc=42.27% (best=60.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2811, acc=33.28% (best=60.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2937, acc=52.34% (best=55.47%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 60.62%\n",
      "          Fold 2 Epoch 10: loss=0.2897, acc=43.28% (best=55.78%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 60.00%\n",
      "          Fold 4 Epoch 15: loss=0.2603, acc=53.36% (best=65.00%)\n",
      "          Fold 5 Epoch 15: loss=0.2579, acc=46.88% (best=55.47%)\n",
      "          Fold 2 Epoch 15: loss=0.2545, acc=44.92% (best=55.78%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 55.47%\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 55.78%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 65.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8a841d6e:\n",
      "        Fold accuracies: ['60.00%', '55.78%', '60.62%', '65.00%', '55.47%']\n",
      "        Average fitness: 59.38% Â± 3.51%\n",
      "        Best fold: Fold 4 with 65.00%\n",
      "      Fitness obtained: 59.38% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 749cd83c)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 749cd83c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7079, acc=58.83% (best=58.83%)\n",
      "          Fold 3 Epoch 1: loss=0.7148, acc=55.23% (best=55.23%)\n",
      "          Fold 4 Epoch 1: loss=0.7075, acc=51.95% (best=51.95%)\n",
      "          Fold 2 Epoch 1: loss=0.7085, acc=49.69% (best=49.69%)\n",
      "          Fold 5 Epoch 1: loss=0.7375, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.4172, acc=56.02% (best=68.05%)\n",
      "          Fold 3 Epoch 5: loss=0.4074, acc=48.67% (best=55.23%)\n",
      "          Fold 4 Epoch 5: loss=0.3971, acc=46.72% (best=59.53%)\n",
      "          Fold 2 Epoch 5: loss=0.3912, acc=63.12% (best=63.12%)\n",
      "          Fold 5 Epoch 5: loss=0.4192, acc=52.50% (best=54.22%)\n",
      "          Fold 3 Epoch 10: loss=0.2913, acc=61.41% (best=66.88%)\n",
      "          Fold 1 Epoch 10: loss=0.2808, acc=61.02% (best=68.05%)\n",
      "          Fold 4 Epoch 10: loss=0.2653, acc=49.30% (best=59.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2818, acc=46.41% (best=63.28%)\n",
      "          Fold 5 Epoch 10: loss=0.2929, acc=52.03% (best=54.22%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 68.05%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 59.53%\n",
      "          Fold 3 Epoch 15: loss=0.2527, acc=55.08% (best=66.88%)\n",
      "          Fold 2 Epoch 15: loss=0.2517, acc=51.25% (best=63.28%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 63.28%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 66.88%\n",
      "          Fold 5 Epoch 15: loss=0.2569, acc=47.27% (best=59.53%)\n",
      "          Fold 5 Epoch 20: loss=0.2374, acc=49.38% (best=59.53%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 59.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 749cd83c:\n",
      "        Fold accuracies: ['68.05%', '63.28%', '66.88%', '59.53%', '59.53%']\n",
      "        Average fitness: 63.45% Â± 3.57%\n",
      "        Best fold: Fold 1 with 68.05%\n",
      "      Fitness obtained: 63.45% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: c8a03d3a)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c8a03d3a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7272, acc=51.17% (best=51.17%)\n",
      "          Fold 1 Epoch 1: loss=0.7167, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 1: loss=0.7143, acc=46.56% (best=46.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6997, acc=58.67% (best=58.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7050, acc=63.36% (best=63.36%)\n",
      "          Fold 5 Epoch 5: loss=0.4918, acc=51.48% (best=52.66%)\n",
      "          Fold 1 Epoch 5: loss=0.4642, acc=64.30% (best=64.30%)\n",
      "          Fold 4 Epoch 5: loss=0.4352, acc=55.39% (best=58.67%)\n",
      "          Fold 2 Epoch 5: loss=0.4481, acc=53.75% (best=56.02%)\n",
      "          Fold 3 Epoch 5: loss=0.3784, acc=63.20% (best=63.36%)\n",
      "          Fold 5 Epoch 10: loss=0.3509, acc=40.62% (best=57.66%)\n",
      "          Fold 1 Epoch 10: loss=0.3206, acc=66.25% (best=66.25%)\n",
      "          Fold 4 Epoch 10: loss=0.3333, acc=56.02% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.3314, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 10: loss=0.2898, acc=59.92% (best=63.36%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 63.36%\n",
      "          Fold 1 Epoch 15: loss=0.2782, acc=59.61% (best=66.25%)\n",
      "          Fold 5 Epoch 15: loss=0.2965, acc=54.69% (best=57.66%)\n",
      "          Fold 4 Epoch 15: loss=0.2952, acc=61.56% (best=64.06%)\n",
      "          Fold 2 Epoch 15: loss=0.2885, acc=54.14% (best=67.50%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 1 Epoch 20: loss=0.2523, acc=56.33% (best=66.25%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 66.25%\n",
      "          Fold 4 Epoch 20: loss=0.2668, acc=58.67% (best=64.06%)\n",
      "          Fold 2 Epoch 20: loss=0.2742, acc=51.09% (best=67.50%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 64.06%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 67.50%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c8a03d3a:\n",
      "        Fold accuracies: ['66.25%', '67.50%', '63.36%', '64.06%', '57.66%']\n",
      "        Average fitness: 63.77% Â± 3.40%\n",
      "        Best fold: Fold 2 with 67.50%\n",
      "      Fitness obtained: 63.77% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: c551493d)\n",
      "      Architecture: 10 conv + 5 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model c551493d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7217, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.6986, acc=49.38% (best=49.38%)\n",
      "          Fold 2 Epoch 1: loss=0.7050, acc=44.45% (best=44.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7170, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7121, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 5: loss=0.6817, acc=41.80% (best=44.45%)\n",
      "          Fold 5 Epoch 5: loss=0.7057, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 5: loss=0.6612, acc=49.22% (best=49.38%)\n",
      "          Fold 3 Epoch 5: loss=0.6992, acc=58.98% (best=58.98%)\n",
      "          Fold 1 Epoch 5: loss=0.6885, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 10: loss=0.6574, acc=46.48% (best=46.95%)\n",
      "          Fold 4 Epoch 10: loss=0.6354, acc=48.59% (best=49.38%)\n",
      "          Fold 5 Epoch 10: loss=0.6956, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 10: loss=0.6826, acc=56.33% (best=59.84%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.38%\n",
      "          Fold 1 Epoch 10: loss=0.6679, acc=50.16% (best=50.23%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.23%\n",
      "          Fold 2 Epoch 15: loss=0.6079, acc=46.56% (best=47.58%)\n",
      "          Fold 5 Epoch 15: loss=0.6499, acc=50.00% (best=50.08%)\n",
      "          Fold 3 Epoch 15: loss=0.6328, acc=54.06% (best=59.84%)\n",
      "          Fold 2 Epoch 20: loss=0.5169, acc=52.66% (best=52.66%)\n",
      "          Fold 5 Epoch 20: loss=0.5679, acc=50.00% (best=52.89%)\n",
      "          Fold 3 Epoch 20: loss=0.5504, acc=62.50% (best=66.25%)\n",
      "          Fold 2 Epoch 25: loss=0.4179, acc=52.66% (best=52.89%)\n",
      "          Fold 5 Epoch 25: loss=0.4854, acc=46.80% (best=52.89%)\n",
      "          Fold 3 Epoch 25: loss=0.4708, acc=61.17% (best=66.25%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 66.25%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 52.89%\n",
      "          Fold 2 Epoch 30: loss=0.3757, acc=49.61% (best=52.89%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 52.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c551493d:\n",
      "        Fold accuracies: ['50.23%', '52.89%', '66.25%', '49.38%', '52.89%']\n",
      "        Average fitness: 54.33% Â± 6.12%\n",
      "        Best fold: Fold 3 with 66.25%\n",
      "      Fitness obtained: 54.33% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: bb1a0735)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model bb1a0735 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6827, acc=48.52% (best=48.52%)\n",
      "          Fold 3 Epoch 1: loss=0.6693, acc=54.92% (best=54.92%)\n",
      "          Fold 1 Epoch 1: loss=0.6988, acc=52.50% (best=52.50%)\n",
      "          Fold 5 Epoch 1: loss=0.6921, acc=65.94% (best=65.94%)\n",
      "          Fold 2 Epoch 5: loss=0.3235, acc=41.25% (best=55.16%)\n",
      "          Fold 3 Epoch 5: loss=0.3409, acc=59.30% (best=66.56%)\n",
      "          Fold 1 Epoch 5: loss=0.3594, acc=57.11% (best=63.36%)\n",
      "          Fold 5 Epoch 5: loss=0.3050, acc=49.38% (best=65.94%)\n",
      "          Fold 2 Epoch 10: loss=0.2510, acc=54.61% (best=55.16%)\n",
      "          Fold 3 Epoch 10: loss=0.2592, acc=65.55% (best=70.70%)\n",
      "          Fold 1 Epoch 10: loss=0.2672, acc=46.88% (best=63.36%)\n",
      "          Fold 5 Epoch 10: loss=0.2491, acc=41.48% (best=65.94%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 55.16%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 63.36%\n",
      "          Fold 3 Epoch 15: loss=0.2379, acc=59.14% (best=70.70%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 70.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for bb1a0735:\n",
      "        Fold accuracies: ['63.36%', '55.16%', '70.70%', '0.00%', '65.94%']\n",
      "        Average fitness: 51.03% Â± 26.01%\n",
      "        Best fold: Fold 3 with 70.70%\n",
      "      Fitness obtained: 51.03% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 38b6c60e)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 38b6c60e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6988, acc=49.14% (best=49.14%)\n",
      "          Fold 3 Epoch 1: loss=0.7203, acc=56.95% (best=56.95%)\n",
      "          Fold 2 Epoch 1: loss=0.7080, acc=55.55% (best=55.55%)\n",
      "          Fold 5 Epoch 1: loss=0.7165, acc=59.84% (best=59.84%)\n",
      "          Fold 1 Epoch 1: loss=0.7102, acc=46.64% (best=46.64%)\n",
      "          Fold 4 Epoch 5: loss=0.6350, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 5: loss=0.7013, acc=58.91% (best=61.48%)\n",
      "          Fold 2 Epoch 5: loss=0.6641, acc=51.02% (best=55.55%)\n",
      "          Fold 5 Epoch 5: loss=0.7067, acc=44.14% (best=59.84%)\n",
      "          Fold 1 Epoch 5: loss=0.6870, acc=53.52% (best=57.81%)\n",
      "          Fold 4 Epoch 10: loss=0.5683, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 10: loss=0.6096, acc=47.34% (best=61.48%)\n",
      "          Fold 2 Epoch 10: loss=0.5642, acc=53.12% (best=58.83%)\n",
      "          Fold 5 Epoch 10: loss=0.7007, acc=53.52% (best=59.84%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.84%\n",
      "          Fold 1 Epoch 10: loss=0.6111, acc=51.09% (best=57.81%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 61.48%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 57.81%\n",
      "          Fold 4 Epoch 15: loss=0.4806, acc=58.75% (best=59.38%)\n",
      "          Fold 2 Epoch 15: loss=0.4301, acc=39.38% (best=58.83%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 58.83%\n",
      "          Fold 4 Epoch 20: loss=0.4103, acc=57.89% (best=63.67%)\n",
      "          Fold 4 Epoch 25: loss=0.3678, acc=58.36% (best=63.91%)\n",
      "          Fold 4 Epoch 30: loss=0.3480, acc=57.50% (best=63.91%)\n",
      "          Fold 4: Early stopping at epoch 34\n",
      "      â†’ Fold 4 completed: 63.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 38b6c60e:\n",
      "        Fold accuracies: ['57.81%', '58.83%', '61.48%', '63.91%', '59.84%']\n",
      "        Average fitness: 60.38% Â± 2.14%\n",
      "        Best fold: Fold 4 with 63.91%\n",
      "      Fitness obtained: 60.38% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 725b056e)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 725b056e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7079, acc=46.25% (best=46.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7186, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 1: loss=0.7287, acc=43.67% (best=43.67%)\n",
      "          Fold 3 Epoch 1: loss=0.7204, acc=49.30% (best=49.30%)\n",
      "          Fold 4 Epoch 1: loss=0.7222, acc=59.45% (best=59.45%)\n",
      "          Fold 2 Epoch 5: loss=0.6796, acc=43.28% (best=43.67%)\n",
      "          Fold 1 Epoch 5: loss=0.6960, acc=58.28% (best=59.06%)\n",
      "          Fold 5 Epoch 5: loss=0.7106, acc=46.95% (best=59.84%)\n",
      "          Fold 3 Epoch 5: loss=0.7017, acc=54.84% (best=55.86%)\n",
      "          Fold 4 Epoch 5: loss=0.6838, acc=61.56% (best=65.94%)\n",
      "          Fold 1 Epoch 10: loss=0.6861, acc=56.02% (best=60.23%)\n",
      "          Fold 2 Epoch 10: loss=0.6682, acc=40.55% (best=43.67%)\n",
      "          Fold 5 Epoch 10: loss=0.7007, acc=50.00% (best=59.84%)\n",
      "          Fold 3 Epoch 10: loss=0.6942, acc=56.48% (best=58.12%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 43.67%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.84%\n",
      "          Fold 4 Epoch 10: loss=0.6669, acc=50.00% (best=65.94%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "          Fold 1 Epoch 15: loss=0.6676, acc=56.88% (best=61.33%)\n",
      "          Fold 3 Epoch 15: loss=0.6773, acc=53.36% (best=58.12%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 58.12%\n",
      "          Fold 1 Epoch 20: loss=0.6229, acc=67.03% (best=67.03%)\n",
      "          Fold 1 Epoch 25: loss=0.5597, acc=69.14% (best=69.14%)\n",
      "          Fold 1 Epoch 30: loss=0.5009, acc=59.38% (best=69.14%)\n",
      "          Fold 1 Epoch 35: loss=0.4469, acc=59.69% (best=69.14%)\n",
      "          Fold 1: Early stopping at epoch 35\n",
      "      â†’ Fold 1 completed: 69.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 725b056e:\n",
      "        Fold accuracies: ['69.14%', '43.67%', '58.12%', '65.94%', '59.84%']\n",
      "        Average fitness: 59.34% Â± 8.80%\n",
      "        Best fold: Fold 1 with 69.14%\n",
      "      Fitness obtained: 59.34% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: cf7716c4)\n",
      "      Architecture: 12 conv + 7 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model cf7716c4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7386, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7183, acc=58.36% (best=58.36%)\n",
      "          Fold 3 Epoch 1: loss=0.7158, acc=50.78% (best=50.78%)\n",
      "          Fold 2 Epoch 1: loss=0.7359, acc=49.06% (best=49.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7197, acc=51.95% (best=51.95%)\n",
      "          Fold 1 Epoch 5: loss=0.7233, acc=49.69% (best=49.84%)\n",
      "          Fold 4 Epoch 5: loss=0.7126, acc=56.33% (best=58.83%)\n",
      "          Fold 3 Epoch 5: loss=0.7228, acc=56.33% (best=61.09%)\n",
      "          Fold 2 Epoch 5: loss=0.7240, acc=52.58% (best=52.58%)\n",
      "          Fold 5 Epoch 5: loss=0.7169, acc=51.02% (best=55.23%)\n",
      "          Fold 1 Epoch 10: loss=0.7145, acc=50.00% (best=53.05%)\n",
      "          Fold 4 Epoch 10: loss=0.7168, acc=64.14% (best=64.14%)\n",
      "          Fold 3 Epoch 10: loss=0.7135, acc=45.08% (best=61.09%)\n",
      "          Fold 2 Epoch 10: loss=0.7208, acc=46.48% (best=52.58%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 61.09%\n",
      "          Fold 5 Epoch 10: loss=0.7177, acc=53.20% (best=55.23%)\n",
      "          Fold 1 Epoch 15: loss=0.7162, acc=52.58% (best=53.05%)\n",
      "          Fold 4 Epoch 15: loss=0.7126, acc=63.05% (best=65.70%)\n",
      "          Fold 2 Epoch 15: loss=0.7119, acc=48.36% (best=57.03%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 55.23%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 53.05%\n",
      "          Fold 4 Epoch 20: loss=0.7110, acc=66.88% (best=66.88%)\n",
      "          Fold 2 Epoch 20: loss=0.7151, acc=42.66% (best=58.12%)\n",
      "          Fold 4 Epoch 25: loss=0.7125, acc=63.52% (best=75.62%)\n",
      "          Fold 2 Epoch 25: loss=0.7143, acc=48.05% (best=64.14%)\n",
      "          Fold 4 Epoch 30: loss=0.7121, acc=61.48% (best=75.62%)\n",
      "          Fold 2 Epoch 30: loss=0.7143, acc=40.55% (best=64.14%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 75.62%\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 64.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cf7716c4:\n",
      "        Fold accuracies: ['53.05%', '64.14%', '61.09%', '75.62%', '55.23%']\n",
      "        Average fitness: 61.83% Â± 7.96%\n",
      "        Best fold: Fold 4 with 75.62%\n",
      "      Fitness obtained: 61.83% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 6efc4ab5)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6efc4ab5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6847, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7090, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7184, acc=50.78% (best=50.78%)\n",
      "          Fold 2 Epoch 1: loss=0.7030, acc=56.02% (best=56.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7241, acc=46.56% (best=46.56%)\n",
      "          Fold 4 Epoch 5: loss=0.4307, acc=51.33% (best=66.56%)\n",
      "          Fold 1 Epoch 5: loss=0.5011, acc=44.77% (best=53.20%)\n",
      "          Fold 3 Epoch 5: loss=0.4132, acc=55.78% (best=55.78%)\n",
      "          Fold 2 Epoch 5: loss=0.4050, acc=47.89% (best=56.02%)\n",
      "          Fold 5 Epoch 5: loss=0.4677, acc=45.47% (best=50.08%)\n",
      "          Fold 4 Epoch 10: loss=0.3175, acc=46.56% (best=66.56%)\n",
      "          Fold 1 Epoch 10: loss=0.3806, acc=55.08% (best=59.84%)\n",
      "          Fold 3 Epoch 10: loss=0.3208, acc=59.53% (best=65.78%)\n",
      "          Fold 2 Epoch 10: loss=0.3087, acc=52.89% (best=56.02%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.02%\n",
      "          Fold 5 Epoch 10: loss=0.3350, acc=49.06% (best=51.95%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.56%\n",
      "          Fold 1 Epoch 15: loss=0.3092, acc=54.69% (best=60.62%)\n",
      "          Fold 3 Epoch 15: loss=0.2775, acc=47.66% (best=67.58%)\n",
      "          Fold 5 Epoch 15: loss=0.2811, acc=41.88% (best=51.95%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 51.95%\n",
      "          Fold 1 Epoch 20: loss=0.2694, acc=62.11% (best=62.11%)\n",
      "          Fold 3 Epoch 20: loss=0.2485, acc=62.50% (best=70.70%)\n",
      "          Fold 1 Epoch 25: loss=0.2475, acc=59.53% (best=62.11%)\n",
      "          Fold 3 Epoch 25: loss=0.2411, acc=59.84% (best=70.86%)\n",
      "          Fold 1 Epoch 30: loss=0.2342, acc=67.66% (best=67.66%)\n",
      "          Fold 3 Epoch 30: loss=0.2316, acc=69.84% (best=70.86%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 70.86%\n",
      "          Fold 1 Epoch 35: loss=0.2280, acc=58.52% (best=67.66%)\n",
      "          Fold 1 Epoch 40: loss=0.2160, acc=57.58% (best=67.66%)\n",
      "          Fold 1: Early stopping at epoch 40\n",
      "      â†’ Fold 1 completed: 67.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6efc4ab5:\n",
      "        Fold accuracies: ['67.66%', '56.02%', '70.86%', '66.56%', '51.95%']\n",
      "        Average fitness: 62.61% Â± 7.30%\n",
      "        Best fold: Fold 3 with 70.86%\n",
      "      Fitness obtained: 62.61% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 26fb27fc)\n",
      "      Architecture: 12 conv + 9 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 26fb27fc with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 4 Epoch 1: loss=0.7168, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7355, acc=43.12% (best=43.12%)\n",
      "          Fold 5 Epoch 1: loss=0.7458, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7200, acc=43.67% (best=43.67%)\n",
      "          Fold 4 Epoch 5: loss=0.5704, acc=58.83% (best=62.97%)\n",
      "          Fold 1 Epoch 5: loss=0.6634, acc=59.53% (best=59.53%)\n",
      "          Fold 2 Epoch 5: loss=0.6634, acc=54.92% (best=54.92%)\n",
      "          Fold 5 Epoch 5: loss=0.6952, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 10: loss=0.3293, acc=55.94% (best=62.97%)\n",
      "          Fold 1 Epoch 10: loss=0.4156, acc=56.72% (best=60.47%)\n",
      "          Fold 2 Epoch 10: loss=0.3830, acc=56.33% (best=56.33%)\n",
      "          Fold 5 Epoch 10: loss=0.6417, acc=44.69% (best=54.06%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 62.97%\n",
      "          Fold 1 Epoch 15: loss=0.3154, acc=48.05% (best=60.47%)\n",
      "          Fold 2 Epoch 15: loss=0.3080, acc=60.16% (best=65.08%)\n",
      "          Fold 5 Epoch 15: loss=0.3286, acc=55.70% (best=55.70%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 60.47%\n",
      "          Fold 2 Epoch 20: loss=0.2681, acc=49.84% (best=65.08%)\n",
      "          Fold 5 Epoch 20: loss=0.2618, acc=46.56% (best=55.70%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 65.08%\n",
      "          Fold 5 Epoch 25: loss=0.2474, acc=49.38% (best=55.70%)\n",
      "          Fold 5: Early stopping at epoch 25\n",
      "      â†’ Fold 5 completed: 55.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 26fb27fc:\n",
      "        Fold accuracies: ['60.47%', '65.08%', '0.00%', '62.97%', '55.70%']\n",
      "        Average fitness: 48.84% Â± 24.62%\n",
      "        Best fold: Fold 2 with 65.08%\n",
      "      Fitness obtained: 48.84% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 8599c291)\n",
      "      Architecture: 10 conv + 7 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 8599c291 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7209, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7169, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7212, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7182, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7211, acc=48.36% (best=48.36%)\n",
      "          Fold 3 Epoch 5: loss=0.6831, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 5: loss=0.6940, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 5: loss=0.6405, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6619, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 5: loss=0.7046, acc=47.19% (best=63.36%)\n",
      "          Fold 3 Epoch 10: loss=0.5397, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 10: loss=0.6303, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 10: loss=0.5318, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 10: loss=0.5958, acc=49.61% (best=49.61%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 49.77%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.22%\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 49.61%\n",
      "          Fold 5 Epoch 10: loss=0.6947, acc=50.00% (best=63.36%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8599c291:\n",
      "        Fold accuracies: ['49.77%', '49.61%', '51.02%', '49.22%', '63.36%']\n",
      "        Average fitness: 52.59% Â± 5.42%\n",
      "        Best fold: Fold 5 with 63.36%\n",
      "      Fitness obtained: 52.59% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: eece22c5)\n",
      "      Architecture: 10 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eece22c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6657, acc=43.44% (best=43.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6725, acc=41.95% (best=41.95%)\n",
      "          Fold 5 Epoch 1: loss=0.6702, acc=49.92% (best=49.92%)\n",
      "          Fold 1 Epoch 1: loss=0.6807, acc=46.09% (best=46.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6416, acc=63.05% (best=63.05%)\n",
      "          Fold 3 Epoch 5: loss=0.3128, acc=53.12% (best=58.91%)\n",
      "          Fold 1 Epoch 5: loss=0.4091, acc=61.33% (best=61.33%)\n",
      "          Fold 5 Epoch 5: loss=0.3440, acc=48.67% (best=56.09%)\n",
      "          Fold 2 Epoch 5: loss=0.3311, acc=40.23% (best=44.69%)\n",
      "          Fold 4 Epoch 5: loss=0.3342, acc=60.08% (best=69.77%)\n",
      "          Fold 3 Epoch 10: loss=0.2569, acc=64.38% (best=65.08%)\n",
      "          Fold 1 Epoch 10: loss=0.2911, acc=59.92% (best=63.28%)\n",
      "          Fold 5 Epoch 10: loss=0.2762, acc=45.16% (best=56.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2699, acc=50.55% (best=51.33%)\n",
      "          Fold 4 Epoch 10: loss=0.2709, acc=62.58% (best=70.00%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.09%\n",
      "          Fold 3 Epoch 15: loss=0.2329, acc=58.83% (best=65.08%)\n",
      "          Fold 1 Epoch 15: loss=0.2496, acc=63.20% (best=67.97%)\n",
      "          Fold 2 Epoch 15: loss=0.2382, acc=46.25% (best=56.09%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 65.08%\n",
      "          Fold 4 Epoch 15: loss=0.2379, acc=49.38% (best=70.00%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 70.00%\n",
      "          Fold 2 Epoch 20: loss=0.2334, acc=44.22% (best=56.09%)\n",
      "          Fold 1 Epoch 20: loss=0.2366, acc=58.52% (best=67.97%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 67.97%\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eece22c5:\n",
      "        Fold accuracies: ['67.97%', '56.09%', '65.08%', '70.00%', '56.09%']\n",
      "        Average fitness: 63.05% Â± 5.89%\n",
      "        Best fold: Fold 4 with 70.00%\n",
      "      Fitness obtained: 63.05% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 452d2536)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 452d2536 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7231, acc=64.92% (best=64.92%)\n",
      "          Fold 1 Epoch 1: loss=0.7137, acc=57.42% (best=57.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6830, acc=57.89% (best=57.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7370, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 1: loss=0.7124, acc=53.36% (best=53.36%)\n",
      "          Fold 5 Epoch 5: loss=0.4777, acc=48.05% (best=54.30%)\n",
      "          Fold 1 Epoch 5: loss=0.5010, acc=50.16% (best=57.42%)\n",
      "          Fold 4 Epoch 5: loss=0.5162, acc=48.28% (best=59.14%)\n",
      "          Fold 3 Epoch 5: loss=0.5029, acc=51.25% (best=64.92%)\n",
      "          Fold 2 Epoch 5: loss=0.4522, acc=56.02% (best=59.06%)\n",
      "          Fold 5 Epoch 10: loss=0.3585, acc=68.83% (best=68.83%)\n",
      "          Fold 1 Epoch 10: loss=0.3943, acc=58.44% (best=59.92%)\n",
      "          Fold 4 Epoch 10: loss=0.3854, acc=58.28% (best=68.05%)\n",
      "          Fold 3 Epoch 10: loss=0.3990, acc=60.31% (best=68.05%)\n",
      "          Fold 2 Epoch 10: loss=0.3534, acc=47.81% (best=59.06%)\n",
      "          Fold 1 Epoch 15: loss=0.3435, acc=57.11% (best=59.92%)\n",
      "          Fold 5 Epoch 15: loss=0.3109, acc=70.70% (best=70.70%)\n",
      "          Fold 4 Epoch 15: loss=0.3135, acc=53.28% (best=68.05%)\n",
      "          Fold 3 Epoch 15: loss=0.3525, acc=60.00% (best=68.05%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 59.06%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 68.05%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 59.92%\n",
      "          Fold 5 Epoch 20: loss=0.2779, acc=60.39% (best=70.70%)\n",
      "          Fold 5 Epoch 25: loss=0.2587, acc=55.23% (best=74.30%)\n",
      "          Fold 5 Epoch 30: loss=0.2456, acc=61.72% (best=74.30%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 74.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 452d2536:\n",
      "        Fold accuracies: ['59.92%', '59.06%', '68.05%', '68.05%', '74.30%']\n",
      "        Average fitness: 65.88% Â± 5.70%\n",
      "        Best fold: Fold 5 with 74.30%\n",
      "      Fitness obtained: 65.88% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4eb2b042)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 4eb2b042 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6841, acc=38.52% (best=38.52%)\n",
      "          Fold 5 Epoch 1: loss=0.6976, acc=47.58% (best=47.58%)\n",
      "          Fold 1 Epoch 1: loss=0.6860, acc=49.84% (best=49.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6725, acc=48.44% (best=48.44%)\n",
      "          Fold 3 Epoch 1: loss=0.7016, acc=41.72% (best=41.72%)\n",
      "          Fold 2 Epoch 5: loss=0.4170, acc=52.42% (best=52.42%)\n",
      "          Fold 5 Epoch 5: loss=0.4273, acc=48.12% (best=54.61%)\n",
      "          Fold 1 Epoch 5: loss=0.4425, acc=48.98% (best=49.84%)\n",
      "          Fold 4 Epoch 5: loss=0.3976, acc=53.20% (best=61.17%)\n",
      "          Fold 3 Epoch 5: loss=0.4100, acc=51.56% (best=63.20%)\n",
      "          Fold 2 Epoch 10: loss=0.3168, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 10: loss=0.3168, acc=43.12% (best=58.59%)\n",
      "          Fold 1 Epoch 10: loss=0.3280, acc=51.41% (best=54.77%)\n",
      "          Fold 4 Epoch 10: loss=0.2817, acc=44.06% (best=61.17%)\n",
      "          Fold 3 Epoch 10: loss=0.3063, acc=62.97% (best=72.89%)\n",
      "          Fold 2 Epoch 15: loss=0.2761, acc=51.33% (best=63.83%)\n",
      "          Fold 5 Epoch 15: loss=0.2787, acc=45.16% (best=58.59%)\n",
      "          Fold 1 Epoch 15: loss=0.2791, acc=59.69% (best=61.80%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 61.17%\n",
      "          Fold 3 Epoch 15: loss=0.2573, acc=58.36% (best=72.89%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 72.89%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 58.59%\n",
      "          Fold 2 Epoch 20: loss=0.2603, acc=52.58% (best=63.83%)\n",
      "          Fold 1 Epoch 20: loss=0.2559, acc=70.16% (best=70.16%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 63.83%\n",
      "          Fold 1 Epoch 25: loss=0.2396, acc=57.89% (best=70.16%)\n",
      "          Fold 1 Epoch 30: loss=0.2250, acc=54.77% (best=70.16%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 70.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4eb2b042:\n",
      "        Fold accuracies: ['70.16%', '63.83%', '72.89%', '61.17%', '58.59%']\n",
      "        Average fitness: 65.33% Â± 5.39%\n",
      "        Best fold: Fold 3 with 72.89%\n",
      "      Fitness obtained: 65.33% | Best in generation: 66.42% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: f65c7336)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f65c7336 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6692, acc=60.86% (best=60.86%)\n",
      "          Fold 5 Epoch 1: loss=0.6889, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6592, acc=58.05% (best=58.05%)\n",
      "          Fold 3 Epoch 1: loss=0.6554, acc=55.23% (best=55.23%)\n",
      "          Fold 1 Epoch 1: loss=0.6974, acc=51.48% (best=51.48%)\n",
      "          Fold 2 Epoch 5: loss=0.3272, acc=65.94% (best=65.94%)\n",
      "          Fold 4 Epoch 5: loss=0.3499, acc=56.48% (best=69.38%)\n",
      "          Fold 5 Epoch 5: loss=0.3268, acc=49.53% (best=64.06%)\n",
      "          Fold 3 Epoch 5: loss=0.3177, acc=54.53% (best=64.61%)\n",
      "          Fold 1 Epoch 5: loss=0.3413, acc=49.77% (best=58.75%)\n",
      "          Fold 2 Epoch 10: loss=0.2641, acc=40.08% (best=72.19%)\n",
      "          Fold 4 Epoch 10: loss=0.2642, acc=55.86% (best=69.38%)\n",
      "          Fold 5 Epoch 10: loss=0.2554, acc=57.89% (best=64.06%)\n",
      "          Fold 3 Epoch 10: loss=0.2573, acc=61.48% (best=69.45%)\n",
      "          Fold 1 Epoch 10: loss=0.2678, acc=54.92% (best=64.61%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 69.38%\n",
      "          Fold 2 Epoch 15: loss=0.2425, acc=64.14% (best=72.19%)\n",
      "          Fold 3 Epoch 15: loss=0.2418, acc=62.11% (best=69.45%)\n",
      "          Fold 1 Epoch 15: loss=0.2396, acc=59.30% (best=64.61%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 72.19%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 69.45%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 64.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f65c7336:\n",
      "        Fold accuracies: ['64.61%', '72.19%', '69.45%', '69.38%', '64.06%']\n",
      "        Average fitness: 67.94% Â± 3.12%\n",
      "        Best fold: Fold 2 with 72.19%\n",
      "      New best fitness in this generation: 67.94%!\n",
      "      Fitness obtained: 67.94% | Best in generation: 67.94% | Global best: 70.92%\n",
      "\n",
      "GENERATION 17 STATISTICS:\n",
      "   Maximum fitness: 67.94%\n",
      "   Average fitness: 60.85%\n",
      "   Minimum fitness: 48.84%\n",
      "   Standard deviation: 5.16%\n",
      "   Best individual: f65c7336 with 67.94%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 6/20\n",
      "Adaptive mutation rate updated to 0.2435 (std_fitness=5.16)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: f65c7336 (fitness: 67.94%)\n",
      "   Elite 2: b30f77bf (fitness: 66.42%)\n",
      "   Elite 3: 452d2536 (fitness: 65.88%)\n",
      "   Elite 4: e5bf30b2 (fitness: 65.69%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 7/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 18\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 18)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: f65c7336)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f65c7336 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6863, acc=51.56% (best=51.56%)\n",
      "          Fold 3 Epoch 1: loss=0.6630, acc=55.86% (best=55.86%)\n",
      "          Fold 5 Epoch 1: loss=0.6765, acc=52.11% (best=52.11%)\n",
      "          Fold 1 Epoch 1: loss=0.6889, acc=54.53% (best=54.53%)\n",
      "          Fold 4 Epoch 1: loss=0.6851, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 5: loss=0.3420, acc=51.88% (best=58.12%)\n",
      "          Fold 3 Epoch 5: loss=0.3381, acc=59.14% (best=59.14%)\n",
      "          Fold 5 Epoch 5: loss=0.3196, acc=50.55% (best=54.45%)\n",
      "          Fold 1 Epoch 5: loss=0.3563, acc=52.81% (best=64.22%)\n",
      "          Fold 4 Epoch 5: loss=0.3462, acc=41.72% (best=57.27%)\n",
      "          Fold 2 Epoch 10: loss=0.2724, acc=54.61% (best=58.12%)\n",
      "          Fold 3 Epoch 10: loss=0.2700, acc=57.42% (best=59.14%)\n",
      "          Fold 5 Epoch 10: loss=0.2598, acc=51.56% (best=61.17%)\n",
      "          Fold 1 Epoch 10: loss=0.2761, acc=61.17% (best=64.84%)\n",
      "          Fold 4 Epoch 10: loss=0.2662, acc=56.56% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.12%\n",
      "          Fold 3 Epoch 15: loss=0.2392, acc=53.05% (best=59.84%)\n",
      "          Fold 5 Epoch 15: loss=0.2356, acc=58.44% (best=61.17%)\n",
      "          Fold 1 Epoch 15: loss=0.2471, acc=57.03% (best=64.84%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 64.84%\n",
      "          Fold 4 Epoch 15: loss=0.2445, acc=59.77% (best=68.05%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 61.17%\n",
      "          Fold 3 Epoch 20: loss=0.2259, acc=49.14% (best=61.64%)\n",
      "          Fold 4 Epoch 20: loss=0.2273, acc=51.33% (best=68.05%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 3 Epoch 25: loss=0.2226, acc=44.77% (best=61.64%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 61.64%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f65c7336:\n",
      "        Fold accuracies: ['64.84%', '58.12%', '61.64%', '68.05%', '61.17%']\n",
      "        Average fitness: 62.77% Â± 3.39%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      New best fitness in this generation: 62.77%!\n",
      "      Fitness obtained: 62.77% | Best in generation: 62.77% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: b30f77bf)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model b30f77bf with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6942, acc=50.70% (best=50.70%)\n",
      "          Fold 3 Epoch 1: loss=0.7127, acc=46.64% (best=46.64%)\n",
      "          Fold 4 Epoch 1: loss=0.6929, acc=58.44% (best=58.44%)\n",
      "          Fold 1 Epoch 1: loss=0.7133, acc=59.06% (best=59.06%)\n",
      "          Fold 5 Epoch 1: loss=0.7165, acc=50.78% (best=50.78%)\n",
      "          Fold 3 Epoch 5: loss=0.6209, acc=57.42% (best=58.12%)\n",
      "          Fold 4 Epoch 5: loss=0.5632, acc=55.39% (best=64.14%)\n",
      "          Fold 2 Epoch 5: loss=0.6284, acc=37.97% (best=52.58%)\n",
      "          Fold 5 Epoch 5: loss=0.6828, acc=45.39% (best=50.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6920, acc=56.56% (best=59.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3915, acc=57.73% (best=58.12%)\n",
      "          Fold 4 Epoch 10: loss=0.3661, acc=60.70% (best=71.17%)\n",
      "          Fold 2 Epoch 10: loss=0.4481, acc=57.50% (best=57.50%)\n",
      "          Fold 5 Epoch 10: loss=0.4332, acc=47.89% (best=60.23%)\n",
      "          Fold 1 Epoch 10: loss=0.5469, acc=51.64% (best=59.45%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 3 Epoch 15: loss=0.3318, acc=63.59% (best=63.59%)\n",
      "          Fold 4 Epoch 15: loss=0.2992, acc=58.44% (best=71.17%)\n",
      "          Fold 2 Epoch 15: loss=0.3438, acc=45.62% (best=57.50%)\n",
      "          Fold 5 Epoch 15: loss=0.3526, acc=48.83% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "          Fold 3 Epoch 20: loss=0.2837, acc=57.89% (best=63.59%)\n",
      "          Fold 2 Epoch 20: loss=0.3111, acc=47.66% (best=57.50%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 57.50%\n",
      "          Fold 3 Epoch 25: loss=0.2570, acc=62.03% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b30f77bf:\n",
      "        Fold accuracies: ['59.45%', '57.50%', '63.59%', '71.17%', '60.23%']\n",
      "        Average fitness: 62.39% Â± 4.81%\n",
      "        Best fold: Fold 4 with 71.17%\n",
      "      Fitness obtained: 62.39% | Best in generation: 62.77% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 452d2536)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 452d2536 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6938, acc=36.80% (best=36.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7257, acc=47.73% (best=47.73%)\n",
      "          Fold 4 Epoch 1: loss=0.6904, acc=60.39% (best=60.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7203, acc=59.22% (best=59.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7473, acc=47.19% (best=47.19%)\n",
      "          Fold 3 Epoch 5: loss=0.4833, acc=51.64% (best=59.92%)\n",
      "          Fold 2 Epoch 5: loss=0.4693, acc=49.61% (best=61.25%)\n",
      "          Fold 4 Epoch 5: loss=0.5207, acc=58.67% (best=67.73%)\n",
      "          Fold 5 Epoch 5: loss=0.5343, acc=45.23% (best=54.30%)\n",
      "          Fold 1 Epoch 5: loss=0.5294, acc=53.12% (best=59.22%)\n",
      "          Fold 3 Epoch 10: loss=0.3832, acc=55.94% (best=59.92%)\n",
      "          Fold 2 Epoch 10: loss=0.3783, acc=39.53% (best=61.25%)\n",
      "          Fold 4 Epoch 10: loss=0.4186, acc=58.52% (best=67.73%)\n",
      "          Fold 5 Epoch 10: loss=0.4015, acc=55.39% (best=57.58%)\n",
      "          Fold 1 Epoch 10: loss=0.4040, acc=58.36% (best=59.22%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.22%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 67.73%\n",
      "          Fold 3 Epoch 15: loss=0.3326, acc=54.84% (best=62.58%)\n",
      "          Fold 2 Epoch 15: loss=0.3217, acc=52.03% (best=64.30%)\n",
      "          Fold 5 Epoch 15: loss=0.3414, acc=54.77% (best=60.23%)\n",
      "          Fold 3 Epoch 20: loss=0.2904, acc=54.22% (best=62.58%)\n",
      "          Fold 2 Epoch 20: loss=0.2870, acc=59.14% (best=65.23%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "          Fold 5 Epoch 20: loss=0.3009, acc=51.17% (best=60.23%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 2 Epoch 25: loss=0.2706, acc=50.70% (best=65.23%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 65.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 452d2536:\n",
      "        Fold accuracies: ['59.22%', '65.23%', '62.58%', '67.73%', '60.23%']\n",
      "        Average fitness: 63.00% Â± 3.15%\n",
      "        Best fold: Fold 4 with 67.73%\n",
      "      New best fitness in this generation: 63.00%!\n",
      "      Fitness obtained: 63.00% | Best in generation: 63.00% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: e5bf30b2)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e5bf30b2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7276, acc=42.89% (best=42.89%)\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=56.09% (best=56.09%)\n",
      "          Fold 4 Epoch 1: loss=0.7147, acc=30.78% (best=30.78%)\n",
      "          Fold 2 Epoch 1: loss=0.7127, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7366, acc=46.95% (best=46.95%)\n",
      "          Fold 1 Epoch 5: loss=0.4526, acc=51.64% (best=55.31%)\n",
      "          Fold 4 Epoch 5: loss=0.4294, acc=41.25% (best=52.58%)\n",
      "          Fold 3 Epoch 5: loss=0.4137, acc=53.59% (best=56.09%)\n",
      "          Fold 2 Epoch 5: loss=0.4082, acc=49.38% (best=53.44%)\n",
      "          Fold 5 Epoch 5: loss=0.3951, acc=47.73% (best=64.61%)\n",
      "          Fold 1 Epoch 10: loss=0.3628, acc=57.50% (best=57.81%)\n",
      "          Fold 4 Epoch 10: loss=0.3272, acc=47.19% (best=58.36%)\n",
      "          Fold 3 Epoch 10: loss=0.3253, acc=48.67% (best=64.06%)\n",
      "          Fold 2 Epoch 10: loss=0.3292, acc=46.41% (best=53.59%)\n",
      "          Fold 5 Epoch 10: loss=0.3269, acc=47.97% (best=64.61%)\n",
      "          Fold 1 Epoch 15: loss=0.3170, acc=56.25% (best=57.81%)\n",
      "          Fold 4 Epoch 15: loss=0.2798, acc=44.45% (best=58.36%)\n",
      "          Fold 3 Epoch 15: loss=0.2921, acc=58.52% (best=64.06%)\n",
      "          Fold 2 Epoch 15: loss=0.2940, acc=46.64% (best=53.59%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 53.59%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 64.61%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 1 Epoch 20: loss=0.2936, acc=53.91% (best=61.02%)\n",
      "          Fold 4 Epoch 20: loss=0.2542, acc=50.31% (best=59.22%)\n",
      "          Fold 1 Epoch 25: loss=0.2708, acc=54.30% (best=62.58%)\n",
      "          Fold 4 Epoch 25: loss=0.2429, acc=45.31% (best=59.22%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 59.22%\n",
      "          Fold 1 Epoch 30: loss=0.2644, acc=57.66% (best=62.58%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 62.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e5bf30b2:\n",
      "        Fold accuracies: ['62.58%', '53.59%', '64.06%', '59.22%', '64.61%']\n",
      "        Average fitness: 60.81% Â± 4.07%\n",
      "        Best fold: Fold 5 with 64.61%\n",
      "      Fitness obtained: 60.81% | Best in generation: 63.00% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: eeff0bb0)\n",
      "      Architecture: 5 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eeff0bb0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4141, acc=52.97% (best=52.97%)\n",
      "          Fold 3 Epoch 1: loss=0.3809, acc=60.62% (best=60.62%)\n",
      "          Fold 4 Epoch 1: loss=0.3827, acc=55.55% (best=55.55%)\n",
      "          Fold 1 Epoch 1: loss=0.3936, acc=53.28% (best=53.28%)\n",
      "          Fold 5 Epoch 1: loss=0.4027, acc=55.23% (best=55.23%)\n",
      "          Fold 2 Epoch 5: loss=0.2220, acc=42.97% (best=54.45%)\n",
      "          Fold 3 Epoch 5: loss=0.2181, acc=56.72% (best=67.66%)\n",
      "          Fold 1 Epoch 5: loss=0.2243, acc=42.42% (best=53.28%)\n",
      "          Fold 4 Epoch 5: loss=0.2102, acc=43.20% (best=57.97%)\n",
      "          Fold 5 Epoch 5: loss=0.2101, acc=47.42% (best=55.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2035, acc=47.58% (best=64.22%)\n",
      "          Fold 3 Epoch 10: loss=0.1999, acc=56.41% (best=67.66%)\n",
      "          Fold 1 Epoch 10: loss=0.1996, acc=57.81% (best=58.20%)\n",
      "          Fold 4 Epoch 10: loss=0.1915, acc=58.67% (best=58.67%)\n",
      "          Fold 5 Epoch 10: loss=0.1961, acc=54.30% (best=55.23%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 55.23%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 67.66%\n",
      "          Fold 2 Epoch 15: loss=0.1934, acc=54.22% (best=64.22%)\n",
      "          Fold 1 Epoch 15: loss=0.1930, acc=51.56% (best=58.20%)\n",
      "          Fold 4 Epoch 15: loss=0.1885, acc=52.27% (best=58.67%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 64.22%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 58.20%\n",
      "          Fold 4 Epoch 20: loss=0.1834, acc=46.48% (best=58.67%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 58.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eeff0bb0:\n",
      "        Fold accuracies: ['58.20%', '64.22%', '67.66%', '58.67%', '55.23%']\n",
      "        Average fitness: 60.80% Â± 4.49%\n",
      "        Best fold: Fold 3 with 67.66%\n",
      "      Fitness obtained: 60.80% | Best in generation: 63.00% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 83b9af13)\n",
      "      Architecture: 10 conv + 8 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 83b9af13 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[160], expected input with shape [*, 160], but got input of size[1, 160, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 83b9af13:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 1 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.00% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: cf9fca17)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cf9fca17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7244, acc=57.11% (best=57.11%)\n",
      "          Fold 2 Epoch 1: loss=0.7181, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7136, acc=58.83% (best=58.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7347, acc=54.92% (best=54.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6853, acc=49.30% (best=49.30%)\n",
      "          Fold 3 Epoch 5: loss=0.3426, acc=44.69% (best=60.70%)\n",
      "          Fold 1 Epoch 5: loss=0.4071, acc=62.03% (best=72.19%)\n",
      "          Fold 2 Epoch 5: loss=0.3378, acc=54.84% (best=54.84%)\n",
      "          Fold 5 Epoch 5: loss=0.3854, acc=50.55% (best=58.67%)\n",
      "          Fold 4 Epoch 5: loss=0.4100, acc=64.69% (best=68.83%)\n",
      "          Fold 3 Epoch 10: loss=0.2645, acc=58.20% (best=60.70%)\n",
      "          Fold 1 Epoch 10: loss=0.2785, acc=60.62% (best=72.19%)\n",
      "          Fold 2 Epoch 10: loss=0.2632, acc=52.50% (best=54.84%)\n",
      "          Fold 5 Epoch 10: loss=0.2860, acc=49.14% (best=58.67%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 60.70%\n",
      "          Fold 4 Epoch 10: loss=0.2587, acc=53.20% (best=68.83%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 72.19%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 58.67%\n",
      "          Fold 2 Epoch 15: loss=0.2410, acc=42.58% (best=54.84%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cf9fca17:\n",
      "        Fold accuracies: ['72.19%', '54.84%', '60.70%', '68.83%', '58.67%']\n",
      "        Average fitness: 63.05% Â± 6.46%\n",
      "        Best fold: Fold 1 with 72.19%\n",
      "      New best fitness in this generation: 63.05%!\n",
      "      Fitness obtained: 63.05% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: b669fde0)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model b669fde0 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=4.9416, acc=55.55% (best=55.55%)\n",
      "          Fold 1 Epoch 1: loss=5.1650, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=7.9020, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=4.8137, acc=52.03% (best=52.03%)\n",
      "          Fold 2 Epoch 1: loss=5.0665, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.6291, acc=59.38% (best=59.38%)\n",
      "          Fold 5 Epoch 5: loss=0.6965, acc=50.00% (best=52.03%)\n",
      "          Fold 1 Epoch 5: loss=0.6829, acc=59.06% (best=59.06%)\n",
      "          Fold 4 Epoch 5: loss=0.6633, acc=67.19% (best=71.64%)\n",
      "          Fold 2 Epoch 5: loss=0.6741, acc=49.84% (best=50.39%)\n",
      "          Fold 3 Epoch 10: loss=0.4621, acc=46.17% (best=59.38%)\n",
      "          Fold 5 Epoch 10: loss=1.0301, acc=46.72% (best=52.03%)\n",
      "          Fold 1 Epoch 10: loss=0.6883, acc=50.23% (best=61.64%)\n",
      "          Fold 4 Epoch 10: loss=0.6770, acc=67.58% (best=71.64%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 52.03%\n",
      "          Fold 2 Epoch 10: loss=0.6703, acc=53.20% (best=53.20%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 71.64%\n",
      "          Fold 3 Epoch 15: loss=0.3718, acc=47.50% (best=62.73%)\n",
      "          Fold 1 Epoch 15: loss=0.6968, acc=49.77% (best=61.64%)\n",
      "          Fold 2 Epoch 15: loss=0.7261, acc=49.61% (best=56.09%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 61.64%\n",
      "          Fold 3 Epoch 20: loss=0.3343, acc=54.69% (best=62.73%)\n",
      "          Fold 2 Epoch 20: loss=0.6956, acc=52.50% (best=56.09%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 62.73%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 56.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b669fde0:\n",
      "        Fold accuracies: ['61.64%', '56.09%', '62.73%', '71.64%', '52.03%']\n",
      "        Average fitness: 60.83% Â± 6.65%\n",
      "        Best fold: Fold 4 with 71.64%\n",
      "      Fitness obtained: 60.83% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 3efc0209)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 3efc0209 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6893, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=0.7114, acc=62.97% (best=62.97%)\n",
      "          Fold 4 Epoch 1: loss=0.6893, acc=44.14% (best=44.14%)\n",
      "          Fold 3 Epoch 1: loss=0.7101, acc=54.30% (best=54.30%)\n",
      "          Fold 5 Epoch 1: loss=0.7254, acc=54.22% (best=54.22%)\n",
      "          Fold 2 Epoch 5: loss=0.4850, acc=52.81% (best=60.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6072, acc=66.48% (best=66.48%)\n",
      "          Fold 4 Epoch 5: loss=0.5570, acc=52.73% (best=64.53%)\n",
      "          Fold 3 Epoch 5: loss=0.5184, acc=57.27% (best=57.27%)\n",
      "          Fold 5 Epoch 5: loss=0.5886, acc=48.05% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.3643, acc=46.88% (best=60.78%)\n",
      "          Fold 1 Epoch 10: loss=0.4382, acc=70.08% (best=70.08%)\n",
      "          Fold 4 Epoch 10: loss=0.4147, acc=52.42% (best=64.53%)\n",
      "          Fold 3 Epoch 10: loss=0.4155, acc=49.92% (best=57.27%)\n",
      "          Fold 5 Epoch 10: loss=0.4227, acc=50.23% (best=60.70%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 64.53%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 60.78%\n",
      "          Fold 1 Epoch 15: loss=0.3690, acc=51.64% (best=70.08%)\n",
      "          Fold 3 Epoch 15: loss=0.3649, acc=50.94% (best=57.27%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 57.27%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.70%\n",
      "          Fold 1 Epoch 20: loss=0.3417, acc=62.19% (best=70.08%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3efc0209:\n",
      "        Fold accuracies: ['70.08%', '60.78%', '57.27%', '64.53%', '60.70%']\n",
      "        Average fitness: 62.67% Â± 4.36%\n",
      "        Best fold: Fold 1 with 70.08%\n",
      "      Fitness obtained: 62.67% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: b0fbfb3c)\n",
      "      Architecture: 7 conv + 6 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model b0fbfb3c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[42], expected input with shape [*, 42], but got input of size[1, 42, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for b0fbfb3c:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 3d6895b5)\n",
      "      Architecture: 12 conv + 7 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model 3d6895b5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 1 Epoch 1: loss=0.7237, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.7661, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 1: loss=0.7583, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7210, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 5: loss=0.7579, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.7633, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.7245, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 5: loss=0.7270, acc=50.00% (best=50.00%)\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 10: loss=0.7480, acc=50.00% (best=50.39%)\n",
      "          Fold 3 Epoch 10: loss=0.7550, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 10: loss=0.7317, acc=50.00% (best=50.00%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 50.39%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3d6895b5:\n",
      "        Fold accuracies: ['0.00%', '50.39%', '51.02%', '0.00%', '50.00%']\n",
      "        Average fitness: 30.28% Â± 24.73%\n",
      "        Best fold: Fold 3 with 51.02%\n",
      "      Fitness obtained: 30.28% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: d419c3cd)\n",
      "      Architecture: 10 conv + 7 fc, opt=adam, lr=5e-05\n",
      "      Training/Evaluating model d419c3cd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7158, acc=53.20% (best=53.20%)\n",
      "          Fold 2 Epoch 1: loss=0.7141, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7061, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7151, acc=52.19% (best=52.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7153, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 5: loss=0.7024, acc=51.02% (best=57.03%)\n",
      "          Fold 4 Epoch 5: loss=0.6526, acc=49.06% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6851, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7058, acc=56.17% (best=56.17%)\n",
      "          Fold 1 Epoch 5: loss=0.6946, acc=62.66% (best=62.66%)\n",
      "          Fold 3 Epoch 10: loss=0.6905, acc=51.02% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.6203, acc=49.69% (best=56.02%)\n",
      "          Fold 2 Epoch 10: loss=0.6711, acc=49.69% (best=50.23%)\n",
      "          Fold 5 Epoch 10: loss=0.7013, acc=51.25% (best=56.41%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 57.03%\n",
      "          Fold 1 Epoch 10: loss=0.6783, acc=52.81% (best=62.66%)\n",
      "          Fold 2 Epoch 15: loss=0.6454, acc=58.98% (best=58.98%)\n",
      "          Fold 4 Epoch 15: loss=0.5787, acc=58.91% (best=59.38%)\n",
      "          Fold 5 Epoch 15: loss=0.7016, acc=44.30% (best=57.89%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 62.66%\n",
      "          Fold 2 Epoch 20: loss=0.5827, acc=50.00% (best=58.98%)\n",
      "          Fold 4 Epoch 20: loss=0.5235, acc=59.06% (best=62.11%)\n",
      "          Fold 5 Epoch 20: loss=0.7017, acc=52.89% (best=58.44%)\n",
      "          Fold 2 Epoch 25: loss=0.5032, acc=43.83% (best=58.98%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 58.98%\n",
      "          Fold 4 Epoch 25: loss=0.4788, acc=56.95% (best=62.11%)\n",
      "          Fold 5 Epoch 25: loss=0.6980, acc=52.58% (best=58.44%)\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 62.11%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 58.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d419c3cd:\n",
      "        Fold accuracies: ['62.66%', '58.98%', '57.03%', '62.11%', '58.44%']\n",
      "        Average fitness: 59.84% Â± 2.18%\n",
      "        Best fold: Fold 1 with 62.66%\n",
      "      Fitness obtained: 59.84% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 080f9158)\n",
      "      Architecture: 1 conv + 4 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 080f9158 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=7.1623, acc=50.78% (best=50.78%)\n",
      "          Fold 2 Epoch 1: loss=9.6507, acc=56.64% (best=56.64%)\n",
      "          Fold 1 Epoch 1: loss=9.0645, acc=54.53% (best=54.53%)\n",
      "          Fold 4 Epoch 1: loss=6.4455, acc=55.62% (best=55.62%)\n",
      "          Fold 5 Epoch 1: loss=11.6017, acc=50.31% (best=50.31%)\n",
      "          Fold 2 Epoch 5: loss=0.3374, acc=48.52% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.3589, acc=51.02% (best=55.39%)\n",
      "          Fold 1 Epoch 5: loss=0.3592, acc=49.06% (best=58.83%)\n",
      "          Fold 4 Epoch 5: loss=0.3561, acc=45.08% (best=62.81%)\n",
      "          Fold 5 Epoch 5: loss=0.3913, acc=51.88% (best=58.05%)\n",
      "          Fold 2 Epoch 10: loss=0.2691, acc=53.52% (best=56.64%)\n",
      "          Fold 3 Epoch 10: loss=0.3157, acc=45.23% (best=55.39%)\n",
      "          Fold 1 Epoch 10: loss=0.3326, acc=48.59% (best=58.83%)\n",
      "          Fold 4 Epoch 10: loss=0.3714, acc=50.16% (best=62.81%)\n",
      "          Fold 5 Epoch 10: loss=0.3066, acc=49.92% (best=58.05%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.64%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 55.39%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 62.81%\n",
      "          Fold 1 Epoch 15: loss=0.2565, acc=45.47% (best=58.91%)\n",
      "          Fold 5 Epoch 15: loss=0.2752, acc=60.62% (best=64.06%)\n",
      "          Fold 1 Epoch 20: loss=0.2473, acc=46.56% (best=58.91%)\n",
      "          Fold 5 Epoch 20: loss=0.2432, acc=52.03% (best=64.06%)\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 58.91%\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 64.06%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 080f9158:\n",
      "        Fold accuracies: ['58.91%', '56.64%', '55.39%', '62.81%', '64.06%']\n",
      "        Average fitness: 59.56% Â± 3.38%\n",
      "        Best fold: Fold 5 with 64.06%\n",
      "      Fitness obtained: 59.56% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: c8af4e0e)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model c8af4e0e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7180, acc=52.66% (best=52.66%)\n",
      "          Fold 4 Epoch 1: loss=0.7099, acc=47.97% (best=47.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7274, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 1: loss=0.7183, acc=49.53% (best=49.53%)\n",
      "          Fold 3 Epoch 1: loss=0.7298, acc=58.91% (best=58.91%)\n",
      "          Fold 2 Epoch 5: loss=0.4199, acc=49.45% (best=52.66%)\n",
      "          Fold 5 Epoch 5: loss=0.4022, acc=57.97% (best=58.59%)\n",
      "          Fold 4 Epoch 5: loss=0.4575, acc=69.61% (best=69.61%)\n",
      "          Fold 1 Epoch 5: loss=0.4830, acc=50.00% (best=50.86%)\n",
      "          Fold 3 Epoch 5: loss=0.4218, acc=52.34% (best=58.91%)\n",
      "          Fold 2 Epoch 10: loss=0.3239, acc=48.05% (best=52.66%)\n",
      "          Fold 5 Epoch 10: loss=0.2964, acc=53.75% (best=58.59%)\n",
      "          Fold 4 Epoch 10: loss=0.3228, acc=70.00% (best=70.00%)\n",
      "          Fold 1 Epoch 10: loss=0.3447, acc=44.77% (best=50.86%)\n",
      "          Fold 3 Epoch 10: loss=0.3080, acc=54.06% (best=62.19%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.59%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 50.86%\n",
      "          Fold 2 Epoch 15: loss=0.2678, acc=44.84% (best=57.27%)\n",
      "          Fold 4 Epoch 15: loss=0.2770, acc=57.19% (best=70.00%)\n",
      "          Fold 3 Epoch 15: loss=0.2618, acc=58.28% (best=62.19%)\n",
      "          Fold 2 Epoch 20: loss=0.2378, acc=53.75% (best=58.28%)\n",
      "          Fold 4 Epoch 20: loss=0.2548, acc=55.08% (best=70.00%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 70.00%\n",
      "          Fold 3 Epoch 20: loss=0.2508, acc=58.91% (best=64.45%)\n",
      "          Fold 2 Epoch 25: loss=0.2341, acc=56.88% (best=61.64%)\n",
      "          Fold 3 Epoch 25: loss=0.2293, acc=55.39% (best=64.45%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 64.45%\n",
      "          Fold 2 Epoch 30: loss=0.2146, acc=57.97% (best=65.94%)\n",
      "          Fold 2 Epoch 35: loss=0.2253, acc=56.33% (best=71.25%)\n",
      "          Fold 2 Epoch 40: loss=0.2149, acc=54.14% (best=71.25%)\n",
      "          Fold 2: Early stopping at epoch 43\n",
      "      â†’ Fold 2 completed: 71.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c8af4e0e:\n",
      "        Fold accuracies: ['50.86%', '71.25%', '64.45%', '70.00%', '58.59%']\n",
      "        Average fitness: 63.03% Â± 7.56%\n",
      "        Best fold: Fold 2 with 71.25%\n",
      "      Fitness obtained: 63.03% | Best in generation: 63.05% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 872fa407)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 872fa407 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6855, acc=43.52% (best=43.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6879, acc=54.38% (best=54.38%)\n",
      "          Fold 5 Epoch 1: loss=0.6780, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6673, acc=46.02% (best=46.02%)\n",
      "          Fold 2 Epoch 1: loss=0.6634, acc=52.11% (best=52.11%)\n",
      "          Fold 3 Epoch 5: loss=0.4055, acc=57.66% (best=61.25%)\n",
      "          Fold 5 Epoch 5: loss=0.3570, acc=59.30% (best=59.30%)\n",
      "          Fold 1 Epoch 5: loss=0.4588, acc=58.75% (best=58.75%)\n",
      "          Fold 4 Epoch 5: loss=0.4159, acc=49.14% (best=61.48%)\n",
      "          Fold 2 Epoch 5: loss=0.3548, acc=69.45% (best=69.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3111, acc=50.55% (best=61.25%)\n",
      "          Fold 5 Epoch 10: loss=0.2759, acc=46.33% (best=59.30%)\n",
      "          Fold 1 Epoch 10: loss=0.2977, acc=72.50% (best=72.50%)\n",
      "          Fold 4 Epoch 10: loss=0.2917, acc=51.56% (best=64.92%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 61.25%\n",
      "          Fold 2 Epoch 10: loss=0.2852, acc=50.94% (best=69.45%)\n",
      "          Fold 5 Epoch 15: loss=0.2438, acc=52.19% (best=59.30%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 59.30%\n",
      "          Fold 1 Epoch 15: loss=0.2539, acc=55.70% (best=72.50%)\n",
      "          Fold 4 Epoch 15: loss=0.2591, acc=50.47% (best=65.16%)\n",
      "          Fold 2 Epoch 15: loss=0.2529, acc=63.28% (best=69.45%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 69.45%\n",
      "          Fold 1 Epoch 20: loss=0.2384, acc=63.36% (best=72.50%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 72.50%\n",
      "          Fold 4 Epoch 20: loss=0.2404, acc=61.80% (best=65.16%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 872fa407:\n",
      "        Fold accuracies: ['72.50%', '69.45%', '61.25%', '65.16%', '59.30%']\n",
      "        Average fitness: 65.53% Â± 4.93%\n",
      "        Best fold: Fold 1 with 72.50%\n",
      "      New best fitness in this generation: 65.53%!\n",
      "      Fitness obtained: 65.53% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 269c5ee2)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 269c5ee2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7218, acc=53.28% (best=53.28%)\n",
      "          Fold 5 Epoch 1: loss=0.7273, acc=50.31% (best=50.31%)\n",
      "          Fold 4 Epoch 1: loss=0.7173, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7153, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.7268, acc=57.11% (best=57.11%)\n",
      "          Fold 4 Epoch 5: loss=0.7040, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.7060, acc=56.72% (best=56.72%)\n",
      "          Fold 5 Epoch 5: loss=0.7153, acc=50.00% (best=50.31%)\n",
      "          Fold 1 Epoch 5: loss=0.7063, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 5: loss=0.7153, acc=54.69% (best=57.11%)\n",
      "          Fold 4 Epoch 10: loss=0.6940, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 10: loss=0.7055, acc=50.16% (best=50.31%)\n",
      "          Fold 2 Epoch 10: loss=0.6976, acc=56.56% (best=56.72%)\n",
      "          Fold 1 Epoch 10: loss=0.6989, acc=49.77% (best=49.77%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.22%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.31%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 49.77%\n",
      "          Fold 3 Epoch 10: loss=0.7058, acc=52.81% (best=59.84%)\n",
      "          Fold 2 Epoch 15: loss=0.6880, acc=48.83% (best=61.25%)\n",
      "          Fold 3 Epoch 15: loss=0.7024, acc=50.86% (best=59.84%)\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 59.84%\n",
      "          Fold 2 Epoch 20: loss=0.6836, acc=45.16% (best=61.25%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 61.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 269c5ee2:\n",
      "        Fold accuracies: ['49.77%', '61.25%', '59.84%', '49.22%', '50.31%']\n",
      "        Average fitness: 54.08% Â± 5.31%\n",
      "        Best fold: Fold 2 with 61.25%\n",
      "      Fitness obtained: 54.08% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: dcfedb24)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.001\n",
      "      Training/Evaluating model dcfedb24 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6905, acc=56.56% (best=56.56%)\n",
      "          Fold 3 Epoch 1: loss=0.6925, acc=42.89% (best=42.89%)\n",
      "          Fold 1 Epoch 1: loss=0.7126, acc=56.56% (best=56.56%)\n",
      "          Fold 5 Epoch 1: loss=0.7118, acc=54.92% (best=54.92%)\n",
      "          Fold 4 Epoch 1: loss=0.7062, acc=57.03% (best=57.03%)\n",
      "          Fold 5 Epoch 5: loss=0.5350, acc=55.31% (best=57.73%)\n",
      "          Fold 2 Epoch 5: loss=0.4160, acc=44.22% (best=56.56%)\n",
      "          Fold 3 Epoch 5: loss=0.4409, acc=57.97% (best=58.12%)\n",
      "          Fold 1 Epoch 5: loss=0.4646, acc=42.97% (best=64.14%)\n",
      "          Fold 4 Epoch 5: loss=0.5056, acc=59.38% (best=63.75%)\n",
      "          Fold 2 Epoch 10: loss=0.3101, acc=50.31% (best=56.56%)\n",
      "          Fold 5 Epoch 10: loss=0.3890, acc=48.52% (best=57.73%)\n",
      "          Fold 3 Epoch 10: loss=0.3424, acc=54.30% (best=58.12%)\n",
      "          Fold 1 Epoch 10: loss=0.3302, acc=49.77% (best=64.14%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.56%\n",
      "          Fold 4 Epoch 10: loss=0.3840, acc=40.62% (best=63.75%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 57.73%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 64.14%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.75%\n",
      "          Fold 3 Epoch 15: loss=0.2899, acc=50.00% (best=58.91%)\n",
      "          Fold 3 Epoch 20: loss=0.2604, acc=47.42% (best=58.91%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 58.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dcfedb24:\n",
      "        Fold accuracies: ['64.14%', '56.56%', '58.91%', '63.75%', '57.73%']\n",
      "        Average fitness: 60.22% Â± 3.13%\n",
      "        Best fold: Fold 1 with 64.14%\n",
      "      Fitness obtained: 60.22% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: c53f8750)\n",
      "      Architecture: 12 conv + 8 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model c53f8750 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7172, acc=60.78% (best=60.78%)\n",
      "          Fold 2 Epoch 1: loss=0.7207, acc=52.73% (best=52.73%)\n",
      "          Fold 3 Epoch 1: loss=0.7185, acc=57.66% (best=57.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7177, acc=55.23% (best=55.23%)\n",
      "          Fold 1 Epoch 1: loss=0.7374, acc=44.22% (best=44.22%)\n",
      "          Fold 4 Epoch 5: loss=0.6937, acc=50.86% (best=60.78%)\n",
      "          Fold 3 Epoch 5: loss=0.7076, acc=58.44% (best=65.23%)\n",
      "          Fold 2 Epoch 5: loss=0.7005, acc=46.88% (best=59.61%)\n",
      "          Fold 5 Epoch 5: loss=0.7053, acc=49.69% (best=65.16%)\n",
      "          Fold 1 Epoch 5: loss=0.7078, acc=42.81% (best=53.12%)\n",
      "          Fold 4 Epoch 10: loss=0.6818, acc=51.64% (best=60.78%)\n",
      "          Fold 3 Epoch 10: loss=0.6969, acc=55.78% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.6840, acc=41.41% (best=59.61%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.78%\n",
      "          Fold 5 Epoch 10: loss=0.7036, acc=54.14% (best=65.16%)\n",
      "          Fold 1 Epoch 10: loss=0.6981, acc=58.12% (best=62.89%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 65.16%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 59.61%\n",
      "          Fold 3 Epoch 15: loss=0.6948, acc=54.53% (best=66.56%)\n",
      "          Fold 1 Epoch 15: loss=0.6890, acc=53.52% (best=62.89%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 62.89%\n",
      "          Fold 3 Epoch 20: loss=0.6862, acc=58.28% (best=67.58%)\n",
      "          Fold 3 Epoch 25: loss=0.6512, acc=50.62% (best=67.58%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 67.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c53f8750:\n",
      "        Fold accuracies: ['62.89%', '59.61%', '67.58%', '60.78%', '65.16%']\n",
      "        Average fitness: 63.20% Â± 2.89%\n",
      "        Best fold: Fold 3 with 67.58%\n",
      "      Fitness obtained: 63.20% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: d80844f1)\n",
      "      Architecture: 16 conv + 7 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model d80844f1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d80844f1:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 4ecd7ffe)\n",
      "      Architecture: 22 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 4ecd7ffe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 182, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 206, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 4ecd7ffe:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.53% | Global best: 70.92%\n",
      "\n",
      "GENERATION 18 STATISTICS:\n",
      "   Maximum fitness: 65.53%\n",
      "   Average fitness: 47.60%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 24.84%\n",
      "   Best individual: 872fa407 with 65.53%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 8/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=24.84)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 872fa407 (fitness: 65.53%)\n",
      "   Elite 2: c53f8750 (fitness: 63.20%)\n",
      "   Elite 3: cf9fca17 (fitness: 63.05%)\n",
      "   Elite 4: c8af4e0e (fitness: 63.03%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 9/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 19\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 19)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 872fa407)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 872fa407 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6702, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 1: loss=0.7050, acc=60.62% (best=60.62%)\n",
      "          Fold 4 Epoch 1: loss=0.6576, acc=68.83% (best=68.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6857, acc=63.91% (best=63.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6998, acc=43.05% (best=43.05%)\n",
      "          Fold 2 Epoch 5: loss=0.3662, acc=31.88% (best=55.16%)\n",
      "          Fold 5 Epoch 5: loss=0.4063, acc=42.34% (best=60.62%)\n",
      "          Fold 4 Epoch 5: loss=0.3991, acc=61.56% (best=68.83%)\n",
      "          Fold 1 Epoch 5: loss=0.4193, acc=56.64% (best=63.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3685, acc=64.06% (best=64.06%)\n",
      "          Fold 2 Epoch 10: loss=0.2752, acc=52.97% (best=55.16%)\n",
      "          Fold 5 Epoch 10: loss=0.2791, acc=45.78% (best=60.62%)\n",
      "          Fold 4 Epoch 10: loss=0.2863, acc=44.84% (best=68.83%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 55.16%\n",
      "          Fold 1 Epoch 10: loss=0.2983, acc=56.88% (best=71.72%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.83%\n",
      "          Fold 3 Epoch 10: loss=0.2927, acc=61.48% (best=64.06%)\n",
      "          Fold 1 Epoch 15: loss=0.2571, acc=74.30% (best=74.30%)\n",
      "          Fold 3 Epoch 15: loss=0.2523, acc=53.59% (best=64.06%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 64.06%\n",
      "          Fold 1 Epoch 20: loss=0.2415, acc=75.78% (best=75.78%)\n",
      "          Fold 1 Epoch 25: loss=0.2281, acc=73.91% (best=75.78%)\n",
      "          Fold 1 Epoch 30: loss=0.2195, acc=68.28% (best=77.19%)\n",
      "          Fold 1 Epoch 35: loss=0.2180, acc=70.94% (best=77.19%)\n",
      "          Fold 1: Early stopping at epoch 37\n",
      "      â†’ Fold 1 completed: 77.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 872fa407:\n",
      "        Fold accuracies: ['77.19%', '55.16%', '64.06%', '68.83%', '60.62%']\n",
      "        Average fitness: 65.17% Â± 7.48%\n",
      "        Best fold: Fold 1 with 77.19%\n",
      "      New best fitness in this generation: 65.17%!\n",
      "      Fitness obtained: 65.17% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: c53f8750)\n",
      "      Architecture: 12 conv + 8 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model c53f8750 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7173, acc=46.17% (best=46.17%)\n",
      "          Fold 3 Epoch 1: loss=0.7226, acc=60.86% (best=60.86%)\n",
      "          Fold 4 Epoch 1: loss=0.7180, acc=51.64% (best=51.64%)\n",
      "          Fold 2 Epoch 1: loss=0.7271, acc=45.62% (best=45.62%)\n",
      "          Fold 5 Epoch 1: loss=0.7234, acc=41.88% (best=41.88%)\n",
      "          Fold 1 Epoch 5: loss=0.7055, acc=49.77% (best=51.02%)\n",
      "          Fold 3 Epoch 5: loss=0.7078, acc=65.86% (best=70.78%)\n",
      "          Fold 4 Epoch 5: loss=0.6955, acc=58.59% (best=60.86%)\n",
      "          Fold 2 Epoch 5: loss=0.6865, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 5: loss=0.7103, acc=50.00% (best=53.44%)\n",
      "          Fold 1 Epoch 10: loss=0.6920, acc=56.02% (best=56.02%)\n",
      "          Fold 3 Epoch 10: loss=0.6980, acc=62.66% (best=70.78%)\n",
      "          Fold 4 Epoch 10: loss=0.6851, acc=65.23% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.6738, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 10: loss=0.7084, acc=50.86% (best=53.44%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 70.78%\n",
      "          Fold 1 Epoch 15: loss=0.6887, acc=43.36% (best=56.02%)\n",
      "          Fold 4 Epoch 15: loss=0.6758, acc=60.62% (best=66.09%)\n",
      "          Fold 2 Epoch 15: loss=0.6656, acc=49.61% (best=50.31%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 53.44%\n",
      "          Fold 1 Epoch 20: loss=0.6809, acc=49.77% (best=56.02%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 56.02%\n",
      "          Fold 4 Epoch 20: loss=0.6655, acc=54.92% (best=66.09%)\n",
      "          Fold 2 Epoch 20: loss=0.6278, acc=49.61% (best=50.31%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 50.31%\n",
      "          Fold 4: Early stopping at epoch 23\n",
      "      â†’ Fold 4 completed: 66.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c53f8750:\n",
      "        Fold accuracies: ['56.02%', '50.31%', '70.78%', '66.09%', '53.44%']\n",
      "        Average fitness: 59.33% Â± 7.80%\n",
      "        Best fold: Fold 3 with 70.78%\n",
      "      Fitness obtained: 59.33% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: cf9fca17)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cf9fca17 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7044, acc=55.31% (best=55.31%)\n",
      "          Fold 3 Epoch 1: loss=0.7233, acc=53.36% (best=53.36%)\n",
      "          Fold 2 Epoch 1: loss=0.7204, acc=49.61% (best=49.61%)\n",
      "          Fold 1 Epoch 1: loss=0.7225, acc=55.55% (best=55.55%)\n",
      "          Fold 5 Epoch 1: loss=0.7367, acc=57.89% (best=57.89%)\n",
      "          Fold 4 Epoch 5: loss=0.3926, acc=52.50% (best=57.03%)\n",
      "          Fold 3 Epoch 5: loss=0.3663, acc=53.12% (best=58.20%)\n",
      "          Fold 5 Epoch 5: loss=0.3621, acc=48.05% (best=57.89%)\n",
      "          Fold 2 Epoch 5: loss=0.3431, acc=53.44% (best=53.44%)\n",
      "          Fold 1 Epoch 5: loss=0.6641, acc=53.75% (best=61.41%)\n",
      "          Fold 4 Epoch 10: loss=0.2690, acc=35.08% (best=57.03%)\n",
      "          Fold 3 Epoch 10: loss=0.2761, acc=60.00% (best=60.00%)\n",
      "          Fold 5 Epoch 10: loss=0.2657, acc=47.97% (best=57.89%)\n",
      "          Fold 2 Epoch 10: loss=0.2599, acc=60.78% (best=60.78%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "          Fold 1 Epoch 10: loss=0.3311, acc=59.45% (best=63.44%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 57.03%\n",
      "          Fold 3 Epoch 15: loss=0.2503, acc=57.89% (best=60.00%)\n",
      "          Fold 2 Epoch 15: loss=0.2280, acc=46.56% (best=60.78%)\n",
      "          Fold 1 Epoch 15: loss=0.2585, acc=55.62% (best=63.44%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 63.44%\n",
      "          Fold 3 Epoch 20: loss=0.2334, acc=56.33% (best=60.47%)\n",
      "          Fold 2 Epoch 20: loss=0.2154, acc=55.55% (best=60.78%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 60.78%\n",
      "          Fold 3 Epoch 25: loss=0.2249, acc=51.41% (best=60.47%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 60.47%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cf9fca17:\n",
      "        Fold accuracies: ['63.44%', '60.78%', '60.47%', '57.03%', '57.89%']\n",
      "        Average fitness: 59.92% Â± 2.28%\n",
      "        Best fold: Fold 1 with 63.44%\n",
      "      Fitness obtained: 59.92% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: c8af4e0e)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model c8af4e0e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7118, acc=53.91% (best=53.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6957, acc=49.30% (best=49.30%)\n",
      "          Fold 5 Epoch 1: loss=0.7314, acc=47.11% (best=47.11%)\n",
      "          Fold 1 Epoch 1: loss=0.7226, acc=60.94% (best=60.94%)\n",
      "          Fold 3 Epoch 1: loss=0.7288, acc=52.34% (best=52.34%)\n",
      "          Fold 2 Epoch 5: loss=0.4519, acc=43.28% (best=60.55%)\n",
      "          Fold 4 Epoch 5: loss=0.4278, acc=54.61% (best=61.88%)\n",
      "          Fold 5 Epoch 5: loss=0.4125, acc=55.08% (best=55.08%)\n",
      "          Fold 1 Epoch 5: loss=0.4748, acc=53.67% (best=60.94%)\n",
      "          Fold 3 Epoch 5: loss=0.4371, acc=57.58% (best=57.58%)\n",
      "          Fold 2 Epoch 10: loss=0.3160, acc=55.31% (best=60.55%)\n",
      "          Fold 4 Epoch 10: loss=0.3263, acc=47.50% (best=61.88%)\n",
      "          Fold 5 Epoch 10: loss=0.3004, acc=46.64% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.3251, acc=52.73% (best=60.94%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 60.94%\n",
      "          Fold 3 Epoch 10: loss=0.3240, acc=49.69% (best=60.39%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 60.55%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 61.88%\n",
      "          Fold 5 Epoch 15: loss=0.2608, acc=45.70% (best=59.92%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 3 Epoch 15: loss=0.2762, acc=52.03% (best=60.39%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 60.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c8af4e0e:\n",
      "        Fold accuracies: ['60.94%', '60.55%', '60.39%', '61.88%', '59.92%']\n",
      "        Average fitness: 60.73% Â± 0.66%\n",
      "        Best fold: Fold 4 with 61.88%\n",
      "      Fitness obtained: 60.73% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 43bdf576)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=1e-05\n",
      "      Training/Evaluating model 43bdf576 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.7222, acc=62.50% (best=62.50%)\n",
      "          Fold 2 Epoch 1: loss=0.7218, acc=55.00% (best=55.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7230, acc=53.83% (best=53.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7160, acc=56.48% (best=56.48%)\n",
      "          Fold 1 Epoch 1: loss=0.7204, acc=52.89% (best=52.89%)\n",
      "          Fold 4 Epoch 5: loss=0.6893, acc=62.19% (best=63.83%)\n",
      "          Fold 2 Epoch 5: loss=0.6839, acc=48.28% (best=55.00%)\n",
      "          Fold 3 Epoch 5: loss=0.7051, acc=58.91% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.7118, acc=60.86% (best=60.86%)\n",
      "          Fold 1 Epoch 5: loss=0.6985, acc=59.22% (best=59.22%)\n",
      "          Fold 2 Epoch 10: loss=0.6695, acc=54.92% (best=55.00%)\n",
      "          Fold 4 Epoch 10: loss=0.6729, acc=60.23% (best=69.84%)\n",
      "          Fold 3 Epoch 10: loss=0.6946, acc=58.75% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.6969, acc=55.86% (best=62.19%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 55.00%\n",
      "          Fold 1 Epoch 10: loss=0.6906, acc=62.58% (best=62.58%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 4 Epoch 15: loss=0.6432, acc=58.67% (best=69.84%)\n",
      "          Fold 5 Epoch 15: loss=0.6632, acc=56.88% (best=62.19%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 69.84%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 62.19%\n",
      "          Fold 1 Epoch 15: loss=0.6853, acc=57.27% (best=62.58%)\n",
      "          Fold 1 Epoch 20: loss=0.6517, acc=50.16% (best=63.59%)\n",
      "          Fold 1 Epoch 25: loss=0.5952, acc=59.45% (best=63.59%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 63.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 43bdf576:\n",
      "        Fold accuracies: ['63.59%', '55.00%', '60.86%', '69.84%', '62.19%']\n",
      "        Average fitness: 62.30% Â± 4.77%\n",
      "        Best fold: Fold 4 with 69.84%\n",
      "      Fitness obtained: 62.30% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: b8dceb58)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b8dceb58 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7051, acc=44.84% (best=44.84%)\n",
      "          Fold 4 Epoch 1: loss=0.6882, acc=59.45% (best=59.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7194, acc=55.31% (best=55.31%)\n",
      "          Fold 5 Epoch 1: loss=0.7396, acc=61.09% (best=61.09%)\n",
      "          Fold 1 Epoch 1: loss=0.7065, acc=52.03% (best=52.03%)\n",
      "          Fold 2 Epoch 5: loss=0.4107, acc=42.11% (best=55.86%)\n",
      "          Fold 4 Epoch 5: loss=0.4776, acc=48.67% (best=69.22%)\n",
      "          Fold 5 Epoch 5: loss=0.4950, acc=50.55% (best=64.45%)\n",
      "          Fold 3 Epoch 5: loss=0.4766, acc=54.22% (best=55.31%)\n",
      "          Fold 1 Epoch 5: loss=0.5203, acc=50.08% (best=58.98%)\n",
      "          Fold 2 Epoch 10: loss=0.3068, acc=45.08% (best=55.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2790, acc=48.20% (best=69.22%)\n",
      "          Fold 5 Epoch 10: loss=0.2977, acc=54.22% (best=64.45%)\n",
      "          Fold 3 Epoch 10: loss=0.3208, acc=65.94% (best=66.48%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 1 Epoch 10: loss=0.3434, acc=43.36% (best=58.98%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 69.22%\n",
      "          Fold 5 Epoch 15: loss=0.2581, acc=64.69% (best=66.48%)\n",
      "          Fold 3 Epoch 15: loss=0.2733, acc=65.62% (best=69.38%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 58.98%\n",
      "          Fold 5 Epoch 20: loss=0.2352, acc=49.92% (best=66.48%)\n",
      "          Fold 3 Epoch 20: loss=0.2530, acc=55.39% (best=69.38%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 69.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b8dceb58:\n",
      "        Fold accuracies: ['58.98%', '55.86%', '69.38%', '69.22%', '66.48%']\n",
      "        Average fitness: 63.98% Â± 5.54%\n",
      "        Best fold: Fold 3 with 69.38%\n",
      "      Fitness obtained: 63.98% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 9cd4263e)\n",
      "      Architecture: 12 conv + 3 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 9cd4263e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7023, acc=41.33% (best=41.33%)\n",
      "          Fold 3 Epoch 1: loss=0.7145, acc=53.28% (best=53.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6927, acc=61.33% (best=61.33%)\n",
      "          Fold 1 Epoch 1: loss=0.7044, acc=65.31% (best=65.31%)\n",
      "          Fold 5 Epoch 1: loss=0.7201, acc=39.22% (best=39.22%)\n",
      "          Fold 2 Epoch 5: loss=0.5849, acc=46.33% (best=51.72%)\n",
      "          Fold 3 Epoch 5: loss=0.6074, acc=52.34% (best=59.45%)\n",
      "          Fold 4 Epoch 5: loss=0.5755, acc=56.72% (best=68.05%)\n",
      "          Fold 1 Epoch 5: loss=0.6629, acc=54.14% (best=65.31%)\n",
      "          Fold 5 Epoch 5: loss=0.6900, acc=47.03% (best=56.17%)\n",
      "          Fold 2 Epoch 10: loss=0.4176, acc=53.05% (best=62.34%)\n",
      "          Fold 3 Epoch 10: loss=0.4526, acc=63.36% (best=63.36%)\n",
      "          Fold 4 Epoch 10: loss=0.4040, acc=63.36% (best=68.05%)\n",
      "          Fold 1 Epoch 10: loss=0.5326, acc=55.78% (best=65.31%)\n",
      "          Fold 5 Epoch 10: loss=0.4841, acc=54.69% (best=60.70%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 65.31%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.05%\n",
      "          Fold 2 Epoch 15: loss=0.3537, acc=50.16% (best=62.34%)\n",
      "          Fold 3 Epoch 15: loss=0.3804, acc=58.44% (best=63.36%)\n",
      "          Fold 5 Epoch 15: loss=0.3836, acc=53.67% (best=60.70%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 60.70%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 62.34%\n",
      "          Fold 3 Epoch 20: loss=0.3510, acc=58.44% (best=63.36%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 63.36%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9cd4263e:\n",
      "        Fold accuracies: ['65.31%', '62.34%', '63.36%', '68.05%', '60.70%']\n",
      "        Average fitness: 63.95% Â± 2.53%\n",
      "        Best fold: Fold 4 with 68.05%\n",
      "      Fitness obtained: 63.95% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: ad718dea)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model ad718dea with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=5.7352, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 1: loss=7.4032, acc=63.20% (best=63.20%)\n",
      "          Fold 2 Epoch 1: loss=4.6239, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=6.9324, acc=49.30% (best=49.30%)\n",
      "          Fold 3 Epoch 1: loss=5.2933, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 5: loss=0.6843, acc=50.23% (best=59.53%)\n",
      "          Fold 4 Epoch 5: loss=0.6822, acc=53.52% (best=63.20%)\n",
      "          Fold 2 Epoch 5: loss=0.6433, acc=49.61% (best=50.94%)\n",
      "          Fold 5 Epoch 5: loss=0.6976, acc=51.33% (best=51.33%)\n",
      "          Fold 3 Epoch 5: loss=0.6989, acc=48.98% (best=59.53%)\n",
      "          Fold 1 Epoch 10: loss=0.6800, acc=59.22% (best=64.92%)\n",
      "          Fold 4 Epoch 10: loss=0.6704, acc=56.64% (best=63.20%)\n",
      "          Fold 2 Epoch 10: loss=0.6742, acc=49.61% (best=50.94%)\n",
      "          Fold 5 Epoch 10: loss=0.8143, acc=50.00% (best=51.33%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.20%\n",
      "          Fold 3 Epoch 10: loss=0.6964, acc=51.02% (best=59.53%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 50.94%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 59.53%\n",
      "          Fold 1 Epoch 15: loss=0.6873, acc=50.23% (best=64.92%)\n",
      "          Fold 5 Epoch 15: loss=0.7020, acc=50.00% (best=51.33%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 51.33%\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ad718dea:\n",
      "        Fold accuracies: ['64.92%', '50.94%', '59.53%', '63.20%', '51.33%']\n",
      "        Average fitness: 57.98% Â± 5.86%\n",
      "        Best fold: Fold 1 with 64.92%\n",
      "      Fitness obtained: 57.98% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: c08a3193)\n",
      "      Architecture: 12 conv + 3 fc, opt=sgd, lr=1e-05\n",
      "      Training/Evaluating model c08a3193 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 4: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[63], expected input with shape [*, 63], but got input of size[1, 63, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for c08a3193:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: df6683d4)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model df6683d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6761, acc=46.95% (best=46.95%)\n",
      "          Fold 3 Epoch 1: loss=0.6706, acc=48.28% (best=48.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6697, acc=67.19% (best=67.19%)\n",
      "          Fold 1 Epoch 1: loss=0.6788, acc=52.81% (best=52.81%)\n",
      "          Fold 5 Epoch 1: loss=0.6868, acc=51.41% (best=51.41%)\n",
      "          Fold 5 Epoch 5: loss=0.4142, acc=48.12% (best=60.94%)\n",
      "          Fold 3 Epoch 5: loss=0.3595, acc=59.30% (best=59.30%)\n",
      "          Fold 2 Epoch 5: loss=0.3713, acc=60.39% (best=60.39%)\n",
      "          Fold 1 Epoch 5: loss=0.4258, acc=55.78% (best=55.78%)\n",
      "          Fold 4 Epoch 5: loss=0.4354, acc=52.58% (best=67.19%)\n",
      "          Fold 5 Epoch 10: loss=0.2958, acc=45.94% (best=60.94%)\n",
      "          Fold 3 Epoch 10: loss=0.2967, acc=50.00% (best=59.30%)\n",
      "          Fold 2 Epoch 10: loss=0.3023, acc=70.94% (best=70.94%)\n",
      "          Fold 1 Epoch 10: loss=0.3132, acc=34.92% (best=55.78%)\n",
      "          Fold 4 Epoch 10: loss=0.3201, acc=50.78% (best=67.19%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.94%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.19%\n",
      "          Fold 3 Epoch 15: loss=0.2706, acc=61.41% (best=61.41%)\n",
      "          Fold 2 Epoch 15: loss=0.2655, acc=53.44% (best=70.94%)\n",
      "          Fold 1 Epoch 15: loss=0.2701, acc=53.59% (best=55.78%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 55.78%\n",
      "          Fold 3 Epoch 20: loss=0.2462, acc=50.39% (best=61.41%)\n",
      "          Fold 2 Epoch 20: loss=0.2491, acc=56.80% (best=70.94%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 70.94%\n",
      "          Fold 3 Epoch 25: loss=0.2348, acc=50.00% (best=61.41%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 61.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for df6683d4:\n",
      "        Fold accuracies: ['55.78%', '70.94%', '61.41%', '67.19%', '60.94%']\n",
      "        Average fitness: 63.25% Â± 5.28%\n",
      "        Best fold: Fold 2 with 70.94%\n",
      "      Fitness obtained: 63.25% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 2ef3caba)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2ef3caba with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7451, acc=44.92% (best=44.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6962, acc=56.25% (best=56.25%)\n",
      "          Fold 3 Epoch 1: loss=0.7409, acc=57.03% (best=57.03%)\n",
      "          Fold 1 Epoch 1: loss=0.7308, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7375, acc=56.25% (best=56.25%)\n",
      "          Fold 4 Epoch 5: loss=0.4775, acc=55.47% (best=56.25%)\n",
      "          Fold 5 Epoch 5: loss=0.6187, acc=52.66% (best=56.25%)\n",
      "          Fold 1 Epoch 5: loss=0.5576, acc=59.14% (best=59.14%)\n",
      "          Fold 2 Epoch 5: loss=0.6356, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 5: loss=0.4979, acc=51.95% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.2754, acc=52.27% (best=56.25%)\n",
      "          Fold 5 Epoch 10: loss=0.3056, acc=40.78% (best=59.14%)\n",
      "          Fold 1 Epoch 10: loss=0.3286, acc=55.86% (best=59.14%)\n",
      "          Fold 2 Epoch 10: loss=0.3154, acc=54.38% (best=58.52%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 56.25%\n",
      "          Fold 3 Epoch 10: loss=0.2846, acc=51.48% (best=60.39%)\n",
      "          Fold 5 Epoch 15: loss=0.2575, acc=49.38% (best=59.14%)\n",
      "          Fold 1 Epoch 15: loss=0.2645, acc=52.73% (best=59.45%)\n",
      "          Fold 2 Epoch 15: loss=0.2566, acc=56.09% (best=58.52%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 59.14%\n",
      "          Fold 3 Epoch 15: loss=0.2505, acc=54.61% (best=65.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2470, acc=50.08% (best=58.75%)\n",
      "          Fold 1 Epoch 20: loss=0.2443, acc=59.30% (best=59.45%)\n",
      "          Fold 3 Epoch 20: loss=0.2463, acc=58.83% (best=65.23%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "          Fold 2 Epoch 25: loss=0.2270, acc=53.59% (best=58.75%)\n",
      "          Fold 1 Epoch 25: loss=0.2272, acc=56.25% (best=60.86%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 58.75%\n",
      "          Fold 1 Epoch 30: loss=0.2196, acc=57.50% (best=61.33%)\n",
      "          Fold 1 Epoch 35: loss=0.2125, acc=54.22% (best=62.42%)\n",
      "          Fold 1 Epoch 40: loss=0.2121, acc=60.23% (best=62.42%)\n",
      "          Fold 1: Early stopping at epoch 42\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2ef3caba:\n",
      "        Fold accuracies: ['62.42%', '58.75%', '65.23%', '56.25%', '59.14%']\n",
      "        Average fitness: 60.36% Â± 3.13%\n",
      "        Best fold: Fold 3 with 65.23%\n",
      "      Fitness obtained: 60.36% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 2787e62c)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=0.0001\n",
      "      Training/Evaluating model 2787e62c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7264, acc=48.67% (best=48.67%)\n",
      "          Fold 2 Epoch 1: loss=0.7240, acc=46.72% (best=46.72%)\n",
      "          Fold 4 Epoch 1: loss=0.7298, acc=59.06% (best=59.06%)\n",
      "          Fold 1 Epoch 1: loss=0.7171, acc=52.11% (best=52.11%)\n",
      "          Fold 5 Epoch 1: loss=0.7217, acc=46.09% (best=46.09%)\n",
      "          Fold 3 Epoch 5: loss=0.7107, acc=48.91% (best=54.06%)\n",
      "          Fold 4 Epoch 5: loss=0.7063, acc=51.09% (best=73.05%)\n",
      "          Fold 2 Epoch 5: loss=0.7097, acc=45.86% (best=54.92%)\n",
      "          Fold 1 Epoch 5: loss=0.7095, acc=57.50% (best=57.50%)\n",
      "          Fold 5 Epoch 5: loss=0.7236, acc=48.28% (best=58.28%)\n",
      "          Fold 3 Epoch 10: loss=0.7148, acc=48.67% (best=56.33%)\n",
      "          Fold 4 Epoch 10: loss=0.7023, acc=67.81% (best=73.05%)\n",
      "          Fold 2 Epoch 10: loss=0.7049, acc=52.27% (best=54.92%)\n",
      "          Fold 1 Epoch 10: loss=0.7113, acc=50.47% (best=57.50%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 73.05%\n",
      "          Fold 5 Epoch 10: loss=0.7147, acc=46.17% (best=58.28%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 54.92%\n",
      "          Fold 3 Epoch 15: loss=0.7146, acc=53.20% (best=57.50%)\n",
      "          Fold 1 Epoch 15: loss=0.7107, acc=66.48% (best=66.48%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.28%\n",
      "          Fold 3 Epoch 20: loss=0.7110, acc=54.06% (best=57.50%)\n",
      "          Fold 1 Epoch 20: loss=0.7104, acc=54.53% (best=66.48%)\n",
      "          Fold 3 Epoch 25: loss=0.7083, acc=50.62% (best=60.23%)\n",
      "          Fold 1 Epoch 25: loss=0.7033, acc=56.17% (best=66.48%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 66.48%\n",
      "          Fold 3 Epoch 30: loss=0.7081, acc=49.92% (best=60.23%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 60.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2787e62c:\n",
      "        Fold accuracies: ['66.48%', '54.92%', '60.23%', '73.05%', '58.28%']\n",
      "        Average fitness: 62.59% Â± 6.44%\n",
      "        Best fold: Fold 4 with 73.05%\n",
      "      Fitness obtained: 62.59% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 6d7bfc80)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6d7bfc80 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7453, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7016, acc=54.30% (best=54.30%)\n",
      "          Fold 3 Epoch 1: loss=0.7455, acc=47.97% (best=47.97%)\n",
      "          Fold 1 Epoch 1: loss=0.7266, acc=50.16% (best=50.16%)\n",
      "          Fold 2 Epoch 1: loss=0.7130, acc=32.11% (best=32.11%)\n",
      "          Fold 5 Epoch 5: loss=0.5738, acc=51.72% (best=51.72%)\n",
      "          Fold 4 Epoch 5: loss=0.5011, acc=44.45% (best=57.11%)\n",
      "          Fold 3 Epoch 5: loss=0.4500, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 5: loss=0.6105, acc=52.97% (best=53.36%)\n",
      "          Fold 2 Epoch 5: loss=0.5211, acc=40.70% (best=41.72%)\n",
      "          Fold 5 Epoch 10: loss=0.3989, acc=59.22% (best=59.22%)\n",
      "          Fold 4 Epoch 10: loss=0.3728, acc=49.22% (best=57.11%)\n",
      "          Fold 3 Epoch 10: loss=0.3700, acc=55.47% (best=60.86%)\n",
      "          Fold 1 Epoch 10: loss=0.4675, acc=52.58% (best=56.17%)\n",
      "          Fold 2 Epoch 10: loss=0.3481, acc=55.86% (best=58.28%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 57.11%\n",
      "          Fold 5 Epoch 15: loss=0.3440, acc=53.67% (best=59.22%)\n",
      "          Fold 3 Epoch 15: loss=0.3286, acc=51.09% (best=60.86%)\n",
      "          Fold 1 Epoch 15: loss=0.3799, acc=46.09% (best=58.20%)\n",
      "          Fold 2 Epoch 15: loss=0.3073, acc=58.36% (best=61.48%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 60.86%\n",
      "          Fold 5 Epoch 20: loss=0.3015, acc=65.08% (best=65.08%)\n",
      "          Fold 1 Epoch 20: loss=0.3292, acc=55.47% (best=58.20%)\n",
      "          Fold 2 Epoch 20: loss=0.2732, acc=40.70% (best=61.48%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 61.48%\n",
      "          Fold 5 Epoch 25: loss=0.2771, acc=52.11% (best=65.08%)\n",
      "          Fold 1 Epoch 25: loss=0.2925, acc=62.66% (best=68.67%)\n",
      "          Fold 5 Epoch 30: loss=0.2648, acc=48.59% (best=65.08%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 65.08%\n",
      "          Fold 1 Epoch 30: loss=0.2650, acc=63.91% (best=68.67%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6d7bfc80:\n",
      "        Fold accuracies: ['68.67%', '61.48%', '60.86%', '57.11%', '65.08%']\n",
      "        Average fitness: 62.64% Â± 3.94%\n",
      "        Best fold: Fold 1 with 68.67%\n",
      "      Fitness obtained: 62.64% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 301cae3e)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 301cae3e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7238, acc=56.95% (best=56.95%)\n",
      "          Fold 2 Epoch 1: loss=0.7097, acc=44.38% (best=44.38%)\n",
      "          Fold 3 Epoch 1: loss=0.7286, acc=45.94% (best=45.94%)\n",
      "          Fold 4 Epoch 1: loss=0.7089, acc=65.23% (best=65.23%)\n",
      "          Fold 5 Epoch 1: loss=0.7506, acc=54.84% (best=54.84%)\n",
      "          Fold 2 Epoch 5: loss=0.3828, acc=49.61% (best=58.20%)\n",
      "          Fold 1 Epoch 5: loss=0.4787, acc=53.05% (best=66.17%)\n",
      "          Fold 5 Epoch 5: loss=0.4087, acc=50.31% (best=55.31%)\n",
      "          Fold 3 Epoch 5: loss=0.3797, acc=56.02% (best=61.80%)\n",
      "          Fold 4 Epoch 5: loss=0.3750, acc=60.55% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2746, acc=39.38% (best=62.66%)\n",
      "          Fold 1 Epoch 10: loss=0.2994, acc=62.27% (best=66.17%)\n",
      "          Fold 5 Epoch 10: loss=0.2727, acc=49.84% (best=61.02%)\n",
      "          Fold 3 Epoch 10: loss=0.2718, acc=59.61% (best=68.75%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 66.17%\n",
      "          Fold 4 Epoch 10: loss=0.2685, acc=53.20% (best=65.23%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "          Fold 2 Epoch 15: loss=0.2451, acc=49.38% (best=62.66%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 62.66%\n",
      "          Fold 5 Epoch 15: loss=0.2424, acc=50.62% (best=61.02%)\n",
      "          Fold 3 Epoch 15: loss=0.2385, acc=53.83% (best=68.75%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 61.02%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 68.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 301cae3e:\n",
      "        Fold accuracies: ['66.17%', '62.66%', '68.75%', '65.23%', '61.02%']\n",
      "        Average fitness: 64.77% Â± 2.70%\n",
      "        Best fold: Fold 3 with 68.75%\n",
      "      Fitness obtained: 64.77% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 1059dbe1)\n",
      "      Architecture: 12 conv + 6 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model 1059dbe1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=1.1134, acc=65.08% (best=65.08%)\n",
      "          Fold 5 Epoch 1: loss=1.2563, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=1.2189, acc=55.78% (best=55.78%)\n",
      "          Fold 2 Epoch 1: loss=1.1257, acc=40.55% (best=40.55%)\n",
      "          Fold 3 Epoch 1: loss=1.1346, acc=51.02% (best=51.02%)\n",
      "          Fold 4 Epoch 5: loss=0.6482, acc=60.08% (best=69.22%)\n",
      "          Fold 5 Epoch 5: loss=0.6967, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 5: loss=0.6829, acc=60.08% (best=62.50%)\n",
      "          Fold 2 Epoch 5: loss=0.6460, acc=55.86% (best=55.86%)\n",
      "          Fold 3 Epoch 5: loss=0.6864, acc=42.34% (best=58.59%)\n",
      "          Fold 4 Epoch 10: loss=0.6410, acc=41.48% (best=69.22%)\n",
      "          Fold 5 Epoch 10: loss=0.6955, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 10: loss=0.6796, acc=62.11% (best=63.05%)\n",
      "          Fold 2 Epoch 10: loss=0.5536, acc=55.23% (best=55.86%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.22%\n",
      "          Fold 3 Epoch 10: loss=0.6245, acc=56.56% (best=58.59%)\n",
      "          Fold 1 Epoch 15: loss=0.6965, acc=50.23% (best=63.05%)\n",
      "          Fold 2 Epoch 15: loss=0.4581, acc=37.97% (best=55.86%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 58.59%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 63.05%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1059dbe1:\n",
      "        Fold accuracies: ['63.05%', '55.86%', '58.59%', '69.22%', '50.00%']\n",
      "        Average fitness: 59.34% Â± 6.50%\n",
      "        Best fold: Fold 4 with 69.22%\n",
      "      Fitness obtained: 59.34% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 1881bff6)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 1881bff6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7068, acc=53.91% (best=53.91%)\n",
      "          Fold 3 Epoch 1: loss=0.7042, acc=50.16% (best=50.16%)\n",
      "          Fold 4 Epoch 1: loss=0.6787, acc=54.14% (best=54.14%)\n",
      "          Fold 1 Epoch 1: loss=0.7181, acc=62.89% (best=62.89%)\n",
      "          Fold 5 Epoch 1: loss=0.7391, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 5: loss=0.5030, acc=45.23% (best=68.91%)\n",
      "          Fold 3 Epoch 5: loss=0.3950, acc=58.83% (best=61.95%)\n",
      "          Fold 5 Epoch 5: loss=0.4173, acc=48.91% (best=56.48%)\n",
      "          Fold 1 Epoch 5: loss=0.5164, acc=57.42% (best=62.89%)\n",
      "          Fold 2 Epoch 5: loss=0.3928, acc=60.55% (best=60.55%)\n",
      "          Fold 4 Epoch 10: loss=0.3471, acc=50.47% (best=68.91%)\n",
      "          Fold 3 Epoch 10: loss=0.3076, acc=54.53% (best=66.72%)\n",
      "          Fold 5 Epoch 10: loss=0.3302, acc=39.92% (best=56.48%)\n",
      "          Fold 1 Epoch 10: loss=0.3619, acc=58.83% (best=64.69%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.91%\n",
      "          Fold 2 Epoch 10: loss=0.2884, acc=57.97% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.48%\n",
      "          Fold 3 Epoch 15: loss=0.2747, acc=59.06% (best=66.72%)\n",
      "          Fold 1 Epoch 15: loss=0.2911, acc=59.14% (best=64.69%)\n",
      "          Fold 2 Epoch 15: loss=0.2477, acc=48.59% (best=60.55%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 60.55%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 66.72%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1881bff6:\n",
      "        Fold accuracies: ['64.69%', '60.55%', '66.72%', '68.91%', '56.48%']\n",
      "        Average fitness: 63.47% Â± 4.45%\n",
      "        Best fold: Fold 4 with 68.91%\n",
      "      Fitness obtained: 63.47% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: aa53b956)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.1\n",
      "      Training/Evaluating model aa53b956 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=1.1665, acc=50.62% (best=50.62%)\n",
      "          Fold 2 Epoch 1: loss=1.3462, acc=40.39% (best=40.39%)\n",
      "          Fold 3 Epoch 1: loss=1.4918, acc=51.25% (best=51.25%)\n",
      "          Fold 4 Epoch 1: loss=1.4956, acc=55.16% (best=55.16%)\n",
      "          Fold 2 Epoch 5: loss=0.6604, acc=42.27% (best=49.61%)\n",
      "          Fold 3 Epoch 5: loss=0.6876, acc=43.20% (best=52.89%)\n",
      "          Fold 4 Epoch 5: loss=0.6617, acc=61.80% (best=61.80%)\n",
      "          Fold 5 Epoch 5: loss=0.6955, acc=50.00% (best=52.42%)\n",
      "          Fold 2 Epoch 10: loss=0.6403, acc=43.05% (best=54.45%)\n",
      "          Fold 3 Epoch 10: loss=0.5617, acc=51.02% (best=52.89%)\n",
      "          Fold 4 Epoch 10: loss=0.6028, acc=55.70% (best=61.80%)\n",
      "          Fold 5 Epoch 10: loss=0.7030, acc=50.00% (best=52.42%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 52.42%\n",
      "          Fold 2 Epoch 15: loss=0.3723, acc=52.73% (best=56.48%)\n",
      "          Fold 3 Epoch 15: loss=0.4803, acc=50.94% (best=56.33%)\n",
      "          Fold 4 Epoch 15: loss=0.4124, acc=52.27% (best=61.80%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 61.80%\n",
      "          Fold 2 Epoch 20: loss=0.3423, acc=54.61% (best=63.44%)\n",
      "          Fold 3 Epoch 20: loss=0.4951, acc=48.98% (best=58.91%)\n",
      "          Fold 2 Epoch 25: loss=0.3247, acc=54.61% (best=63.44%)\n",
      "          Fold 3 Epoch 25: loss=0.3673, acc=53.44% (best=62.34%)\n",
      "          Fold 2 Epoch 30: loss=0.3260, acc=55.23% (best=74.22%)\n",
      "          Fold 3 Epoch 30: loss=0.3452, acc=54.06% (best=62.34%)\n",
      "          Fold 3: Early stopping at epoch 33\n",
      "      â†’ Fold 3 completed: 62.34%\n",
      "          Fold 2 Epoch 35: loss=0.3342, acc=66.41% (best=74.22%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 74.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for aa53b956:\n",
      "        Fold accuracies: ['0.00%', '74.22%', '62.34%', '61.80%', '52.42%']\n",
      "        Average fitness: 50.16% Â± 26.01%\n",
      "        Best fold: Fold 2 with 74.22%\n",
      "      Fitness obtained: 50.16% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: c6b584ce)\n",
      "      Architecture: 1 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c6b584ce with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4788, acc=53.05% (best=53.05%)\n",
      "          Fold 3 Epoch 1: loss=0.4725, acc=59.84% (best=59.84%)\n",
      "          Fold 4 Epoch 1: loss=0.4628, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 1: loss=0.4699, acc=36.09% (best=36.09%)\n",
      "      ERROR in Fold 2: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 30, in _train_one_fold\n",
      "    optimizer.step()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 177, in step\n",
      "    rmsprop(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 149, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 522, in rmsprop\n",
      "    func(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/optim/rmsprop.py\", line 445, in _multi_tensor_rmsprop\n",
      "    avg = torch._foreach_sqrt(grouped_square_avgs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 5 Epoch 1: loss=0.4690, acc=57.19% (best=57.19%)\n",
      "          Fold 3 Epoch 5: loss=0.2466, acc=56.02% (best=59.84%)\n",
      "          Fold 4 Epoch 5: loss=0.2361, acc=47.97% (best=57.97%)\n",
      "          Fold 1 Epoch 5: loss=0.2478, acc=39.69% (best=40.70%)\n",
      "          Fold 5 Epoch 5: loss=0.2480, acc=60.86% (best=60.86%)\n",
      "          Fold 3 Epoch 10: loss=0.2229, acc=49.77% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.2115, acc=55.23% (best=58.67%)\n",
      "          Fold 1 Epoch 10: loss=0.2193, acc=41.33% (best=43.91%)\n",
      "          Fold 5 Epoch 10: loss=0.2175, acc=57.03% (best=63.59%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 59.84%\n",
      "          Fold 4 Epoch 15: loss=0.1997, acc=50.55% (best=58.67%)\n",
      "          Fold 1 Epoch 15: loss=0.2049, acc=55.78% (best=55.78%)\n",
      "          Fold 5 Epoch 15: loss=0.2052, acc=60.55% (best=63.59%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 58.67%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 63.59%\n",
      "          Fold 1 Epoch 20: loss=0.2034, acc=48.91% (best=55.78%)\n",
      "          Fold 1 Epoch 25: loss=0.1970, acc=44.14% (best=55.78%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 55.78%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c6b584ce:\n",
      "        Fold accuracies: ['55.78%', '0.00%', '59.84%', '58.67%', '63.59%']\n",
      "        Average fitness: 47.58% Â± 23.92%\n",
      "        Best fold: Fold 5 with 63.59%\n",
      "      Fitness obtained: 47.58% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 4e91fddb)\n",
      "      Architecture: 12 conv + 6 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 4e91fddb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
      "    return F.max_pool1d(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_jit_internal.py\", line 627, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
      "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7251, acc=41.72% (best=41.72%)\n",
      "          Fold 1 Epoch 1: loss=0.7385, acc=58.98% (best=58.98%)\n",
      "          Fold 4 Epoch 1: loss=0.7190, acc=41.41% (best=41.41%)\n",
      "          Fold 2 Epoch 5: loss=0.4659, acc=53.75% (best=60.94%)\n",
      "          Fold 1 Epoch 5: loss=0.5555, acc=56.17% (best=62.81%)\n",
      "          Fold 4 Epoch 5: loss=0.5324, acc=61.64% (best=61.64%)\n",
      "          Fold 2 Epoch 10: loss=0.3215, acc=47.73% (best=66.56%)\n",
      "          Fold 1 Epoch 10: loss=0.3403, acc=67.11% (best=67.27%)\n",
      "          Fold 4 Epoch 10: loss=0.3219, acc=58.28% (best=68.67%)\n",
      "          Fold 2 Epoch 15: loss=0.2716, acc=48.67% (best=66.56%)\n",
      "          Fold 1 Epoch 15: loss=0.2757, acc=56.95% (best=67.27%)\n",
      "          Fold 4 Epoch 15: loss=0.2703, acc=62.11% (best=68.67%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 66.56%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 67.27%\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 68.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 4e91fddb:\n",
      "        Fold accuracies: ['67.27%', '66.56%', '0.00%', '68.67%', '0.00%']\n",
      "        Average fitness: 40.50% Â± 33.08%\n",
      "        Best fold: Fold 4 with 68.67%\n",
      "      Fitness obtained: 40.50% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 93e82d27)\n",
      "      Architecture: 9 conv + 8 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model 93e82d27 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7171, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 1: loss=0.7153, acc=50.31% (best=50.31%)\n",
      "          Fold 3 Epoch 1: loss=0.7150, acc=52.73% (best=52.73%)\n",
      "          Fold 4 Epoch 1: loss=0.7048, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7229, acc=48.59% (best=48.59%)\n",
      "          Fold 3 Epoch 5: loss=0.7099, acc=50.94% (best=52.73%)\n",
      "          Fold 1 Epoch 5: loss=0.7049, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 5: loss=0.6837, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 5: loss=0.7045, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 5: loss=0.7098, acc=49.69% (best=49.69%)\n",
      "          Fold 3 Epoch 10: loss=0.7035, acc=41.95% (best=52.73%)\n",
      "          Fold 1 Epoch 10: loss=0.6964, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 10: loss=0.6723, acc=49.22% (best=49.22%)\n",
      "          Fold 2 Epoch 10: loss=0.7002, acc=50.39% (best=50.39%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 52.73%\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 50.23%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.22%\n",
      "          Fold 5 Epoch 10: loss=0.7101, acc=43.59% (best=49.69%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 50.39%\n",
      "          Fold 5 Epoch 15: loss=0.7020, acc=43.59% (best=52.34%)\n",
      "          Fold 5 Epoch 20: loss=0.7046, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 25: loss=0.6996, acc=49.92% (best=55.16%)\n",
      "          Fold 5 Epoch 30: loss=0.7032, acc=50.08% (best=55.16%)\n",
      "          Fold 5: Early stopping at epoch 30\n",
      "      â†’ Fold 5 completed: 55.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 93e82d27:\n",
      "        Fold accuracies: ['50.23%', '50.39%', '52.73%', '49.22%', '55.16%']\n",
      "        Average fitness: 51.55% Â± 2.14%\n",
      "        Best fold: Fold 5 with 55.16%\n",
      "      Fitness obtained: 51.55% | Best in generation: 65.17% | Global best: 70.92%\n",
      "\n",
      "GENERATION 19 STATISTICS:\n",
      "   Maximum fitness: 65.17%\n",
      "   Average fitness: 55.98%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 14.33%\n",
      "   Best individual: 872fa407 with 65.17%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 10/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=14.33)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 872fa407 (fitness: 65.17%)\n",
      "   Elite 2: 301cae3e (fitness: 64.77%)\n",
      "   Elite 3: b8dceb58 (fitness: 63.98%)\n",
      "   Elite 4: 9cd4263e (fitness: 63.95%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 11/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 20\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 20)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 872fa407)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 872fa407 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6665, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.6778, acc=51.09% (best=51.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6616, acc=59.06% (best=59.06%)\n",
      "          Fold 1 Epoch 1: loss=0.6858, acc=55.16% (best=55.16%)\n",
      "          Fold 5 Epoch 1: loss=0.6991, acc=52.42% (best=52.42%)\n",
      "          Fold 2 Epoch 5: loss=0.3464, acc=61.09% (best=61.09%)\n",
      "          Fold 3 Epoch 5: loss=0.3950, acc=50.47% (best=56.02%)\n",
      "          Fold 4 Epoch 5: loss=0.4104, acc=47.73% (best=65.31%)\n",
      "          Fold 1 Epoch 5: loss=0.4139, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.4367, acc=48.75% (best=56.88%)\n",
      "          Fold 3 Epoch 10: loss=0.3078, acc=56.41% (best=60.94%)\n",
      "          Fold 2 Epoch 10: loss=0.2667, acc=58.91% (best=61.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2871, acc=60.86% (best=65.31%)\n",
      "          Fold 1 Epoch 10: loss=0.3029, acc=61.56% (best=65.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2791, acc=46.09% (best=56.88%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.31%\n",
      "          Fold 3 Epoch 15: loss=0.2596, acc=56.25% (best=63.83%)\n",
      "          Fold 2 Epoch 15: loss=0.2440, acc=53.75% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 56.88%\n",
      "          Fold 1 Epoch 15: loss=0.2701, acc=57.11% (best=66.02%)\n",
      "          Fold 3 Epoch 20: loss=0.2446, acc=57.73% (best=65.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2290, acc=59.45% (best=63.05%)\n",
      "          Fold 1 Epoch 20: loss=0.2434, acc=66.72% (best=66.72%)\n",
      "          Fold 2 Epoch 25: loss=0.2204, acc=64.30% (best=64.30%)\n",
      "          Fold 3 Epoch 25: loss=0.2314, acc=59.61% (best=65.23%)\n",
      "          Fold 1 Epoch 25: loss=0.2299, acc=64.14% (best=71.56%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 65.23%\n",
      "          Fold 2 Epoch 30: loss=0.2148, acc=59.61% (best=66.41%)\n",
      "          Fold 1 Epoch 30: loss=0.2189, acc=55.62% (best=71.56%)\n",
      "          Fold 1: Early stopping at epoch 33\n",
      "      â†’ Fold 1 completed: 71.56%\n",
      "          Fold 2 Epoch 35: loss=0.2155, acc=53.44% (best=66.41%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 66.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 872fa407:\n",
      "        Fold accuracies: ['71.56%', '66.41%', '65.23%', '65.31%', '56.88%']\n",
      "        Average fitness: 65.08% Â± 4.72%\n",
      "        Best fold: Fold 1 with 71.56%\n",
      "      New best fitness in this generation: 65.08%!\n",
      "      Fitness obtained: 65.08% | Best in generation: 65.08% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 301cae3e)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 301cae3e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7152, acc=56.02% (best=56.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7276, acc=45.62% (best=45.62%)\n",
      "          Fold 3 Epoch 1: loss=0.7362, acc=56.33% (best=56.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6920, acc=56.48% (best=56.48%)\n",
      "          Fold 5 Epoch 1: loss=0.7402, acc=49.14% (best=49.14%)\n",
      "          Fold 2 Epoch 5: loss=0.3645, acc=54.77% (best=58.28%)\n",
      "          Fold 1 Epoch 5: loss=0.4136, acc=52.50% (best=56.33%)\n",
      "          Fold 3 Epoch 5: loss=0.4073, acc=66.25% (best=66.72%)\n",
      "          Fold 4 Epoch 5: loss=0.4323, acc=60.31% (best=66.17%)\n",
      "          Fold 5 Epoch 5: loss=0.3794, acc=45.78% (best=64.77%)\n",
      "          Fold 2 Epoch 10: loss=0.2728, acc=55.23% (best=63.67%)\n",
      "          Fold 1 Epoch 10: loss=0.2828, acc=56.41% (best=66.72%)\n",
      "          Fold 3 Epoch 10: loss=0.2874, acc=64.92% (best=66.72%)\n",
      "          Fold 4 Epoch 10: loss=0.2814, acc=50.39% (best=66.17%)\n",
      "          Fold 5 Epoch 10: loss=0.2636, acc=48.12% (best=64.77%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 66.72%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 66.17%\n",
      "          Fold 2 Epoch 15: loss=0.2345, acc=51.33% (best=68.52%)\n",
      "          Fold 1 Epoch 15: loss=0.2462, acc=47.03% (best=66.72%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 64.77%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 66.72%\n",
      "          Fold 2 Epoch 20: loss=0.2228, acc=60.08% (best=68.52%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 68.52%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 301cae3e:\n",
      "        Fold accuracies: ['66.72%', '68.52%', '66.72%', '66.17%', '64.77%']\n",
      "        Average fitness: 66.58% Â± 1.20%\n",
      "        Best fold: Fold 2 with 68.52%\n",
      "      New best fitness in this generation: 66.58%!\n",
      "      Fitness obtained: 66.58% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: b8dceb58)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b8dceb58 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6882, acc=50.62% (best=50.62%)\n",
      "          Fold 2 Epoch 1: loss=0.7115, acc=48.44% (best=48.44%)\n",
      "          Fold 1 Epoch 1: loss=0.7081, acc=57.97% (best=57.97%)\n",
      "          Fold 3 Epoch 1: loss=0.7060, acc=66.17% (best=66.17%)\n",
      "          Fold 5 Epoch 1: loss=0.7302, acc=46.17% (best=46.17%)\n",
      "          Fold 2 Epoch 5: loss=0.4076, acc=57.81% (best=57.81%)\n",
      "          Fold 4 Epoch 5: loss=0.4633, acc=45.47% (best=55.55%)\n",
      "          Fold 1 Epoch 5: loss=0.4672, acc=51.95% (best=57.97%)\n",
      "          Fold 3 Epoch 5: loss=0.4415, acc=54.06% (best=66.17%)\n",
      "          Fold 5 Epoch 5: loss=0.5650, acc=59.30% (best=63.75%)\n",
      "          Fold 2 Epoch 10: loss=0.2825, acc=46.56% (best=57.81%)\n",
      "          Fold 4 Epoch 10: loss=0.2877, acc=62.27% (best=62.27%)\n",
      "          Fold 1 Epoch 10: loss=0.3187, acc=57.11% (best=57.97%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 57.97%\n",
      "          Fold 3 Epoch 10: loss=0.3095, acc=62.97% (best=66.17%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 66.17%\n",
      "          Fold 5 Epoch 10: loss=0.3358, acc=45.78% (best=63.75%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 4 Epoch 15: loss=0.2448, acc=52.11% (best=62.27%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 63.75%\n",
      "          Fold 4 Epoch 20: loss=0.2249, acc=39.77% (best=62.27%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 62.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b8dceb58:\n",
      "        Fold accuracies: ['57.97%', '57.81%', '66.17%', '62.27%', '63.75%']\n",
      "        Average fitness: 61.59% Â± 3.27%\n",
      "        Best fold: Fold 3 with 66.17%\n",
      "      Fitness obtained: 61.59% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: 9cd4263e)\n",
      "      Architecture: 12 conv + 3 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 9cd4263e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7024, acc=62.11% (best=62.11%)\n",
      "          Fold 4 Epoch 1: loss=0.6967, acc=62.50% (best=62.50%)\n",
      "          Fold 3 Epoch 1: loss=0.7108, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 1: loss=0.6981, acc=48.44% (best=48.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7220, acc=47.03% (best=47.03%)\n",
      "          Fold 1 Epoch 5: loss=0.6538, acc=53.75% (best=62.11%)\n",
      "          Fold 4 Epoch 5: loss=0.5958, acc=52.66% (best=62.50%)\n",
      "          Fold 3 Epoch 5: loss=0.5533, acc=46.95% (best=57.73%)\n",
      "          Fold 5 Epoch 5: loss=0.6280, acc=55.16% (best=67.50%)\n",
      "          Fold 2 Epoch 5: loss=0.5716, acc=58.98% (best=58.98%)\n",
      "          Fold 1 Epoch 10: loss=0.4769, acc=50.16% (best=62.89%)\n",
      "          Fold 4 Epoch 10: loss=0.4317, acc=54.06% (best=62.50%)\n",
      "          Fold 3 Epoch 10: loss=0.3956, acc=52.27% (best=57.73%)\n",
      "          Fold 5 Epoch 10: loss=0.4500, acc=61.09% (best=67.50%)\n",
      "          Fold 2 Epoch 10: loss=0.3962, acc=55.78% (best=59.45%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 62.50%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 57.73%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 67.50%\n",
      "          Fold 1 Epoch 15: loss=0.4058, acc=50.47% (best=62.89%)\n",
      "          Fold 2 Epoch 15: loss=0.3409, acc=54.38% (best=59.45%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 59.45%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9cd4263e:\n",
      "        Fold accuracies: ['62.89%', '59.45%', '57.73%', '62.50%', '67.50%']\n",
      "        Average fitness: 62.02% Â± 3.35%\n",
      "        Best fold: Fold 5 with 67.50%\n",
      "      Fitness obtained: 62.02% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 3950cb04)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3950cb04 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6638, acc=52.81% (best=52.81%)\n",
      "          Fold 3 Epoch 1: loss=0.6793, acc=43.59% (best=43.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6874, acc=56.17% (best=56.17%)\n",
      "          Fold 4 Epoch 1: loss=0.6701, acc=63.20% (best=63.20%)\n",
      "          Fold 5 Epoch 1: loss=0.7043, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.3034, acc=35.55% (best=52.81%)\n",
      "          Fold 3 Epoch 5: loss=0.3310, acc=49.22% (best=56.33%)\n",
      "          Fold 5 Epoch 5: loss=0.3623, acc=66.95% (best=66.95%)\n",
      "          Fold 4 Epoch 5: loss=0.3292, acc=53.20% (best=65.00%)\n",
      "          Fold 1 Epoch 5: loss=0.3692, acc=60.70% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2451, acc=47.58% (best=52.81%)\n",
      "          Fold 3 Epoch 10: loss=0.2552, acc=53.28% (best=56.41%)\n",
      "          Fold 5 Epoch 10: loss=0.2713, acc=46.95% (best=66.95%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 52.81%\n",
      "          Fold 4 Epoch 10: loss=0.2471, acc=36.48% (best=65.00%)\n",
      "          Fold 1 Epoch 10: loss=0.2746, acc=53.05% (best=60.70%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.00%\n",
      "          Fold 3 Epoch 15: loss=0.2342, acc=60.31% (best=60.31%)\n",
      "          Fold 5 Epoch 15: loss=0.2380, acc=53.36% (best=66.95%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 66.95%\n",
      "          Fold 1 Epoch 15: loss=0.2423, acc=58.98% (best=63.44%)\n",
      "          Fold 3 Epoch 20: loss=0.2172, acc=45.94% (best=60.31%)\n",
      "          Fold 1 Epoch 20: loss=0.2233, acc=62.66% (best=63.44%)\n",
      "          Fold 3 Epoch 25: loss=0.2141, acc=48.83% (best=60.70%)\n",
      "          Fold 1 Epoch 25: loss=0.2170, acc=56.80% (best=64.14%)\n",
      "          Fold 3 Epoch 30: loss=0.2102, acc=56.95% (best=60.70%)\n",
      "          Fold 3: Early stopping at epoch 31\n",
      "      â†’ Fold 3 completed: 60.70%\n",
      "          Fold 1 Epoch 30: loss=0.2143, acc=48.44% (best=64.14%)\n",
      "          Fold 1: Early stopping at epoch 32\n",
      "      â†’ Fold 1 completed: 64.14%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3950cb04:\n",
      "        Fold accuracies: ['64.14%', '52.81%', '60.70%', '65.00%', '66.95%']\n",
      "        Average fitness: 61.92% Â± 4.98%\n",
      "        Best fold: Fold 5 with 66.95%\n",
      "      Fitness obtained: 61.92% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 6c675bcb)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=0.0001\n",
      "      Training/Evaluating model 6c675bcb with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7205, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=0.7204, acc=48.98% (best=48.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7244, acc=42.50% (best=42.50%)\n",
      "          Fold 4 Epoch 1: loss=0.7290, acc=47.34% (best=47.34%)\n",
      "          Fold 2 Epoch 1: loss=0.7446, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.7114, acc=42.03% (best=60.23%)\n",
      "          Fold 5 Epoch 5: loss=0.7179, acc=51.80% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.7130, acc=49.14% (best=49.14%)\n",
      "          Fold 4 Epoch 5: loss=0.7080, acc=44.14% (best=63.91%)\n",
      "          Fold 2 Epoch 5: loss=0.7159, acc=51.64% (best=54.45%)\n",
      "          Fold 1 Epoch 10: loss=0.7163, acc=65.31% (best=66.72%)\n",
      "          Fold 5 Epoch 10: loss=0.7176, acc=49.30% (best=56.64%)\n",
      "          Fold 3 Epoch 10: loss=0.7134, acc=48.52% (best=53.52%)\n",
      "          Fold 4 Epoch 10: loss=0.7108, acc=50.55% (best=63.91%)\n",
      "          Fold 2 Epoch 10: loss=0.7078, acc=49.84% (best=55.08%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.91%\n",
      "          Fold 1 Epoch 15: loss=0.7073, acc=51.02% (best=66.72%)\n",
      "          Fold 5 Epoch 15: loss=0.7182, acc=51.72% (best=70.39%)\n",
      "          Fold 3 Epoch 15: loss=0.7102, acc=51.88% (best=53.52%)\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 53.52%\n",
      "          Fold 2 Epoch 15: loss=0.6995, acc=46.80% (best=55.08%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 66.72%\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 55.08%\n",
      "          Fold 5 Epoch 20: loss=0.7173, acc=41.17% (best=70.39%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 70.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6c675bcb:\n",
      "        Fold accuracies: ['66.72%', '55.08%', '53.52%', '63.91%', '70.39%']\n",
      "        Average fitness: 61.92% Â± 6.58%\n",
      "        Best fold: Fold 5 with 70.39%\n",
      "      Fitness obtained: 61.92% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 37e1d8ad)\n",
      "      Architecture: 12 conv + 7 fc, opt=sgd, lr=0.0005\n",
      "      Training/Evaluating model 37e1d8ad with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7197, acc=58.28% (best=58.28%)\n",
      "          Fold 4 Epoch 1: loss=0.7138, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 1: loss=0.7212, acc=44.22% (best=44.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7204, acc=45.62% (best=45.62%)\n",
      "          Fold 1 Epoch 1: loss=0.7224, acc=50.70% (best=50.70%)\n",
      "          Fold 2 Epoch 5: loss=0.7079, acc=56.72% (best=58.75%)\n",
      "          Fold 4 Epoch 5: loss=0.7024, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 5: loss=0.7133, acc=51.80% (best=55.39%)\n",
      "          Fold 5 Epoch 5: loss=0.7149, acc=45.47% (best=61.72%)\n",
      "          Fold 1 Epoch 5: loss=0.7130, acc=49.77% (best=51.41%)\n",
      "          Fold 2 Epoch 10: loss=0.7036, acc=58.83% (best=58.83%)\n",
      "          Fold 4 Epoch 10: loss=0.6790, acc=49.22% (best=49.22%)\n",
      "          Fold 3 Epoch 10: loss=0.7100, acc=46.25% (best=55.39%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 49.22%\n",
      "          Fold 5 Epoch 10: loss=0.7097, acc=51.80% (best=61.72%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 55.39%\n",
      "          Fold 1 Epoch 10: loss=0.7041, acc=49.77% (best=52.73%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.72%\n",
      "          Fold 2 Epoch 15: loss=0.7002, acc=41.80% (best=58.83%)\n",
      "          Fold 1 Epoch 15: loss=0.7007, acc=51.56% (best=64.61%)\n",
      "          Fold 2 Epoch 20: loss=0.6938, acc=50.08% (best=58.83%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 58.83%\n",
      "          Fold 1 Epoch 20: loss=0.6997, acc=53.28% (best=64.61%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 64.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 37e1d8ad:\n",
      "        Fold accuracies: ['64.61%', '58.83%', '55.39%', '49.22%', '61.72%']\n",
      "        Average fitness: 57.95% Â± 5.33%\n",
      "        Best fold: Fold 1 with 64.61%\n",
      "      Fitness obtained: 57.95% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 45e08ff4)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 45e08ff4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 3: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 45e08ff4:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fitness obtained: 0.00% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 02b2acfe)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 02b2acfe with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6776, acc=45.55% (best=45.55%)\n",
      "          Fold 3 Epoch 1: loss=0.6888, acc=59.14% (best=59.14%)\n",
      "          Fold 1 Epoch 1: loss=0.6904, acc=47.66% (best=47.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6630, acc=58.05% (best=58.05%)\n",
      "          Fold 5 Epoch 1: loss=0.6995, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 5: loss=0.3130, acc=49.06% (best=57.89%)\n",
      "          Fold 1 Epoch 5: loss=0.4645, acc=56.02% (best=60.47%)\n",
      "          Fold 3 Epoch 5: loss=0.4049, acc=55.94% (best=59.14%)\n",
      "          Fold 5 Epoch 5: loss=0.4514, acc=46.56% (best=50.78%)\n",
      "          Fold 4 Epoch 5: loss=0.4010, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2600, acc=50.62% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.2930, acc=50.55% (best=60.47%)\n",
      "          Fold 3 Epoch 10: loss=0.3152, acc=58.59% (best=62.27%)\n",
      "          Fold 5 Epoch 10: loss=0.2955, acc=46.17% (best=62.34%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 60.47%\n",
      "          Fold 4 Epoch 10: loss=0.2788, acc=60.23% (best=60.23%)\n",
      "          Fold 2 Epoch 15: loss=0.2389, acc=50.39% (best=59.92%)\n",
      "          Fold 3 Epoch 15: loss=0.2654, acc=58.52% (best=62.27%)\n",
      "          Fold 5 Epoch 15: loss=0.2588, acc=50.62% (best=62.34%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 62.34%\n",
      "          Fold 4 Epoch 15: loss=0.2454, acc=44.77% (best=60.23%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 3 Epoch 20: loss=0.2367, acc=62.11% (best=64.22%)\n",
      "          Fold 4 Epoch 20: loss=0.2290, acc=53.59% (best=62.34%)\n",
      "          Fold 3 Epoch 25: loss=0.2267, acc=57.58% (best=64.22%)\n",
      "          Fold 4 Epoch 25: loss=0.2211, acc=54.38% (best=66.72%)\n",
      "          Fold 3 Epoch 30: loss=0.2186, acc=64.38% (best=66.17%)\n",
      "          Fold 4 Epoch 30: loss=0.2205, acc=57.19% (best=66.72%)\n",
      "          Fold 3 Epoch 35: loss=0.2186, acc=64.06% (best=66.17%)\n",
      "          Fold 4: Early stopping at epoch 33\n",
      "      â†’ Fold 4 completed: 66.72%\n",
      "          Fold 3: Early stopping at epoch 38\n",
      "      â†’ Fold 3 completed: 66.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 02b2acfe:\n",
      "        Fold accuracies: ['60.47%', '59.92%', '66.17%', '66.72%', '62.34%']\n",
      "        Average fitness: 63.12% Â± 2.83%\n",
      "        Best fold: Fold 4 with 66.72%\n",
      "      Fitness obtained: 63.12% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: ae9f4134)\n",
      "      Architecture: 1 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model ae9f4134 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.4579, acc=50.08% (best=50.08%)\n",
      "          Fold 3 Epoch 1: loss=0.4877, acc=54.30% (best=54.30%)\n",
      "          Fold 4 Epoch 1: loss=0.4527, acc=46.25% (best=46.25%)\n",
      "          Fold 1 Epoch 1: loss=0.5152, acc=47.81% (best=47.81%)\n",
      "          Fold 5 Epoch 1: loss=0.4926, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 5: loss=0.2426, acc=60.08% (best=60.08%)\n",
      "          Fold 3 Epoch 5: loss=0.2518, acc=57.66% (best=58.59%)\n",
      "          Fold 1 Epoch 5: loss=0.2539, acc=37.89% (best=50.16%)\n",
      "          Fold 4 Epoch 5: loss=0.2267, acc=44.06% (best=52.58%)\n",
      "          Fold 5 Epoch 5: loss=0.2454, acc=58.67% (best=60.70%)\n",
      "          Fold 2 Epoch 10: loss=0.2233, acc=55.23% (best=60.08%)\n",
      "          Fold 3 Epoch 10: loss=0.2293, acc=49.53% (best=58.59%)\n",
      "          Fold 1 Epoch 10: loss=0.2227, acc=41.64% (best=50.16%)\n",
      "          Fold 4 Epoch 10: loss=0.2183, acc=50.16% (best=52.58%)\n",
      "          Fold 5 Epoch 10: loss=0.2204, acc=60.16% (best=60.70%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 50.16%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 58.59%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 52.58%\n",
      "          Fold 2 Epoch 15: loss=0.2052, acc=52.66% (best=60.08%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 60.08%\n",
      "          Fold 5 Epoch 15: loss=0.2121, acc=54.77% (best=61.09%)\n",
      "          Fold 5 Epoch 20: loss=0.2044, acc=57.19% (best=61.09%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 61.09%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for ae9f4134:\n",
      "        Fold accuracies: ['50.16%', '60.08%', '58.59%', '52.58%', '61.09%']\n",
      "        Average fitness: 56.50% Â± 4.33%\n",
      "        Best fold: Fold 5 with 61.09%\n",
      "      Fitness obtained: 56.50% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: e1e4eb06)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=1e-05\n",
      "      Training/Evaluating model e1e4eb06 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7121, acc=59.84% (best=59.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6988, acc=46.56% (best=46.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6943, acc=61.56% (best=61.56%)\n",
      "          Fold 5 Epoch 1: loss=0.7157, acc=49.69% (best=49.69%)\n",
      "          Fold 3 Epoch 1: loss=0.7059, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 5: loss=0.6914, acc=58.83% (best=62.34%)\n",
      "          Fold 2 Epoch 5: loss=0.6796, acc=42.34% (best=52.34%)\n",
      "          Fold 5 Epoch 5: loss=0.7098, acc=44.45% (best=53.59%)\n",
      "          Fold 4 Epoch 5: loss=0.6810, acc=58.20% (best=65.39%)\n",
      "          Fold 3 Epoch 5: loss=0.7039, acc=41.64% (best=49.30%)\n",
      "          Fold 1 Epoch 10: loss=0.6873, acc=59.06% (best=62.34%)\n",
      "          Fold 2 Epoch 10: loss=0.6691, acc=48.52% (best=52.34%)\n",
      "          Fold 5 Epoch 10: loss=0.7052, acc=38.98% (best=53.59%)\n",
      "          Fold 4 Epoch 10: loss=0.6573, acc=54.53% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.6987, acc=48.91% (best=49.30%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 52.34%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.59%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.34%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 3 Epoch 15: loss=0.6930, acc=45.23% (best=49.84%)\n",
      "          Fold 3 Epoch 20: loss=0.6874, acc=44.53% (best=49.84%)\n",
      "          Fold 3 Epoch 25: loss=0.6752, acc=57.27% (best=60.94%)\n",
      "          Fold 3 Epoch 30: loss=0.6596, acc=61.48% (best=63.91%)\n",
      "          Fold 3 Epoch 35: loss=0.6429, acc=59.22% (best=63.91%)\n",
      "          Fold 3: Early stopping at epoch 39\n",
      "      â†’ Fold 3 completed: 63.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e1e4eb06:\n",
      "        Fold accuracies: ['62.34%', '52.34%', '63.91%', '65.39%', '53.59%']\n",
      "        Average fitness: 59.52% Â± 5.45%\n",
      "        Best fold: Fold 4 with 65.39%\n",
      "      Fitness obtained: 59.52% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 9be8d773)\n",
      "      Architecture: 12 conv + 7 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 9be8d773 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7222, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.7238, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7165, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7175, acc=50.78% (best=50.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7240, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 5: loss=0.6967, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 5: loss=0.7056, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.6843, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 5: loss=0.7081, acc=52.97% (best=53.91%)\n",
      "          Fold 4 Epoch 5: loss=0.6394, acc=49.22% (best=50.78%)\n",
      "          Fold 1 Epoch 10: loss=0.5890, acc=49.92% (best=52.89%)\n",
      "          Fold 3 Epoch 10: loss=0.6460, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 10: loss=0.5884, acc=52.73% (best=52.73%)\n",
      "          Fold 5 Epoch 10: loss=0.7050, acc=50.31% (best=53.91%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 4 Epoch 10: loss=0.5210, acc=49.22% (best=55.47%)\n",
      "          Fold 1 Epoch 15: loss=0.4681, acc=49.77% (best=52.89%)\n",
      "          Fold 2 Epoch 15: loss=0.3968, acc=53.05% (best=53.05%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 53.91%\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 52.89%\n",
      "          Fold 4 Epoch 15: loss=0.4145, acc=55.47% (best=55.62%)\n",
      "          Fold 2 Epoch 20: loss=0.3390, acc=49.84% (best=53.05%)\n",
      "          Fold 4 Epoch 20: loss=0.3479, acc=58.59% (best=58.59%)\n",
      "          Fold 2 Epoch 25: loss=0.3251, acc=49.69% (best=53.05%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 53.05%\n",
      "          Fold 4 Epoch 25: loss=0.3160, acc=55.39% (best=58.59%)\n",
      "          Fold 4 Epoch 30: loss=0.2936, acc=55.62% (best=58.98%)\n",
      "          Fold 4 Epoch 35: loss=0.2764, acc=49.22% (best=59.22%)\n",
      "          Fold 4 Epoch 40: loss=0.2686, acc=55.62% (best=59.22%)\n",
      "          Fold 4: Early stopping at epoch 41\n",
      "      â†’ Fold 4 completed: 59.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9be8d773:\n",
      "        Fold accuracies: ['52.89%', '53.05%', '51.02%', '59.22%', '53.91%']\n",
      "        Average fitness: 54.02% Â± 2.77%\n",
      "        Best fold: Fold 4 with 59.22%\n",
      "      Fitness obtained: 54.02% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 852c5b48)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 852c5b48 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=8.3396, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 1: loss=9.6246, acc=50.78% (best=50.78%)\n",
      "          Fold 3 Epoch 1: loss=8.8768, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 1: loss=11.0302, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=9.8341, acc=52.73% (best=52.73%)\n",
      "          Fold 1 Epoch 5: loss=0.6871, acc=49.77% (best=56.41%)\n",
      "          Fold 4 Epoch 5: loss=0.6420, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 5: loss=0.6740, acc=55.78% (best=55.78%)\n",
      "          Fold 5 Epoch 5: loss=0.7039, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6699, acc=56.25% (best=56.95%)\n",
      "          Fold 1 Epoch 10: loss=0.7260, acc=50.23% (best=56.41%)\n",
      "          Fold 4 Epoch 10: loss=0.9093, acc=57.42% (best=63.83%)\n",
      "          Fold 3 Epoch 10: loss=0.7098, acc=51.02% (best=55.94%)\n",
      "          Fold 5 Epoch 10: loss=0.9317, acc=56.02% (best=56.02%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 56.41%\n",
      "          Fold 2 Epoch 10: loss=0.6928, acc=49.53% (best=59.06%)\n",
      "          Fold 4 Epoch 15: loss=0.6581, acc=51.56% (best=63.83%)\n",
      "          Fold 3 Epoch 15: loss=0.7096, acc=51.02% (best=55.94%)\n",
      "          Fold 5 Epoch 15: loss=0.6944, acc=50.00% (best=56.02%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 55.94%\n",
      "          Fold 2 Epoch 15: loss=0.5366, acc=54.53% (best=59.06%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 63.83%\n",
      "          Fold 5 Epoch 20: loss=0.7076, acc=50.00% (best=56.02%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 56.02%\n",
      "          Fold 2 Epoch 20: loss=0.4317, acc=47.58% (best=62.19%)\n",
      "          Fold 2 Epoch 25: loss=0.3752, acc=47.03% (best=62.19%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 62.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 852c5b48:\n",
      "        Fold accuracies: ['56.41%', '62.19%', '55.94%', '63.83%', '56.02%']\n",
      "        Average fitness: 58.88% Â± 3.42%\n",
      "        Best fold: Fold 4 with 63.83%\n",
      "      Fitness obtained: 58.88% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 99283435)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 99283435 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7131, acc=54.92% (best=54.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7156, acc=43.59% (best=43.59%)\n",
      "          Fold 1 Epoch 1: loss=0.7009, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 1: loss=0.6891, acc=60.55% (best=60.55%)\n",
      "          Fold 5 Epoch 1: loss=0.7321, acc=60.00% (best=60.00%)\n",
      "          Fold 5 Epoch 5: loss=0.5167, acc=53.83% (best=60.00%)\n",
      "          Fold 3 Epoch 5: loss=0.3811, acc=53.05% (best=55.70%)\n",
      "          Fold 4 Epoch 5: loss=0.4333, acc=51.64% (best=60.55%)\n",
      "          Fold 2 Epoch 5: loss=0.3670, acc=53.05% (best=60.94%)\n",
      "          Fold 1 Epoch 5: loss=0.4340, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 10: loss=0.3127, acc=46.17% (best=60.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2912, acc=63.75% (best=66.64%)\n",
      "          Fold 4 Epoch 10: loss=0.2904, acc=53.05% (best=64.14%)\n",
      "          Fold 2 Epoch 10: loss=0.2857, acc=67.27% (best=67.27%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.00%\n",
      "          Fold 1 Epoch 10: loss=0.3036, acc=54.06% (best=59.45%)\n",
      "          Fold 3 Epoch 15: loss=0.2586, acc=56.17% (best=66.64%)\n",
      "          Fold 4 Epoch 15: loss=0.2448, acc=53.75% (best=64.14%)\n",
      "          Fold 2 Epoch 15: loss=0.2510, acc=66.41% (best=67.27%)\n",
      "          Fold 1 Epoch 15: loss=0.2673, acc=54.38% (best=59.45%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 64.14%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 66.64%\n",
      "          Fold 2 Epoch 20: loss=0.2286, acc=49.77% (best=67.27%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 67.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 99283435:\n",
      "        Fold accuracies: ['59.45%', '67.27%', '66.64%', '64.14%', '60.00%']\n",
      "        Average fitness: 63.50% Â± 3.26%\n",
      "        Best fold: Fold 2 with 67.27%\n",
      "      Fitness obtained: 63.50% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 85137d05)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 85137d05 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7263, acc=56.09% (best=56.09%)\n",
      "          Fold 2 Epoch 1: loss=0.7128, acc=52.73% (best=52.73%)\n",
      "          Fold 5 Epoch 1: loss=0.7400, acc=52.03% (best=52.03%)\n",
      "          Fold 3 Epoch 1: loss=0.7184, acc=50.55% (best=50.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6982, acc=58.12% (best=58.12%)\n",
      "          Fold 1 Epoch 5: loss=0.4653, acc=58.59% (best=58.59%)\n",
      "          Fold 2 Epoch 5: loss=0.3843, acc=49.61% (best=54.30%)\n",
      "          Fold 5 Epoch 5: loss=0.4228, acc=43.98% (best=52.03%)\n",
      "          Fold 3 Epoch 5: loss=0.4112, acc=48.44% (best=57.81%)\n",
      "          Fold 4 Epoch 5: loss=0.4391, acc=57.27% (best=58.12%)\n",
      "          Fold 1 Epoch 10: loss=0.3200, acc=57.89% (best=58.59%)\n",
      "          Fold 2 Epoch 10: loss=0.2759, acc=48.91% (best=57.66%)\n",
      "          Fold 5 Epoch 10: loss=0.2856, acc=48.59% (best=54.92%)\n",
      "          Fold 3 Epoch 10: loss=0.3041, acc=47.27% (best=63.52%)\n",
      "          Fold 4 Epoch 10: loss=0.2740, acc=41.48% (best=58.12%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 58.12%\n",
      "          Fold 1 Epoch 15: loss=0.2596, acc=47.58% (best=64.92%)\n",
      "          Fold 2 Epoch 15: loss=0.2493, acc=48.59% (best=57.66%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 57.66%\n",
      "          Fold 5 Epoch 15: loss=0.2477, acc=49.06% (best=54.92%)\n",
      "          Fold 3 Epoch 15: loss=0.2601, acc=60.78% (best=63.52%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 54.92%\n",
      "          Fold 1 Epoch 20: loss=0.2460, acc=62.03% (best=64.92%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "          Fold 3 Epoch 20: loss=0.2368, acc=55.47% (best=64.45%)\n",
      "          Fold 3 Epoch 25: loss=0.2249, acc=61.17% (best=64.45%)\n",
      "          Fold 3 Epoch 30: loss=0.2162, acc=67.50% (best=72.03%)\n",
      "          Fold 3 Epoch 35: loss=0.2150, acc=47.11% (best=72.03%)\n",
      "          Fold 3: Early stopping at epoch 36\n",
      "      â†’ Fold 3 completed: 72.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 85137d05:\n",
      "        Fold accuracies: ['64.92%', '57.66%', '72.03%', '58.12%', '54.92%']\n",
      "        Average fitness: 61.53% Â± 6.20%\n",
      "        Best fold: Fold 3 with 72.03%\n",
      "      Fitness obtained: 61.53% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: e0cab2fa)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e0cab2fa with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6984, acc=51.88% (best=51.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7023, acc=68.44% (best=68.44%)\n",
      "          Fold 2 Epoch 1: loss=0.7069, acc=50.47% (best=50.47%)\n",
      "          Fold 5 Epoch 1: loss=0.7152, acc=56.33% (best=56.33%)\n",
      "          Fold 4 Epoch 1: loss=0.6864, acc=65.47% (best=65.47%)\n",
      "          Fold 1 Epoch 5: loss=0.5275, acc=45.31% (best=53.98%)\n",
      "          Fold 3 Epoch 5: loss=0.4381, acc=57.42% (best=68.44%)\n",
      "          Fold 5 Epoch 5: loss=0.5370, acc=50.39% (best=56.33%)\n",
      "          Fold 4 Epoch 5: loss=0.4569, acc=68.28% (best=68.28%)\n",
      "          Fold 2 Epoch 5: loss=0.6126, acc=49.92% (best=55.70%)\n",
      "          Fold 1 Epoch 10: loss=0.3855, acc=47.19% (best=62.03%)\n",
      "          Fold 3 Epoch 10: loss=0.3403, acc=58.05% (best=68.44%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 68.44%\n",
      "          Fold 5 Epoch 10: loss=0.3524, acc=54.14% (best=66.48%)\n",
      "          Fold 4 Epoch 10: loss=0.2872, acc=53.28% (best=68.28%)\n",
      "          Fold 2 Epoch 10: loss=0.3752, acc=50.23% (best=55.70%)\n",
      "          Fold 1 Epoch 15: loss=0.3279, acc=53.52% (best=62.03%)\n",
      "          Fold 5 Epoch 15: loss=0.3026, acc=53.12% (best=66.48%)\n",
      "          Fold 4 Epoch 15: loss=0.2551, acc=49.77% (best=68.28%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 68.28%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 66.48%\n",
      "          Fold 2 Epoch 15: loss=0.3161, acc=49.69% (best=56.80%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "          Fold 2 Epoch 20: loss=0.2850, acc=51.41% (best=56.80%)\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 56.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e0cab2fa:\n",
      "        Fold accuracies: ['62.03%', '56.80%', '68.44%', '68.28%', '66.48%']\n",
      "        Average fitness: 64.41% Â± 4.45%\n",
      "        Best fold: Fold 3 with 68.44%\n",
      "      Fitness obtained: 64.41% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 68d46a34)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 68d46a34 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7018, acc=43.75% (best=43.75%)\n",
      "          Fold 3 Epoch 1: loss=0.7057, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6753, acc=63.98% (best=63.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7107, acc=50.62% (best=50.62%)\n",
      "          Fold 5 Epoch 1: loss=0.7240, acc=51.09% (best=51.09%)\n",
      "          Fold 5 Epoch 5: loss=0.4899, acc=56.64% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.4442, acc=49.06% (best=57.66%)\n",
      "          Fold 2 Epoch 5: loss=0.4421, acc=56.48% (best=56.48%)\n",
      "          Fold 4 Epoch 5: loss=0.4286, acc=60.47% (best=63.98%)\n",
      "          Fold 1 Epoch 5: loss=0.4616, acc=50.55% (best=60.78%)\n",
      "          Fold 5 Epoch 10: loss=0.3594, acc=40.94% (best=56.64%)\n",
      "          Fold 3 Epoch 10: loss=0.3455, acc=57.73% (best=60.47%)\n",
      "          Fold 2 Epoch 10: loss=0.3479, acc=52.11% (best=56.80%)\n",
      "          Fold 4 Epoch 10: loss=0.3099, acc=51.17% (best=63.98%)\n",
      "          Fold 1 Epoch 10: loss=0.3105, acc=56.48% (best=65.47%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 63.98%\n",
      "          Fold 5 Epoch 15: loss=0.3113, acc=43.75% (best=56.64%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 56.64%\n",
      "          Fold 3 Epoch 15: loss=0.2847, acc=59.22% (best=60.47%)\n",
      "          Fold 2 Epoch 15: loss=0.3197, acc=41.02% (best=56.80%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 56.80%\n",
      "          Fold 1 Epoch 15: loss=0.2636, acc=63.12% (best=65.47%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 60.47%\n",
      "          Fold 1 Epoch 20: loss=0.2473, acc=66.80% (best=66.88%)\n",
      "          Fold 1 Epoch 25: loss=0.2333, acc=62.19% (best=69.69%)\n",
      "          Fold 1 Epoch 30: loss=0.2266, acc=55.62% (best=72.81%)\n",
      "          Fold 1 Epoch 35: loss=0.2252, acc=52.97% (best=72.81%)\n",
      "          Fold 1 Epoch 40: loss=0.2172, acc=68.83% (best=72.89%)\n",
      "          Fold 1 Epoch 45: loss=0.2148, acc=70.62% (best=72.89%)\n",
      "          Fold 1: Early stopping at epoch 46\n",
      "      â†’ Fold 1 completed: 72.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 68d46a34:\n",
      "        Fold accuracies: ['72.89%', '56.80%', '60.47%', '63.98%', '56.64%']\n",
      "        Average fitness: 62.16% Â± 6.01%\n",
      "        Best fold: Fold 1 with 72.89%\n",
      "      Fitness obtained: 62.16% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: f54ee213)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f54ee213 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6812, acc=44.92% (best=44.92%)\n",
      "          Fold 1 Epoch 1: loss=0.6714, acc=53.59% (best=53.59%)\n",
      "          Fold 3 Epoch 1: loss=0.6760, acc=59.14% (best=59.14%)\n",
      "          Fold 4 Epoch 1: loss=0.6656, acc=55.86% (best=55.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7126, acc=52.19% (best=52.19%)\n",
      "          Fold 2 Epoch 5: loss=0.3108, acc=49.77% (best=55.47%)\n",
      "          Fold 1 Epoch 5: loss=0.3230, acc=55.08% (best=55.08%)\n",
      "          Fold 4 Epoch 5: loss=0.4152, acc=44.92% (best=65.39%)\n",
      "          Fold 3 Epoch 5: loss=0.3215, acc=51.25% (best=63.75%)\n",
      "          Fold 5 Epoch 5: loss=0.4407, acc=57.34% (best=60.23%)\n",
      "          Fold 2 Epoch 10: loss=0.2466, acc=60.16% (best=60.16%)\n",
      "          Fold 1 Epoch 10: loss=0.2576, acc=55.31% (best=68.98%)\n",
      "          Fold 4 Epoch 10: loss=0.2883, acc=55.94% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.2606, acc=49.61% (best=63.75%)\n",
      "          Fold 5 Epoch 10: loss=0.3010, acc=61.80% (best=61.80%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 63.75%\n",
      "          Fold 2 Epoch 15: loss=0.2314, acc=64.30% (best=64.30%)\n",
      "          Fold 1 Epoch 15: loss=0.2382, acc=60.08% (best=68.98%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 68.98%\n",
      "          Fold 5 Epoch 15: loss=0.2552, acc=56.25% (best=63.05%)\n",
      "          Fold 2 Epoch 20: loss=0.2218, acc=51.41% (best=65.31%)\n",
      "          Fold 5 Epoch 20: loss=0.2379, acc=63.05% (best=65.94%)\n",
      "          Fold 2 Epoch 25: loss=0.2053, acc=58.52% (best=65.31%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 65.31%\n",
      "          Fold 5 Epoch 25: loss=0.2223, acc=55.55% (best=65.94%)\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 65.94%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f54ee213:\n",
      "        Fold accuracies: ['68.98%', '65.31%', '63.75%', '65.39%', '65.94%']\n",
      "        Average fitness: 65.88% Â± 1.72%\n",
      "        Best fold: Fold 1 with 68.98%\n",
      "      Fitness obtained: 65.88% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 1fd00a46)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0001\n",
      "      Training/Evaluating model 1fd00a46 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7211, acc=47.03% (best=47.03%)\n",
      "          Fold 2 Epoch 1: loss=0.7104, acc=43.98% (best=43.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6885, acc=58.36% (best=58.36%)\n",
      "          Fold 5 Epoch 1: loss=0.7205, acc=55.00% (best=55.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7146, acc=49.84% (best=49.84%)\n",
      "          Fold 3 Epoch 5: loss=0.6832, acc=47.34% (best=52.81%)\n",
      "          Fold 5 Epoch 5: loss=0.7035, acc=47.58% (best=59.53%)\n",
      "          Fold 4 Epoch 5: loss=0.6114, acc=49.22% (best=58.36%)\n",
      "          Fold 2 Epoch 5: loss=0.6633, acc=45.70% (best=46.56%)\n",
      "          Fold 1 Epoch 5: loss=0.6660, acc=45.08% (best=55.62%)\n",
      "          Fold 3 Epoch 10: loss=0.5082, acc=44.69% (best=52.81%)\n",
      "          Fold 5 Epoch 10: loss=0.5635, acc=50.55% (best=59.53%)\n",
      "          Fold 4 Epoch 10: loss=0.4812, acc=53.52% (best=58.36%)\n",
      "          Fold 2 Epoch 10: loss=0.4515, acc=40.70% (best=48.91%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 58.36%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 52.81%\n",
      "          Fold 1 Epoch 10: loss=0.5139, acc=49.92% (best=55.62%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 55.62%\n",
      "          Fold 5 Epoch 15: loss=0.4039, acc=50.70% (best=63.67%)\n",
      "          Fold 2 Epoch 15: loss=0.3546, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 20: loss=0.3299, acc=49.14% (best=63.67%)\n",
      "          Fold 2 Epoch 20: loss=0.3032, acc=44.53% (best=56.64%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 63.67%\n",
      "          Fold 2 Epoch 25: loss=0.2778, acc=45.55% (best=57.11%)\n",
      "          Fold 2 Epoch 30: loss=0.2681, acc=49.22% (best=57.11%)\n",
      "          Fold 2: Early stopping at epoch 33\n",
      "      â†’ Fold 2 completed: 57.11%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1fd00a46:\n",
      "        Fold accuracies: ['55.62%', '57.11%', '52.81%', '58.36%', '63.67%']\n",
      "        Average fitness: 57.52% Â± 3.59%\n",
      "        Best fold: Fold 5 with 63.67%\n",
      "      Fitness obtained: 57.52% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 8d0eabb5)\n",
      "      Architecture: 12 conv + 3 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8d0eabb5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.6608, acc=45.16% (best=45.16%)\n",
      "          Fold 3 Epoch 1: loss=0.6211, acc=46.09% (best=46.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6525, acc=57.03% (best=57.03%)\n",
      "          Fold 5 Epoch 1: loss=0.7041, acc=53.91% (best=53.91%)\n",
      "          Fold 2 Epoch 5: loss=0.2924, acc=49.53% (best=54.84%)\n",
      "          Fold 3 Epoch 5: loss=0.2771, acc=46.72% (best=53.91%)\n",
      "          Fold 4 Epoch 5: loss=0.2881, acc=59.45% (best=59.45%)\n",
      "          Fold 5 Epoch 5: loss=0.2811, acc=48.98% (best=53.91%)\n",
      "          Fold 2 Epoch 10: loss=0.2458, acc=43.98% (best=54.84%)\n",
      "          Fold 3 Epoch 10: loss=0.2426, acc=56.56% (best=61.25%)\n",
      "          Fold 4 Epoch 10: loss=0.2362, acc=43.44% (best=59.45%)\n",
      "          Fold 5 Epoch 10: loss=0.2370, acc=38.28% (best=53.91%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 53.91%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 54.84%\n",
      "          Fold 3 Epoch 15: loss=0.2253, acc=41.02% (best=61.25%)\n",
      "          Fold 4 Epoch 15: loss=0.2175, acc=51.64% (best=59.45%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 59.45%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 61.25%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8d0eabb5:\n",
      "        Fold accuracies: ['0.00%', '54.84%', '61.25%', '59.45%', '53.91%']\n",
      "        Average fitness: 45.89% Â± 23.11%\n",
      "        Best fold: Fold 3 with 61.25%\n",
      "      Fitness obtained: 45.89% | Best in generation: 66.58% | Global best: 70.92%\n",
      "\n",
      "GENERATION 20 STATISTICS:\n",
      "   Maximum fitness: 66.58%\n",
      "   Average fitness: 57.50%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 13.96%\n",
      "   Best individual: 301cae3e with 66.58%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 12/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=13.96)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 301cae3e (fitness: 66.58%)\n",
      "   Elite 2: f54ee213 (fitness: 65.88%)\n",
      "   Elite 3: 872fa407 (fitness: 65.08%)\n",
      "   Elite 4: e0cab2fa (fitness: 64.41%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 13/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 21\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 21)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 301cae3e)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 301cae3e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7127, acc=55.16% (best=55.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7197, acc=48.05% (best=48.05%)\n",
      "          Fold 2 Epoch 1: loss=0.7103, acc=43.75% (best=43.75%)\n",
      "          Fold 4 Epoch 1: loss=0.7067, acc=66.25% (best=66.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7489, acc=54.77% (best=54.77%)\n",
      "          Fold 1 Epoch 5: loss=0.4775, acc=63.59% (best=63.59%)\n",
      "          Fold 3 Epoch 5: loss=0.4058, acc=52.03% (best=54.77%)\n",
      "          Fold 2 Epoch 5: loss=0.3568, acc=56.02% (best=59.22%)\n",
      "          Fold 5 Epoch 5: loss=0.4483, acc=56.33% (best=67.50%)\n",
      "          Fold 4 Epoch 5: loss=0.3989, acc=66.64% (best=70.16%)\n",
      "          Fold 1 Epoch 10: loss=0.3055, acc=57.73% (best=65.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2825, acc=50.23% (best=58.83%)\n",
      "          Fold 2 Epoch 10: loss=0.2674, acc=46.48% (best=59.22%)\n",
      "          Fold 5 Epoch 10: loss=0.2659, acc=45.62% (best=67.50%)\n",
      "          Fold 4 Epoch 10: loss=0.2736, acc=37.66% (best=70.16%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 59.22%\n",
      "          Fold 1 Epoch 15: loss=0.2698, acc=50.78% (best=65.00%)\n",
      "          Fold 3 Epoch 15: loss=0.2580, acc=54.84% (best=58.83%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 67.50%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 70.16%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 58.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 301cae3e:\n",
      "        Fold accuracies: ['65.00%', '59.22%', '58.83%', '70.16%', '67.50%']\n",
      "        Average fitness: 64.14% Â± 4.49%\n",
      "        Best fold: Fold 4 with 70.16%\n",
      "      New best fitness in this generation: 64.14%!\n",
      "      Fitness obtained: 64.14% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: f54ee213)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f54ee213 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7199, acc=52.42% (best=52.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6844, acc=61.25% (best=61.25%)\n",
      "          Fold 4 Epoch 1: loss=0.6542, acc=52.97% (best=52.97%)\n",
      "          Fold 2 Epoch 1: loss=0.6697, acc=48.83% (best=48.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6713, acc=46.33% (best=46.33%)\n",
      "          Fold 5 Epoch 5: loss=0.3976, acc=39.30% (best=58.91%)\n",
      "          Fold 1 Epoch 5: loss=0.3450, acc=48.28% (best=61.25%)\n",
      "          Fold 4 Epoch 5: loss=0.3256, acc=54.77% (best=68.67%)\n",
      "          Fold 2 Epoch 5: loss=0.3267, acc=44.22% (best=55.86%)\n",
      "          Fold 3 Epoch 5: loss=0.3393, acc=49.53% (best=58.98%)\n",
      "          Fold 5 Epoch 10: loss=0.2752, acc=45.47% (best=58.91%)\n",
      "          Fold 1 Epoch 10: loss=0.2642, acc=48.12% (best=61.25%)\n",
      "          Fold 4 Epoch 10: loss=0.2440, acc=45.70% (best=68.67%)\n",
      "          Fold 2 Epoch 10: loss=0.2530, acc=50.00% (best=55.86%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 61.25%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 58.91%\n",
      "          Fold 3 Epoch 10: loss=0.2705, acc=49.38% (best=61.33%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 68.67%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 3 Epoch 15: loss=0.2408, acc=55.78% (best=61.33%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 61.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f54ee213:\n",
      "        Fold accuracies: ['61.25%', '55.86%', '61.33%', '68.67%', '58.91%']\n",
      "        Average fitness: 61.20% Â± 4.23%\n",
      "        Best fold: Fold 4 with 68.67%\n",
      "      Fitness obtained: 61.20% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 872fa407)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 872fa407 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6732, acc=45.94% (best=45.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6652, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.6913, acc=59.92% (best=59.92%)\n",
      "          Fold 3 Epoch 1: loss=0.6953, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7082, acc=41.80% (best=41.80%)\n",
      "          Fold 2 Epoch 5: loss=0.3421, acc=54.22% (best=54.22%)\n",
      "          Fold 4 Epoch 5: loss=0.3701, acc=55.78% (best=69.06%)\n",
      "          Fold 1 Epoch 5: loss=0.4513, acc=52.42% (best=59.92%)\n",
      "          Fold 5 Epoch 5: loss=0.4015, acc=57.42% (best=57.42%)\n",
      "          Fold 3 Epoch 5: loss=0.3749, acc=50.86% (best=62.73%)\n",
      "          Fold 2 Epoch 10: loss=0.2655, acc=53.59% (best=65.55%)\n",
      "          Fold 4 Epoch 10: loss=0.2712, acc=50.23% (best=69.06%)\n",
      "          Fold 1 Epoch 10: loss=0.3213, acc=56.33% (best=59.92%)\n",
      "          Fold 5 Epoch 10: loss=0.2824, acc=52.81% (best=57.42%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 59.92%\n",
      "          Fold 3 Epoch 10: loss=0.2908, acc=56.80% (best=62.73%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 69.06%\n",
      "          Fold 2 Epoch 15: loss=0.2454, acc=54.77% (best=65.55%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 62.73%\n",
      "          Fold 5 Epoch 15: loss=0.2481, acc=53.59% (best=57.42%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.42%\n",
      "          Fold 2 Epoch 20: loss=0.2327, acc=65.55% (best=66.56%)\n",
      "          Fold 2 Epoch 25: loss=0.2231, acc=47.50% (best=66.56%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 66.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 872fa407:\n",
      "        Fold accuracies: ['59.92%', '66.56%', '62.73%', '69.06%', '57.42%']\n",
      "        Average fitness: 63.14% Â± 4.24%\n",
      "        Best fold: Fold 4 with 69.06%\n",
      "      Fitness obtained: 63.14% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: e0cab2fa)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e0cab2fa with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6919, acc=45.31% (best=45.31%)\n",
      "          Fold 1 Epoch 1: loss=0.7043, acc=60.39% (best=60.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7138, acc=61.95% (best=61.95%)\n",
      "          Fold 4 Epoch 1: loss=0.6896, acc=58.98% (best=58.98%)\n",
      "          Fold 5 Epoch 1: loss=0.7256, acc=50.47% (best=50.47%)\n",
      "          Fold 2 Epoch 5: loss=0.4779, acc=42.97% (best=49.92%)\n",
      "          Fold 1 Epoch 5: loss=0.5285, acc=58.98% (best=62.03%)\n",
      "          Fold 3 Epoch 5: loss=0.4310, acc=52.11% (best=61.95%)\n",
      "          Fold 4 Epoch 5: loss=0.4763, acc=55.23% (best=67.34%)\n",
      "          Fold 5 Epoch 5: loss=0.4639, acc=45.47% (best=50.47%)\n",
      "          Fold 2 Epoch 10: loss=0.3048, acc=44.92% (best=55.86%)\n",
      "          Fold 1 Epoch 10: loss=0.3775, acc=61.56% (best=68.44%)\n",
      "          Fold 3 Epoch 10: loss=0.3323, acc=54.30% (best=61.95%)\n",
      "          Fold 4 Epoch 10: loss=0.3425, acc=47.11% (best=67.34%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 61.95%\n",
      "          Fold 5 Epoch 10: loss=0.3198, acc=45.86% (best=58.75%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 67.34%\n",
      "          Fold 2 Epoch 15: loss=0.2510, acc=41.80% (best=55.86%)\n",
      "          Fold 1 Epoch 15: loss=0.2863, acc=53.12% (best=68.44%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 68.44%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 5 Epoch 15: loss=0.2641, acc=34.61% (best=58.75%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 58.75%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e0cab2fa:\n",
      "        Fold accuracies: ['68.44%', '55.86%', '61.95%', '67.34%', '58.75%']\n",
      "        Average fitness: 62.47% Â± 4.84%\n",
      "        Best fold: Fold 1 with 68.44%\n",
      "      Fitness obtained: 62.47% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: dacd86ef)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model dacd86ef with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7091, acc=57.11% (best=57.11%)\n",
      "          Fold 1 Epoch 1: loss=0.7209, acc=50.23% (best=50.23%)\n",
      "          Fold 3 Epoch 1: loss=0.7391, acc=54.45% (best=54.45%)\n",
      "          Fold 4 Epoch 1: loss=0.6831, acc=57.03% (best=57.03%)\n",
      "          Fold 5 Epoch 1: loss=0.7380, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.5143, acc=50.16% (best=57.11%)\n",
      "          Fold 1 Epoch 5: loss=0.5858, acc=49.14% (best=50.23%)\n",
      "          Fold 4 Epoch 5: loss=0.5361, acc=61.48% (best=67.50%)\n",
      "          Fold 3 Epoch 5: loss=0.4838, acc=45.00% (best=54.45%)\n",
      "          Fold 5 Epoch 5: loss=0.5279, acc=53.44% (best=53.44%)\n",
      "          Fold 2 Epoch 10: loss=0.3821, acc=50.16% (best=57.11%)\n",
      "          Fold 1 Epoch 10: loss=0.4361, acc=45.55% (best=50.23%)\n",
      "          Fold 4 Epoch 10: loss=0.4027, acc=48.67% (best=67.50%)\n",
      "          Fold 3 Epoch 10: loss=0.3915, acc=55.70% (best=55.70%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 57.11%\n",
      "          Fold 5 Epoch 10: loss=0.4090, acc=52.81% (best=62.58%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 1 Epoch 15: loss=0.3692, acc=45.31% (best=55.78%)\n",
      "          Fold 3 Epoch 15: loss=0.3308, acc=47.89% (best=55.70%)\n",
      "          Fold 5 Epoch 15: loss=0.3551, acc=52.03% (best=62.58%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "          Fold 1 Epoch 20: loss=0.3345, acc=60.23% (best=66.88%)\n",
      "          Fold 3 Epoch 20: loss=0.3118, acc=44.77% (best=55.70%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 55.70%\n",
      "          Fold 1 Epoch 25: loss=0.3006, acc=54.38% (best=66.88%)\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 66.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dacd86ef:\n",
      "        Fold accuracies: ['66.88%', '57.11%', '55.70%', '67.50%', '62.58%']\n",
      "        Average fitness: 61.95% Â± 4.86%\n",
      "        Best fold: Fold 4 with 67.50%\n",
      "      Fitness obtained: 61.95% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 86436b07)\n",
      "      Architecture: 13 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 86436b07 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7152, acc=47.89% (best=47.89%)\n",
      "          Fold 1 Epoch 1: loss=0.7098, acc=40.70% (best=40.70%)\n",
      "          Fold 2 Epoch 1: loss=0.7070, acc=56.64% (best=56.64%)\n",
      "          Fold 5 Epoch 1: loss=0.7259, acc=53.05% (best=53.05%)\n",
      "          Fold 4 Epoch 1: loss=0.6896, acc=37.42% (best=37.42%)\n",
      "          Fold 3 Epoch 5: loss=0.4019, acc=51.41% (best=62.11%)\n",
      "          Fold 1 Epoch 5: loss=0.5238, acc=45.39% (best=66.25%)\n",
      "          Fold 2 Epoch 5: loss=0.3658, acc=47.11% (best=56.64%)\n",
      "          Fold 5 Epoch 5: loss=0.6812, acc=53.83% (best=63.20%)\n",
      "          Fold 4 Epoch 5: loss=0.4640, acc=51.95% (best=63.91%)\n",
      "          Fold 3 Epoch 10: loss=0.2777, acc=55.55% (best=62.11%)\n",
      "          Fold 1 Epoch 10: loss=0.2918, acc=52.34% (best=66.25%)\n",
      "          Fold 2 Epoch 10: loss=0.2549, acc=41.88% (best=56.64%)\n",
      "          Fold 5 Epoch 10: loss=0.2890, acc=49.30% (best=63.20%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.64%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 66.25%\n",
      "          Fold 4 Epoch 10: loss=0.2637, acc=54.14% (best=63.91%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 62.11%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 63.91%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 86436b07:\n",
      "        Fold accuracies: ['66.25%', '56.64%', '62.11%', '63.91%', '63.20%']\n",
      "        Average fitness: 62.42% Â± 3.19%\n",
      "        Best fold: Fold 1 with 66.25%\n",
      "      Fitness obtained: 62.42% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 03b46463)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 03b46463 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7332, acc=54.38% (best=54.38%)\n",
      "          Fold 1 Epoch 1: loss=0.7423, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7264, acc=50.39% (best=50.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7499, acc=47.34% (best=47.34%)\n",
      "          Fold 4 Epoch 1: loss=0.7128, acc=69.30% (best=69.30%)\n",
      "          Fold 1 Epoch 5: loss=0.5902, acc=45.94% (best=51.88%)\n",
      "          Fold 3 Epoch 5: loss=0.4898, acc=48.12% (best=54.38%)\n",
      "          Fold 2 Epoch 5: loss=0.5123, acc=50.47% (best=50.47%)\n",
      "          Fold 5 Epoch 5: loss=0.6981, acc=58.20% (best=59.22%)\n",
      "          Fold 4 Epoch 5: loss=0.5851, acc=35.16% (best=69.30%)\n",
      "          Fold 1 Epoch 10: loss=0.4247, acc=50.16% (best=62.27%)\n",
      "          Fold 3 Epoch 10: loss=0.3808, acc=47.81% (best=54.38%)\n",
      "          Fold 2 Epoch 10: loss=0.3795, acc=46.56% (best=58.28%)\n",
      "          Fold 5 Epoch 10: loss=0.5919, acc=51.72% (best=59.22%)\n",
      "          Fold 4 Epoch 10: loss=0.4666, acc=51.56% (best=69.30%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 59.22%\n",
      "          Fold 1 Epoch 15: loss=0.3302, acc=59.77% (best=62.27%)\n",
      "          Fold 3 Epoch 15: loss=0.3217, acc=51.33% (best=54.77%)\n",
      "          Fold 2 Epoch 15: loss=0.3121, acc=40.39% (best=58.28%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 58.28%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.27%\n",
      "          Fold 3 Epoch 20: loss=0.2880, acc=60.31% (best=60.31%)\n",
      "          Fold 3 Epoch 25: loss=0.2610, acc=46.80% (best=60.31%)\n",
      "          Fold 3 Epoch 30: loss=0.2474, acc=50.08% (best=60.31%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 60.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 03b46463:\n",
      "        Fold accuracies: ['62.27%', '58.28%', '60.31%', '69.30%', '59.22%']\n",
      "        Average fitness: 61.88% Â± 3.94%\n",
      "        Best fold: Fold 4 with 69.30%\n",
      "      Fitness obtained: 61.88% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 98bf7687)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=0.0001\n",
      "      Training/Evaluating model 98bf7687 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7194, acc=58.36% (best=58.36%)\n",
      "          Fold 2 Epoch 1: loss=0.7133, acc=49.06% (best=49.06%)\n",
      "          Fold 1 Epoch 1: loss=0.7301, acc=46.80% (best=46.80%)\n",
      "          Fold 5 Epoch 1: loss=0.7251, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7262, acc=56.33% (best=56.33%)\n",
      "          Fold 3 Epoch 5: loss=0.7204, acc=53.67% (best=58.36%)\n",
      "          Fold 2 Epoch 5: loss=0.7086, acc=48.05% (best=58.28%)\n",
      "          Fold 1 Epoch 5: loss=0.7174, acc=46.56% (best=55.94%)\n",
      "          Fold 5 Epoch 5: loss=0.7156, acc=50.00% (best=50.31%)\n",
      "          Fold 4 Epoch 5: loss=0.7094, acc=52.27% (best=61.72%)\n",
      "          Fold 3 Epoch 10: loss=0.7102, acc=62.42% (best=62.42%)\n",
      "          Fold 2 Epoch 10: loss=0.7059, acc=47.27% (best=58.28%)\n",
      "          Fold 1 Epoch 10: loss=0.7167, acc=57.89% (best=65.78%)\n",
      "          Fold 5 Epoch 10: loss=0.7247, acc=50.00% (best=50.31%)\n",
      "          Fold 4 Epoch 10: loss=0.6979, acc=66.88% (best=66.88%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 50.31%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.28%\n",
      "          Fold 3 Epoch 15: loss=0.7141, acc=56.33% (best=65.31%)\n",
      "          Fold 1 Epoch 15: loss=0.7099, acc=55.08% (best=65.78%)\n",
      "          Fold 4 Epoch 15: loss=0.6973, acc=60.00% (best=66.88%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 65.78%\n",
      "          Fold 3 Epoch 20: loss=0.7126, acc=53.20% (best=65.31%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 65.31%\n",
      "          Fold 4 Epoch 20: loss=0.6915, acc=55.94% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 98bf7687:\n",
      "        Fold accuracies: ['65.78%', '58.28%', '65.31%', '66.88%', '50.31%']\n",
      "        Average fitness: 61.31% Â± 6.28%\n",
      "        Best fold: Fold 4 with 66.88%\n",
      "      Fitness obtained: 61.31% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: f12745f2)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f12745f2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7267, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 1: loss=0.7233, acc=49.77% (best=49.77%)\n",
      "          Fold 4 Epoch 1: loss=0.7142, acc=58.28% (best=58.28%)\n",
      "          Fold 2 Epoch 1: loss=0.7197, acc=56.41% (best=56.41%)\n",
      "          Fold 5 Epoch 1: loss=0.7311, acc=59.22% (best=59.22%)\n",
      "          Fold 3 Epoch 5: loss=0.4716, acc=57.11% (best=57.11%)\n",
      "          Fold 1 Epoch 5: loss=0.5937, acc=53.05% (best=55.78%)\n",
      "          Fold 4 Epoch 5: loss=0.5723, acc=54.45% (best=65.31%)\n",
      "          Fold 2 Epoch 5: loss=0.6302, acc=43.75% (best=56.41%)\n",
      "          Fold 5 Epoch 5: loss=0.6630, acc=45.86% (best=59.22%)\n",
      "          Fold 3 Epoch 10: loss=0.3087, acc=50.31% (best=57.11%)\n",
      "          Fold 1 Epoch 10: loss=0.3365, acc=40.86% (best=55.78%)\n",
      "          Fold 4 Epoch 10: loss=0.3189, acc=43.59% (best=66.41%)\n",
      "          Fold 2 Epoch 10: loss=0.3590, acc=49.69% (best=56.41%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 56.41%\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 55.78%\n",
      "          Fold 5 Epoch 10: loss=0.3680, acc=54.45% (best=59.22%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 59.22%\n",
      "          Fold 3 Epoch 15: loss=0.2696, acc=46.56% (best=57.11%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 57.11%\n",
      "          Fold 4 Epoch 15: loss=0.2612, acc=49.38% (best=66.41%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 66.41%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f12745f2:\n",
      "        Fold accuracies: ['55.78%', '56.41%', '57.11%', '66.41%', '59.22%']\n",
      "        Average fitness: 58.98% Â± 3.89%\n",
      "        Best fold: Fold 4 with 66.41%\n",
      "      Fitness obtained: 58.98% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 8496aee2)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8496aee2 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7236, acc=53.83% (best=53.83%)\n",
      "          Fold 3 Epoch 1: loss=0.6993, acc=50.86% (best=50.86%)\n",
      "          Fold 4 Epoch 1: loss=0.6913, acc=69.14% (best=69.14%)\n",
      "          Fold 2 Epoch 1: loss=0.7102, acc=41.17% (best=41.17%)\n",
      "          Fold 1 Epoch 1: loss=0.6988, acc=52.73% (best=52.73%)\n",
      "          Fold 3 Epoch 5: loss=0.3609, acc=55.47% (best=60.62%)\n",
      "          Fold 5 Epoch 5: loss=0.3951, acc=57.66% (best=57.73%)\n",
      "          Fold 4 Epoch 5: loss=0.3709, acc=71.88% (best=71.88%)\n",
      "          Fold 1 Epoch 5: loss=0.4090, acc=38.05% (best=59.61%)\n",
      "          Fold 2 Epoch 5: loss=0.3856, acc=48.36% (best=53.67%)\n",
      "          Fold 3 Epoch 10: loss=0.2759, acc=55.00% (best=60.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2968, acc=49.38% (best=57.73%)\n",
      "          Fold 4 Epoch 10: loss=0.2657, acc=53.12% (best=71.88%)\n",
      "          Fold 1 Epoch 10: loss=0.2931, acc=42.42% (best=59.61%)\n",
      "          Fold 2 Epoch 10: loss=0.2742, acc=58.20% (best=58.20%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 60.62%\n",
      "          Fold 5 Epoch 15: loss=0.2565, acc=52.03% (best=61.48%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 59.61%\n",
      "          Fold 4 Epoch 15: loss=0.2393, acc=60.08% (best=71.88%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 71.88%\n",
      "          Fold 2 Epoch 15: loss=0.2354, acc=49.14% (best=61.48%)\n",
      "          Fold 5 Epoch 20: loss=0.2465, acc=49.69% (best=61.48%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 2 Epoch 20: loss=0.2238, acc=49.22% (best=61.48%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 61.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8496aee2:\n",
      "        Fold accuracies: ['59.61%', '61.48%', '60.62%', '71.88%', '61.48%']\n",
      "        Average fitness: 63.02% Â± 4.48%\n",
      "        Best fold: Fold 4 with 71.88%\n",
      "      Fitness obtained: 63.02% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 2389be0f)\n",
      "      Architecture: 4 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2389be0f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.5024, acc=44.92% (best=44.92%)\n",
      "          Fold 1 Epoch 1: loss=0.5114, acc=53.44% (best=53.44%)\n",
      "          Fold 3 Epoch 1: loss=0.4891, acc=54.14% (best=54.14%)\n",
      "          Fold 4 Epoch 1: loss=0.5282, acc=56.88% (best=56.88%)\n",
      "          Fold 5 Epoch 1: loss=0.4886, acc=52.19% (best=52.19%)\n",
      "          Fold 2 Epoch 5: loss=0.2208, acc=48.59% (best=60.70%)\n",
      "          Fold 3 Epoch 5: loss=0.2300, acc=58.59% (best=58.59%)\n",
      "          Fold 1 Epoch 5: loss=0.2300, acc=52.81% (best=53.44%)\n",
      "          Fold 4 Epoch 5: loss=0.2200, acc=44.69% (best=56.88%)\n",
      "          Fold 5 Epoch 5: loss=0.2210, acc=58.36% (best=61.48%)\n",
      "          Fold 2 Epoch 10: loss=0.2029, acc=57.89% (best=60.70%)\n",
      "          Fold 3 Epoch 10: loss=0.2065, acc=57.58% (best=60.70%)\n",
      "          Fold 1 Epoch 10: loss=0.2059, acc=52.89% (best=53.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2033, acc=44.69% (best=56.88%)\n",
      "          Fold 5 Epoch 10: loss=0.2053, acc=58.98% (best=61.48%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 53.44%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 56.88%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 60.70%\n",
      "          Fold 3 Epoch 15: loss=0.1991, acc=57.50% (best=63.98%)\n",
      "          Fold 3 Epoch 20: loss=0.1991, acc=56.09% (best=65.16%)\n",
      "          Fold 3 Epoch 25: loss=0.1995, acc=58.67% (best=65.16%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2389be0f:\n",
      "        Fold accuracies: ['53.44%', '60.70%', '65.16%', '56.88%', '61.48%']\n",
      "        Average fitness: 59.53% Â± 4.03%\n",
      "        Best fold: Fold 3 with 65.16%\n",
      "      Fitness obtained: 59.53% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 9cdbf789)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9cdbf789 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7218, acc=53.98% (best=53.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6792, acc=48.98% (best=48.98%)\n",
      "          Fold 2 Epoch 1: loss=0.7005, acc=44.53% (best=44.53%)\n",
      "          Fold 3 Epoch 1: loss=0.6929, acc=53.28% (best=53.28%)\n",
      "          Fold 1 Epoch 1: loss=0.7049, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.4632, acc=58.98% (best=61.48%)\n",
      "          Fold 4 Epoch 5: loss=0.4772, acc=57.19% (best=57.19%)\n",
      "          Fold 1 Epoch 5: loss=0.5395, acc=55.94% (best=64.92%)\n",
      "          Fold 2 Epoch 5: loss=0.4727, acc=50.70% (best=59.38%)\n",
      "          Fold 3 Epoch 5: loss=0.3784, acc=60.62% (best=60.62%)\n",
      "          Fold 5 Epoch 10: loss=0.2955, acc=46.72% (best=61.48%)\n",
      "          Fold 4 Epoch 10: loss=0.3161, acc=29.92% (best=63.36%)\n",
      "          Fold 1 Epoch 10: loss=0.3364, acc=49.84% (best=64.92%)\n",
      "          Fold 2 Epoch 10: loss=0.3071, acc=56.41% (best=59.38%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "          Fold 3 Epoch 10: loss=0.2864, acc=55.16% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "          Fold 4 Epoch 15: loss=0.2524, acc=53.59% (best=67.97%)\n",
      "          Fold 2 Epoch 15: loss=0.2563, acc=48.28% (best=62.73%)\n",
      "          Fold 3 Epoch 15: loss=0.2650, acc=54.77% (best=60.62%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 60.62%\n",
      "          Fold 4 Epoch 20: loss=0.2402, acc=54.61% (best=67.97%)\n",
      "          Fold 2 Epoch 20: loss=0.2410, acc=56.33% (best=64.61%)\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 2 Epoch 25: loss=0.2255, acc=55.86% (best=64.61%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 64.61%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9cdbf789:\n",
      "        Fold accuracies: ['64.92%', '64.61%', '60.62%', '67.97%', '61.48%']\n",
      "        Average fitness: 63.92% Â± 2.63%\n",
      "        Best fold: Fold 4 with 67.97%\n",
      "      Fitness obtained: 63.92% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 3e709478)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3e709478 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6962, acc=45.94% (best=45.94%)\n",
      "          Fold 5 Epoch 1: loss=0.7293, acc=39.84% (best=39.84%)\n",
      "          Fold 3 Epoch 1: loss=0.7021, acc=44.84% (best=44.84%)\n",
      "          Fold 1 Epoch 1: loss=0.6968, acc=56.09% (best=56.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6820, acc=63.44% (best=63.44%)\n",
      "          Fold 2 Epoch 5: loss=0.3664, acc=59.30% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.4338, acc=49.77% (best=49.77%)\n",
      "          Fold 1 Epoch 5: loss=0.5169, acc=48.36% (best=57.11%)\n",
      "          Fold 4 Epoch 5: loss=0.4787, acc=62.66% (best=63.52%)\n",
      "          Fold 3 Epoch 5: loss=0.4296, acc=55.86% (best=63.20%)\n",
      "          Fold 2 Epoch 10: loss=0.2943, acc=54.22% (best=59.30%)\n",
      "          Fold 5 Epoch 10: loss=0.2984, acc=40.86% (best=56.56%)\n",
      "          Fold 1 Epoch 10: loss=0.3563, acc=57.03% (best=59.45%)\n",
      "          Fold 4 Epoch 10: loss=0.4003, acc=48.12% (best=63.52%)\n",
      "          Fold 3 Epoch 10: loss=0.3437, acc=51.80% (best=63.20%)\n",
      "          Fold 2 Epoch 15: loss=0.2751, acc=43.59% (best=59.30%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 59.30%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 63.20%\n",
      "          Fold 5 Epoch 15: loss=0.2509, acc=49.14% (best=56.56%)\n",
      "          Fold 1 Epoch 15: loss=0.2890, acc=47.50% (best=59.45%)\n",
      "          Fold 4 Epoch 15: loss=0.3223, acc=43.91% (best=73.36%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 59.45%\n",
      "          Fold 5 Epoch 20: loss=0.2323, acc=49.06% (best=58.98%)\n",
      "          Fold 4 Epoch 20: loss=0.2616, acc=50.16% (best=73.36%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 73.36%\n",
      "          Fold 5 Epoch 25: loss=0.2243, acc=47.73% (best=58.98%)\n",
      "          Fold 5: Early stopping at epoch 27\n",
      "      â†’ Fold 5 completed: 58.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3e709478:\n",
      "        Fold accuracies: ['59.45%', '59.30%', '63.20%', '73.36%', '58.98%']\n",
      "        Average fitness: 62.86% Â± 5.47%\n",
      "        Best fold: Fold 4 with 73.36%\n",
      "      Fitness obtained: 62.86% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 218134d3)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 218134d3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=6.7218, acc=59.38% (best=59.38%)\n",
      "          Fold 2 Epoch 1: loss=5.2334, acc=46.64% (best=46.64%)\n",
      "          Fold 4 Epoch 1: loss=5.8179, acc=57.34% (best=57.34%)\n",
      "          Fold 5 Epoch 1: loss=3.3712, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=5.0178, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 5: loss=0.6728, acc=50.23% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.6855, acc=50.23% (best=61.88%)\n",
      "          Fold 4 Epoch 5: loss=0.6807, acc=65.23% (best=65.23%)\n",
      "          Fold 5 Epoch 5: loss=0.6996, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 5: loss=0.6964, acc=48.98% (best=51.02%)\n",
      "          Fold 2 Epoch 10: loss=0.7058, acc=50.39% (best=56.72%)\n",
      "          Fold 1 Epoch 10: loss=0.8916, acc=49.53% (best=65.00%)\n",
      "          Fold 4 Epoch 10: loss=0.6614, acc=49.22% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.6977, acc=50.00% (best=55.16%)\n",
      "          Fold 3 Epoch 10: loss=0.7442, acc=51.02% (best=51.02%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 51.02%\n",
      "          Fold 2 Epoch 15: loss=0.6954, acc=49.61% (best=56.72%)\n",
      "          Fold 1 Epoch 15: loss=0.6861, acc=49.77% (best=65.00%)\n",
      "          Fold 4 Epoch 15: loss=0.6698, acc=51.09% (best=65.23%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 65.23%\n",
      "          Fold 5 Epoch 15: loss=0.7042, acc=50.00% (best=55.16%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 56.72%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 55.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 218134d3:\n",
      "        Fold accuracies: ['65.00%', '56.72%', '51.02%', '65.23%', '55.16%']\n",
      "        Average fitness: 58.62% Â± 5.62%\n",
      "        Best fold: Fold 4 with 65.23%\n",
      "      Fitness obtained: 58.62% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: dc0bb8b4)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model dc0bb8b4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6998, acc=46.64% (best=46.64%)\n",
      "          Fold 5 Epoch 1: loss=0.7341, acc=45.55% (best=45.55%)\n",
      "          Fold 4 Epoch 1: loss=0.7000, acc=55.47% (best=55.47%)\n",
      "          Fold 1 Epoch 1: loss=0.7203, acc=58.98% (best=58.98%)\n",
      "          Fold 3 Epoch 1: loss=0.7090, acc=43.91% (best=43.91%)\n",
      "          Fold 2 Epoch 5: loss=0.3443, acc=51.17% (best=55.16%)\n",
      "          Fold 5 Epoch 5: loss=0.3596, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 5: loss=0.3703, acc=70.62% (best=70.62%)\n",
      "          Fold 1 Epoch 5: loss=0.3713, acc=52.42% (best=58.98%)\n",
      "          Fold 3 Epoch 5: loss=0.3295, acc=56.33% (best=60.55%)\n",
      "          Fold 2 Epoch 10: loss=0.2681, acc=50.86% (best=66.33%)\n",
      "          Fold 5 Epoch 10: loss=0.2776, acc=54.92% (best=57.66%)\n",
      "          Fold 4 Epoch 10: loss=0.2754, acc=52.03% (best=70.62%)\n",
      "          Fold 1 Epoch 10: loss=0.2779, acc=53.44% (best=58.98%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 58.98%\n",
      "          Fold 3 Epoch 10: loss=0.2552, acc=57.03% (best=60.55%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 60.55%\n",
      "          Fold 2 Epoch 15: loss=0.2366, acc=59.53% (best=66.33%)\n",
      "          Fold 5 Epoch 15: loss=0.2447, acc=49.45% (best=57.66%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 4 Epoch 15: loss=0.2377, acc=61.72% (best=70.62%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 70.62%\n",
      "          Fold 2 Epoch 20: loss=0.2186, acc=59.77% (best=66.80%)\n",
      "          Fold 2 Epoch 25: loss=0.2184, acc=66.88% (best=66.88%)\n",
      "          Fold 2 Epoch 30: loss=0.2056, acc=61.72% (best=66.88%)\n",
      "          Fold 2 Epoch 35: loss=0.2039, acc=57.58% (best=68.98%)\n",
      "          Fold 2 Epoch 40: loss=0.2010, acc=55.70% (best=68.98%)\n",
      "          Fold 2: Early stopping at epoch 44\n",
      "      â†’ Fold 2 completed: 68.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dc0bb8b4:\n",
      "        Fold accuracies: ['58.98%', '68.98%', '60.55%', '70.62%', '57.66%']\n",
      "        Average fitness: 63.36% Â± 5.37%\n",
      "        Best fold: Fold 4 with 70.62%\n",
      "      Fitness obtained: 63.36% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: c0f63868)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c0f63868 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for c0f63868:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 03702c09)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model 03702c09 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7080, acc=56.72% (best=56.72%)\n",
      "          Fold 5 Epoch 1: loss=0.7177, acc=50.31% (best=50.31%)\n",
      "          Fold 1 Epoch 1: loss=0.7045, acc=50.55% (best=50.55%)\n",
      "          Fold 4 Epoch 1: loss=0.6889, acc=66.64% (best=66.64%)\n",
      "          Fold 2 Epoch 1: loss=0.6818, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 5: loss=0.4913, acc=53.98% (best=60.78%)\n",
      "          Fold 5 Epoch 5: loss=0.5877, acc=45.86% (best=55.78%)\n",
      "          Fold 1 Epoch 5: loss=0.6000, acc=62.03% (best=62.03%)\n",
      "          Fold 4 Epoch 5: loss=0.5363, acc=62.11% (best=66.64%)\n",
      "          Fold 2 Epoch 5: loss=0.5441, acc=45.39% (best=58.59%)\n",
      "          Fold 3 Epoch 10: loss=0.3543, acc=50.86% (best=61.48%)\n",
      "          Fold 5 Epoch 10: loss=0.3777, acc=40.39% (best=55.78%)\n",
      "          Fold 1 Epoch 10: loss=0.3872, acc=57.89% (best=62.03%)\n",
      "          Fold 4 Epoch 10: loss=0.3874, acc=43.28% (best=66.64%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.64%\n",
      "          Fold 2 Epoch 10: loss=0.3550, acc=51.72% (best=58.59%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 55.78%\n",
      "          Fold 3 Epoch 15: loss=0.2821, acc=59.06% (best=61.48%)\n",
      "          Fold 1 Epoch 15: loss=0.3218, acc=53.52% (best=63.44%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.59%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 61.48%\n",
      "          Fold 1 Epoch 20: loss=0.2808, acc=41.33% (best=63.44%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 03702c09:\n",
      "        Fold accuracies: ['63.44%', '58.59%', '61.48%', '66.64%', '55.78%']\n",
      "        Average fitness: 61.19% Â± 3.76%\n",
      "        Best fold: Fold 4 with 66.64%\n",
      "      Fitness obtained: 61.19% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 8f2979fd)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8f2979fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7273, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7190, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 1: loss=0.7116, acc=43.36% (best=43.36%)\n",
      "          Fold 3 Epoch 1: loss=0.7147, acc=49.69% (best=49.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6886, acc=61.02% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.6731, acc=54.45% (best=57.89%)\n",
      "          Fold 1 Epoch 5: loss=0.5440, acc=61.48% (best=61.48%)\n",
      "          Fold 2 Epoch 5: loss=0.6430, acc=44.92% (best=56.33%)\n",
      "          Fold 4 Epoch 5: loss=0.5072, acc=61.64% (best=69.30%)\n",
      "          Fold 3 Epoch 5: loss=0.4043, acc=61.41% (best=61.41%)\n",
      "          Fold 5 Epoch 10: loss=0.4027, acc=52.11% (best=57.89%)\n",
      "          Fold 1 Epoch 10: loss=0.3099, acc=52.81% (best=62.11%)\n",
      "          Fold 2 Epoch 10: loss=0.3553, acc=62.89% (best=68.28%)\n",
      "          Fold 4 Epoch 10: loss=0.3131, acc=67.97% (best=69.30%)\n",
      "          Fold 3 Epoch 10: loss=0.2874, acc=51.41% (best=61.41%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 57.89%\n",
      "          Fold 1 Epoch 15: loss=0.2606, acc=52.19% (best=62.11%)\n",
      "          Fold 2 Epoch 15: loss=0.2789, acc=60.47% (best=68.28%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 62.11%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 69.30%\n",
      "          Fold 3 Epoch 15: loss=0.2625, acc=44.69% (best=61.41%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 61.41%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 68.28%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8f2979fd:\n",
      "        Fold accuracies: ['62.11%', '68.28%', '61.41%', '69.30%', '57.89%']\n",
      "        Average fitness: 63.80% Â± 4.33%\n",
      "        Best fold: Fold 4 with 69.30%\n",
      "      Fitness obtained: 63.80% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 98d083d1)\n",
      "      Architecture: 12 conv + 4 fc, opt=sgd, lr=0.0001\n",
      "      Training/Evaluating model 98d083d1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7167, acc=47.42% (best=47.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7135, acc=44.53% (best=44.53%)\n",
      "          Fold 3 Epoch 1: loss=0.7345, acc=52.03% (best=52.03%)\n",
      "          Fold 1 Epoch 1: loss=0.7208, acc=53.05% (best=53.05%)\n",
      "          Fold 4 Epoch 1: loss=0.7315, acc=46.72% (best=46.72%)\n",
      "          Fold 5 Epoch 5: loss=0.7125, acc=47.89% (best=53.44%)\n",
      "          Fold 1 Epoch 5: loss=0.7149, acc=44.38% (best=53.05%)\n",
      "          Fold 4 Epoch 5: loss=0.7098, acc=52.11% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.7275, acc=53.67% (best=55.94%)\n",
      "          Fold 2 Epoch 5: loss=0.7101, acc=45.62% (best=47.42%)\n",
      "          Fold 5 Epoch 10: loss=0.7136, acc=43.75% (best=53.44%)\n",
      "          Fold 1 Epoch 10: loss=0.7048, acc=59.61% (best=59.61%)\n",
      "          Fold 4 Epoch 10: loss=0.6975, acc=57.27% (best=59.92%)\n",
      "          Fold 3 Epoch 10: loss=0.7210, acc=45.39% (best=55.94%)\n",
      "          Fold 2 Epoch 10: loss=0.6997, acc=47.58% (best=50.23%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 55.94%\n",
      "          Fold 5 Epoch 15: loss=0.7134, acc=42.42% (best=53.75%)\n",
      "          Fold 1 Epoch 15: loss=0.7015, acc=54.06% (best=59.61%)\n",
      "          Fold 4 Epoch 15: loss=0.6941, acc=62.11% (best=62.11%)\n",
      "          Fold 2 Epoch 15: loss=0.6970, acc=47.11% (best=50.23%)\n",
      "          Fold 5 Epoch 20: loss=0.7137, acc=53.28% (best=53.75%)\n",
      "          Fold 1 Epoch 20: loss=0.7005, acc=53.67% (best=59.61%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 59.61%\n",
      "          Fold 4 Epoch 20: loss=0.6911, acc=58.05% (best=62.11%)\n",
      "          Fold 5: Early stopping at epoch 21\n",
      "      â†’ Fold 5 completed: 53.75%\n",
      "          Fold 2 Epoch 20: loss=0.6923, acc=50.16% (best=54.92%)\n",
      "          Fold 4 Epoch 25: loss=0.6859, acc=58.67% (best=62.11%)\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 62.11%\n",
      "          Fold 2 Epoch 25: loss=0.6912, acc=41.72% (best=54.92%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 54.92%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 98d083d1:\n",
      "        Fold accuracies: ['59.61%', '54.92%', '55.94%', '62.11%', '53.75%']\n",
      "        Average fitness: 57.27% Â± 3.12%\n",
      "        Best fold: Fold 4 with 62.11%\n",
      "      Fitness obtained: 57.27% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 57136a12)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 57136a12 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6713, acc=51.48% (best=51.48%)\n",
      "          Fold 2 Epoch 1: loss=0.7097, acc=48.59% (best=48.59%)\n",
      "          Fold 5 Epoch 1: loss=0.7086, acc=49.77% (best=49.77%)\n",
      "          Fold 3 Epoch 1: loss=0.7105, acc=43.98% (best=43.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7217, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 5: loss=0.3074, acc=66.17% (best=66.17%)\n",
      "          Fold 2 Epoch 5: loss=0.3438, acc=46.88% (best=57.97%)\n",
      "          Fold 5 Epoch 5: loss=0.3428, acc=46.41% (best=57.66%)\n",
      "          Fold 3 Epoch 5: loss=0.3338, acc=62.19% (best=63.20%)\n",
      "          Fold 1 Epoch 5: loss=0.3158, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 10: loss=0.2581, acc=55.86% (best=57.97%)\n",
      "          Fold 4 Epoch 10: loss=0.2508, acc=52.42% (best=66.17%)\n",
      "          Fold 5 Epoch 10: loss=0.2703, acc=46.25% (best=57.66%)\n",
      "          Fold 3 Epoch 10: loss=0.2667, acc=49.92% (best=63.20%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 57.97%\n",
      "          Fold 1 Epoch 10: loss=0.2510, acc=53.83% (best=58.52%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 57.66%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 63.20%\n",
      "          Fold 4 Epoch 15: loss=0.2263, acc=58.91% (best=66.17%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 66.17%\n",
      "          Fold 1 Epoch 15: loss=0.2247, acc=63.44% (best=63.44%)\n",
      "          Fold 1 Epoch 20: loss=0.2163, acc=59.53% (best=63.44%)\n",
      "          Fold 1 Epoch 25: loss=0.2074, acc=56.33% (best=64.84%)\n",
      "          Fold 1 Epoch 30: loss=0.2051, acc=67.27% (best=67.73%)\n",
      "          Fold 1 Epoch 35: loss=0.1992, acc=61.33% (best=69.22%)\n",
      "          Fold 1 Epoch 40: loss=0.1992, acc=55.23% (best=69.22%)\n",
      "          Fold 1: Early stopping at epoch 41\n",
      "      â†’ Fold 1 completed: 69.22%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 57136a12:\n",
      "        Fold accuracies: ['69.22%', '57.97%', '63.20%', '66.17%', '57.66%']\n",
      "        Average fitness: 62.84% Â± 4.53%\n",
      "        Best fold: Fold 1 with 69.22%\n",
      "      Fitness obtained: 62.84% | Best in generation: 64.14% | Global best: 70.92%\n",
      "\n",
      "GENERATION 21 STATISTICS:\n",
      "   Maximum fitness: 64.14%\n",
      "   Average fitness: 58.70%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 13.59%\n",
      "   Best individual: 301cae3e with 64.14%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 14/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=13.59)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 301cae3e (fitness: 64.14%)\n",
      "   Elite 2: 9cdbf789 (fitness: 63.92%)\n",
      "   Elite 3: 8f2979fd (fitness: 63.80%)\n",
      "   Elite 4: dc0bb8b4 (fitness: 63.36%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 15/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 22\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 22)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 301cae3e)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 301cae3e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7229, acc=44.30% (best=44.30%)\n",
      "          Fold 1 Epoch 1: loss=0.7261, acc=60.86% (best=60.86%)\n",
      "          Fold 5 Epoch 1: loss=0.7348, acc=54.14% (best=54.14%)\n",
      "          Fold 2 Epoch 1: loss=0.7083, acc=47.58% (best=47.58%)\n",
      "          Fold 4 Epoch 1: loss=0.7180, acc=54.69% (best=54.69%)\n",
      "          Fold 3 Epoch 5: loss=0.3803, acc=45.39% (best=65.70%)\n",
      "          Fold 5 Epoch 5: loss=0.4095, acc=49.06% (best=57.27%)\n",
      "          Fold 1 Epoch 5: loss=0.4565, acc=63.98% (best=63.98%)\n",
      "          Fold 4 Epoch 5: loss=0.4610, acc=48.52% (best=65.08%)\n",
      "          Fold 2 Epoch 5: loss=0.4057, acc=45.39% (best=55.55%)\n",
      "          Fold 3 Epoch 10: loss=0.2770, acc=56.02% (best=65.70%)\n",
      "          Fold 5 Epoch 10: loss=0.2668, acc=52.19% (best=60.39%)\n",
      "          Fold 1 Epoch 10: loss=0.2937, acc=56.95% (best=63.98%)\n",
      "          Fold 4 Epoch 10: loss=0.2735, acc=52.81% (best=65.08%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 65.70%\n",
      "          Fold 2 Epoch 10: loss=0.2738, acc=51.17% (best=68.83%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.08%\n",
      "          Fold 5 Epoch 15: loss=0.2486, acc=33.91% (best=60.39%)\n",
      "          Fold 1 Epoch 15: loss=0.2503, acc=54.84% (best=63.98%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.98%\n",
      "          Fold 2 Epoch 15: loss=0.2553, acc=59.69% (best=68.83%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 68.83%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 301cae3e:\n",
      "        Fold accuracies: ['63.98%', '68.83%', '65.70%', '65.08%', '60.39%']\n",
      "        Average fitness: 64.80% Â± 2.73%\n",
      "        Best fold: Fold 2 with 68.83%\n",
      "      New best fitness in this generation: 64.80%!\n",
      "      Fitness obtained: 64.80% | Best in generation: 64.80% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 9cdbf789)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9cdbf789 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6938, acc=53.44% (best=53.44%)\n",
      "          Fold 2 Epoch 1: loss=0.6957, acc=51.09% (best=51.09%)\n",
      "          Fold 3 Epoch 1: loss=0.6978, acc=58.28% (best=58.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6862, acc=70.78% (best=70.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7202, acc=64.53% (best=64.53%)\n",
      "          Fold 1 Epoch 5: loss=0.5150, acc=53.05% (best=53.44%)\n",
      "          Fold 2 Epoch 5: loss=0.4378, acc=50.47% (best=63.36%)\n",
      "          Fold 3 Epoch 5: loss=0.4303, acc=63.98% (best=63.98%)\n",
      "          Fold 5 Epoch 5: loss=0.5047, acc=48.91% (best=64.53%)\n",
      "          Fold 4 Epoch 5: loss=0.4757, acc=42.81% (best=70.78%)\n",
      "          Fold 1 Epoch 10: loss=0.3825, acc=49.22% (best=56.95%)\n",
      "          Fold 2 Epoch 10: loss=0.2947, acc=43.28% (best=63.36%)\n",
      "          Fold 3 Epoch 10: loss=0.3097, acc=69.61% (best=69.61%)\n",
      "          Fold 5 Epoch 10: loss=0.3154, acc=43.98% (best=64.53%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 63.36%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "          Fold 4 Epoch 10: loss=0.3135, acc=54.69% (best=70.78%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 70.78%\n",
      "          Fold 1 Epoch 15: loss=0.3110, acc=50.62% (best=58.91%)\n",
      "          Fold 3 Epoch 15: loss=0.2574, acc=60.39% (best=69.61%)\n",
      "          Fold 1 Epoch 20: loss=0.2672, acc=51.48% (best=62.81%)\n",
      "          Fold 3 Epoch 20: loss=0.2423, acc=70.39% (best=70.39%)\n",
      "          Fold 1 Epoch 25: loss=0.2405, acc=47.89% (best=62.81%)\n",
      "          Fold 3 Epoch 25: loss=0.2286, acc=60.39% (best=70.39%)\n",
      "          Fold 1 Epoch 30: loss=0.2386, acc=50.39% (best=62.97%)\n",
      "          Fold 3 Epoch 30: loss=0.2249, acc=53.28% (best=70.39%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 70.39%\n",
      "          Fold 1 Epoch 35: loss=0.2255, acc=38.91% (best=62.97%)\n",
      "          Fold 1: Early stopping at epoch 36\n",
      "      â†’ Fold 1 completed: 62.97%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9cdbf789:\n",
      "        Fold accuracies: ['62.97%', '63.36%', '70.39%', '70.78%', '64.53%']\n",
      "        Average fitness: 66.41% Â± 3.45%\n",
      "        Best fold: Fold 4 with 70.78%\n",
      "      New best fitness in this generation: 66.41%!\n",
      "      Fitness obtained: 66.41% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 8f2979fd)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8f2979fd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7302, acc=58.28% (best=58.28%)\n",
      "          Fold 2 Epoch 1: loss=0.7091, acc=59.45% (best=59.45%)\n",
      "          Fold 3 Epoch 1: loss=0.7253, acc=45.00% (best=45.00%)\n",
      "          Fold 1 Epoch 1: loss=0.7046, acc=52.42% (best=52.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6915, acc=57.27% (best=57.27%)\n",
      "          Fold 2 Epoch 5: loss=0.4278, acc=61.64% (best=61.64%)\n",
      "          Fold 5 Epoch 5: loss=0.7001, acc=60.00% (best=60.00%)\n",
      "          Fold 3 Epoch 5: loss=0.5070, acc=50.39% (best=59.61%)\n",
      "          Fold 1 Epoch 5: loss=0.5434, acc=54.45% (best=64.92%)\n",
      "          Fold 4 Epoch 5: loss=0.5568, acc=36.09% (best=60.94%)\n",
      "          Fold 2 Epoch 10: loss=0.2905, acc=64.69% (best=64.69%)\n",
      "          Fold 5 Epoch 10: loss=0.5940, acc=51.33% (best=60.00%)\n",
      "          Fold 3 Epoch 10: loss=0.2939, acc=43.28% (best=59.61%)\n",
      "          Fold 1 Epoch 10: loss=0.3315, acc=51.80% (best=64.92%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 59.61%\n",
      "          Fold 4 Epoch 10: loss=0.2882, acc=47.34% (best=61.17%)\n",
      "          Fold 2 Epoch 15: loss=0.2554, acc=62.19% (best=64.69%)\n",
      "          Fold 5 Epoch 15: loss=0.3207, acc=54.69% (best=60.00%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.00%\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 64.92%\n",
      "          Fold 4 Epoch 15: loss=0.2434, acc=52.66% (best=61.17%)\n",
      "          Fold 2 Epoch 20: loss=0.2349, acc=57.34% (best=69.69%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 61.17%\n",
      "          Fold 2 Epoch 25: loss=0.2332, acc=37.89% (best=69.69%)\n",
      "          Fold 2: Early stopping at epoch 27\n",
      "      â†’ Fold 2 completed: 69.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8f2979fd:\n",
      "        Fold accuracies: ['64.92%', '69.69%', '59.61%', '61.17%', '60.00%']\n",
      "        Average fitness: 63.08% Â± 3.80%\n",
      "        Best fold: Fold 2 with 69.69%\n",
      "      Fitness obtained: 63.08% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: dc0bb8b4)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model dc0bb8b4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7035, acc=50.70% (best=50.70%)\n",
      "          Fold 3 Epoch 1: loss=0.6950, acc=57.73% (best=57.73%)\n",
      "          Fold 5 Epoch 1: loss=0.7494, acc=55.39% (best=55.39%)\n",
      "          Fold 2 Epoch 1: loss=0.7022, acc=53.52% (best=53.52%)\n",
      "          Fold 4 Epoch 1: loss=0.6827, acc=61.09% (best=61.09%)\n",
      "          Fold 5 Epoch 5: loss=0.3657, acc=61.80% (best=61.80%)\n",
      "          Fold 1 Epoch 5: loss=0.3777, acc=57.03% (best=58.28%)\n",
      "          Fold 3 Epoch 5: loss=0.3626, acc=59.69% (best=67.97%)\n",
      "          Fold 2 Epoch 5: loss=0.3379, acc=48.20% (best=53.52%)\n",
      "          Fold 4 Epoch 5: loss=0.4045, acc=51.95% (best=63.20%)\n",
      "          Fold 5 Epoch 10: loss=0.2663, acc=51.56% (best=61.80%)\n",
      "          Fold 1 Epoch 10: loss=0.2712, acc=46.95% (best=59.14%)\n",
      "          Fold 3 Epoch 10: loss=0.2793, acc=53.75% (best=67.97%)\n",
      "          Fold 2 Epoch 10: loss=0.2561, acc=59.30% (best=59.30%)\n",
      "          Fold 4 Epoch 10: loss=0.2822, acc=47.42% (best=69.77%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 67.97%\n",
      "          Fold 5 Epoch 15: loss=0.2400, acc=56.95% (best=61.80%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "          Fold 1 Epoch 15: loss=0.2339, acc=52.73% (best=60.23%)\n",
      "          Fold 2 Epoch 15: loss=0.2396, acc=47.89% (best=63.36%)\n",
      "          Fold 4 Epoch 15: loss=0.2412, acc=60.86% (best=69.77%)\n",
      "          Fold 1 Epoch 20: loss=0.2209, acc=49.22% (best=60.23%)\n",
      "          Fold 2 Epoch 20: loss=0.2276, acc=57.27% (best=65.55%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 60.23%\n",
      "          Fold 4 Epoch 20: loss=0.2254, acc=53.28% (best=70.00%)\n",
      "          Fold 2 Epoch 25: loss=0.2144, acc=62.81% (best=65.55%)\n",
      "          Fold 4 Epoch 25: loss=0.2128, acc=68.20% (best=70.00%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 70.00%\n",
      "          Fold 2 Epoch 30: loss=0.2071, acc=58.44% (best=66.17%)\n",
      "          Fold 2 Epoch 35: loss=0.2110, acc=54.14% (best=66.17%)\n",
      "          Fold 2: Early stopping at epoch 36\n",
      "      â†’ Fold 2 completed: 66.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dc0bb8b4:\n",
      "        Fold accuracies: ['60.23%', '66.17%', '67.97%', '70.00%', '61.80%']\n",
      "        Average fitness: 65.23% Â± 3.68%\n",
      "        Best fold: Fold 4 with 70.00%\n",
      "      Fitness obtained: 65.23% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 83ccbb40)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 83ccbb40 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.6981, acc=62.66% (best=62.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7197, acc=47.58% (best=47.58%)\n",
      "          Fold 2 Epoch 1: loss=0.6848, acc=50.47% (best=50.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6739, acc=51.41% (best=51.41%)\n",
      "          Fold 3 Epoch 1: loss=0.7061, acc=49.84% (best=49.84%)\n",
      "          Fold 1 Epoch 5: loss=0.4956, acc=59.69% (best=65.23%)\n",
      "          Fold 5 Epoch 5: loss=0.5169, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 5: loss=0.4638, acc=54.77% (best=61.56%)\n",
      "          Fold 3 Epoch 5: loss=0.4387, acc=47.50% (best=56.80%)\n",
      "          Fold 2 Epoch 5: loss=0.4249, acc=50.16% (best=50.47%)\n",
      "          Fold 1 Epoch 10: loss=0.3583, acc=56.56% (best=65.23%)\n",
      "          Fold 5 Epoch 10: loss=0.3239, acc=50.70% (best=62.42%)\n",
      "          Fold 4 Epoch 10: loss=0.3566, acc=56.64% (best=61.56%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 3 Epoch 10: loss=0.3372, acc=57.58% (best=57.58%)\n",
      "          Fold 2 Epoch 10: loss=0.2977, acc=40.70% (best=50.47%)\n",
      "          Fold 5 Epoch 15: loss=0.2697, acc=34.84% (best=62.42%)\n",
      "          Fold 4 Epoch 15: loss=0.2828, acc=52.50% (best=69.22%)\n",
      "          Fold 3 Epoch 15: loss=0.2800, acc=58.28% (best=59.45%)\n",
      "          Fold 2 Epoch 15: loss=0.2781, acc=47.19% (best=52.66%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 62.42%\n",
      "          Fold 4 Epoch 20: loss=0.2464, acc=51.02% (best=69.22%)\n",
      "          Fold 3 Epoch 20: loss=0.2568, acc=64.30% (best=64.30%)\n",
      "          Fold 4: Early stopping at epoch 21\n",
      "      â†’ Fold 4 completed: 69.22%\n",
      "          Fold 2 Epoch 20: loss=0.2498, acc=41.72% (best=52.66%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 52.66%\n",
      "          Fold 3 Epoch 25: loss=0.2393, acc=49.30% (best=64.30%)\n",
      "          Fold 3 Epoch 30: loss=0.2363, acc=57.89% (best=64.30%)\n",
      "          Fold 3: Early stopping at epoch 30\n",
      "      â†’ Fold 3 completed: 64.30%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 83ccbb40:\n",
      "        Fold accuracies: ['65.23%', '52.66%', '64.30%', '69.22%', '62.42%']\n",
      "        Average fitness: 62.77% Â± 5.52%\n",
      "        Best fold: Fold 4 with 69.22%\n",
      "      Fitness obtained: 62.77% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: 1681fb0e)\n",
      "      Architecture: 12 conv + 4 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 1681fb0e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6493, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 1: loss=0.6918, acc=47.73% (best=47.73%)\n",
      "          Fold 1 Epoch 1: loss=0.6741, acc=48.67% (best=48.67%)\n",
      "          Fold 4 Epoch 1: loss=0.6502, acc=67.27% (best=67.27%)\n",
      "          Fold 3 Epoch 1: loss=0.6833, acc=48.05% (best=48.05%)\n",
      "          Fold 2 Epoch 5: loss=0.3138, acc=34.22% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.3638, acc=42.58% (best=53.28%)\n",
      "          Fold 1 Epoch 5: loss=0.4008, acc=60.39% (best=62.66%)\n",
      "          Fold 4 Epoch 5: loss=0.3585, acc=57.03% (best=67.27%)\n",
      "          Fold 3 Epoch 5: loss=0.3621, acc=47.34% (best=55.47%)\n",
      "          Fold 2 Epoch 10: loss=0.2490, acc=36.33% (best=52.73%)\n",
      "          Fold 5 Epoch 10: loss=0.2620, acc=51.33% (best=53.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2762, acc=55.47% (best=74.53%)\n",
      "          Fold 4 Epoch 10: loss=0.2455, acc=53.67% (best=67.27%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.27%\n",
      "          Fold 3 Epoch 10: loss=0.2572, acc=53.98% (best=57.58%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 53.28%\n",
      "          Fold 2 Epoch 15: loss=0.2308, acc=44.45% (best=52.73%)\n",
      "          Fold 1 Epoch 15: loss=0.2470, acc=72.73% (best=74.53%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 52.73%\n",
      "          Fold 3 Epoch 15: loss=0.2286, acc=50.00% (best=57.58%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 74.53%\n",
      "          Fold 3 Epoch 20: loss=0.2245, acc=53.20% (best=58.67%)\n",
      "          Fold 3 Epoch 25: loss=0.2206, acc=51.25% (best=58.67%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 58.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1681fb0e:\n",
      "        Fold accuracies: ['74.53%', '52.73%', '58.67%', '67.27%', '53.28%']\n",
      "        Average fitness: 61.30% Â± 8.43%\n",
      "        Best fold: Fold 1 with 74.53%\n",
      "      Fitness obtained: 61.30% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: df64d054)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model df64d054 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7016, acc=55.47% (best=55.47%)\n",
      "          Fold 2 Epoch 1: loss=0.7066, acc=43.12% (best=43.12%)\n",
      "          Fold 4 Epoch 1: loss=0.6901, acc=61.25% (best=61.25%)\n",
      "          Fold 5 Epoch 1: loss=0.7075, acc=52.73% (best=52.73%)\n",
      "          Fold 3 Epoch 1: loss=0.6991, acc=57.58% (best=57.58%)\n",
      "          Fold 1 Epoch 5: loss=0.4260, acc=61.72% (best=61.72%)\n",
      "          Fold 2 Epoch 5: loss=0.3721, acc=40.94% (best=52.97%)\n",
      "          Fold 4 Epoch 5: loss=0.5071, acc=49.92% (best=61.25%)\n",
      "          Fold 5 Epoch 5: loss=0.3425, acc=37.50% (best=52.73%)\n",
      "          Fold 3 Epoch 5: loss=0.3672, acc=55.00% (best=63.98%)\n",
      "          Fold 1 Epoch 10: loss=0.2807, acc=41.80% (best=61.72%)\n",
      "          Fold 2 Epoch 10: loss=0.2614, acc=49.77% (best=52.97%)\n",
      "          Fold 4 Epoch 10: loss=0.2904, acc=53.59% (best=61.25%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 61.25%\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 52.97%\n",
      "          Fold 5 Epoch 10: loss=0.2661, acc=42.66% (best=52.73%)\n",
      "          Fold 3 Epoch 10: loss=0.2833, acc=55.31% (best=63.98%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 52.73%\n",
      "          Fold 1 Epoch 15: loss=0.2399, acc=51.72% (best=61.72%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 61.72%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 63.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for df64d054:\n",
      "        Fold accuracies: ['61.72%', '52.97%', '63.98%', '61.25%', '52.73%']\n",
      "        Average fitness: 58.53% Â± 4.73%\n",
      "        Best fold: Fold 3 with 63.98%\n",
      "      Fitness obtained: 58.53% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: df10cb81)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model df10cb81 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6858, acc=59.14% (best=59.14%)\n",
      "          Fold 1 Epoch 1: loss=0.7029, acc=53.67% (best=53.67%)\n",
      "          Fold 2 Epoch 1: loss=0.7003, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7075, acc=55.39% (best=55.39%)\n",
      "          Fold 5 Epoch 1: loss=0.6979, acc=51.72% (best=51.72%)\n",
      "          Fold 4 Epoch 5: loss=0.4473, acc=62.58% (best=63.98%)\n",
      "          Fold 1 Epoch 5: loss=0.4923, acc=47.81% (best=62.19%)\n",
      "          Fold 3 Epoch 5: loss=0.4199, acc=48.83% (best=55.39%)\n",
      "          Fold 2 Epoch 5: loss=0.6031, acc=53.44% (best=57.81%)\n",
      "          Fold 5 Epoch 5: loss=0.4497, acc=47.42% (best=59.22%)\n",
      "          Fold 4 Epoch 10: loss=0.3068, acc=56.17% (best=65.94%)\n",
      "          Fold 1 Epoch 10: loss=0.3109, acc=60.31% (best=62.19%)\n",
      "          Fold 3 Epoch 10: loss=0.3060, acc=60.23% (best=61.56%)\n",
      "          Fold 2 Epoch 10: loss=0.2943, acc=36.95% (best=57.81%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.19%\n",
      "          Fold 5 Epoch 10: loss=0.3089, acc=56.17% (best=59.22%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 57.81%\n",
      "          Fold 4 Epoch 15: loss=0.2512, acc=60.47% (best=65.94%)\n",
      "          Fold 3 Epoch 15: loss=0.2415, acc=46.48% (best=61.56%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 59.22%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 65.94%\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 61.56%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for df10cb81:\n",
      "        Fold accuracies: ['62.19%', '57.81%', '61.56%', '65.94%', '59.22%']\n",
      "        Average fitness: 61.34% Â± 2.79%\n",
      "        Best fold: Fold 4 with 65.94%\n",
      "      Fitness obtained: 61.34% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 41a208d4)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 41a208d4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7406, acc=49.84% (best=49.84%)\n",
      "          Fold 1 Epoch 1: loss=0.7396, acc=47.11% (best=47.11%)\n",
      "          Fold 5 Epoch 1: loss=0.7619, acc=50.16% (best=50.16%)\n",
      "          Fold 4 Epoch 1: loss=0.7220, acc=58.91% (best=58.91%)\n",
      "          Fold 3 Epoch 1: loss=0.7450, acc=49.69% (best=49.69%)\n",
      "          Fold 2 Epoch 5: loss=0.5537, acc=52.66% (best=52.66%)\n",
      "          Fold 1 Epoch 5: loss=0.5339, acc=48.59% (best=62.42%)\n",
      "          Fold 5 Epoch 5: loss=0.6394, acc=58.12% (best=58.12%)\n",
      "          Fold 4 Epoch 5: loss=0.4982, acc=65.55% (best=65.55%)\n",
      "          Fold 3 Epoch 5: loss=0.5318, acc=42.11% (best=55.00%)\n",
      "          Fold 2 Epoch 10: loss=0.3391, acc=46.95% (best=52.66%)\n",
      "          Fold 1 Epoch 10: loss=0.3543, acc=56.72% (best=62.42%)\n",
      "          Fold 5 Epoch 10: loss=0.4329, acc=63.05% (best=66.25%)\n",
      "          Fold 4 Epoch 10: loss=0.2950, acc=51.95% (best=65.55%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 62.42%\n",
      "          Fold 3 Epoch 10: loss=0.3126, acc=59.30% (best=59.61%)\n",
      "          Fold 2 Epoch 15: loss=0.2821, acc=55.86% (best=56.09%)\n",
      "          Fold 5 Epoch 15: loss=0.3198, acc=55.94% (best=66.25%)\n",
      "          Fold 4 Epoch 15: loss=0.2533, acc=47.81% (best=65.55%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 65.55%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 66.25%\n",
      "          Fold 3 Epoch 15: loss=0.2674, acc=65.78% (best=65.78%)\n",
      "          Fold 2 Epoch 20: loss=0.2469, acc=46.48% (best=61.95%)\n",
      "          Fold 3 Epoch 20: loss=0.2445, acc=53.75% (best=65.78%)\n",
      "          Fold 2 Epoch 25: loss=0.2419, acc=62.03% (best=62.03%)\n",
      "          Fold 3 Epoch 25: loss=0.2296, acc=48.52% (best=65.78%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 65.78%\n",
      "          Fold 2 Epoch 30: loss=0.2260, acc=57.81% (best=62.03%)\n",
      "          Fold 2 Epoch 35: loss=0.2188, acc=40.70% (best=62.03%)\n",
      "          Fold 2: Early stopping at epoch 35\n",
      "      â†’ Fold 2 completed: 62.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 41a208d4:\n",
      "        Fold accuracies: ['62.42%', '62.03%', '65.78%', '65.55%', '66.25%']\n",
      "        Average fitness: 64.41% Â± 1.80%\n",
      "        Best fold: Fold 5 with 66.25%\n",
      "      Fitness obtained: 64.41% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: e62c95c5)\n",
      "      Architecture: 21 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e62c95c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 114, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for e62c95c5:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 5 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 3cf76ed3)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 3cf76ed3 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7109, acc=49.61% (best=49.61%)\n",
      "          Fold 3 Epoch 1: loss=0.7314, acc=53.59% (best=53.59%)\n",
      "          Fold 1 Epoch 1: loss=0.7172, acc=50.23% (best=50.23%)\n",
      "          Fold 4 Epoch 1: loss=0.7036, acc=48.44% (best=48.44%)\n",
      "          Fold 5 Epoch 1: loss=0.7308, acc=50.08% (best=50.08%)\n",
      "          Fold 5 Epoch 5: loss=0.5254, acc=38.75% (best=52.50%)\n",
      "          Fold 4 Epoch 5: loss=0.5437, acc=53.12% (best=65.86%)\n",
      "          Fold 3 Epoch 5: loss=0.5009, acc=42.27% (best=53.59%)\n",
      "          Fold 1 Epoch 5: loss=0.5849, acc=50.08% (best=65.00%)\n",
      "          Fold 2 Epoch 5: loss=0.5266, acc=47.03% (best=50.55%)\n",
      "          Fold 5 Epoch 10: loss=0.3439, acc=45.08% (best=52.50%)\n",
      "          Fold 4 Epoch 10: loss=0.3549, acc=59.45% (best=65.86%)\n",
      "          Fold 3 Epoch 10: loss=0.3995, acc=56.02% (best=60.86%)\n",
      "          Fold 1 Epoch 10: loss=0.4947, acc=49.77% (best=65.00%)\n",
      "          Fold 2 Epoch 10: loss=0.3736, acc=54.14% (best=56.64%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 52.50%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 65.86%\n",
      "          Fold 3 Epoch 15: loss=0.3656, acc=54.92% (best=60.86%)\n",
      "          Fold 2 Epoch 15: loss=0.3321, acc=45.00% (best=56.64%)\n",
      "          Fold 3 Epoch 20: loss=0.3229, acc=59.53% (best=62.42%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 56.64%\n",
      "          Fold 3 Epoch 25: loss=0.3029, acc=51.56% (best=62.42%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 62.42%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 3cf76ed3:\n",
      "        Fold accuracies: ['65.00%', '56.64%', '62.42%', '65.86%', '52.50%']\n",
      "        Average fitness: 60.48% Â± 5.13%\n",
      "        Best fold: Fold 4 with 65.86%\n",
      "      Fitness obtained: 60.48% | Best in generation: 66.41% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 57ce2930)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 57ce2930 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7161, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 1: loss=0.7094, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7121, acc=57.11% (best=57.11%)\n",
      "          Fold 5 Epoch 1: loss=0.7197, acc=56.09% (best=56.09%)\n",
      "          Fold 4 Epoch 1: loss=0.6952, acc=62.34% (best=62.34%)\n",
      "          Fold 3 Epoch 5: loss=0.4394, acc=51.09% (best=57.42%)\n",
      "          Fold 2 Epoch 5: loss=0.4231, acc=56.48% (best=60.47%)\n",
      "          Fold 1 Epoch 5: loss=0.4582, acc=75.55% (best=75.55%)\n",
      "          Fold 5 Epoch 5: loss=0.4174, acc=51.64% (best=56.09%)\n",
      "          Fold 4 Epoch 5: loss=0.4910, acc=61.88% (best=63.28%)\n",
      "          Fold 3 Epoch 10: loss=0.3240, acc=49.06% (best=57.50%)\n",
      "          Fold 1 Epoch 10: loss=0.3219, acc=75.47% (best=75.55%)\n",
      "          Fold 5 Epoch 10: loss=0.3007, acc=46.17% (best=56.09%)\n",
      "          Fold 2 Epoch 10: loss=0.3115, acc=63.91% (best=76.80%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 56.09%\n",
      "          Fold 4 Epoch 10: loss=0.3494, acc=57.73% (best=63.28%)\n",
      "          Fold 3 Epoch 15: loss=0.2822, acc=47.89% (best=57.50%)\n",
      "          Fold 1 Epoch 15: loss=0.2711, acc=58.20% (best=75.55%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 75.55%\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 57.50%\n",
      "          Fold 2 Epoch 15: loss=0.2702, acc=58.98% (best=76.80%)\n",
      "          Fold 4 Epoch 15: loss=0.2860, acc=63.98% (best=64.53%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 76.80%\n",
      "          Fold 4 Epoch 20: loss=0.2629, acc=61.72% (best=66.80%)\n",
      "          Fold 4 Epoch 25: loss=0.2407, acc=54.61% (best=66.80%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 66.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 57ce2930:\n",
      "        Fold accuracies: ['75.55%', '76.80%', '57.50%', '66.80%', '56.09%']\n",
      "        Average fitness: 66.55% Â± 8.69%\n",
      "        Best fold: Fold 2 with 76.80%\n",
      "      New best fitness in this generation: 66.55%!\n",
      "      Fitness obtained: 66.55% | Best in generation: 66.55% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: cd01398b)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cd01398b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7146, acc=50.16% (best=50.16%)\n",
      "          Fold 4 Epoch 1: loss=0.7002, acc=57.73% (best=57.73%)\n",
      "          Fold 1 Epoch 1: loss=0.7131, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 1: loss=0.7381, acc=43.83% (best=43.83%)\n",
      "          Fold 5 Epoch 1: loss=0.7217, acc=49.30% (best=49.30%)\n",
      "          Fold 2 Epoch 5: loss=0.3927, acc=56.88% (best=56.88%)\n",
      "          Fold 4 Epoch 5: loss=0.4154, acc=53.36% (best=57.73%)\n",
      "          Fold 1 Epoch 5: loss=0.4020, acc=63.05% (best=63.05%)\n",
      "          Fold 3 Epoch 5: loss=0.4107, acc=62.03% (best=62.03%)\n",
      "          Fold 5 Epoch 5: loss=0.4231, acc=56.17% (best=59.06%)\n",
      "          Fold 2 Epoch 10: loss=0.2926, acc=52.66% (best=56.88%)\n",
      "          Fold 4 Epoch 10: loss=0.2773, acc=67.11% (best=71.17%)\n",
      "          Fold 1 Epoch 10: loss=0.2873, acc=54.69% (best=63.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2865, acc=56.72% (best=65.47%)\n",
      "          Fold 5 Epoch 10: loss=0.3162, acc=64.53% (best=64.53%)\n",
      "          Fold 2 Epoch 15: loss=0.2518, acc=53.28% (best=61.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2418, acc=55.39% (best=71.17%)\n",
      "          Fold 1 Epoch 15: loss=0.2490, acc=52.66% (best=63.05%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.05%\n",
      "          Fold 3 Epoch 15: loss=0.2562, acc=61.17% (best=65.47%)\n",
      "          Fold 5 Epoch 15: loss=0.2663, acc=63.20% (best=64.53%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 71.17%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.47%\n",
      "          Fold 2 Epoch 20: loss=0.2326, acc=56.80% (best=61.88%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 61.88%\n",
      "          Fold 5 Epoch 20: loss=0.2404, acc=56.41% (best=64.53%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cd01398b:\n",
      "        Fold accuracies: ['63.05%', '61.88%', '65.47%', '71.17%', '64.53%']\n",
      "        Average fitness: 65.22% Â± 3.22%\n",
      "        Best fold: Fold 4 with 71.17%\n",
      "      Fitness obtained: 65.22% | Best in generation: 66.55% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 8fe5fa18)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 8fe5fa18 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7488, acc=50.39% (best=50.39%)\n",
      "          Fold 3 Epoch 1: loss=0.7538, acc=49.30% (best=49.30%)\n",
      "          Fold 1 Epoch 1: loss=0.7394, acc=58.75% (best=58.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6968, acc=49.30% (best=49.30%)\n",
      "          Fold 5 Epoch 1: loss=0.7408, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 5: loss=0.6744, acc=47.11% (best=50.39%)\n",
      "          Fold 5 Epoch 5: loss=0.6628, acc=48.05% (best=50.70%)\n",
      "          Fold 1 Epoch 5: loss=0.6445, acc=63.83% (best=63.83%)\n",
      "          Fold 4 Epoch 5: loss=0.5011, acc=51.95% (best=52.11%)\n",
      "          Fold 3 Epoch 5: loss=0.5789, acc=51.95% (best=56.64%)\n",
      "          Fold 2 Epoch 10: loss=0.3753, acc=46.41% (best=50.39%)\n",
      "          Fold 5 Epoch 10: loss=0.3070, acc=49.38% (best=54.69%)\n",
      "          Fold 1 Epoch 10: loss=0.3609, acc=56.48% (best=63.83%)\n",
      "          Fold 4 Epoch 10: loss=0.2839, acc=45.70% (best=61.33%)\n",
      "          Fold 3 Epoch 10: loss=0.3169, acc=54.22% (best=58.36%)\n",
      "          Fold 2 Epoch 15: loss=0.2815, acc=40.62% (best=52.89%)\n",
      "          Fold 5 Epoch 15: loss=0.2645, acc=51.48% (best=54.69%)\n",
      "          Fold 1 Epoch 15: loss=0.2800, acc=44.22% (best=63.83%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 63.83%\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 54.69%\n",
      "          Fold 4 Epoch 15: loss=0.2585, acc=55.86% (best=61.33%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 61.33%\n",
      "          Fold 3 Epoch 15: loss=0.2578, acc=57.34% (best=58.36%)\n",
      "          Fold 2 Epoch 20: loss=0.2583, acc=52.50% (best=64.84%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 58.36%\n",
      "          Fold 2 Epoch 25: loss=0.2344, acc=49.30% (best=64.84%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 64.84%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8fe5fa18:\n",
      "        Fold accuracies: ['63.83%', '64.84%', '58.36%', '61.33%', '54.69%']\n",
      "        Average fitness: 60.61% Â± 3.71%\n",
      "        Best fold: Fold 2 with 64.84%\n",
      "      Fitness obtained: 60.61% | Best in generation: 66.55% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: 72b53f76)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 72b53f76 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7192, acc=53.91% (best=53.91%)\n",
      "          Fold 3 Epoch 1: loss=0.6711, acc=55.47% (best=55.47%)\n",
      "          Fold 1 Epoch 1: loss=0.7114, acc=52.50% (best=52.50%)\n",
      "          Fold 2 Epoch 1: loss=0.6948, acc=59.69% (best=59.69%)\n",
      "          Fold 4 Epoch 1: loss=0.6835, acc=62.03% (best=62.03%)\n",
      "          Fold 3 Epoch 5: loss=0.4699, acc=54.38% (best=61.80%)\n",
      "          Fold 5 Epoch 5: loss=0.4390, acc=37.81% (best=54.61%)\n",
      "          Fold 1 Epoch 5: loss=0.5039, acc=48.67% (best=56.25%)\n",
      "          Fold 2 Epoch 5: loss=0.4155, acc=50.00% (best=59.69%)\n",
      "          Fold 4 Epoch 5: loss=0.4633, acc=68.12% (best=68.12%)\n",
      "          Fold 3 Epoch 10: loss=0.3644, acc=56.80% (best=61.80%)\n",
      "          Fold 5 Epoch 10: loss=0.3205, acc=46.80% (best=54.61%)\n",
      "          Fold 1 Epoch 10: loss=0.3784, acc=49.69% (best=57.34%)\n",
      "          Fold 2 Epoch 10: loss=0.3206, acc=47.27% (best=59.69%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 61.80%\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 54.61%\n",
      "          Fold 4 Epoch 10: loss=0.3312, acc=50.08% (best=68.12%)\n",
      "          Fold 1 Epoch 15: loss=0.3341, acc=50.31% (best=66.72%)\n",
      "          Fold 4 Epoch 15: loss=0.2734, acc=56.25% (best=68.12%)\n",
      "          Fold 4: Early stopping at epoch 15\n",
      "      â†’ Fold 4 completed: 68.12%\n",
      "          Fold 1 Epoch 20: loss=0.2971, acc=50.86% (best=66.72%)\n",
      "          Fold 1: Early stopping at epoch 22\n",
      "      â†’ Fold 1 completed: 66.72%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 72b53f76:\n",
      "        Fold accuracies: ['66.72%', '59.69%', '61.80%', '68.12%', '54.61%']\n",
      "        Average fitness: 62.19% Â± 4.89%\n",
      "        Best fold: Fold 4 with 68.12%\n",
      "      Fitness obtained: 62.19% | Best in generation: 66.55% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 81b039f8)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 81b039f8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7272, acc=49.61% (best=49.61%)\n",
      "          Fold 5 Epoch 1: loss=0.7536, acc=56.56% (best=56.56%)\n",
      "          Fold 4 Epoch 1: loss=0.7175, acc=39.22% (best=39.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7315, acc=56.80% (best=56.80%)\n",
      "          Fold 3 Epoch 1: loss=0.7415, acc=56.88% (best=56.88%)\n",
      "          Fold 2 Epoch 5: loss=0.5329, acc=43.36% (best=58.28%)\n",
      "          Fold 5 Epoch 5: loss=0.6067, acc=49.38% (best=63.20%)\n",
      "          Fold 4 Epoch 5: loss=0.4204, acc=57.34% (best=67.58%)\n",
      "          Fold 1 Epoch 5: loss=0.4088, acc=48.75% (best=57.19%)\n",
      "          Fold 3 Epoch 5: loss=0.4493, acc=50.08% (best=56.88%)\n",
      "          Fold 2 Epoch 10: loss=0.3028, acc=47.11% (best=58.28%)\n",
      "          Fold 5 Epoch 10: loss=0.3154, acc=44.92% (best=63.20%)\n",
      "          Fold 4 Epoch 10: loss=0.2813, acc=46.88% (best=67.58%)\n",
      "          Fold 1 Epoch 10: loss=0.2762, acc=59.45% (best=59.45%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 3 Epoch 10: loss=0.2992, acc=57.34% (best=63.28%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 58.28%\n",
      "          Fold 1 Epoch 15: loss=0.2482, acc=62.27% (best=62.27%)\n",
      "          Fold 3 Epoch 15: loss=0.2687, acc=56.09% (best=63.91%)\n",
      "          Fold 1 Epoch 20: loss=0.2290, acc=57.66% (best=62.27%)\n",
      "          Fold 3 Epoch 20: loss=0.2407, acc=56.02% (best=63.91%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 63.91%\n",
      "          Fold 1 Epoch 25: loss=0.2118, acc=58.12% (best=62.27%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 62.27%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 81b039f8:\n",
      "        Fold accuracies: ['62.27%', '58.28%', '63.91%', '67.58%', '63.20%']\n",
      "        Average fitness: 63.05% Â± 2.99%\n",
      "        Best fold: Fold 4 with 67.58%\n",
      "      Fitness obtained: 63.05% | Best in generation: 66.55% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 772f589d)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 772f589d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7072, acc=60.62% (best=60.62%)\n",
      "          Fold 4 Epoch 1: loss=0.6572, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 1: loss=0.6830, acc=49.92% (best=49.92%)\n",
      "          Fold 2 Epoch 1: loss=0.6779, acc=58.67% (best=58.67%)\n",
      "          Fold 3 Epoch 1: loss=0.6783, acc=50.23% (best=50.23%)\n",
      "          Fold 5 Epoch 5: loss=0.4457, acc=46.33% (best=60.62%)\n",
      "          Fold 4 Epoch 5: loss=0.4406, acc=54.92% (best=61.25%)\n",
      "          Fold 1 Epoch 5: loss=0.4736, acc=51.25% (best=56.33%)\n",
      "          Fold 2 Epoch 5: loss=0.3817, acc=60.16% (best=64.06%)\n",
      "          Fold 3 Epoch 5: loss=0.4113, acc=51.72% (best=55.39%)\n",
      "          Fold 5 Epoch 10: loss=0.3063, acc=66.56% (best=70.86%)\n",
      "          Fold 4 Epoch 10: loss=0.2986, acc=47.27% (best=61.95%)\n",
      "          Fold 1 Epoch 10: loss=0.3206, acc=62.97% (best=62.97%)\n",
      "          Fold 2 Epoch 10: loss=0.2978, acc=55.62% (best=64.06%)\n",
      "          Fold 3 Epoch 10: loss=0.3356, acc=57.19% (best=57.19%)\n",
      "          Fold 5 Epoch 15: loss=0.2720, acc=40.62% (best=70.86%)\n",
      "          Fold 4 Epoch 15: loss=0.2701, acc=55.08% (best=61.95%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 64.06%\n",
      "          Fold 1 Epoch 15: loss=0.2782, acc=53.59% (best=62.97%)\n",
      "          Fold 5: Early stopping at epoch 18\n",
      "      â†’ Fold 5 completed: 70.86%\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 61.95%\n",
      "          Fold 3 Epoch 15: loss=0.2792, acc=51.33% (best=69.14%)\n",
      "          Fold 1 Epoch 20: loss=0.2582, acc=53.36% (best=66.95%)\n",
      "          Fold 3 Epoch 20: loss=0.2598, acc=49.22% (best=69.14%)\n",
      "          Fold 1 Epoch 25: loss=0.2375, acc=57.81% (best=66.95%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 69.14%\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 66.95%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 772f589d:\n",
      "        Fold accuracies: ['66.95%', '64.06%', '69.14%', '61.95%', '70.86%']\n",
      "        Average fitness: 66.59% Â± 3.25%\n",
      "        Best fold: Fold 5 with 70.86%\n",
      "      New best fitness in this generation: 66.59%!\n",
      "      Fitness obtained: 66.59% | Best in generation: 66.59% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: c4c51d48)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=5e-05\n",
      "      Training/Evaluating model c4c51d48 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6917, acc=65.94% (best=65.94%)\n",
      "          Fold 1 Epoch 1: loss=0.6875, acc=47.42% (best=47.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7125, acc=60.62% (best=60.62%)\n",
      "          Fold 2 Epoch 1: loss=0.6779, acc=48.83% (best=48.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6705, acc=48.12% (best=48.12%)\n",
      "          Fold 3 Epoch 5: loss=0.4578, acc=56.80% (best=65.94%)\n",
      "          Fold 1 Epoch 5: loss=0.4744, acc=53.44% (best=56.64%)\n",
      "          Fold 5 Epoch 5: loss=0.5877, acc=47.03% (best=60.62%)\n",
      "          Fold 2 Epoch 5: loss=0.4509, acc=43.98% (best=48.83%)\n",
      "          Fold 4 Epoch 5: loss=0.4606, acc=49.22% (best=52.27%)\n",
      "          Fold 3 Epoch 10: loss=0.3300, acc=57.58% (best=65.94%)\n",
      "          Fold 1 Epoch 10: loss=0.3395, acc=48.44% (best=56.64%)\n",
      "          Fold 5 Epoch 10: loss=0.3626, acc=57.58% (best=60.62%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 65.94%\n",
      "          Fold 4 Epoch 10: loss=0.3161, acc=54.53% (best=54.53%)\n",
      "          Fold 2 Epoch 10: loss=0.2991, acc=50.62% (best=54.77%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 1 Epoch 15: loss=0.2739, acc=57.97% (best=57.97%)\n",
      "          Fold 4 Epoch 15: loss=0.2514, acc=48.91% (best=54.53%)\n",
      "          Fold 2 Epoch 15: loss=0.2606, acc=50.08% (best=54.77%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 54.77%\n",
      "          Fold 1 Epoch 20: loss=0.2439, acc=56.02% (best=57.97%)\n",
      "          Fold 4 Epoch 20: loss=0.2265, acc=47.27% (best=57.89%)\n",
      "          Fold 1 Epoch 25: loss=0.2245, acc=47.27% (best=57.97%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 57.97%\n",
      "          Fold 4 Epoch 25: loss=0.2137, acc=46.88% (best=57.89%)\n",
      "          Fold 4: Early stopping at epoch 27\n",
      "      â†’ Fold 4 completed: 57.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c4c51d48:\n",
      "        Fold accuracies: ['57.97%', '54.77%', '65.94%', '57.89%', '60.62%']\n",
      "        Average fitness: 59.44% Â± 3.74%\n",
      "        Best fold: Fold 3 with 65.94%\n",
      "      Fitness obtained: 59.44% | Best in generation: 66.59% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: fa11dcfd)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model fa11dcfd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "      ERROR in Fold 1: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 29, in _train_one_fold\n",
      "    loss.backward()\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7317, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7177, acc=64.22% (best=64.22%)\n",
      "          Fold 2 Epoch 5: loss=0.6720, acc=53.28% (best=53.28%)\n",
      "          Fold 4 Epoch 5: loss=0.5551, acc=46.41% (best=64.22%)\n",
      "          Fold 2 Epoch 10: loss=0.3736, acc=40.47% (best=60.16%)\n",
      "          Fold 4 Epoch 10: loss=0.2843, acc=56.72% (best=64.22%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 64.22%\n",
      "          Fold 2 Epoch 15: loss=0.2996, acc=47.58% (best=60.16%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 60.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fa11dcfd:\n",
      "        Fold accuracies: ['0.00%', '60.16%', '0.00%', '64.22%', '0.00%']\n",
      "        Average fitness: 24.88% Â± 30.49%\n",
      "        Best fold: Fold 4 with 64.22%\n",
      "      Fitness obtained: 24.88% | Best in generation: 66.59% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 9bc2c0f8)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.1\n",
      "      Training/Evaluating model 9bc2c0f8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=6.3998, acc=46.17% (best=46.17%)\n",
      "          Fold 4 Epoch 1: loss=5.3718, acc=56.95% (best=56.95%)\n",
      "          Fold 5 Epoch 1: loss=5.6842, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 1: loss=7.9983, acc=51.02% (best=51.02%)\n",
      "          Fold 2 Epoch 1: loss=7.8028, acc=49.14% (best=49.14%)\n",
      "          Fold 1 Epoch 5: loss=0.6958, acc=59.30% (best=59.30%)\n",
      "          Fold 4 Epoch 5: loss=0.6741, acc=64.77% (best=64.77%)\n",
      "          Fold 5 Epoch 5: loss=0.6972, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 5: loss=0.6773, acc=55.86% (best=55.86%)\n",
      "          Fold 2 Epoch 5: loss=0.6796, acc=50.78% (best=50.78%)\n",
      "          Fold 1 Epoch 10: loss=0.8151, acc=46.25% (best=59.30%)\n",
      "          Fold 4 Epoch 10: loss=0.6766, acc=65.94% (best=65.94%)\n",
      "          Fold 5 Epoch 10: loss=0.6973, acc=50.00% (best=50.00%)\n",
      "          Fold 3 Epoch 10: loss=0.8410, acc=48.98% (best=66.17%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 50.00%\n",
      "          Fold 2 Epoch 10: loss=0.6867, acc=49.61% (best=50.78%)\n",
      "          Fold 1 Epoch 15: loss=0.6869, acc=50.23% (best=62.27%)\n",
      "          Fold 4 Epoch 15: loss=0.6950, acc=50.78% (best=73.12%)\n",
      "          Fold 3 Epoch 15: loss=0.7100, acc=48.98% (best=66.17%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 66.17%\n",
      "          Fold 2 Epoch 15: loss=1.1394, acc=50.39% (best=50.78%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 50.78%\n",
      "          Fold 1 Epoch 20: loss=0.6828, acc=65.08% (best=65.08%)\n",
      "          Fold 4 Epoch 20: loss=0.9237, acc=51.80% (best=73.12%)\n",
      "          Fold 4: Early stopping at epoch 22\n",
      "      â†’ Fold 4 completed: 73.12%\n",
      "          Fold 1 Epoch 25: loss=0.6976, acc=50.23% (best=65.08%)\n",
      "          Fold 1 Epoch 30: loss=0.6963, acc=50.23% (best=65.08%)\n",
      "          Fold 1: Early stopping at epoch 30\n",
      "      â†’ Fold 1 completed: 65.08%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9bc2c0f8:\n",
      "        Fold accuracies: ['65.08%', '50.78%', '66.17%', '73.12%', '50.00%']\n",
      "        Average fitness: 61.03% Â± 9.12%\n",
      "        Best fold: Fold 4 with 73.12%\n",
      "      Fitness obtained: 61.03% | Best in generation: 66.59% | Global best: 70.92%\n",
      "\n",
      "GENERATION 22 STATISTICS:\n",
      "   Maximum fitness: 66.59%\n",
      "   Average fitness: 57.89%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 15.82%\n",
      "   Best individual: 772f589d with 66.59%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 16/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=15.82)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 772f589d (fitness: 66.59%)\n",
      "   Elite 2: 57ce2930 (fitness: 66.55%)\n",
      "   Elite 3: 9cdbf789 (fitness: 66.41%)\n",
      "   Elite 4: dc0bb8b4 (fitness: 65.23%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 17/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 23\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 23)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 772f589d)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 772f589d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7138, acc=54.69% (best=54.69%)\n",
      "          Fold 2 Epoch 1: loss=0.6775, acc=51.95% (best=51.95%)\n",
      "          Fold 3 Epoch 1: loss=0.6891, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.6612, acc=51.56% (best=51.56%)\n",
      "          Fold 1 Epoch 1: loss=0.6912, acc=42.42% (best=42.42%)\n",
      "          Fold 2 Epoch 5: loss=0.3868, acc=47.27% (best=60.78%)\n",
      "          Fold 5 Epoch 5: loss=0.4738, acc=57.34% (best=57.34%)\n",
      "          Fold 3 Epoch 5: loss=0.4156, acc=51.48% (best=54.77%)\n",
      "          Fold 4 Epoch 5: loss=0.4308, acc=52.19% (best=69.61%)\n",
      "          Fold 1 Epoch 5: loss=0.4822, acc=61.09% (best=61.09%)\n",
      "          Fold 2 Epoch 10: loss=0.2962, acc=50.23% (best=60.78%)\n",
      "          Fold 5 Epoch 10: loss=0.3139, acc=49.22% (best=59.69%)\n",
      "          Fold 3 Epoch 10: loss=0.3310, acc=56.80% (best=61.17%)\n",
      "          Fold 4 Epoch 10: loss=0.2927, acc=56.41% (best=69.61%)\n",
      "          Fold 1 Epoch 10: loss=0.3373, acc=65.16% (best=65.16%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 69.61%\n",
      "          Fold 2 Epoch 15: loss=0.2680, acc=50.55% (best=61.56%)\n",
      "          Fold 5 Epoch 15: loss=0.2680, acc=51.88% (best=59.69%)\n",
      "          Fold 3 Epoch 15: loss=0.2783, acc=61.48% (best=61.48%)\n",
      "          Fold 1 Epoch 15: loss=0.2879, acc=58.44% (best=65.16%)\n",
      "          Fold 5: Early stopping at epoch 19\n",
      "      â†’ Fold 5 completed: 59.69%\n",
      "          Fold 2 Epoch 20: loss=0.2446, acc=63.67% (best=63.67%)\n",
      "          Fold 3 Epoch 20: loss=0.2524, acc=57.81% (best=61.48%)\n",
      "          Fold 1 Epoch 20: loss=0.2587, acc=49.22% (best=65.16%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 65.16%\n",
      "          Fold 2 Epoch 25: loss=0.2334, acc=49.30% (best=63.67%)\n",
      "          Fold 3 Epoch 25: loss=0.2391, acc=52.81% (best=61.48%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 61.48%\n",
      "          Fold 2 Epoch 30: loss=0.2273, acc=46.25% (best=63.67%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 63.67%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 772f589d:\n",
      "        Fold accuracies: ['65.16%', '63.67%', '61.48%', '69.61%', '59.69%']\n",
      "        Average fitness: 63.92% Â± 3.40%\n",
      "        Best fold: Fold 4 with 69.61%\n",
      "      New best fitness in this generation: 63.92%!\n",
      "      Fitness obtained: 63.92% | Best in generation: 63.92% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 57ce2930)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 57ce2930 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7207, acc=54.53% (best=54.53%)\n",
      "          Fold 2 Epoch 1: loss=0.7114, acc=49.30% (best=49.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6931, acc=63.36% (best=63.36%)\n",
      "          Fold 5 Epoch 1: loss=0.7492, acc=47.03% (best=47.03%)\n",
      "          Fold 3 Epoch 1: loss=0.7275, acc=72.50% (best=72.50%)\n",
      "          Fold 2 Epoch 5: loss=0.4038, acc=43.91% (best=51.80%)\n",
      "          Fold 1 Epoch 5: loss=0.5007, acc=56.33% (best=61.72%)\n",
      "          Fold 4 Epoch 5: loss=0.4601, acc=52.42% (best=63.98%)\n",
      "          Fold 5 Epoch 5: loss=0.4972, acc=50.55% (best=57.11%)\n",
      "          Fold 3 Epoch 5: loss=0.4520, acc=55.16% (best=72.50%)\n",
      "          Fold 2 Epoch 10: loss=0.3052, acc=48.83% (best=51.80%)\n",
      "          Fold 1 Epoch 10: loss=0.3369, acc=59.45% (best=61.72%)\n",
      "          Fold 4 Epoch 10: loss=0.3201, acc=67.42% (best=67.42%)\n",
      "          Fold 5 Epoch 10: loss=0.3063, acc=50.00% (best=60.55%)\n",
      "          Fold 3 Epoch 10: loss=0.3424, acc=50.16% (best=72.50%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 72.50%\n",
      "          Fold 2 Epoch 15: loss=0.2641, acc=65.39% (best=65.39%)\n",
      "          Fold 1 Epoch 15: loss=0.2628, acc=65.00% (best=68.52%)\n",
      "          Fold 4 Epoch 15: loss=0.2622, acc=42.73% (best=67.42%)\n",
      "          Fold 5 Epoch 15: loss=0.2668, acc=59.45% (best=60.55%)\n",
      "          Fold 5: Early stopping at epoch 16\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 2 Epoch 20: loss=0.2427, acc=56.95% (best=65.39%)\n",
      "          Fold 1 Epoch 20: loss=0.2495, acc=57.11% (best=68.52%)\n",
      "          Fold 4 Epoch 20: loss=0.2462, acc=51.09% (best=67.42%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 67.42%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 68.52%\n",
      "          Fold 2 Epoch 25: loss=0.2276, acc=54.69% (best=65.39%)\n",
      "          Fold 2: Early stopping at epoch 25\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 57ce2930:\n",
      "        Fold accuracies: ['68.52%', '65.39%', '72.50%', '67.42%', '60.55%']\n",
      "        Average fitness: 66.88% Â± 3.92%\n",
      "        Best fold: Fold 3 with 72.50%\n",
      "      New best fitness in this generation: 66.88%!\n",
      "      Fitness obtained: 66.88% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: 9cdbf789)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9cdbf789 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6823, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6906, acc=47.66% (best=47.66%)\n",
      "          Fold 4 Epoch 1: loss=0.6712, acc=60.31% (best=60.31%)\n",
      "          Fold 3 Epoch 1: loss=0.7005, acc=64.45% (best=64.45%)\n",
      "          Fold 5 Epoch 1: loss=0.7283, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 5: loss=0.4789, acc=52.81% (best=52.81%)\n",
      "          Fold 1 Epoch 5: loss=0.4827, acc=56.41% (best=56.41%)\n",
      "          Fold 4 Epoch 5: loss=0.4476, acc=59.30% (best=67.58%)\n",
      "          Fold 3 Epoch 5: loss=0.4248, acc=60.00% (best=64.45%)\n",
      "          Fold 5 Epoch 5: loss=0.6882, acc=56.41% (best=56.48%)\n",
      "          Fold 2 Epoch 10: loss=0.3369, acc=61.02% (best=61.02%)\n",
      "          Fold 1 Epoch 10: loss=0.3335, acc=60.23% (best=60.23%)\n",
      "          Fold 4 Epoch 10: loss=0.3022, acc=63.05% (best=67.58%)\n",
      "          Fold 3 Epoch 10: loss=0.3106, acc=54.77% (best=64.45%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 64.45%\n",
      "          Fold 5 Epoch 10: loss=0.3982, acc=56.41% (best=56.48%)\n",
      "          Fold 2 Epoch 15: loss=0.2843, acc=46.72% (best=61.02%)\n",
      "          Fold 1 Epoch 15: loss=0.2643, acc=61.02% (best=61.02%)\n",
      "          Fold 4 Epoch 15: loss=0.2555, acc=71.02% (best=71.02%)\n",
      "          Fold 5 Epoch 15: loss=0.3077, acc=52.89% (best=63.20%)\n",
      "          Fold 2 Epoch 20: loss=0.2586, acc=61.72% (best=61.72%)\n",
      "          Fold 1 Epoch 20: loss=0.2433, acc=54.77% (best=61.64%)\n",
      "          Fold 4 Epoch 20: loss=0.2371, acc=63.59% (best=71.02%)\n",
      "          Fold 5 Epoch 20: loss=0.2749, acc=47.58% (best=63.20%)\n",
      "          Fold 2 Epoch 25: loss=0.2480, acc=50.78% (best=61.72%)\n",
      "          Fold 1 Epoch 25: loss=0.2228, acc=54.53% (best=62.03%)\n",
      "          Fold 4 Epoch 25: loss=0.2261, acc=58.75% (best=71.02%)\n",
      "          Fold 4: Early stopping at epoch 25\n",
      "      â†’ Fold 4 completed: 71.02%\n",
      "          Fold 5: Early stopping at epoch 24\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 2 Epoch 30: loss=0.2351, acc=56.56% (best=61.72%)\n",
      "          Fold 2: Early stopping at epoch 30\n",
      "      â†’ Fold 2 completed: 61.72%\n",
      "          Fold 1 Epoch 30: loss=0.2208, acc=56.33% (best=62.03%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 62.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9cdbf789:\n",
      "        Fold accuracies: ['62.03%', '61.72%', '64.45%', '71.02%', '63.20%']\n",
      "        Average fitness: 64.48% Â± 3.40%\n",
      "        Best fold: Fold 4 with 71.02%\n",
      "      Fitness obtained: 64.48% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: dc0bb8b4)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model dc0bb8b4 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7121, acc=47.58% (best=47.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6846, acc=67.34% (best=67.34%)\n",
      "          Fold 5 Epoch 1: loss=0.7433, acc=47.19% (best=47.19%)\n",
      "          Fold 1 Epoch 1: loss=0.7198, acc=56.64% (best=56.64%)\n",
      "          Fold 3 Epoch 1: loss=0.7440, acc=56.56% (best=56.56%)\n",
      "          Fold 2 Epoch 5: loss=0.3608, acc=53.20% (best=57.42%)\n",
      "          Fold 5 Epoch 5: loss=0.3553, acc=52.03% (best=52.50%)\n",
      "          Fold 4 Epoch 5: loss=0.3661, acc=54.06% (best=67.34%)\n",
      "          Fold 1 Epoch 5: loss=0.3762, acc=50.31% (best=56.64%)\n",
      "          Fold 3 Epoch 5: loss=0.3361, acc=61.09% (best=70.16%)\n",
      "          Fold 2 Epoch 10: loss=0.2698, acc=50.47% (best=60.78%)\n",
      "          Fold 5 Epoch 10: loss=0.2612, acc=49.61% (best=53.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2812, acc=53.98% (best=67.34%)\n",
      "          Fold 1 Epoch 10: loss=0.2803, acc=55.08% (best=63.59%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.34%\n",
      "          Fold 3 Epoch 10: loss=0.2696, acc=60.86% (best=70.16%)\n",
      "          Fold 2 Epoch 15: loss=0.2406, acc=48.52% (best=60.78%)\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 70.16%\n",
      "          Fold 5 Epoch 15: loss=0.2459, acc=37.58% (best=53.44%)\n",
      "          Fold 1 Epoch 15: loss=0.2485, acc=54.84% (best=64.53%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 53.44%\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 60.78%\n",
      "          Fold 1 Epoch 20: loss=0.2310, acc=58.20% (best=65.00%)\n",
      "          Fold 1 Epoch 25: loss=0.2183, acc=54.61% (best=65.00%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 65.00%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for dc0bb8b4:\n",
      "        Fold accuracies: ['65.00%', '60.78%', '70.16%', '67.34%', '53.44%']\n",
      "        Average fitness: 63.34% Â± 5.83%\n",
      "        Best fold: Fold 3 with 70.16%\n",
      "      Fitness obtained: 63.34% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: 874c299f)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 874c299f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7025, acc=50.62% (best=50.62%)\n",
      "          Fold 4 Epoch 1: loss=0.6796, acc=60.23% (best=60.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6862, acc=40.55% (best=40.55%)\n",
      "          Fold 1 Epoch 1: loss=0.6931, acc=52.50% (best=52.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7091, acc=50.16% (best=50.16%)\n",
      "          Fold 3 Epoch 5: loss=0.3840, acc=55.62% (best=55.62%)\n",
      "          Fold 4 Epoch 5: loss=0.4503, acc=45.78% (best=60.62%)\n",
      "          Fold 1 Epoch 5: loss=0.3779, acc=47.97% (best=56.64%)\n",
      "          Fold 5 Epoch 5: loss=0.4247, acc=61.64% (best=61.64%)\n",
      "          Fold 2 Epoch 5: loss=0.3954, acc=53.67% (best=53.67%)\n",
      "          Fold 3 Epoch 10: loss=0.2844, acc=51.41% (best=57.03%)\n",
      "          Fold 4 Epoch 10: loss=0.3224, acc=62.11% (best=63.28%)\n",
      "          Fold 1 Epoch 10: loss=0.2758, acc=57.19% (best=59.69%)\n",
      "          Fold 5 Epoch 10: loss=0.2629, acc=49.69% (best=61.64%)\n",
      "          Fold 2 Epoch 10: loss=0.2844, acc=46.25% (best=53.67%)\n",
      "          Fold 3 Epoch 15: loss=0.2524, acc=55.08% (best=59.77%)\n",
      "          Fold 4 Epoch 15: loss=0.2752, acc=57.42% (best=64.14%)\n",
      "          Fold 1 Epoch 15: loss=0.2541, acc=52.58% (best=59.69%)\n",
      "          Fold 5 Epoch 15: loss=0.2421, acc=44.69% (best=61.64%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 61.64%\n",
      "          Fold 2 Epoch 15: loss=0.2518, acc=44.22% (best=59.69%)\n",
      "          Fold 3 Epoch 20: loss=0.2367, acc=56.41% (best=65.08%)\n",
      "          Fold 4 Epoch 20: loss=0.2463, acc=53.28% (best=64.14%)\n",
      "          Fold 1 Epoch 20: loss=0.2386, acc=54.45% (best=60.86%)\n",
      "          Fold 2 Epoch 20: loss=0.2327, acc=48.59% (best=59.69%)\n",
      "          Fold 4: Early stopping at epoch 24\n",
      "      â†’ Fold 4 completed: 64.14%\n",
      "          Fold 3 Epoch 25: loss=0.2271, acc=44.69% (best=65.08%)\n",
      "          Fold 1 Epoch 25: loss=0.2259, acc=52.89% (best=60.86%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 65.08%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 60.86%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 874c299f:\n",
      "        Fold accuracies: ['60.86%', '59.69%', '65.08%', '64.14%', '61.64%']\n",
      "        Average fitness: 62.28% Â± 2.02%\n",
      "        Best fold: Fold 3 with 65.08%\n",
      "      Fitness obtained: 62.28% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: a0f0e284)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model a0f0e284 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7338, acc=50.47% (best=50.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7465, acc=51.02% (best=51.02%)\n",
      "          Fold 5 Epoch 1: loss=0.7512, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7258, acc=50.39% (best=50.39%)\n",
      "          Fold 4 Epoch 1: loss=0.7143, acc=58.44% (best=58.44%)\n",
      "          Fold 1 Epoch 5: loss=0.6407, acc=47.19% (best=50.47%)\n",
      "          Fold 3 Epoch 5: loss=0.5225, acc=49.30% (best=59.38%)\n",
      "          Fold 5 Epoch 5: loss=0.6774, acc=47.50% (best=54.77%)\n",
      "          Fold 2 Epoch 5: loss=0.5782, acc=44.38% (best=50.39%)\n",
      "          Fold 4 Epoch 5: loss=0.5011, acc=49.61% (best=58.98%)\n",
      "          Fold 1 Epoch 10: loss=0.4001, acc=54.30% (best=54.30%)\n",
      "          Fold 3 Epoch 10: loss=0.3791, acc=48.36% (best=59.38%)\n",
      "          Fold 5 Epoch 10: loss=0.4039, acc=47.81% (best=54.77%)\n",
      "          Fold 2 Epoch 10: loss=0.3893, acc=52.66% (best=52.66%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 59.38%\n",
      "          Fold 4 Epoch 10: loss=0.3348, acc=49.77% (best=63.20%)\n",
      "          Fold 1 Epoch 15: loss=0.3243, acc=54.22% (best=60.70%)\n",
      "          Fold 5 Epoch 15: loss=0.3304, acc=49.22% (best=55.62%)\n",
      "          Fold 2 Epoch 15: loss=0.3310, acc=44.14% (best=52.66%)\n",
      "          Fold 4 Epoch 15: loss=0.2721, acc=59.77% (best=63.20%)\n",
      "          Fold 1 Epoch 20: loss=0.2798, acc=58.52% (best=60.70%)\n",
      "          Fold 5 Epoch 20: loss=0.2982, acc=42.58% (best=60.08%)\n",
      "          Fold 2 Epoch 20: loss=0.2966, acc=53.52% (best=59.69%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 63.20%\n",
      "          Fold 1 Epoch 25: loss=0.2631, acc=55.94% (best=61.95%)\n",
      "          Fold 2 Epoch 25: loss=0.2776, acc=50.31% (best=59.69%)\n",
      "          Fold 5 Epoch 25: loss=0.2739, acc=44.53% (best=60.08%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 59.69%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 60.08%\n",
      "          Fold 1 Epoch 30: loss=0.2412, acc=60.23% (best=66.33%)\n",
      "          Fold 1 Epoch 35: loss=0.2362, acc=54.45% (best=66.33%)\n",
      "          Fold 1: Early stopping at epoch 39\n",
      "      â†’ Fold 1 completed: 66.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for a0f0e284:\n",
      "        Fold accuracies: ['66.33%', '59.69%', '59.38%', '63.20%', '60.08%']\n",
      "        Average fitness: 61.73% Â± 2.67%\n",
      "        Best fold: Fold 1 with 66.33%\n",
      "      Fitness obtained: 61.73% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: eea91401)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eea91401 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7287, acc=50.55% (best=50.55%)\n",
      "          Fold 2 Epoch 1: loss=0.7115, acc=50.39% (best=50.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7263, acc=46.80% (best=46.80%)\n",
      "          Fold 4 Epoch 1: loss=0.6939, acc=49.22% (best=49.22%)\n",
      "          Fold 5 Epoch 1: loss=0.7335, acc=58.28% (best=58.28%)\n",
      "          Fold 3 Epoch 5: loss=0.4490, acc=51.17% (best=57.89%)\n",
      "          Fold 2 Epoch 5: loss=0.4771, acc=46.02% (best=50.39%)\n",
      "          Fold 1 Epoch 5: loss=0.5694, acc=48.98% (best=55.94%)\n",
      "          Fold 5 Epoch 5: loss=0.6306, acc=51.25% (best=58.28%)\n",
      "          Fold 4 Epoch 5: loss=0.5213, acc=60.55% (best=60.55%)\n",
      "          Fold 3 Epoch 10: loss=0.3502, acc=59.14% (best=59.14%)\n",
      "          Fold 2 Epoch 10: loss=0.3319, acc=57.73% (best=57.73%)\n",
      "          Fold 1 Epoch 10: loss=0.3361, acc=52.89% (best=63.91%)\n",
      "          Fold 5 Epoch 10: loss=0.4078, acc=53.44% (best=60.94%)\n",
      "          Fold 4 Epoch 10: loss=0.3758, acc=55.86% (best=61.88%)\n",
      "          Fold 3 Epoch 15: loss=0.3080, acc=52.03% (best=59.14%)\n",
      "          Fold 2 Epoch 15: loss=0.2877, acc=61.95% (best=61.95%)\n",
      "          Fold 1 Epoch 15: loss=0.2845, acc=49.69% (best=64.77%)\n",
      "          Fold 5 Epoch 15: loss=0.3163, acc=59.14% (best=62.11%)\n",
      "          Fold 4 Epoch 15: loss=0.3070, acc=59.14% (best=61.88%)\n",
      "          Fold 3 Epoch 20: loss=0.2830, acc=56.25% (best=60.78%)\n",
      "          Fold 2 Epoch 20: loss=0.2616, acc=55.86% (best=62.58%)\n",
      "          Fold 1 Epoch 20: loss=0.2640, acc=60.08% (best=64.77%)\n",
      "          Fold 5 Epoch 20: loss=0.2793, acc=60.55% (best=64.14%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 61.88%\n",
      "          Fold 3 Epoch 25: loss=0.2574, acc=56.25% (best=60.78%)\n",
      "          Fold 2 Epoch 25: loss=0.2525, acc=58.75% (best=62.58%)\n",
      "          Fold 2: Early stopping at epoch 26\n",
      "      â†’ Fold 2 completed: 62.58%\n",
      "          Fold 1 Epoch 25: loss=0.2415, acc=58.59% (best=67.66%)\n",
      "          Fold 5 Epoch 25: loss=0.2578, acc=63.12% (best=67.27%)\n",
      "          Fold 3: Early stopping at epoch 29\n",
      "      â†’ Fold 3 completed: 60.78%\n",
      "          Fold 1 Epoch 30: loss=0.2296, acc=59.22% (best=67.66%)\n",
      "          Fold 5 Epoch 30: loss=0.2498, acc=52.19% (best=67.27%)\n",
      "          Fold 1 Epoch 35: loss=0.2254, acc=65.78% (best=69.92%)\n",
      "          Fold 5: Early stopping at epoch 34\n",
      "      â†’ Fold 5 completed: 67.27%\n",
      "          Fold 1 Epoch 40: loss=0.2249, acc=71.48% (best=71.48%)\n",
      "          Fold 1 Epoch 45: loss=0.2215, acc=67.34% (best=71.48%)\n",
      "          Fold 1 Epoch 50: loss=0.2140, acc=60.47% (best=71.48%)\n",
      "          Fold 1: Early stopping at epoch 50\n",
      "      â†’ Fold 1 completed: 71.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eea91401:\n",
      "        Fold accuracies: ['71.48%', '62.58%', '60.78%', '61.88%', '67.27%']\n",
      "        Average fitness: 64.80% Â± 4.01%\n",
      "        Best fold: Fold 1 with 71.48%\n",
      "      Fitness obtained: 64.80% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: eaec9ccd)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eaec9ccd with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6794, acc=57.66% (best=57.66%)\n",
      "          Fold 2 Epoch 1: loss=0.6944, acc=41.48% (best=41.48%)\n",
      "          Fold 1 Epoch 1: loss=0.7045, acc=56.88% (best=56.88%)\n",
      "          Fold 3 Epoch 1: loss=0.7095, acc=58.12% (best=58.12%)\n",
      "          Fold 5 Epoch 1: loss=0.7379, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 5: loss=0.3274, acc=38.67% (best=57.42%)\n",
      "          Fold 4 Epoch 5: loss=0.3836, acc=55.23% (best=60.47%)\n",
      "          Fold 1 Epoch 5: loss=0.3592, acc=60.55% (best=60.55%)\n",
      "          Fold 3 Epoch 5: loss=0.3857, acc=57.34% (best=58.12%)\n",
      "          Fold 5 Epoch 5: loss=0.4119, acc=55.31% (best=57.03%)\n",
      "          Fold 2 Epoch 10: loss=0.2523, acc=49.06% (best=60.47%)\n",
      "          Fold 4 Epoch 10: loss=0.2528, acc=59.38% (best=60.47%)\n",
      "          Fold 1 Epoch 10: loss=0.2584, acc=47.50% (best=60.55%)\n",
      "          Fold 3 Epoch 10: loss=0.2702, acc=56.64% (best=58.12%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 60.47%\n",
      "          Fold 5 Epoch 10: loss=0.2804, acc=45.70% (best=58.52%)\n",
      "          Fold 2 Epoch 15: loss=0.2273, acc=51.95% (best=60.47%)\n",
      "          Fold 1 Epoch 15: loss=0.2286, acc=60.62% (best=60.62%)\n",
      "          Fold 3 Epoch 15: loss=0.2367, acc=54.30% (best=60.78%)\n",
      "          Fold 5 Epoch 15: loss=0.2478, acc=52.03% (best=58.52%)\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 60.47%\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 1 Epoch 20: loss=0.2138, acc=53.59% (best=60.62%)\n",
      "          Fold 3 Epoch 20: loss=0.2326, acc=53.67% (best=60.86%)\n",
      "          Fold 1 Epoch 25: loss=0.2154, acc=48.44% (best=60.62%)\n",
      "          Fold 1: Early stopping at epoch 25\n",
      "      â†’ Fold 1 completed: 60.62%\n",
      "          Fold 3 Epoch 25: loss=0.2204, acc=65.16% (best=65.16%)\n",
      "          Fold 3 Epoch 30: loss=0.2168, acc=54.38% (best=65.16%)\n",
      "          Fold 3 Epoch 35: loss=0.2147, acc=52.42% (best=65.16%)\n",
      "          Fold 3: Early stopping at epoch 35\n",
      "      â†’ Fold 3 completed: 65.16%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eaec9ccd:\n",
      "        Fold accuracies: ['60.62%', '60.47%', '65.16%', '60.47%', '58.52%']\n",
      "        Average fitness: 61.05% Â± 2.20%\n",
      "        Best fold: Fold 3 with 65.16%\n",
      "      Fitness obtained: 61.05% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: 1e95968a)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 1e95968a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7016, acc=63.52% (best=63.52%)\n",
      "          Fold 2 Epoch 1: loss=0.6597, acc=49.84% (best=49.84%)\n",
      "          Fold 3 Epoch 1: loss=0.6886, acc=48.20% (best=48.20%)\n",
      "          Fold 4 Epoch 1: loss=0.6797, acc=71.48% (best=71.48%)\n",
      "          Fold 5 Epoch 1: loss=0.7255, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 5: loss=0.4001, acc=54.30% (best=63.52%)\n",
      "          Fold 3 Epoch 5: loss=0.4118, acc=55.47% (best=61.88%)\n",
      "          Fold 2 Epoch 5: loss=0.3940, acc=49.30% (best=52.97%)\n",
      "          Fold 4 Epoch 5: loss=0.3919, acc=65.47% (best=71.48%)\n",
      "          Fold 5 Epoch 5: loss=0.3820, acc=55.78% (best=63.20%)\n",
      "          Fold 1 Epoch 10: loss=0.2755, acc=54.45% (best=63.52%)\n",
      "          Fold 3 Epoch 10: loss=0.2890, acc=58.83% (best=65.31%)\n",
      "          Fold 2 Epoch 10: loss=0.2869, acc=56.64% (best=59.77%)\n",
      "          Fold 4 Epoch 10: loss=0.2701, acc=60.62% (best=71.48%)\n",
      "          Fold 1: Early stopping at epoch 11\n",
      "      â†’ Fold 1 completed: 63.52%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 71.48%\n",
      "          Fold 5 Epoch 10: loss=0.2659, acc=48.36% (best=63.20%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 63.20%\n",
      "          Fold 2 Epoch 15: loss=0.2569, acc=54.30% (best=59.77%)\n",
      "          Fold 3 Epoch 15: loss=0.2464, acc=49.45% (best=65.31%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 59.77%\n",
      "          Fold 3: Early stopping at epoch 18\n",
      "      â†’ Fold 3 completed: 65.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 1e95968a:\n",
      "        Fold accuracies: ['63.52%', '59.77%', '65.31%', '71.48%', '63.20%']\n",
      "        Average fitness: 64.66% Â± 3.86%\n",
      "        Best fold: Fold 4 with 71.48%\n",
      "      Fitness obtained: 64.66% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: 0710a0c5)\n",
      "      Architecture: 12 conv + 8 fc, opt=sgd, lr=5e-05\n",
      "      Training/Evaluating model 0710a0c5 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7251, acc=39.69% (best=39.69%)\n",
      "          Fold 3 Epoch 1: loss=0.7171, acc=47.27% (best=47.27%)\n",
      "          Fold 1 Epoch 1: loss=0.7265, acc=46.25% (best=46.25%)\n",
      "          Fold 4 Epoch 1: loss=0.7331, acc=50.16% (best=50.16%)\n",
      "          Fold 5 Epoch 1: loss=0.7240, acc=45.55% (best=45.55%)\n",
      "          Fold 2 Epoch 5: loss=0.7135, acc=48.28% (best=61.48%)\n",
      "          Fold 1 Epoch 5: loss=0.7197, acc=45.86% (best=55.16%)\n",
      "          Fold 3 Epoch 5: loss=0.7193, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 5: loss=0.7233, acc=51.02% (best=53.05%)\n",
      "          Fold 5 Epoch 5: loss=0.7238, acc=49.92% (best=53.05%)\n",
      "          Fold 2 Epoch 10: loss=0.7182, acc=53.05% (best=61.48%)\n",
      "          Fold 1 Epoch 10: loss=0.7221, acc=42.89% (best=57.11%)\n",
      "          Fold 3 Epoch 10: loss=0.7182, acc=45.70% (best=53.67%)\n",
      "          Fold 4 Epoch 10: loss=0.7162, acc=50.78% (best=53.12%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 61.48%\n",
      "          Fold 5 Epoch 10: loss=0.7201, acc=50.00% (best=53.05%)\n",
      "          Fold 1 Epoch 15: loss=0.7214, acc=50.86% (best=57.11%)\n",
      "          Fold 3 Epoch 15: loss=0.7171, acc=49.45% (best=54.53%)\n",
      "          Fold 4 Epoch 15: loss=0.7168, acc=47.81% (best=53.12%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 53.05%\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 53.12%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 57.11%\n",
      "          Fold 3 Epoch 20: loss=0.7165, acc=56.88% (best=56.88%)\n",
      "          Fold 3 Epoch 25: loss=0.7123, acc=55.70% (best=56.88%)\n",
      "          Fold 3 Epoch 30: loss=0.7158, acc=50.94% (best=57.89%)\n",
      "          Fold 3 Epoch 35: loss=0.7109, acc=55.39% (best=58.12%)\n",
      "          Fold 3 Epoch 40: loss=0.7186, acc=56.48% (best=58.12%)\n",
      "          Fold 3: Early stopping at epoch 44\n",
      "      â†’ Fold 3 completed: 58.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0710a0c5:\n",
      "        Fold accuracies: ['57.11%', '61.48%', '58.12%', '53.12%', '53.05%']\n",
      "        Average fitness: 56.58% Â± 3.20%\n",
      "        Best fold: Fold 2 with 61.48%\n",
      "      Fitness obtained: 56.58% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 9f78dcb6)\n",
      "      Architecture: 25 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 9f78dcb6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9f78dcb6:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: 76708c7f)\n",
      "      Architecture: 15 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 76708c7f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 244, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "      ERROR in Fold 4: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "      ERROR in Fold 1: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "      ERROR in Fold 3: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "      ERROR in Fold 5: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2815, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2781, in _verify_batch_size\n",
      "    raise ValueError(\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 197, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 76708c7f:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 4 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: f01d5454)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f01d5454 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6583, acc=58.36% (best=58.36%)\n",
      "          Fold 2 Epoch 1: loss=0.6711, acc=40.16% (best=40.16%)\n",
      "          Fold 1 Epoch 1: loss=0.6905, acc=60.31% (best=60.31%)\n",
      "          Fold 3 Epoch 1: loss=0.6847, acc=51.88% (best=51.88%)\n",
      "          Fold 5 Epoch 1: loss=0.7027, acc=60.47% (best=60.47%)\n",
      "          Fold 4 Epoch 5: loss=0.4583, acc=59.38% (best=69.84%)\n",
      "          Fold 2 Epoch 5: loss=0.3705, acc=40.16% (best=55.94%)\n",
      "          Fold 1 Epoch 5: loss=0.5388, acc=52.73% (best=60.31%)\n",
      "          Fold 3 Epoch 5: loss=0.4002, acc=56.33% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.5241, acc=49.06% (best=60.47%)\n",
      "          Fold 4 Epoch 10: loss=0.2758, acc=59.61% (best=69.84%)\n",
      "          Fold 2 Epoch 10: loss=0.2733, acc=55.47% (best=55.94%)\n",
      "          Fold 1 Epoch 10: loss=0.3105, acc=54.92% (best=63.67%)\n",
      "          Fold 3 Epoch 10: loss=0.2863, acc=60.08% (best=63.67%)\n",
      "          Fold 5 Epoch 10: loss=0.2823, acc=43.20% (best=60.47%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 69.84%\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 60.47%\n",
      "          Fold 2 Epoch 15: loss=0.2493, acc=51.56% (best=58.12%)\n",
      "          Fold 1 Epoch 15: loss=0.2518, acc=51.95% (best=63.67%)\n",
      "          Fold 3 Epoch 15: loss=0.2392, acc=52.27% (best=63.67%)\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 63.67%\n",
      "          Fold 2 Epoch 20: loss=0.2469, acc=55.39% (best=58.12%)\n",
      "          Fold 3: Early stopping at epoch 19\n",
      "      â†’ Fold 3 completed: 63.67%\n",
      "          Fold 2: Early stopping at epoch 23\n",
      "      â†’ Fold 2 completed: 58.12%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f01d5454:\n",
      "        Fold accuracies: ['63.67%', '58.12%', '63.67%', '69.84%', '60.47%']\n",
      "        Average fitness: 63.16% Â± 3.94%\n",
      "        Best fold: Fold 4 with 69.84%\n",
      "      Fitness obtained: 63.16% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 6dd343d9)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6dd343d9 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 5: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 106, in _train_fold_in_thread\n",
      "    fold_acc = self._train_one_fold(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 27, in _train_one_fold\n",
      "    output = model(data)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 173, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 371, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 366, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":1131, please report a bug to PyTorch. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Fold 2 Epoch 1: loss=0.7253, acc=49.92% (best=49.92%)\n",
      "          Fold 3 Epoch 1: loss=0.7282, acc=61.25% (best=61.25%)\n",
      "          Fold 4 Epoch 1: loss=0.7282, acc=63.75% (best=63.75%)\n",
      "          Fold 1 Epoch 1: loss=0.7366, acc=51.72% (best=51.72%)\n",
      "          Fold 2 Epoch 5: loss=0.5473, acc=47.81% (best=53.91%)\n",
      "          Fold 3 Epoch 5: loss=0.4518, acc=50.94% (best=61.25%)\n",
      "          Fold 4 Epoch 5: loss=0.4752, acc=61.25% (best=66.02%)\n",
      "          Fold 1 Epoch 5: loss=0.5293, acc=52.42% (best=55.62%)\n",
      "          Fold 2 Epoch 10: loss=0.3030, acc=44.84% (best=53.91%)\n",
      "          Fold 3 Epoch 10: loss=0.3229, acc=46.09% (best=61.56%)\n",
      "          Fold 4 Epoch 10: loss=0.3404, acc=58.20% (best=66.02%)\n",
      "          Fold 1 Epoch 10: loss=0.3412, acc=49.53% (best=61.41%)\n",
      "          Fold 2: Early stopping at epoch 13\n",
      "      â†’ Fold 2 completed: 53.91%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 66.02%\n",
      "          Fold 3 Epoch 15: loss=0.2653, acc=53.44% (best=64.53%)\n",
      "          Fold 1 Epoch 15: loss=0.2778, acc=53.75% (best=61.41%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 61.41%\n",
      "          Fold 3 Epoch 20: loss=0.2397, acc=50.31% (best=64.53%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 64.53%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6dd343d9:\n",
      "        Fold accuracies: ['61.41%', '53.91%', '64.53%', '66.02%', '0.00%']\n",
      "        Average fitness: 49.17% Â± 24.94%\n",
      "        Best fold: Fold 4 with 66.02%\n",
      "      Fitness obtained: 49.17% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: e966d26e)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e966d26e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7368, acc=48.59% (best=48.59%)\n",
      "          Fold 2 Epoch 1: loss=0.7140, acc=46.56% (best=46.56%)\n",
      "          Fold 1 Epoch 1: loss=0.7222, acc=49.14% (best=49.14%)\n",
      "          Fold 5 Epoch 1: loss=0.7365, acc=51.25% (best=51.25%)\n",
      "          Fold 4 Epoch 1: loss=0.7027, acc=58.20% (best=58.20%)\n",
      "          Fold 3 Epoch 5: loss=0.4910, acc=43.28% (best=60.78%)\n",
      "          Fold 5 Epoch 5: loss=0.4932, acc=47.50% (best=55.62%)\n",
      "          Fold 1 Epoch 5: loss=0.4981, acc=42.27% (best=58.83%)\n",
      "          Fold 2 Epoch 5: loss=0.4628, acc=49.92% (best=52.03%)\n",
      "          Fold 4 Epoch 5: loss=0.5429, acc=49.77% (best=59.38%)\n",
      "          Fold 3 Epoch 10: loss=0.3795, acc=42.89% (best=60.78%)\n",
      "          Fold 5 Epoch 10: loss=0.3657, acc=56.17% (best=56.17%)\n",
      "          Fold 1 Epoch 10: loss=0.3839, acc=54.38% (best=65.23%)\n",
      "          Fold 2 Epoch 10: loss=0.3545, acc=65.00% (best=65.00%)\n",
      "          Fold 4 Epoch 10: loss=0.3410, acc=49.84% (best=69.14%)\n",
      "          Fold 3 Epoch 15: loss=0.3378, acc=61.95% (best=61.95%)\n",
      "          Fold 5 Epoch 15: loss=0.3085, acc=50.94% (best=59.38%)\n",
      "          Fold 1 Epoch 15: loss=0.3400, acc=59.22% (best=65.23%)\n",
      "          Fold 2 Epoch 15: loss=0.3218, acc=46.25% (best=65.00%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 65.23%\n",
      "          Fold 4 Epoch 15: loss=0.2829, acc=35.47% (best=69.14%)\n",
      "          Fold 4: Early stopping at epoch 16\n",
      "      â†’ Fold 4 completed: 69.14%\n",
      "          Fold 3 Epoch 20: loss=0.3029, acc=51.33% (best=61.95%)\n",
      "          Fold 5 Epoch 20: loss=0.2758, acc=47.50% (best=62.03%)\n",
      "          Fold 2 Epoch 20: loss=0.2912, acc=52.34% (best=65.00%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 65.00%\n",
      "          Fold 3 Epoch 25: loss=0.2827, acc=58.12% (best=61.95%)\n",
      "          Fold 3: Early stopping at epoch 25\n",
      "      â†’ Fold 3 completed: 61.95%\n",
      "          Fold 5 Epoch 25: loss=0.2659, acc=50.08% (best=62.03%)\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 62.03%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e966d26e:\n",
      "        Fold accuracies: ['65.23%', '65.00%', '61.95%', '69.14%', '62.03%']\n",
      "        Average fitness: 64.67% Â± 2.64%\n",
      "        Best fold: Fold 4 with 69.14%\n",
      "      Fitness obtained: 64.67% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 15ecba8e)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 15ecba8e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6954, acc=46.95% (best=46.95%)\n",
      "          Fold 3 Epoch 1: loss=0.7135, acc=48.20% (best=48.20%)\n",
      "          Fold 5 Epoch 1: loss=0.7203, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 1: loss=0.6923, acc=58.20% (best=58.20%)\n",
      "          Fold 1 Epoch 1: loss=0.7011, acc=57.42% (best=57.42%)\n",
      "          Fold 2 Epoch 5: loss=0.6359, acc=58.75% (best=58.75%)\n",
      "          Fold 3 Epoch 5: loss=0.6274, acc=57.34% (best=57.34%)\n",
      "          Fold 5 Epoch 5: loss=0.6686, acc=52.89% (best=59.38%)\n",
      "          Fold 4 Epoch 5: loss=0.6225, acc=56.95% (best=60.62%)\n",
      "          Fold 1 Epoch 5: loss=0.6222, acc=52.89% (best=57.42%)\n",
      "          Fold 2 Epoch 10: loss=0.4517, acc=57.73% (best=59.14%)\n",
      "          Fold 3 Epoch 10: loss=0.4628, acc=46.09% (best=57.73%)\n",
      "          Fold 5 Epoch 10: loss=0.4669, acc=57.66% (best=65.62%)\n",
      "          Fold 4 Epoch 10: loss=0.4521, acc=50.94% (best=62.73%)\n",
      "          Fold 1 Epoch 10: loss=0.4518, acc=60.31% (best=60.31%)\n",
      "          Fold 2 Epoch 15: loss=0.3471, acc=50.31% (best=59.14%)\n",
      "          Fold 3 Epoch 15: loss=0.3778, acc=53.98% (best=57.73%)\n",
      "          Fold 5 Epoch 15: loss=0.3615, acc=56.88% (best=65.62%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 57.73%\n",
      "          Fold 4 Epoch 15: loss=0.3585, acc=55.55% (best=62.73%)\n",
      "          Fold 5: Early stopping at epoch 17\n",
      "      â†’ Fold 5 completed: 65.62%\n",
      "          Fold 1 Epoch 15: loss=0.3877, acc=55.86% (best=63.67%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 62.73%\n",
      "          Fold 2 Epoch 20: loss=0.2946, acc=55.47% (best=66.17%)\n",
      "          Fold 1 Epoch 20: loss=0.3223, acc=62.97% (best=75.23%)\n",
      "          Fold 2 Epoch 25: loss=0.2751, acc=59.22% (best=66.17%)\n",
      "          Fold 2: Early stopping at epoch 28\n",
      "      â†’ Fold 2 completed: 66.17%\n",
      "          Fold 1 Epoch 25: loss=0.2906, acc=59.84% (best=75.23%)\n",
      "          Fold 1: Early stopping at epoch 29\n",
      "      â†’ Fold 1 completed: 75.23%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15ecba8e:\n",
      "        Fold accuracies: ['75.23%', '66.17%', '57.73%', '62.73%', '65.62%']\n",
      "        Average fitness: 65.50% Â± 5.71%\n",
      "        Best fold: Fold 1 with 75.23%\n",
      "      Fitness obtained: 65.50% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: 8761555f)\n",
      "      Architecture: 12 conv + 3 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model 8761555f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6380, acc=41.88% (best=41.88%)\n",
      "          Fold 5 Epoch 1: loss=0.6930, acc=50.00% (best=50.00%)\n",
      "          Fold 1 Epoch 1: loss=0.6626, acc=60.16% (best=60.16%)\n",
      "          Fold 3 Epoch 1: loss=0.6581, acc=55.00% (best=55.00%)\n",
      "          Fold 2 Epoch 1: loss=0.6516, acc=53.67% (best=53.67%)\n",
      "          Fold 4 Epoch 5: loss=0.3677, acc=46.41% (best=63.52%)\n",
      "          Fold 5 Epoch 5: loss=0.3527, acc=51.02% (best=60.23%)\n",
      "          Fold 1 Epoch 5: loss=0.4034, acc=54.14% (best=60.16%)\n",
      "          Fold 3 Epoch 5: loss=0.3506, acc=51.02% (best=59.38%)\n",
      "          Fold 2 Epoch 5: loss=0.3732, acc=40.55% (best=53.67%)\n",
      "          Fold 4 Epoch 10: loss=0.2731, acc=60.55% (best=63.52%)\n",
      "          Fold 5 Epoch 10: loss=0.2665, acc=47.50% (best=60.23%)\n",
      "          Fold 1 Epoch 10: loss=0.2780, acc=65.70% (best=65.70%)\n",
      "          Fold 3 Epoch 10: loss=0.2677, acc=51.33% (best=59.38%)\n",
      "          Fold 2 Epoch 10: loss=0.2607, acc=40.94% (best=56.80%)\n",
      "          Fold 4: Early stopping at epoch 12\n",
      "      â†’ Fold 4 completed: 63.52%\n",
      "          Fold 3: Early stopping at epoch 13\n",
      "      â†’ Fold 3 completed: 59.38%\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.23%\n",
      "          Fold 1 Epoch 15: loss=0.2416, acc=52.73% (best=65.70%)\n",
      "          Fold 2 Epoch 15: loss=0.2347, acc=55.16% (best=56.80%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 56.80%\n",
      "          Fold 1 Epoch 20: loss=0.2290, acc=53.12% (best=65.70%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 65.70%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 8761555f:\n",
      "        Fold accuracies: ['65.70%', '56.80%', '59.38%', '63.52%', '60.23%']\n",
      "        Average fitness: 61.12% Â± 3.14%\n",
      "        Best fold: Fold 1 with 65.70%\n",
      "      Fitness obtained: 61.12% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 62f33d13)\n",
      "      Architecture: 12 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 62f33d13 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 3: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 1: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 2: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 62f33d13:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 3 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: fbf22240)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model fbf22240 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7037, acc=59.61% (best=59.61%)\n",
      "          Fold 4 Epoch 1: loss=0.6773, acc=60.31% (best=60.31%)\n",
      "          Fold 3 Epoch 1: loss=0.7003, acc=52.89% (best=52.89%)\n",
      "          Fold 2 Epoch 1: loss=0.6931, acc=40.55% (best=40.55%)\n",
      "          Fold 5 Epoch 1: loss=0.7135, acc=54.45% (best=54.45%)\n",
      "          Fold 1 Epoch 5: loss=0.5082, acc=53.98% (best=59.61%)\n",
      "          Fold 4 Epoch 5: loss=0.4371, acc=51.72% (best=60.31%)\n",
      "          Fold 3 Epoch 5: loss=0.4335, acc=49.45% (best=54.84%)\n",
      "          Fold 2 Epoch 5: loss=0.4965, acc=50.16% (best=50.70%)\n",
      "          Fold 5 Epoch 5: loss=0.5364, acc=55.47% (best=55.47%)\n",
      "          Fold 1 Epoch 10: loss=0.3276, acc=59.30% (best=70.08%)\n",
      "          Fold 4 Epoch 10: loss=0.2931, acc=55.86% (best=61.95%)\n",
      "          Fold 3 Epoch 10: loss=0.3416, acc=64.53% (best=64.53%)\n",
      "          Fold 2 Epoch 10: loss=0.3439, acc=54.30% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3577, acc=43.98% (best=55.47%)\n",
      "          Fold 1 Epoch 15: loss=0.2808, acc=54.06% (best=70.08%)\n",
      "          Fold 4 Epoch 15: loss=0.2570, acc=49.14% (best=61.95%)\n",
      "          Fold 3 Epoch 15: loss=0.2912, acc=61.17% (best=69.77%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 70.08%\n",
      "          Fold 2 Epoch 15: loss=0.2973, acc=35.55% (best=60.86%)\n",
      "          Fold 2: Early stopping at epoch 17\n",
      "      â†’ Fold 2 completed: 60.86%\n",
      "          Fold 5 Epoch 15: loss=0.2951, acc=47.50% (best=58.44%)\n",
      "          Fold 4: Early stopping at epoch 19\n",
      "      â†’ Fold 4 completed: 61.95%\n",
      "          Fold 3 Epoch 20: loss=0.2609, acc=55.39% (best=69.77%)\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 69.77%\n",
      "          Fold 5 Epoch 20: loss=0.2739, acc=42.97% (best=60.86%)\n",
      "          Fold 5 Epoch 25: loss=0.2599, acc=43.28% (best=61.48%)\n",
      "          Fold 5 Epoch 30: loss=0.2403, acc=40.55% (best=61.48%)\n",
      "          Fold 5: Early stopping at epoch 32\n",
      "      â†’ Fold 5 completed: 61.48%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fbf22240:\n",
      "        Fold accuracies: ['70.08%', '60.86%', '69.77%', '61.95%', '61.48%']\n",
      "        Average fitness: 64.83% Â± 4.17%\n",
      "        Best fold: Fold 1 with 70.08%\n",
      "      Fitness obtained: 64.83% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: 2e90866c)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 2e90866c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7513, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 1: loss=0.7516, acc=50.00% (best=50.00%)\n",
      "          Fold 2 Epoch 1: loss=0.7383, acc=49.38% (best=49.38%)\n",
      "          Fold 4 Epoch 1: loss=0.7338, acc=50.78% (best=50.78%)\n",
      "          Fold 3 Epoch 1: loss=0.7459, acc=48.98% (best=48.98%)\n",
      "          Fold 1 Epoch 5: loss=0.5390, acc=49.77% (best=49.77%)\n",
      "          Fold 5 Epoch 5: loss=0.5423, acc=50.00% (best=50.62%)\n",
      "          Fold 2 Epoch 5: loss=0.4746, acc=49.61% (best=49.61%)\n",
      "          Fold 4 Epoch 5: loss=0.5201, acc=50.70% (best=51.02%)\n",
      "          Fold 3 Epoch 5: loss=0.5141, acc=53.28% (best=53.28%)\n",
      "          Fold 1 Epoch 10: loss=0.3883, acc=54.53% (best=54.53%)\n",
      "          Fold 5 Epoch 10: loss=0.3643, acc=49.61% (best=50.62%)\n",
      "          Fold 2 Epoch 10: loss=0.3623, acc=52.97% (best=52.97%)\n",
      "          Fold 4 Epoch 10: loss=0.3755, acc=66.88% (best=66.88%)\n",
      "          Fold 3 Epoch 10: loss=0.3557, acc=56.88% (best=56.88%)\n",
      "          Fold 1 Epoch 15: loss=0.3230, acc=44.06% (best=62.73%)\n",
      "          Fold 5 Epoch 15: loss=0.3118, acc=50.16% (best=53.59%)\n",
      "          Fold 2 Epoch 15: loss=0.3119, acc=50.23% (best=52.97%)\n",
      "          Fold 4 Epoch 15: loss=0.3183, acc=58.05% (best=66.88%)\n",
      "          Fold 1 Epoch 20: loss=0.2832, acc=52.73% (best=62.73%)\n",
      "          Fold 3 Epoch 15: loss=0.3115, acc=61.17% (best=62.89%)\n",
      "          Fold 5 Epoch 20: loss=0.2762, acc=45.78% (best=55.39%)\n",
      "          Fold 2 Epoch 20: loss=0.2750, acc=45.00% (best=52.97%)\n",
      "          Fold 2: Early stopping at epoch 20\n",
      "      â†’ Fold 2 completed: 52.97%\n",
      "          Fold 1: Early stopping at epoch 21\n",
      "      â†’ Fold 1 completed: 62.73%\n",
      "          Fold 4 Epoch 20: loss=0.2895, acc=52.66% (best=66.88%)\n",
      "          Fold 4: Early stopping at epoch 20\n",
      "      â†’ Fold 4 completed: 66.88%\n",
      "          Fold 3 Epoch 20: loss=0.2854, acc=58.52% (best=62.89%)\n",
      "          Fold 5 Epoch 25: loss=0.2720, acc=42.89% (best=55.39%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 62.89%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 55.39%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 2e90866c:\n",
      "        Fold accuracies: ['62.73%', '52.97%', '62.89%', '66.88%', '55.39%']\n",
      "        Average fitness: 60.17% Â± 5.17%\n",
      "        Best fold: Fold 4 with 66.88%\n",
      "      Fitness obtained: 60.17% | Best in generation: 66.88% | Global best: 70.92%\n",
      "\n",
      "GENERATION 23 STATISTICS:\n",
      "   Maximum fitness: 66.88%\n",
      "   Average fitness: 52.92%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 22.54%\n",
      "   Best individual: 57ce2930 with 66.88%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 18/20\n",
      "Adaptive mutation rate updated to 0.1 (std_fitness=22.54)\n",
      "\n",
      "Starting selection and reproduction...\n",
      "Selecting 4 elite individuals:\n",
      "   Elite 1: 57ce2930 (fitness: 66.88%)\n",
      "   Elite 2: 15ecba8e (fitness: 65.50%)\n",
      "   Elite 3: fbf22240 (fitness: 64.83%)\n",
      "   Elite 4: eea91401 (fitness: 64.80%)\n",
      "Creating 16 new individuals through crossover and mutation...\n",
      "   Created 4 of 16 new individuals...\n",
      "   Created 8 of 16 new individuals...\n",
      "   Created 12 of 16 new individuals...\n",
      "   Created 16 of 16 new individuals...\n",
      "New generation created with 20 individuals\n",
      "   Elite preserved: 4\n",
      "   New individuals: 16\n",
      "\n",
      "Preparing for next generation...\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 19/20\n",
      "\n",
      "================================================================================\n",
      "GENERATION 24\n",
      "================================================================================\n",
      "\n",
      "Evaluating population (Generation 24)...\n",
      "Processing 20 individuals...\n",
      "\n",
      "   Evaluating individual 1/20 (ID: 57ce2930)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 57ce2930 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7318, acc=44.14% (best=44.14%)\n",
      "          Fold 5 Epoch 1: loss=0.7281, acc=48.75% (best=48.75%)\n",
      "          Fold 4 Epoch 1: loss=0.6884, acc=67.97% (best=67.97%)\n",
      "          Fold 2 Epoch 1: loss=0.7169, acc=44.06% (best=44.06%)\n",
      "          Fold 1 Epoch 1: loss=0.7154, acc=40.86% (best=40.86%)\n",
      "          Fold 3 Epoch 5: loss=0.3998, acc=48.28% (best=52.27%)\n",
      "          Fold 5 Epoch 5: loss=0.4724, acc=56.02% (best=56.02%)\n",
      "          Fold 4 Epoch 5: loss=0.4379, acc=62.66% (best=67.97%)\n",
      "          Fold 2 Epoch 5: loss=0.4462, acc=47.27% (best=49.69%)\n",
      "          Fold 1 Epoch 5: loss=0.4314, acc=56.48% (best=56.48%)\n",
      "          Fold 3 Epoch 10: loss=0.2942, acc=47.73% (best=62.27%)\n",
      "          Fold 5 Epoch 10: loss=0.3030, acc=38.28% (best=56.02%)\n",
      "          Fold 4 Epoch 10: loss=0.2979, acc=66.95% (best=67.97%)\n",
      "          Fold 2 Epoch 10: loss=0.3390, acc=56.17% (best=63.12%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.97%\n",
      "          Fold 1 Epoch 10: loss=0.2995, acc=52.42% (best=57.73%)\n",
      "          Fold 3 Epoch 15: loss=0.2600, acc=57.34% (best=62.27%)\n",
      "          Fold 5 Epoch 15: loss=0.2668, acc=41.17% (best=56.17%)\n",
      "          Fold 2 Epoch 15: loss=0.2964, acc=46.80% (best=64.53%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 62.27%\n",
      "          Fold 1 Epoch 15: loss=0.2679, acc=56.56% (best=58.20%)\n",
      "          Fold 5 Epoch 20: loss=0.2479, acc=43.20% (best=56.17%)\n",
      "          Fold 2 Epoch 20: loss=0.2632, acc=56.64% (best=64.53%)\n",
      "          Fold 1 Epoch 20: loss=0.2418, acc=53.44% (best=58.20%)\n",
      "          Fold 5: Early stopping at epoch 23\n",
      "      â†’ Fold 5 completed: 56.17%\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 64.53%\n",
      "          Fold 1 Epoch 25: loss=0.2292, acc=56.17% (best=62.66%)\n",
      "          Fold 1 Epoch 30: loss=0.2198, acc=62.34% (best=62.66%)\n",
      "          Fold 1: Early stopping at epoch 34\n",
      "      â†’ Fold 1 completed: 62.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 57ce2930:\n",
      "        Fold accuracies: ['62.66%', '64.53%', '62.27%', '67.97%', '56.17%']\n",
      "        Average fitness: 62.72% Â± 3.84%\n",
      "        Best fold: Fold 4 with 67.97%\n",
      "      New best fitness in this generation: 62.72%!\n",
      "      Fitness obtained: 62.72% | Best in generation: 62.72% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 2/20 (ID: 15ecba8e)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0001\n",
      "      Training/Evaluating model 15ecba8e with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7030, acc=59.92% (best=59.92%)\n",
      "          Fold 4 Epoch 1: loss=0.6868, acc=46.95% (best=46.95%)\n",
      "          Fold 5 Epoch 1: loss=0.7182, acc=44.84% (best=44.84%)\n",
      "          Fold 2 Epoch 1: loss=0.6925, acc=41.48% (best=41.48%)\n",
      "          Fold 3 Epoch 1: loss=0.7085, acc=54.77% (best=54.77%)\n",
      "          Fold 1 Epoch 5: loss=0.6271, acc=50.86% (best=59.92%)\n",
      "          Fold 4 Epoch 5: loss=0.6197, acc=60.16% (best=68.67%)\n",
      "          Fold 5 Epoch 5: loss=0.6905, acc=50.16% (best=57.66%)\n",
      "          Fold 2 Epoch 5: loss=0.6300, acc=46.64% (best=55.86%)\n",
      "          Fold 3 Epoch 5: loss=0.5625, acc=58.67% (best=58.67%)\n",
      "          Fold 1 Epoch 10: loss=0.4697, acc=36.48% (best=62.81%)\n",
      "          Fold 4 Epoch 10: loss=0.4845, acc=48.36% (best=69.06%)\n",
      "          Fold 5 Epoch 10: loss=0.4813, acc=62.58% (best=62.58%)\n",
      "          Fold 2 Epoch 10: loss=0.4523, acc=47.34% (best=55.86%)\n",
      "          Fold 3 Epoch 10: loss=0.4222, acc=53.83% (best=58.67%)\n",
      "          Fold 1 Epoch 15: loss=0.3760, acc=62.27% (best=62.81%)\n",
      "          Fold 4 Epoch 15: loss=0.3703, acc=53.12% (best=69.06%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 55.86%\n",
      "          Fold 5 Epoch 15: loss=0.3730, acc=57.11% (best=62.58%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 69.06%\n",
      "          Fold 3 Epoch 15: loss=0.3533, acc=54.06% (best=58.67%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 58.67%\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 62.81%\n",
      "          Fold 5 Epoch 20: loss=0.3218, acc=55.08% (best=62.58%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 62.58%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 15ecba8e:\n",
      "        Fold accuracies: ['62.81%', '55.86%', '58.67%', '69.06%', '62.58%']\n",
      "        Average fitness: 61.80% Â± 4.46%\n",
      "        Best fold: Fold 4 with 69.06%\n",
      "      Fitness obtained: 61.80% | Best in generation: 62.72% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 3/20 (ID: fbf22240)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model fbf22240 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6832, acc=40.47% (best=40.47%)\n",
      "          Fold 4 Epoch 1: loss=0.6761, acc=52.42% (best=52.42%)\n",
      "          Fold 5 Epoch 1: loss=0.7119, acc=50.16% (best=50.16%)\n",
      "          Fold 3 Epoch 1: loss=0.7004, acc=52.27% (best=52.27%)\n",
      "          Fold 1 Epoch 1: loss=0.6979, acc=52.89% (best=52.89%)\n",
      "          Fold 2 Epoch 5: loss=0.5685, acc=47.27% (best=48.05%)\n",
      "          Fold 4 Epoch 5: loss=0.4218, acc=53.91% (best=64.53%)\n",
      "          Fold 5 Epoch 5: loss=0.4388, acc=47.03% (best=61.33%)\n",
      "          Fold 1 Epoch 5: loss=0.5797, acc=54.30% (best=65.62%)\n",
      "          Fold 3 Epoch 5: loss=0.3905, acc=54.30% (best=57.58%)\n",
      "          Fold 2 Epoch 10: loss=0.3300, acc=40.55% (best=48.44%)\n",
      "          Fold 4 Epoch 10: loss=0.2975, acc=47.66% (best=64.92%)\n",
      "          Fold 5 Epoch 10: loss=0.3205, acc=42.34% (best=61.33%)\n",
      "          Fold 1 Epoch 10: loss=0.3660, acc=47.03% (best=65.62%)\n",
      "          Fold 3 Epoch 10: loss=0.2977, acc=55.31% (best=62.73%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 61.33%\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 65.62%\n",
      "          Fold 2 Epoch 15: loss=0.2847, acc=49.92% (best=54.14%)\n",
      "          Fold 4 Epoch 15: loss=0.2641, acc=69.14% (best=69.14%)\n",
      "          Fold 3 Epoch 15: loss=0.2695, acc=58.59% (best=62.73%)\n",
      "          Fold 3: Early stopping at epoch 16\n",
      "      â†’ Fold 3 completed: 62.73%\n",
      "          Fold 2 Epoch 20: loss=0.2578, acc=47.81% (best=54.14%)\n",
      "          Fold 4 Epoch 20: loss=0.2381, acc=55.94% (best=70.31%)\n",
      "          Fold 2: Early stopping at epoch 24\n",
      "      â†’ Fold 2 completed: 54.14%\n",
      "          Fold 4 Epoch 25: loss=0.2296, acc=44.45% (best=70.31%)\n",
      "          Fold 4: Early stopping at epoch 26\n",
      "      â†’ Fold 4 completed: 70.31%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for fbf22240:\n",
      "        Fold accuracies: ['65.62%', '54.14%', '62.73%', '70.31%', '61.33%']\n",
      "        Average fitness: 62.83% Â± 5.32%\n",
      "        Best fold: Fold 4 with 70.31%\n",
      "      New best fitness in this generation: 62.83%!\n",
      "      Fitness obtained: 62.83% | Best in generation: 62.83% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 4/20 (ID: eea91401)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eea91401 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7169, acc=38.28% (best=38.28%)\n",
      "          Fold 3 Epoch 1: loss=0.7290, acc=47.66% (best=47.66%)\n",
      "          Fold 5 Epoch 1: loss=0.7334, acc=50.00% (best=50.00%)\n",
      "          Fold 4 Epoch 1: loss=0.7126, acc=55.31% (best=55.31%)\n",
      "          Fold 1 Epoch 1: loss=0.7274, acc=49.77% (best=49.77%)\n",
      "          Fold 2 Epoch 5: loss=0.5715, acc=40.47% (best=52.66%)\n",
      "          Fold 3 Epoch 5: loss=0.5350, acc=55.86% (best=55.86%)\n",
      "          Fold 5 Epoch 5: loss=0.4940, acc=52.58% (best=56.25%)\n",
      "          Fold 4 Epoch 5: loss=0.4913, acc=61.88% (best=61.88%)\n",
      "          Fold 1 Epoch 5: loss=0.5378, acc=60.39% (best=60.39%)\n",
      "          Fold 2 Epoch 10: loss=0.3327, acc=42.81% (best=52.66%)\n",
      "          Fold 3 Epoch 10: loss=0.3548, acc=49.22% (best=55.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3604, acc=48.98% (best=58.05%)\n",
      "          Fold 4 Epoch 10: loss=0.2914, acc=60.08% (best=68.75%)\n",
      "          Fold 1 Epoch 10: loss=0.3606, acc=55.08% (best=66.56%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 52.66%\n",
      "          Fold 3 Epoch 15: loss=0.2908, acc=44.14% (best=55.86%)\n",
      "          Fold 3: Early stopping at epoch 15\n",
      "      â†’ Fold 3 completed: 55.86%\n",
      "          Fold 5 Epoch 15: loss=0.2985, acc=50.78% (best=63.44%)\n",
      "          Fold 4 Epoch 15: loss=0.2578, acc=58.91% (best=68.75%)\n",
      "          Fold 1 Epoch 15: loss=0.3053, acc=51.25% (best=66.56%)\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 68.75%\n",
      "          Fold 5 Epoch 20: loss=0.2819, acc=45.70% (best=63.44%)\n",
      "          Fold 1: Early stopping at epoch 18\n",
      "      â†’ Fold 1 completed: 66.56%\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 63.44%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eea91401:\n",
      "        Fold accuracies: ['66.56%', '52.66%', '55.86%', '68.75%', '63.44%']\n",
      "        Average fitness: 61.45% Â± 6.20%\n",
      "        Best fold: Fold 4 with 68.75%\n",
      "      Fitness obtained: 61.45% | Best in generation: 62.83% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 5/20 (ID: b9704789)\n",
      "      Architecture: 12 conv + 5 fc, opt=adamw, lr=0.0005\n",
      "      Training/Evaluating model b9704789 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7170, acc=52.27% (best=52.27%)\n",
      "          Fold 2 Epoch 1: loss=0.7205, acc=43.59% (best=43.59%)\n",
      "          Fold 1 Epoch 1: loss=0.7213, acc=49.92% (best=49.92%)\n",
      "          Fold 4 Epoch 1: loss=0.7054, acc=55.39% (best=55.39%)\n",
      "          Fold 5 Epoch 1: loss=0.7395, acc=50.94% (best=50.94%)\n",
      "          Fold 3 Epoch 5: loss=0.4953, acc=48.44% (best=52.27%)\n",
      "          Fold 2 Epoch 5: loss=0.5024, acc=45.70% (best=47.27%)\n",
      "          Fold 1 Epoch 5: loss=0.6421, acc=58.98% (best=60.55%)\n",
      "          Fold 4 Epoch 5: loss=0.5149, acc=51.02% (best=67.58%)\n",
      "          Fold 5 Epoch 5: loss=0.6625, acc=60.39% (best=60.39%)\n",
      "          Fold 3 Epoch 10: loss=0.3804, acc=51.80% (best=53.20%)\n",
      "          Fold 2 Epoch 10: loss=0.3423, acc=41.64% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.4196, acc=56.80% (best=60.55%)\n",
      "          Fold 4 Epoch 10: loss=0.3461, acc=57.42% (best=67.58%)\n",
      "          Fold 5 Epoch 10: loss=0.4371, acc=55.08% (best=60.39%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 60.55%\n",
      "          Fold 3 Epoch 15: loss=0.3297, acc=57.03% (best=57.03%)\n",
      "          Fold 2 Epoch 15: loss=0.3042, acc=49.69% (best=59.92%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 2: Early stopping at epoch 18\n",
      "      â†’ Fold 2 completed: 59.92%\n",
      "          Fold 5 Epoch 15: loss=0.3563, acc=45.78% (best=60.39%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 60.39%\n",
      "          Fold 3 Epoch 20: loss=0.2995, acc=50.31% (best=57.58%)\n",
      "          Fold 3 Epoch 25: loss=0.2862, acc=43.98% (best=58.98%)\n",
      "          Fold 3 Epoch 30: loss=0.2603, acc=47.50% (best=58.98%)\n",
      "          Fold 3: Early stopping at epoch 34\n",
      "      â†’ Fold 3 completed: 58.98%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b9704789:\n",
      "        Fold accuracies: ['60.55%', '59.92%', '58.98%', '67.58%', '60.39%']\n",
      "        Average fitness: 61.48% Â± 3.10%\n",
      "        Best fold: Fold 4 with 67.58%\n",
      "      Fitness obtained: 61.48% | Best in generation: 62.83% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 6/20 (ID: e01c6a9d)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model e01c6a9d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.7305, acc=59.06% (best=59.06%)\n",
      "          Fold 2 Epoch 1: loss=0.7182, acc=53.75% (best=53.75%)\n",
      "          Fold 5 Epoch 1: loss=0.7276, acc=61.48% (best=61.48%)\n",
      "          Fold 4 Epoch 1: loss=0.6955, acc=55.39% (best=55.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7318, acc=48.91% (best=48.91%)\n",
      "          Fold 3 Epoch 5: loss=0.4252, acc=49.84% (best=59.06%)\n",
      "          Fold 5 Epoch 5: loss=0.5124, acc=62.89% (best=62.89%)\n",
      "          Fold 2 Epoch 5: loss=0.4591, acc=57.03% (best=57.97%)\n",
      "          Fold 4 Epoch 5: loss=0.4513, acc=66.48% (best=66.48%)\n",
      "          Fold 1 Epoch 5: loss=0.4939, acc=70.47% (best=70.47%)\n",
      "          Fold 3 Epoch 10: loss=0.2914, acc=58.98% (best=59.06%)\n",
      "          Fold 5 Epoch 10: loss=0.3244, acc=50.39% (best=62.89%)\n",
      "          Fold 2 Epoch 10: loss=0.2702, acc=59.84% (best=59.84%)\n",
      "          Fold 4 Epoch 10: loss=0.3018, acc=68.91% (best=68.91%)\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 59.06%\n",
      "          Fold 1 Epoch 10: loss=0.2984, acc=52.58% (best=70.47%)\n",
      "          Fold 2 Epoch 15: loss=0.2524, acc=54.14% (best=61.80%)\n",
      "          Fold 5 Epoch 15: loss=0.2869, acc=46.17% (best=62.89%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 62.89%\n",
      "          Fold 4 Epoch 15: loss=0.2607, acc=49.30% (best=68.91%)\n",
      "          Fold 1 Epoch 15: loss=0.2596, acc=55.00% (best=70.47%)\n",
      "          Fold 1: Early stopping at epoch 15\n",
      "      â†’ Fold 1 completed: 70.47%\n",
      "          Fold 2 Epoch 20: loss=0.2329, acc=47.11% (best=61.80%)\n",
      "          Fold 4 Epoch 20: loss=0.2389, acc=68.59% (best=69.22%)\n",
      "          Fold 2: Early stopping at epoch 22\n",
      "      â†’ Fold 2 completed: 61.80%\n",
      "          Fold 4 Epoch 25: loss=0.2328, acc=53.28% (best=72.19%)\n",
      "          Fold 4 Epoch 30: loss=0.2124, acc=62.58% (best=72.19%)\n",
      "          Fold 4: Early stopping at epoch 32\n",
      "      â†’ Fold 4 completed: 72.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for e01c6a9d:\n",
      "        Fold accuracies: ['70.47%', '61.80%', '59.06%', '72.19%', '62.89%']\n",
      "        Average fitness: 65.28% Â± 5.12%\n",
      "        Best fold: Fold 4 with 72.19%\n",
      "      New best fitness in this generation: 65.28%!\n",
      "      Fitness obtained: 65.28% | Best in generation: 65.28% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 7/20 (ID: 622a098f)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 622a098f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "      ERROR in Fold 2: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 1: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 5: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ERROR in Fold 3: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "      ERROR in Fold 4: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_36771/2350498088.py\", line 100, in _train_fold_in_thread\n",
      "    model = EvolvableCNN(genome, self.config).to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 19, in __init__\n",
      "    self.conv_output_size = self._calculate_conv_output_size()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36771/4268941183.py\", line 117, in _calculate_conv_output_size\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/modules/normalization.py\", line 217, in forward\n",
      "    return F.layer_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/.local/lib/python3.11/site-packages/torch/nn/functional.py\", line 2905, in layer_norm\n",
      "    return torch.layer_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given normalized_shape=[98], expected input with shape [*, 98], but got input of size[1, 98, 11520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ“ PARALLEL 5-Fold CV Results for 622a098f:\n",
      "        Fold accuracies: ['0.00%', '0.00%', '0.00%', '0.00%', '0.00%']\n",
      "        Average fitness: 0.00% Â± 0.00%\n",
      "        Best fold: Fold 2 with 0.00%\n",
      "      Fitness obtained: 0.00% | Best in generation: 65.28% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 8/20 (ID: 017e8ff8)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 017e8ff8 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6991, acc=67.58% (best=67.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7334, acc=52.42% (best=52.42%)\n",
      "          Fold 3 Epoch 1: loss=0.7307, acc=48.98% (best=48.98%)\n",
      "          Fold 1 Epoch 1: loss=0.7179, acc=50.55% (best=50.55%)\n",
      "          Fold 2 Epoch 1: loss=0.7240, acc=50.78% (best=50.78%)\n",
      "          Fold 4 Epoch 5: loss=0.4755, acc=60.31% (best=67.58%)\n",
      "          Fold 5 Epoch 5: loss=0.4963, acc=58.44% (best=61.33%)\n",
      "          Fold 3 Epoch 5: loss=0.4692, acc=59.22% (best=59.22%)\n",
      "          Fold 1 Epoch 5: loss=0.5488, acc=58.05% (best=61.56%)\n",
      "          Fold 2 Epoch 5: loss=0.4917, acc=49.06% (best=50.78%)\n",
      "          Fold 4 Epoch 10: loss=0.3118, acc=66.88% (best=67.58%)\n",
      "          Fold 5 Epoch 10: loss=0.3445, acc=62.19% (best=64.14%)\n",
      "          Fold 3 Epoch 10: loss=0.3200, acc=62.73% (best=62.73%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 67.58%\n",
      "          Fold 1 Epoch 10: loss=0.3472, acc=56.72% (best=62.34%)\n",
      "          Fold 2 Epoch 10: loss=0.3109, acc=51.33% (best=51.33%)\n",
      "          Fold 5 Epoch 15: loss=0.2978, acc=47.89% (best=67.03%)\n",
      "          Fold 3 Epoch 15: loss=0.2771, acc=60.55% (best=62.73%)\n",
      "          Fold 1 Epoch 15: loss=0.2849, acc=58.52% (best=63.59%)\n",
      "          Fold 2 Epoch 15: loss=0.2774, acc=43.28% (best=61.41%)\n",
      "          Fold 5 Epoch 20: loss=0.2675, acc=60.55% (best=67.03%)\n",
      "          Fold 3 Epoch 20: loss=0.2455, acc=50.00% (best=62.73%)\n",
      "          Fold 3: Early stopping at epoch 20\n",
      "      â†’ Fold 3 completed: 62.73%\n",
      "          Fold 1 Epoch 20: loss=0.2618, acc=59.30% (best=69.06%)\n",
      "          Fold 5: Early stopping at epoch 22\n",
      "      â†’ Fold 5 completed: 67.03%\n",
      "          Fold 2 Epoch 20: loss=0.2539, acc=44.53% (best=61.41%)\n",
      "          Fold 1 Epoch 25: loss=0.2393, acc=66.48% (best=69.06%)\n",
      "          Fold 1: Early stopping at epoch 26\n",
      "      â†’ Fold 1 completed: 69.06%\n",
      "          Fold 2 Epoch 25: loss=0.2403, acc=52.34% (best=64.38%)\n",
      "          Fold 2 Epoch 30: loss=0.2308, acc=59.84% (best=64.38%)\n",
      "          Fold 2: Early stopping at epoch 32\n",
      "      â†’ Fold 2 completed: 64.38%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 017e8ff8:\n",
      "        Fold accuracies: ['69.06%', '64.38%', '62.73%', '67.58%', '67.03%']\n",
      "        Average fitness: 66.16% Â± 2.29%\n",
      "        Best fold: Fold 1 with 69.06%\n",
      "      New best fitness in this generation: 66.16%!\n",
      "      Fitness obtained: 66.16% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 9/20 (ID: d759df2f)\n",
      "      Architecture: 12 conv + 8 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model d759df2f with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7207, acc=50.23% (best=50.23%)\n",
      "          Fold 2 Epoch 1: loss=0.6972, acc=52.58% (best=52.58%)\n",
      "          Fold 5 Epoch 1: loss=0.7226, acc=54.84% (best=54.84%)\n",
      "          Fold 3 Epoch 1: loss=0.7272, acc=48.98% (best=48.98%)\n",
      "          Fold 4 Epoch 1: loss=0.6899, acc=60.31% (best=60.31%)\n",
      "          Fold 2 Epoch 5: loss=0.4820, acc=63.12% (best=63.12%)\n",
      "          Fold 1 Epoch 5: loss=0.5110, acc=55.86% (best=55.86%)\n",
      "          Fold 5 Epoch 5: loss=0.4966, acc=46.17% (best=60.62%)\n",
      "          Fold 3 Epoch 5: loss=0.4609, acc=55.94% (best=60.86%)\n",
      "          Fold 4 Epoch 5: loss=0.4442, acc=38.98% (best=60.31%)\n",
      "          Fold 2 Epoch 10: loss=0.3241, acc=36.95% (best=63.12%)\n",
      "          Fold 1 Epoch 10: loss=0.3371, acc=62.42% (best=63.67%)\n",
      "          Fold 5 Epoch 10: loss=0.3207, acc=42.89% (best=60.62%)\n",
      "          Fold 3 Epoch 10: loss=0.3277, acc=63.44% (best=63.44%)\n",
      "          Fold 4 Epoch 10: loss=0.3037, acc=29.92% (best=60.31%)\n",
      "          Fold 5: Early stopping at epoch 13\n",
      "      â†’ Fold 5 completed: 60.62%\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 60.31%\n",
      "          Fold 2 Epoch 15: loss=0.2836, acc=62.66% (best=63.12%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 63.12%\n",
      "          Fold 1 Epoch 15: loss=0.2766, acc=47.27% (best=65.39%)\n",
      "          Fold 3 Epoch 15: loss=0.2777, acc=58.75% (best=64.69%)\n",
      "          Fold 1 Epoch 20: loss=0.2510, acc=60.39% (best=65.39%)\n",
      "          Fold 3 Epoch 20: loss=0.2619, acc=58.98% (best=64.69%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 65.39%\n",
      "          Fold 3: Early stopping at epoch 23\n",
      "      â†’ Fold 3 completed: 64.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for d759df2f:\n",
      "        Fold accuracies: ['65.39%', '63.12%', '64.69%', '60.31%', '60.62%']\n",
      "        Average fitness: 62.83% Â± 2.06%\n",
      "        Best fold: Fold 1 with 65.39%\n",
      "      Fitness obtained: 62.83% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 10/20 (ID: eb120b37)\n",
      "      Architecture: 11 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model eb120b37 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7084, acc=44.06% (best=44.06%)\n",
      "          Fold 3 Epoch 1: loss=0.7127, acc=52.58% (best=52.58%)\n",
      "          Fold 4 Epoch 1: loss=0.6579, acc=54.14% (best=54.14%)\n",
      "          Fold 1 Epoch 1: loss=0.6970, acc=49.92% (best=49.92%)\n",
      "          Fold 5 Epoch 1: loss=0.7187, acc=43.05% (best=43.05%)\n",
      "          Fold 2 Epoch 5: loss=0.4326, acc=43.20% (best=65.39%)\n",
      "          Fold 3 Epoch 5: loss=0.3845, acc=45.39% (best=53.59%)\n",
      "          Fold 4 Epoch 5: loss=0.4155, acc=46.64% (best=70.08%)\n",
      "          Fold 1 Epoch 5: loss=0.5587, acc=58.44% (best=60.86%)\n",
      "          Fold 5 Epoch 5: loss=0.6193, acc=54.61% (best=54.61%)\n",
      "          Fold 2 Epoch 10: loss=0.2794, acc=63.05% (best=65.39%)\n",
      "          Fold 3 Epoch 10: loss=0.2709, acc=38.83% (best=53.59%)\n",
      "          Fold 4 Epoch 10: loss=0.2676, acc=46.02% (best=70.08%)\n",
      "          Fold 1 Epoch 10: loss=0.2906, acc=50.62% (best=66.33%)\n",
      "          Fold 3: Early stopping at epoch 12\n",
      "      â†’ Fold 3 completed: 53.59%\n",
      "          Fold 5 Epoch 10: loss=0.3128, acc=60.86% (best=60.86%)\n",
      "          Fold 2: Early stopping at epoch 14\n",
      "      â†’ Fold 2 completed: 65.39%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 70.08%\n",
      "          Fold 1 Epoch 15: loss=0.2471, acc=60.62% (best=66.33%)\n",
      "          Fold 5 Epoch 15: loss=0.2563, acc=38.75% (best=60.86%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 66.33%\n",
      "          Fold 5 Epoch 20: loss=0.2339, acc=60.08% (best=61.33%)\n",
      "          Fold 5 Epoch 25: loss=0.2192, acc=45.70% (best=61.33%)\n",
      "          Fold 5: Early stopping at epoch 28\n",
      "      â†’ Fold 5 completed: 61.33%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for eb120b37:\n",
      "        Fold accuracies: ['66.33%', '65.39%', '53.59%', '70.08%', '61.33%']\n",
      "        Average fitness: 63.34% Â± 5.61%\n",
      "        Best fold: Fold 4 with 70.08%\n",
      "      Fitness obtained: 63.34% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 11/20 (ID: 21178374)\n",
      "      Architecture: 12 conv + 6 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 21178374 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7132, acc=55.86% (best=55.86%)\n",
      "          Fold 3 Epoch 1: loss=0.7366, acc=52.42% (best=52.42%)\n",
      "          Fold 4 Epoch 1: loss=0.6991, acc=48.83% (best=48.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7390, acc=52.50% (best=52.50%)\n",
      "          Fold 5 Epoch 1: loss=0.7514, acc=51.72% (best=51.72%)\n",
      "          Fold 2 Epoch 5: loss=0.4446, acc=50.16% (best=60.08%)\n",
      "          Fold 5 Epoch 5: loss=0.5660, acc=49.45% (best=51.72%)\n",
      "          Fold 3 Epoch 5: loss=0.4253, acc=57.42% (best=57.42%)\n",
      "          Fold 4 Epoch 5: loss=0.4262, acc=58.12% (best=65.47%)\n",
      "          Fold 1 Epoch 5: loss=0.4662, acc=46.95% (best=62.50%)\n",
      "          Fold 2 Epoch 10: loss=0.3121, acc=44.92% (best=60.86%)\n",
      "          Fold 5 Epoch 10: loss=0.3890, acc=46.95% (best=55.86%)\n",
      "          Fold 3 Epoch 10: loss=0.3346, acc=51.64% (best=57.42%)\n",
      "          Fold 4 Epoch 10: loss=0.2948, acc=44.61% (best=65.47%)\n",
      "          Fold 1 Epoch 10: loss=0.3218, acc=51.72% (best=62.50%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 65.47%\n",
      "          Fold 2 Epoch 15: loss=0.2656, acc=47.42% (best=65.94%)\n",
      "          Fold 1: Early stopping at epoch 12\n",
      "      â†’ Fold 1 completed: 62.50%\n",
      "          Fold 5 Epoch 15: loss=0.3217, acc=48.05% (best=55.86%)\n",
      "          Fold 3 Epoch 15: loss=0.2845, acc=59.45% (best=61.09%)\n",
      "          Fold 2 Epoch 20: loss=0.2503, acc=61.48% (best=65.94%)\n",
      "          Fold 5 Epoch 20: loss=0.2821, acc=48.59% (best=61.80%)\n",
      "          Fold 3 Epoch 20: loss=0.2623, acc=56.09% (best=65.00%)\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 65.94%\n",
      "          Fold 3 Epoch 25: loss=0.2475, acc=51.33% (best=65.00%)\n",
      "          Fold 5 Epoch 25: loss=0.2646, acc=50.47% (best=61.80%)\n",
      "          Fold 3: Early stopping at epoch 27\n",
      "      â†’ Fold 3 completed: 65.00%\n",
      "          Fold 5: Early stopping at epoch 29\n",
      "      â†’ Fold 5 completed: 61.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 21178374:\n",
      "        Fold accuracies: ['62.50%', '65.94%', '65.00%', '65.47%', '61.80%']\n",
      "        Average fitness: 64.14% Â± 1.67%\n",
      "        Best fold: Fold 2 with 65.94%\n",
      "      Fitness obtained: 64.14% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 12/20 (ID: c615f055)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model c615f055 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 1 Epoch 1: loss=0.7460, acc=49.61% (best=49.61%)\n",
      "          Fold 2 Epoch 1: loss=0.7197, acc=51.41% (best=51.41%)\n",
      "          Fold 5 Epoch 1: loss=0.7460, acc=44.61% (best=44.61%)\n",
      "          Fold 4 Epoch 1: loss=0.7178, acc=49.14% (best=49.14%)\n",
      "          Fold 3 Epoch 1: loss=0.7438, acc=51.02% (best=51.02%)\n",
      "          Fold 1 Epoch 5: loss=0.6284, acc=52.42% (best=59.30%)\n",
      "          Fold 5 Epoch 5: loss=0.6995, acc=49.92% (best=51.25%)\n",
      "          Fold 2 Epoch 5: loss=0.6196, acc=46.48% (best=51.41%)\n",
      "          Fold 4 Epoch 5: loss=0.5539, acc=50.78% (best=56.17%)\n",
      "          Fold 3 Epoch 5: loss=0.6884, acc=47.73% (best=51.17%)\n",
      "          Fold 1 Epoch 10: loss=0.5527, acc=34.69% (best=59.30%)\n",
      "          Fold 2 Epoch 10: loss=0.3520, acc=50.39% (best=51.41%)\n",
      "          Fold 5 Epoch 10: loss=0.5134, acc=58.12% (best=58.12%)\n",
      "          Fold 2: Early stopping at epoch 11\n",
      "      â†’ Fold 2 completed: 51.41%\n",
      "          Fold 4 Epoch 10: loss=0.3974, acc=50.78% (best=58.59%)\n",
      "          Fold 3 Epoch 10: loss=0.4939, acc=57.19% (best=57.19%)\n",
      "          Fold 1: Early stopping at epoch 13\n",
      "      â†’ Fold 1 completed: 59.30%\n",
      "          Fold 5 Epoch 15: loss=0.4045, acc=52.03% (best=58.12%)\n",
      "          Fold 4 Epoch 15: loss=0.3394, acc=55.39% (best=58.59%)\n",
      "          Fold 3 Epoch 15: loss=0.4000, acc=51.48% (best=57.19%)\n",
      "          Fold 4: Early stopping at epoch 18\n",
      "      â†’ Fold 4 completed: 58.59%\n",
      "          Fold 5 Epoch 20: loss=0.3437, acc=53.20% (best=58.12%)\n",
      "          Fold 5: Early stopping at epoch 20\n",
      "      â†’ Fold 5 completed: 58.12%\n",
      "          Fold 3 Epoch 20: loss=0.3622, acc=52.89% (best=67.19%)\n",
      "          Fold 3 Epoch 25: loss=0.3286, acc=54.06% (best=67.19%)\n",
      "          Fold 3: Early stopping at epoch 28\n",
      "      â†’ Fold 3 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for c615f055:\n",
      "        Fold accuracies: ['59.30%', '51.41%', '67.19%', '58.59%', '58.12%']\n",
      "        Average fitness: 58.92% Â± 5.01%\n",
      "        Best fold: Fold 3 with 67.19%\n",
      "      Fitness obtained: 58.92% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 13/20 (ID: 504c099b)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 504c099b with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 4 Epoch 1: loss=0.6617, acc=64.38% (best=64.38%)\n",
      "          Fold 3 Epoch 1: loss=0.6901, acc=60.39% (best=60.39%)\n",
      "          Fold 2 Epoch 1: loss=0.6796, acc=50.78% (best=50.78%)\n",
      "          Fold 5 Epoch 1: loss=0.7054, acc=47.42% (best=47.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6853, acc=57.73% (best=57.73%)\n",
      "          Fold 4 Epoch 5: loss=0.3541, acc=45.62% (best=68.20%)\n",
      "          Fold 3 Epoch 5: loss=0.3503, acc=59.30% (best=60.39%)\n",
      "          Fold 2 Epoch 5: loss=0.3958, acc=49.22% (best=61.02%)\n",
      "          Fold 5 Epoch 5: loss=0.3685, acc=56.02% (best=56.02%)\n",
      "          Fold 1 Epoch 5: loss=0.4144, acc=61.09% (best=61.09%)\n",
      "          Fold 4 Epoch 10: loss=0.2657, acc=57.27% (best=68.20%)\n",
      "          Fold 3 Epoch 10: loss=0.2748, acc=60.70% (best=67.42%)\n",
      "          Fold 2 Epoch 10: loss=0.2946, acc=43.36% (best=61.02%)\n",
      "          Fold 5 Epoch 10: loss=0.2738, acc=43.36% (best=56.02%)\n",
      "          Fold 2: Early stopping at epoch 12\n",
      "      â†’ Fold 2 completed: 61.02%\n",
      "          Fold 1 Epoch 10: loss=0.2779, acc=66.41% (best=66.41%)\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 68.20%\n",
      "          Fold 3 Epoch 15: loss=0.2600, acc=59.45% (best=67.42%)\n",
      "          Fold 5 Epoch 15: loss=0.2464, acc=46.80% (best=56.02%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 56.02%\n",
      "          Fold 3: Early stopping at epoch 17\n",
      "      â†’ Fold 3 completed: 67.42%\n",
      "          Fold 1 Epoch 15: loss=0.2546, acc=57.81% (best=69.45%)\n",
      "          Fold 1 Epoch 20: loss=0.2335, acc=49.53% (best=69.45%)\n",
      "          Fold 1: Early stopping at epoch 24\n",
      "      â†’ Fold 1 completed: 69.45%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 504c099b:\n",
      "        Fold accuracies: ['69.45%', '61.02%', '67.42%', '68.20%', '56.02%']\n",
      "        Average fitness: 64.42% Â± 5.12%\n",
      "        Best fold: Fold 1 with 69.45%\n",
      "      Fitness obtained: 64.42% | Best in generation: 66.16% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 14/20 (ID: 95cd874d)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 95cd874d with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7058, acc=44.84% (best=44.84%)\n",
      "          Fold 3 Epoch 1: loss=0.7136, acc=52.19% (best=52.19%)\n",
      "          Fold 5 Epoch 1: loss=0.7240, acc=49.22% (best=49.22%)\n",
      "          Fold 1 Epoch 1: loss=0.7080, acc=47.03% (best=47.03%)\n",
      "          Fold 4 Epoch 1: loss=0.6919, acc=68.28% (best=68.28%)\n",
      "          Fold 2 Epoch 5: loss=0.4058, acc=51.95% (best=55.55%)\n",
      "          Fold 3 Epoch 5: loss=0.4339, acc=56.02% (best=59.77%)\n",
      "          Fold 5 Epoch 5: loss=0.4151, acc=57.03% (best=68.20%)\n",
      "          Fold 1 Epoch 5: loss=0.4463, acc=41.56% (best=65.62%)\n",
      "          Fold 4 Epoch 5: loss=0.3418, acc=61.72% (best=68.28%)\n",
      "          Fold 2 Epoch 10: loss=0.2822, acc=53.83% (best=56.95%)\n",
      "          Fold 3 Epoch 10: loss=0.3210, acc=60.23% (best=60.23%)\n",
      "          Fold 5 Epoch 10: loss=0.2807, acc=42.34% (best=68.20%)\n",
      "          Fold 1 Epoch 10: loss=0.2897, acc=67.27% (best=67.27%)\n",
      "          Fold 4 Epoch 10: loss=0.2547, acc=55.86% (best=68.28%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 68.28%\n",
      "          Fold 2 Epoch 15: loss=0.2509, acc=45.31% (best=56.95%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 68.20%\n",
      "          Fold 3 Epoch 15: loss=0.2684, acc=53.59% (best=66.48%)\n",
      "          Fold 1 Epoch 15: loss=0.2532, acc=65.47% (best=74.45%)\n",
      "          Fold 2: Early stopping at epoch 19\n",
      "      â†’ Fold 2 completed: 56.95%\n",
      "          Fold 3 Epoch 20: loss=0.2459, acc=59.61% (best=66.48%)\n",
      "          Fold 1 Epoch 20: loss=0.2300, acc=69.53% (best=76.17%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 66.48%\n",
      "          Fold 1 Epoch 25: loss=0.2251, acc=66.95% (best=76.17%)\n",
      "          Fold 1: Early stopping at epoch 28\n",
      "      â†’ Fold 1 completed: 76.17%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 95cd874d:\n",
      "        Fold accuracies: ['76.17%', '56.95%', '66.48%', '68.28%', '68.20%']\n",
      "        Average fitness: 67.22% Â± 6.13%\n",
      "        Best fold: Fold 1 with 76.17%\n",
      "      New best fitness in this generation: 67.22%!\n",
      "      Fitness obtained: 67.22% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 15/20 (ID: cbcb794c)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model cbcb794c with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6990, acc=58.28% (best=58.28%)\n",
      "          Fold 4 Epoch 1: loss=0.6989, acc=65.39% (best=65.39%)\n",
      "          Fold 1 Epoch 1: loss=0.7227, acc=47.81% (best=47.81%)\n",
      "          Fold 3 Epoch 1: loss=0.7266, acc=52.11% (best=52.11%)\n",
      "          Fold 5 Epoch 1: loss=0.7396, acc=50.86% (best=50.86%)\n",
      "          Fold 2 Epoch 5: loss=0.4460, acc=48.91% (best=61.02%)\n",
      "          Fold 4 Epoch 5: loss=0.4955, acc=62.34% (best=65.39%)\n",
      "          Fold 1 Epoch 5: loss=0.4705, acc=53.52% (best=67.50%)\n",
      "          Fold 3 Epoch 5: loss=0.4802, acc=56.25% (best=60.39%)\n",
      "          Fold 5 Epoch 5: loss=0.5197, acc=58.52% (best=58.52%)\n",
      "          Fold 2 Epoch 10: loss=0.3570, acc=61.56% (best=64.30%)\n",
      "          Fold 4 Epoch 10: loss=0.3008, acc=51.88% (best=65.39%)\n",
      "          Fold 1 Epoch 10: loss=0.3141, acc=69.84% (best=69.84%)\n",
      "          Fold 3 Epoch 10: loss=0.3374, acc=52.66% (best=60.39%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 65.39%\n",
      "          Fold 5 Epoch 10: loss=0.3358, acc=49.14% (best=58.52%)\n",
      "          Fold 2 Epoch 15: loss=0.3118, acc=52.81% (best=64.30%)\n",
      "          Fold 1 Epoch 15: loss=0.2685, acc=47.81% (best=69.84%)\n",
      "          Fold 3 Epoch 15: loss=0.2782, acc=50.39% (best=62.58%)\n",
      "          Fold 5 Epoch 15: loss=0.2770, acc=48.44% (best=58.52%)\n",
      "          Fold 5: Early stopping at epoch 15\n",
      "      â†’ Fold 5 completed: 58.52%\n",
      "          Fold 2 Epoch 20: loss=0.2871, acc=48.67% (best=66.17%)\n",
      "          Fold 1 Epoch 20: loss=0.2454, acc=62.66% (best=69.84%)\n",
      "          Fold 1: Early stopping at epoch 20\n",
      "      â†’ Fold 1 completed: 69.84%\n",
      "          Fold 3 Epoch 20: loss=0.2626, acc=55.55% (best=62.58%)\n",
      "          Fold 2 Epoch 25: loss=0.2622, acc=67.03% (best=72.66%)\n",
      "          Fold 3: Early stopping at epoch 24\n",
      "      â†’ Fold 3 completed: 62.58%\n",
      "          Fold 2 Epoch 30: loss=0.2587, acc=64.77% (best=72.66%)\n",
      "          Fold 2: Early stopping at epoch 34\n",
      "      â†’ Fold 2 completed: 72.66%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for cbcb794c:\n",
      "        Fold accuracies: ['69.84%', '72.66%', '62.58%', '65.39%', '58.52%']\n",
      "        Average fitness: 65.80% Â± 5.04%\n",
      "        Best fold: Fold 2 with 72.66%\n",
      "      Fitness obtained: 65.80% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 16/20 (ID: 0e8ffee1)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 0e8ffee1 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7342, acc=57.11% (best=57.11%)\n",
      "          Fold 2 Epoch 1: loss=0.7042, acc=50.31% (best=50.31%)\n",
      "          Fold 1 Epoch 1: loss=0.7129, acc=55.94% (best=55.94%)\n",
      "          Fold 4 Epoch 1: loss=0.6974, acc=60.47% (best=60.47%)\n",
      "          Fold 3 Epoch 1: loss=0.7287, acc=52.66% (best=52.66%)\n",
      "          Fold 5 Epoch 5: loss=0.4385, acc=56.41% (best=59.92%)\n",
      "          Fold 1 Epoch 5: loss=0.4862, acc=51.48% (best=62.34%)\n",
      "          Fold 2 Epoch 5: loss=0.5340, acc=57.66% (best=57.66%)\n",
      "          Fold 4 Epoch 5: loss=0.4511, acc=56.95% (best=60.47%)\n",
      "          Fold 3 Epoch 5: loss=0.4275, acc=57.03% (best=61.41%)\n",
      "          Fold 5 Epoch 10: loss=0.3188, acc=42.73% (best=59.92%)\n",
      "          Fold 1 Epoch 10: loss=0.3198, acc=49.38% (best=62.34%)\n",
      "          Fold 2 Epoch 10: loss=0.3314, acc=47.89% (best=57.66%)\n",
      "          Fold 4 Epoch 10: loss=0.3084, acc=64.45% (best=67.19%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 59.92%\n",
      "          Fold 3 Epoch 10: loss=0.3147, acc=53.98% (best=61.41%)\n",
      "          Fold 1: Early stopping at epoch 14\n",
      "      â†’ Fold 1 completed: 62.34%\n",
      "          Fold 2 Epoch 15: loss=0.2925, acc=53.05% (best=57.66%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 57.66%\n",
      "          Fold 4 Epoch 15: loss=0.2646, acc=63.52% (best=67.19%)\n",
      "          Fold 3: Early stopping at epoch 14\n",
      "      â†’ Fold 3 completed: 61.41%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 67.19%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 0e8ffee1:\n",
      "        Fold accuracies: ['62.34%', '57.66%', '61.41%', '67.19%', '59.92%']\n",
      "        Average fitness: 61.70% Â± 3.17%\n",
      "        Best fold: Fold 4 with 67.19%\n",
      "      Fitness obtained: 61.70% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 17/20 (ID: f2008b8a)\n",
      "      Architecture: 12 conv + 5 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model f2008b8a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 3 Epoch 1: loss=0.6773, acc=64.30% (best=64.30%)\n",
      "          Fold 4 Epoch 1: loss=0.6799, acc=66.95% (best=66.95%)\n",
      "          Fold 2 Epoch 1: loss=0.6843, acc=47.97% (best=47.97%)\n",
      "          Fold 5 Epoch 1: loss=0.7037, acc=48.52% (best=48.52%)\n",
      "          Fold 1 Epoch 1: loss=0.6854, acc=53.59% (best=53.59%)\n",
      "          Fold 3 Epoch 5: loss=0.3784, acc=50.55% (best=64.30%)\n",
      "          Fold 5 Epoch 5: loss=0.3871, acc=53.98% (best=60.55%)\n",
      "          Fold 2 Epoch 5: loss=0.3559, acc=45.16% (best=54.38%)\n",
      "          Fold 4 Epoch 5: loss=0.4145, acc=50.78% (best=66.95%)\n",
      "          Fold 1 Epoch 5: loss=0.4192, acc=52.66% (best=61.48%)\n",
      "          Fold 5 Epoch 10: loss=0.2602, acc=52.50% (best=60.55%)\n",
      "          Fold 4 Epoch 10: loss=0.2657, acc=48.98% (best=66.95%)\n",
      "          Fold 3 Epoch 10: loss=0.2700, acc=49.53% (best=64.30%)\n",
      "          Fold 1 Epoch 10: loss=0.2730, acc=61.02% (best=66.80%)\n",
      "          Fold 4: Early stopping at epoch 11\n",
      "      â†’ Fold 4 completed: 66.95%\n",
      "          Fold 3: Early stopping at epoch 11\n",
      "      â†’ Fold 3 completed: 64.30%\n",
      "          Fold 2 Epoch 10: loss=0.2655, acc=45.47% (best=55.55%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 60.55%\n",
      "          Fold 1 Epoch 15: loss=0.2368, acc=61.48% (best=66.80%)\n",
      "          Fold 2 Epoch 15: loss=0.2405, acc=40.86% (best=55.55%)\n",
      "          Fold 2: Early stopping at epoch 16\n",
      "      â†’ Fold 2 completed: 55.55%\n",
      "          Fold 1: Early stopping at epoch 17\n",
      "      â†’ Fold 1 completed: 66.80%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for f2008b8a:\n",
      "        Fold accuracies: ['66.80%', '55.55%', '64.30%', '66.95%', '60.55%']\n",
      "        Average fitness: 62.83% Â± 4.32%\n",
      "        Best fold: Fold 4 with 66.95%\n",
      "      Fitness obtained: 62.83% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 18/20 (ID: 6ab21f4a)\n",
      "      Architecture: 12 conv + 4 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model 6ab21f4a with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 5 Epoch 1: loss=0.7007, acc=48.59% (best=48.59%)\n",
      "          Fold 3 Epoch 1: loss=0.7074, acc=51.56% (best=51.56%)\n",
      "          Fold 4 Epoch 1: loss=0.6568, acc=48.59% (best=48.59%)\n",
      "          Fold 1 Epoch 1: loss=0.6903, acc=53.83% (best=53.83%)\n",
      "          Fold 2 Epoch 1: loss=0.6699, acc=42.58% (best=42.58%)\n",
      "          Fold 5 Epoch 5: loss=0.3965, acc=45.47% (best=56.09%)\n",
      "          Fold 3 Epoch 5: loss=0.3979, acc=48.12% (best=52.11%)\n",
      "          Fold 4 Epoch 5: loss=0.4234, acc=61.33% (best=61.33%)\n",
      "          Fold 1 Epoch 5: loss=0.4662, acc=44.30% (best=56.02%)\n",
      "          Fold 2 Epoch 5: loss=0.3503, acc=58.05% (best=58.05%)\n",
      "          Fold 3 Epoch 10: loss=0.2779, acc=54.84% (best=58.36%)\n",
      "          Fold 5 Epoch 10: loss=0.2874, acc=41.88% (best=56.09%)\n",
      "          Fold 4 Epoch 10: loss=0.3055, acc=49.77% (best=63.59%)\n",
      "          Fold 1 Epoch 10: loss=0.3166, acc=57.03% (best=57.97%)\n",
      "          Fold 5: Early stopping at epoch 12\n",
      "      â†’ Fold 5 completed: 56.09%\n",
      "          Fold 2 Epoch 10: loss=0.2767, acc=44.69% (best=58.05%)\n",
      "          Fold 3 Epoch 15: loss=0.2577, acc=47.66% (best=61.88%)\n",
      "          Fold 4 Epoch 15: loss=0.2502, acc=60.94% (best=63.59%)\n",
      "          Fold 1 Epoch 15: loss=0.2629, acc=52.27% (best=58.75%)\n",
      "          Fold 2 Epoch 15: loss=0.2483, acc=35.47% (best=58.05%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 58.05%\n",
      "          Fold 4: Early stopping at epoch 17\n",
      "      â†’ Fold 4 completed: 63.59%\n",
      "          Fold 3 Epoch 20: loss=0.2330, acc=46.64% (best=61.88%)\n",
      "          Fold 1 Epoch 20: loss=0.2411, acc=41.56% (best=68.59%)\n",
      "          Fold 3: Early stopping at epoch 22\n",
      "      â†’ Fold 3 completed: 61.88%\n",
      "          Fold 1 Epoch 25: loss=0.2288, acc=41.80% (best=68.59%)\n",
      "          Fold 1: Early stopping at epoch 27\n",
      "      â†’ Fold 1 completed: 68.59%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 6ab21f4a:\n",
      "        Fold accuracies: ['68.59%', '58.05%', '61.88%', '63.59%', '56.09%']\n",
      "        Average fitness: 61.64% Â± 4.38%\n",
      "        Best fold: Fold 1 with 68.59%\n",
      "      Fitness obtained: 61.64% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 19/20 (ID: 9dc1ee87)\n",
      "      Architecture: 12 conv + 3 fc, opt=adam, lr=0.0005\n",
      "      Training/Evaluating model 9dc1ee87 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.7067, acc=44.69% (best=44.69%)\n",
      "          Fold 3 Epoch 1: loss=0.7143, acc=43.83% (best=43.83%)\n",
      "          Fold 1 Epoch 1: loss=0.7012, acc=53.83% (best=53.83%)\n",
      "          Fold 4 Epoch 1: loss=0.6850, acc=51.09% (best=51.09%)\n",
      "          Fold 5 Epoch 1: loss=0.7105, acc=52.66% (best=52.66%)\n",
      "          Fold 5 Epoch 5: loss=0.4930, acc=52.19% (best=52.66%)\n",
      "          Fold 3 Epoch 5: loss=0.4429, acc=51.48% (best=51.48%)\n",
      "          Fold 4 Epoch 5: loss=0.5149, acc=65.39% (best=67.50%)\n",
      "          Fold 1 Epoch 5: loss=0.5373, acc=41.95% (best=53.83%)\n",
      "          Fold 2 Epoch 5: loss=0.4838, acc=56.25% (best=56.25%)\n",
      "          Fold 5 Epoch 10: loss=0.3082, acc=45.08% (best=52.66%)\n",
      "          Fold 3 Epoch 10: loss=0.3329, acc=53.91% (best=57.97%)\n",
      "          Fold 4 Epoch 10: loss=0.3543, acc=55.16% (best=67.50%)\n",
      "          Fold 1 Epoch 10: loss=0.3507, acc=48.28% (best=58.05%)\n",
      "          Fold 2 Epoch 10: loss=0.3254, acc=50.86% (best=56.25%)\n",
      "          Fold 5: Early stopping at epoch 11\n",
      "      â†’ Fold 5 completed: 52.66%\n",
      "          Fold 4: Early stopping at epoch 14\n",
      "      â†’ Fold 4 completed: 67.50%\n",
      "          Fold 3 Epoch 15: loss=0.2825, acc=57.89% (best=67.34%)\n",
      "          Fold 1 Epoch 15: loss=0.2853, acc=57.89% (best=58.05%)\n",
      "          Fold 2 Epoch 15: loss=0.2834, acc=48.36% (best=57.89%)\n",
      "          Fold 1: Early stopping at epoch 19\n",
      "      â†’ Fold 1 completed: 58.05%\n",
      "          Fold 3 Epoch 20: loss=0.2566, acc=62.73% (best=67.34%)\n",
      "          Fold 2 Epoch 20: loss=0.2521, acc=54.53% (best=57.89%)\n",
      "          Fold 3: Early stopping at epoch 21\n",
      "      â†’ Fold 3 completed: 67.34%\n",
      "          Fold 2: Early stopping at epoch 21\n",
      "      â†’ Fold 2 completed: 57.89%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for 9dc1ee87:\n",
      "        Fold accuracies: ['58.05%', '57.89%', '67.34%', '67.50%', '52.66%']\n",
      "        Average fitness: 60.69% Â± 5.83%\n",
      "        Best fold: Fold 4 with 67.50%\n",
      "      Fitness obtained: 60.69% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "   Evaluating individual 20/20 (ID: b392eed6)\n",
      "      Architecture: 12 conv + 7 fc, opt=rmsprop, lr=0.0005\n",
      "      Training/Evaluating model b392eed6 with PARALLEL 5-FOLD CROSS-VALIDATION\n",
      "      â†’ Submitting 5 folds to thread pool...\n",
      "      â†’ Waiting for all 5 folds to complete...\n",
      "          Fold 2 Epoch 1: loss=0.6789, acc=53.20% (best=53.20%)\n",
      "          Fold 5 Epoch 1: loss=0.7089, acc=53.75% (best=53.75%)\n",
      "          Fold 3 Epoch 1: loss=0.6920, acc=47.42% (best=47.42%)\n",
      "          Fold 1 Epoch 1: loss=0.6895, acc=48.91% (best=48.91%)\n",
      "          Fold 4 Epoch 1: loss=0.6712, acc=52.11% (best=52.11%)\n",
      "          Fold 2 Epoch 5: loss=0.4634, acc=54.69% (best=54.69%)\n",
      "          Fold 5 Epoch 5: loss=0.5621, acc=40.31% (best=58.05%)\n",
      "          Fold 3 Epoch 5: loss=0.4554, acc=58.36% (best=58.36%)\n",
      "          Fold 1 Epoch 5: loss=0.5308, acc=47.73% (best=60.47%)\n",
      "          Fold 4 Epoch 5: loss=0.5001, acc=66.88% (best=67.11%)\n",
      "          Fold 2 Epoch 10: loss=0.3276, acc=45.70% (best=54.69%)\n",
      "          Fold 5 Epoch 10: loss=0.3814, acc=57.73% (best=58.05%)\n",
      "          Fold 3 Epoch 10: loss=0.3523, acc=57.73% (best=58.36%)\n",
      "          Fold 1 Epoch 10: loss=0.3814, acc=50.39% (best=65.78%)\n",
      "          Fold 4 Epoch 10: loss=0.3329, acc=50.55% (best=67.11%)\n",
      "          Fold 5: Early stopping at epoch 14\n",
      "      â†’ Fold 5 completed: 58.05%\n",
      "          Fold 2 Epoch 15: loss=0.2787, acc=52.03% (best=54.69%)\n",
      "          Fold 2: Early stopping at epoch 15\n",
      "      â†’ Fold 2 completed: 54.69%\n",
      "          Fold 3 Epoch 15: loss=0.2974, acc=56.56% (best=58.52%)\n",
      "          Fold 4: Early stopping at epoch 13\n",
      "      â†’ Fold 4 completed: 67.11%\n",
      "          Fold 1 Epoch 15: loss=0.3159, acc=45.47% (best=65.78%)\n",
      "          Fold 1: Early stopping at epoch 16\n",
      "      â†’ Fold 1 completed: 65.78%\n",
      "          Fold 3 Epoch 20: loss=0.2744, acc=56.88% (best=59.69%)\n",
      "          Fold 3 Epoch 25: loss=0.2472, acc=51.25% (best=59.69%)\n",
      "          Fold 3: Early stopping at epoch 26\n",
      "      â†’ Fold 3 completed: 59.69%\n",
      "      âœ“ PARALLEL 5-Fold CV Results for b392eed6:\n",
      "        Fold accuracies: ['65.78%', '54.69%', '59.69%', '67.11%', '58.05%']\n",
      "        Average fitness: 61.06% Â± 4.70%\n",
      "        Best fold: Fold 4 with 67.11%\n",
      "      Fitness obtained: 61.06% | Best in generation: 67.22% | Global best: 70.92%\n",
      "\n",
      "GENERATION 24 STATISTICS:\n",
      "   Maximum fitness: 67.22%\n",
      "   Average fitness: 59.82%\n",
      "   Minimum fitness: 0.00%\n",
      "   Standard deviation: 13.87%\n",
      "   Best individual: 95cd874d with 67.22%\n",
      "   Global best individual: 7cf1d714 with 70.92%\n",
      "\n",
      "â³ No significant improvement | Generations without improvement: 20/20\n",
      "\n",
      "ðŸ›‘ EARLY STOPPING: No improvement for 20 generations\n",
      "   Best fitness plateau: 70.92%\n",
      "\n",
      "================================================================================\n",
      "EVOLUTION COMPLETED!\n",
      "================================================================================\n",
      "Best individual found:\n",
      "   ID: 7cf1d714\n",
      "   Fitness: 70.92%\n",
      "   Origin generation: 24\n",
      "   Total generations processed: 25\n",
      "   Generations without improvement: 20/20\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "EVOLUTION PROCESS COMPLETED\n",
      "============================================================\n",
      "Completed at: 17:03:57\n",
      "Total execution time: 2 days, 22:13:57.446301\n",
      "Total generations: 24\n",
      "Best fitness achieved: 70.92%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CONFIGURACIÃ“N DE DATASET DE AUDIO\n",
    "# ==========================================\n",
    "\n",
    "# Ruta OS-independiente usando os.path.join\n",
    "CONFIG['data_path'] = os.path.join('data', 'sets', 'folds_5')\n",
    "\n",
    "# ==========================================\n",
    "# AJUSTES OPCIONALES\n",
    "# ==========================================\n",
    "\n",
    "# Ajustar poblaciÃ³n y generaciones si es necesario\n",
    "# CONFIG['population_size'] = 8\n",
    "# CONFIG['max_generations'] = 20\n",
    "# CONFIG['fitness_threshold'] = 85.0  # Para audio, 85% es buen objetivo\n",
    "# CONFIG['batch_size'] = 16  # Reducir si hay problemas de memoria\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUDIO NEUROEVOLUTION CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Dataset: Audio (Parkinson Classification)\")\n",
    "print(f\"   Dataset ID: {CONFIG['dataset_id']}\")\n",
    "print(f\"   Fold ID: {CONFIG['fold_id']}\")\n",
    "print(f\"   Number of folds: {CONFIG['num_folds']} (all used during evolution)\")\n",
    "print(f\"   Data Path: {CONFIG['data_path']}\")\n",
    "print(f\"   Number of channels: {CONFIG['num_channels']} (1D audio)\")\n",
    "print(f\"   Sequence length: {CONFIG['sequence_length']} (will be auto-detected)\")\n",
    "print(f\"   Number of classes: {CONFIG['num_classes']} (Control vs Pathological)\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Population: {CONFIG['population_size']} individuals\")\n",
    "print(f\"   Maximum generations: {CONFIG['max_generations']}\")\n",
    "print(f\"   Target fitness: {CONFIG['fitness_threshold']}%\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Platform: {os.name} ({'Windows' if os.name == 'nt' else 'Unix/Linux/Mac'})\")\n",
    "print(f\"   Parallelization: Enabled (5 threads per individual)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify dataset availability with the new configuration\n",
    "print(f\"\\nVerifying audio dataset...\")\n",
    "load_dataset(CONFIG)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET VERIFIED - READY FOR PARALLEL 5-FOLD CV EVOLUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Initialize neuroevolution system\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nStarting audio neuroevolution at {start_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Architecture: Conv1D -> BatchNorm1D -> Activation -> MaxPool1D -> FC\")\n",
    "print(f\"Each individual will be evaluated on all 5 folds IN PARALLEL\")\n",
    "print(f\"Using ThreadPoolExecutor with 5 workers (one per fold)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create system instance (no need for train/test loaders anymore)\n",
    "neuroevolution = HybridNeuroevolution(CONFIG)\n",
    "\n",
    "# Execute evolution process\n",
    "best_genome = neuroevolution.evolve()\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVOLUTION PROCESS COMPLETED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Completed at: {end_time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Total execution time: {execution_time}\")\n",
    "print(f\"Total generations: {neuroevolution.generation}\")\n",
    "print(f\"Best fitness achieved: {best_genome['fitness']:.2f}%\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555d9b",
   "metadata": {},
   "source": [
    "## 8. Results Visualization and Analysis\n",
    "\n",
    "### 8.1 Fitness Evolution Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "308a9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Fitness visualization function defined\n"
     ]
    }
   ],
   "source": [
    "# Configure matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Function to visualize fitness evolution\n",
    "def plot_fitness_evolution(neuroevolution):\n",
    "    \"\"\"Plots fitness evolution across generations.\"\"\"\n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics data to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extract data and filter 0.00 fitness\n",
    "    generations = []\n",
    "    avg_fitness = []\n",
    "    max_fitness = []\n",
    "    min_fitness = []\n",
    "    std_fitness = []\n",
    "    \n",
    "    for stat in neuroevolution.generation_stats:\n",
    "        # Only include if valid fitness (> 0.00)\n",
    "        if stat['max_fitness'] > 0.00:\n",
    "            generations.append(stat['generation'])\n",
    "            avg_fitness.append(stat['avg_fitness'])\n",
    "            max_fitness.append(stat['max_fitness'])\n",
    "            min_fitness.append(stat['min_fitness'])\n",
    "            std_fitness.append(stat['std_fitness'])\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"WARNING: No valid fitness data to plot (all are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    # Graph 1: Fitness evolution\n",
    "    ax1.plot(generations, max_fitness, 'g-', linewidth=2, marker='o', label='Maximum Fitness')\n",
    "    ax1.plot(generations, avg_fitness, 'b-', linewidth=2, marker='s', label='Average Fitness')\n",
    "    ax1.plot(generations, min_fitness, 'r-', linewidth=2, marker='^', label='Minimum Fitness')\n",
    "    ax1.fill_between(generations, \n",
    "                     [max(0, avg - std) for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     [avg + std for avg, std in zip(avg_fitness, std_fitness)],\n",
    "                     alpha=0.2, color='blue')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness (%)')\n",
    "    ax1.set_title('Fitness Evolution by Generation (Excluding 0.00%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add target fitness line\n",
    "    ax1.axhline(y=CONFIG['fitness_threshold'], color='orange', linestyle='--', \n",
    "                label=f\"Target ({CONFIG['fitness_threshold']}%)\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Set Y axis limits for better visualization\n",
    "    y_min = max(0, min(min_fitness) - 5)\n",
    "    y_max = min(100, max(max_fitness) + 5)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Graph 2: Diversity (standard deviation)\n",
    "    ax2.plot(generations, std_fitness, 'purple', linewidth=2, marker='D')\n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Fitness Standard Deviation')\n",
    "    ax2.set_title('Population Diversity (Excluding 0.00%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show additional information\n",
    "    print(f\"Plotted data:\")\n",
    "    print(f\"   Generations with valid fitness: {len(generations)}\")\n",
    "    print(f\"   Best fitness achieved: {max(max_fitness):.2f}%\")\n",
    "    print(f\"   Final average fitness: {avg_fitness[-1]:.2f}%\")\n",
    "    if len(generations) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(generations)\n",
    "        print(f\"   WARNING: Excluded generations (0.00 fitness): {excluded}\")\n",
    "\n",
    "print(\"âœ“ Fitness visualization function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f69d6",
   "metadata": {},
   "source": [
    "### 8.2 Detailed Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29684a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Evolution statistics function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to show detailed statistics\n",
    "def show_evolution_statistics(neuroevolution):\n",
    "    \"\"\"Shows detailed evolution statistics.\"\"\"\n",
    "    print(\"DETAILED EVOLUTION STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not neuroevolution.generation_stats:\n",
    "        print(\"WARNING: No statistics available\")\n",
    "        return\n",
    "    \n",
    "    # Filter statistics with valid fitness\n",
    "    valid_stats = [stat for stat in neuroevolution.generation_stats if stat['max_fitness'] > 0.00]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"WARNING: No valid statistics (all fitness are 0.00)\")\n",
    "        return\n",
    "    \n",
    "    final_stats = valid_stats[-1]\n",
    "    \n",
    "    print(f\"Completed generations: {neuroevolution.generation}\")\n",
    "    print(f\"Generations with valid fitness: {len(valid_stats)}\")\n",
    "    if len(valid_stats) < len(neuroevolution.generation_stats):\n",
    "        excluded = len(neuroevolution.generation_stats) - len(valid_stats)\n",
    "        print(f\"WARNING: Generations with 0.00 fitness (excluded): {excluded}\")\n",
    "    \n",
    "    print(f\"\\nFINAL STATISTICS (excluding 0.00 fitness):\")\n",
    "    print(f\"   Final best fitness: {final_stats['max_fitness']:.2f}%\")\n",
    "    print(f\"   Final average fitness: {final_stats['avg_fitness']:.2f}%\")\n",
    "    print(f\"   Final minimum fitness: {final_stats['min_fitness']:.2f}%\")\n",
    "    print(f\"   Final standard deviation: {final_stats['std_fitness']:.2f}%\")\n",
    "    \n",
    "    # Progress across generations\n",
    "    if len(valid_stats) > 1:\n",
    "        initial_max = valid_stats[0]['max_fitness']\n",
    "        final_max = valid_stats[-1]['max_fitness']\n",
    "        improvement = final_max - initial_max\n",
    "        \n",
    "        print(f\"\\nPROGRESS:\")\n",
    "        print(f\"   Initial fitness: {initial_max:.2f}%\")\n",
    "        print(f\"   Final fitness: {final_max:.2f}%\")\n",
    "        print(f\"   Total improvement: {improvement:.2f}%\")\n",
    "        if initial_max > 0:\n",
    "            print(f\"   Relative improvement: {(improvement/initial_max)*100:.1f}%\")\n",
    "    \n",
    "    # Convergence analysis\n",
    "    print(f\"\\nCONVERGENCE CRITERIA:\")\n",
    "    if neuroevolution.best_individual and neuroevolution.best_individual['fitness'] >= CONFIG['fitness_threshold']:\n",
    "        print(f\"   OK: Target fitness reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    else:\n",
    "        print(f\"   ERROR: Target fitness NOT reached ({CONFIG['fitness_threshold']}%)\")\n",
    "    \n",
    "    if neuroevolution.generation >= CONFIG['max_generations']:\n",
    "        print(f\"   TIME: Maximum generations reached ({CONFIG['max_generations']})\")\n",
    "    \n",
    "    # Additional performance statistics\n",
    "    all_max_fitness = [stat['max_fitness'] for stat in valid_stats]\n",
    "    all_avg_fitness = [stat['avg_fitness'] for stat in valid_stats]\n",
    "    \n",
    "    print(f\"\\nGENERAL STATISTICS:\")\n",
    "    print(f\"   Best fitness of entire evolution: {max(all_max_fitness):.2f}%\")\n",
    "    print(f\"   Average fitness of entire evolution: {np.mean(all_avg_fitness):.2f}%\")\n",
    "    print(f\"   Average improvement per generation: {(max(all_max_fitness) - min(all_max_fitness))/len(valid_stats):.2f}%\")\n",
    "    \n",
    "    if neuroevolution.best_individual:\n",
    "        print(f\"\\nBest individual ID: {neuroevolution.best_individual['id']}\")\n",
    "        print(f\"Best individual fitness: {neuroevolution.best_individual['fitness']:.2f}%\")\n",
    "\n",
    "print(\"âœ“ Evolution statistics function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a17a2",
   "metadata": {},
   "source": [
    "### 8.3 Failure Analysis and Visualization Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103104c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted data:\n",
      "   Generations with valid fitness: 25\n",
      "   Best fitness achieved: 70.92%\n",
      "   Final average fitness: 59.82%\n",
      "DETAILED EVOLUTION STATISTICS\n",
      "============================================================\n",
      "Completed generations: 24\n",
      "Generations with valid fitness: 25\n",
      "\n",
      "FINAL STATISTICS (excluding 0.00 fitness):\n",
      "   Final best fitness: 67.22%\n",
      "   Final average fitness: 59.82%\n",
      "   Final minimum fitness: 0.00%\n",
      "   Final standard deviation: 13.87%\n",
      "\n",
      "PROGRESS:\n",
      "   Initial fitness: 65.08%\n",
      "   Final fitness: 67.22%\n",
      "   Total improvement: 2.14%\n",
      "   Relative improvement: 3.3%\n",
      "\n",
      "CONVERGENCE CRITERIA:\n",
      "   ERROR: Target fitness NOT reached (80.0%)\n",
      "\n",
      "GENERAL STATISTICS:\n",
      "   Best fitness of entire evolution: 70.92%\n",
      "   Average fitness of entire evolution: 53.18%\n",
      "   Average improvement per generation: 0.32%\n",
      "\n",
      "Best individual ID: 7cf1d714\n",
      "Best individual fitness: 70.92%\n",
      "\n",
      "FAILED EVALUATIONS ANALYSIS\n",
      "==================================================\n",
      "OK: No failed evaluations (0.00 fitness)\n"
     ]
    }
   ],
   "source": [
    "# Additional function for failure analysis\n",
    "def analyze_failed_evaluations(neuroevolution):\n",
    "    \"\"\"Analyzes evaluations that resulted in 0.00 fitness.\"\"\"\n",
    "    print(\"\\nFAILED EVALUATIONS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_generations = len(neuroevolution.generation_stats)\n",
    "    failed_generations = len([stat for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00])\n",
    "    \n",
    "    if failed_generations == 0:\n",
    "        print(\"OK: No failed evaluations (0.00 fitness)\")\n",
    "        return\n",
    "    \n",
    "    success_rate = ((total_generations - failed_generations) / total_generations) * 100\n",
    "    \n",
    "    print(f\"Failure summary:\")\n",
    "    print(f\"   Total generations: {total_generations}\")\n",
    "    print(f\"   Failed generations: {failed_generations}\")\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    if failed_generations > 0:\n",
    "        failed_gens = [stat['generation'] for stat in neuroevolution.generation_stats if stat['max_fitness'] == 0.00]\n",
    "        print(f\"   Generations with failures: {failed_gens}\")\n",
    "        \n",
    "        print(f\"\\nPossible causes of 0.00 fitness:\")\n",
    "        print(f\"   â€¢ Errors in model architecture\")\n",
    "        print(f\"   â€¢ Memory problems (GPU/RAM)\")\n",
    "        print(f\"   â€¢ Invalid hyperparameter configurations\")\n",
    "        print(f\"   â€¢ Errors during training\")\n",
    "\n",
    "# Execute visualizations\n",
    "plot_fitness_evolution(neuroevolution)\n",
    "show_evolution_statistics(neuroevolution)\n",
    "analyze_failed_evaluations(neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6688660",
   "metadata": {},
   "source": [
    "## 9. BEST ARCHITECTURE FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a847dd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "    BEST EVOLVED ARCHITECTURE (1D AUDIO)\n",
      "============================================================\n",
      "\n",
      "GENERAL INFORMATION:\n",
      "   Genome ID: 7cf1d714\n",
      "   Fitness Achieved: 70.92%\n",
      "   Generation: 24\n",
      "   Dataset: AUDIO\n",
      "   Dataset ID: all_real_syn_n\n",
      "   Fold: N/A\n",
      "\n",
      "NETWORK ARCHITECTURE:\n",
      "   Input: 1D Audio Signal (length=11520)\n",
      "   Convolutional Layers (Conv1D): 12\n",
      "   Fully Connected Layers: 4\n",
      "   Output: 2 classes\n",
      "\n",
      "CONVOLUTIONAL LAYER DETAILS (1D):\n",
      "   Conv1D-1: 42 filters, kernel_size=1, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-2: 4 filters, kernel_size=7, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-3: 5 filters, kernel_size=13, activation=leaky_relu\n",
      "             -> BatchNorm1D -> LEAKY_RELU -> MaxPool1D(2)\n",
      "   Conv1D-4: 88 filters, kernel_size=13, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-5: 75 filters, kernel_size=5, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-6: 97 filters, kernel_size=5, activation=leaky_relu\n",
      "             -> BatchNorm1D -> LEAKY_RELU -> MaxPool1D(2)\n",
      "   Conv1D-7: 24 filters, kernel_size=15, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-8: 205 filters, kernel_size=13, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-9: 93 filters, kernel_size=11, activation=leaky_relu\n",
      "             -> BatchNorm1D -> LEAKY_RELU -> MaxPool1D(2)\n",
      "   Conv1D-10: 146 filters, kernel_size=13, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-11: 140 filters, kernel_size=3, activation=tanh\n",
      "             -> BatchNorm1D -> TANH -> MaxPool1D(2)\n",
      "   Conv1D-12: 3 filters, kernel_size=9, activation=leaky_relu\n",
      "             -> BatchNorm1D -> LEAKY_RELU -> MaxPool1D(2)\n",
      "\n",
      "FULLY CONNECTED LAYER DETAILS:\n",
      "   FC1: 260 neurons -> BatchNorm1D -> ReLU -> Dropout(0.500)\n",
      "   FC2: 113 neurons -> BatchNorm1D -> ReLU -> Dropout(0.500)\n",
      "   FC3: 353 neurons -> BatchNorm1D -> ReLU -> Dropout(0.500)\n",
      "   FC4: 236 neurons -> BatchNorm1D -> ReLU -> Dropout(0.500)\n",
      "   Output: 2 neurons (Control vs Pathological)\n",
      "\n",
      "HYPERPARAMETERS:\n",
      "   Optimizer: RMSPROP\n",
      "   Learning Rate: 0.000500\n",
      "   Dropout Rate: 0.500\n",
      "   Activation Functions: leaky_relu, tanh\n",
      "\n",
      "CREATING FINAL MODEL...\n",
      "   Model created successfully\n",
      "   Total parameters: 787,129\n",
      "   Trainable parameters: 787,129\n",
      "   Model size: ~3.00 MB (float32)\n",
      "\n",
      "COMPACT SUMMARY:\n",
      "   Conv1D Layers: 12 | Filters: [42, 4, 5, 88, 75, 97, 24, 205, 93, 146, 140, 3] | Kernel Sizes: [1, 7, 13, 13, 5, 5, 15, 13, 11, 13, 3, 9] | FC Layers: 4 | FC Nodes: [260, 113, 353, 236] | Activations: ['tanh', 'tanh', 'leaky_relu'] | Normalization: batch | Dropout: 0.500 | Optimizer: rmsprop | Learning Rate: 0.0005\n",
      "\n",
      "SUMMARY TABLE:\n",
      "================================================================================\n",
      "Parameter                 Value                          Description              \n",
      "================================================================================\n",
      "ID                        7cf1d714                       Unique identifier        \n",
      "Fitness                   70.92%                          Accuracy achieved        \n",
      "Architecture              Conv1D + FC                    1D Convolutional         \n",
      "Conv Layers               12                             Conv1D layers            \n",
      "FC Layers                 4                              FC layers                \n",
      "Optimizer                 rmsprop                        Optimization algorithm   \n",
      "Learning Rate             0.000500                       Learning rate            \n",
      "Dropout                   0.5003511198366439             Dropout rate             \n",
      "Input Length              11520                          Audio sequence length    \n",
      "Classes                   2                              Binary classification    \n",
      "================================================================================\n",
      "\n",
      "COMPARISON WITH OBJECTIVES:\n",
      "   âœ— TARGET NOT REACHED: 70.92% < 80.0%\n",
      "     Gap: 9.08%\n",
      "   Generations used: 24/100\n",
      "\n",
      "âœ“ Results saved to: best_architecture_audio_20251027_170358.json\n",
      "\n",
      "============================================================\n",
      "HYBRID NEUROEVOLUTION FOR AUDIO COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def display_best_architecture(best_genome, config):\n",
    "    \"\"\"\n",
    "    Shows the best architecture found in detailed and visual format.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"    BEST EVOLVED ARCHITECTURE (1D AUDIO)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # General information\n",
    "    print(f\"\\nGENERAL INFORMATION:\")\n",
    "    print(f\"   Genome ID: {best_genome['id']}\")\n",
    "    print(f\"   Fitness Achieved: {best_genome['fitness']:.2f}%\")\n",
    "    print(f\"   Generation: {neuroevolution.generation}\")\n",
    "    print(f\"   Dataset: {config['dataset']}\")\n",
    "    print(f\"   Dataset ID: {config.get('dataset_id', 'N/A')}\")\n",
    "    print(f\"   Fold: {config.get('current_fold', 'N/A')}\")\n",
    "    \n",
    "    # Architecture details\n",
    "    print(f\"\\nNETWORK ARCHITECTURE:\")\n",
    "    print(f\"   Input: 1D Audio Signal (length={config['sequence_length']})\")\n",
    "    print(f\"   Convolutional Layers (Conv1D): {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   Fully Connected Layers: {best_genome['num_fc_layers']}\")\n",
    "    print(f\"   Output: {config['num_classes']} classes\")\n",
    "    \n",
    "    print(f\"\\nCONVOLUTIONAL LAYER DETAILS (1D):\")\n",
    "    for i in range(best_genome['num_conv_layers']):\n",
    "        filters = best_genome['filters'][i]\n",
    "        kernel = best_genome['kernel_sizes'][i]\n",
    "        activation = best_genome['activations'][i % len(best_genome['activations'])]\n",
    "        print(f\"   Conv1D-{i+1}: {filters} filters, kernel_size={kernel}, activation={activation}\")\n",
    "        print(f\"             -> BatchNorm1D -> {activation.upper()} -> MaxPool1D(2)\")\n",
    "    \n",
    "    print(f\"\\nFULLY CONNECTED LAYER DETAILS:\")\n",
    "    for i, nodes in enumerate(best_genome['fc_nodes']):\n",
    "        print(f\"   FC{i+1}: {nodes} neurons -> BatchNorm1D -> ReLU -> Dropout({best_genome['dropout_rate']:.3f})\")\n",
    "    print(f\"   Output: {config['num_classes']} neurons (Control vs Pathological)\")\n",
    "    \n",
    "    print(f\"\\nHYPERPARAMETERS:\")\n",
    "    print(f\"   Optimizer: {best_genome['optimizer'].upper()}\")\n",
    "    print(f\"   Learning Rate: {best_genome['learning_rate']:.6f}\")\n",
    "    print(f\"   Dropout Rate: {best_genome['dropout_rate']:.3f}\")\n",
    "    print(f\"   Activation Functions: {', '.join(set(best_genome['activations']))}\")\n",
    "    \n",
    "    # Create and show final model\n",
    "    print(f\"\\nCREATING FINAL MODEL...\")\n",
    "    try:\n",
    "        final_model = EvolvableCNN(best_genome, config)\n",
    "        total_params = sum(p.numel() for p in final_model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"   Model created successfully\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"   Model size: ~{total_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n",
    "        \n",
    "        # Architecture summary\n",
    "        print(f\"\\nCOMPACT SUMMARY:\")\n",
    "        print(f\"   {final_model.get_architecture_summary()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR creating model: {e}\")\n",
    "    \n",
    "    # Visualization in table format\n",
    "    print(f\"\\nSUMMARY TABLE:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Parameter':<25} {'Value':<30} {'Description':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'ID':<25} {best_genome['id']:<30} {'Unique identifier':<25}\")\n",
    "    print(f\"{'Fitness':<25} {best_genome['fitness']:.2f}%{'':<25} {'Accuracy achieved':<25}\")\n",
    "    print(f\"{'Architecture':<25} {'Conv1D + FC':<30} {'1D Convolutional':<25}\")\n",
    "    print(f\"{'Conv Layers':<25} {best_genome['num_conv_layers']:<30} {'Conv1D layers':<25}\")\n",
    "    print(f\"{'FC Layers':<25} {best_genome['num_fc_layers']:<30} {'FC layers':<25}\")\n",
    "    print(f\"{'Optimizer':<25} {best_genome['optimizer']:<30} {'Optimization algorithm':<25}\")\n",
    "    print(f\"{'Learning Rate':<25} {best_genome['learning_rate']:<30.6f} {'Learning rate':<25}\")\n",
    "    print(f\"{'Dropout':<25} {best_genome['dropout_rate']:<30} {'Dropout rate':<25}\")\n",
    "    print(f\"{'Input Length':<25} {config['sequence_length']:<30} {'Audio sequence length':<25}\")\n",
    "    print(f\"{'Classes':<25} {config['num_classes']:<30} {'Binary classification':<25}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Comparison with initial configuration\n",
    "    print(f\"\\nCOMPARISON WITH OBJECTIVES:\")\n",
    "    if best_genome['fitness'] >= config['fitness_threshold']:\n",
    "        print(f\"   âœ“ TARGET REACHED: {best_genome['fitness']:.2f}% >= {config['fitness_threshold']}%\")\n",
    "    else:\n",
    "        print(f\"   âœ— TARGET NOT REACHED: {best_genome['fitness']:.2f}% < {config['fitness_threshold']}%\")\n",
    "        print(f\"     Gap: {config['fitness_threshold'] - best_genome['fitness']:.2f}%\")\n",
    "    \n",
    "    print(f\"   Generations used: {neuroevolution.generation}/{config['max_generations']}\")\n",
    "    \n",
    "    # Save information to JSON\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"best_architecture_audio_{timestamp}.json\"\n",
    "    \n",
    "    results_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'execution_time': str(execution_time),\n",
    "        'dataset_type': 'audio_1D',\n",
    "        'dataset_id': config.get('dataset_id', 'N/A'),\n",
    "        'fold': config.get('current_fold', 'N/A'),\n",
    "        'config_used': {k: v for k, v in config.items() if not k.startswith('_')},\n",
    "        'best_genome': best_genome,\n",
    "        'final_generation': neuroevolution.generation,\n",
    "        'evolution_stats': neuroevolution.generation_stats\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2, default=str)\n",
    "        print(f\"\\nâœ“ Results saved to: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— WARNING: Error saving results: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HYBRID NEUROEVOLUTION FOR AUDIO COMPLETED!\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Show the best architecture found\n",
    "display_best_architecture(best_genome, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d17f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFORMACIÃ“N DEL CHECKPOINT DEL MEJOR MODELO\n",
      "================================================================================\n",
      "\n",
      "âœ“ Checkpoint guardado en: checkpoints/best_model_gen14_id7cf1d714_fitness70.92.pth\n",
      "  TamaÃ±o: 3.06 MB\n",
      "\n",
      "  InformaciÃ³n del modelo guardado:\n",
      "    GeneraciÃ³n: 14\n",
      "    Fitness: 70.92%\n",
      "    ID Genoma: 7cf1d714\n",
      "    Arquitectura: 12 Conv1D + 4 FC\n",
      "    Optimizador: rmsprop\n",
      "    Learning Rate: 0.0005\n",
      "\n",
      "  Este checkpoint se usarÃ¡ como punto de partida para el 5-fold CV\n",
      "  (Transfer learning desde el modelo pre-entrenado)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar informaciÃ³n del checkpoint guardado\n",
    "print(\"=\"*80)\n",
    "print(\"INFORMACIÃ“N DEL CHECKPOINT DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if neuroevolution.best_checkpoint_path:\n",
    "    print(f\"\\nâœ“ Checkpoint guardado en: {neuroevolution.best_checkpoint_path}\")\n",
    "    \n",
    "    # Obtener informaciÃ³n del archivo\n",
    "    import os\n",
    "    if os.path.exists(neuroevolution.best_checkpoint_path):\n",
    "        file_size = os.path.getsize(neuroevolution.best_checkpoint_path)\n",
    "        file_size_mb = file_size / (1024 * 1024)\n",
    "        print(f\"  TamaÃ±o: {file_size_mb:.2f} MB\")\n",
    "        \n",
    "        # Cargar y mostrar informaciÃ³n del checkpoint\n",
    "        checkpoint_data = torch.load(neuroevolution.best_checkpoint_path, map_location=device, weights_only=False)\n",
    "        print(f\"\\n  InformaciÃ³n del modelo guardado:\")\n",
    "        print(f\"    GeneraciÃ³n: {checkpoint_data['generation']}\")\n",
    "        print(f\"    Fitness: {checkpoint_data['fitness']:.2f}%\")\n",
    "        print(f\"    ID Genoma: {checkpoint_data['genome']['id']}\")\n",
    "        print(f\"    Arquitectura: {checkpoint_data['genome']['num_conv_layers']} Conv1D + {checkpoint_data['genome']['num_fc_layers']} FC\")\n",
    "        print(f\"    Optimizador: {checkpoint_data['genome']['optimizer']}\")\n",
    "        print(f\"    Learning Rate: {checkpoint_data['genome']['learning_rate']}\")\n",
    "        \n",
    "        print(f\"\\n  Este checkpoint se usarÃ¡ como punto de partida para el 5-fold CV\")\n",
    "        print(f\"  (Transfer learning desde el modelo pre-entrenado)\")\n",
    "    else:\n",
    "        print(f\"  âœ— Archivo no encontrado\")\n",
    "else:\n",
    "    print(\"\\nâœ— No hay checkpoint disponible\")\n",
    "    print(\"  El 5-fold CV entrenarÃ¡ desde cero\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cb925",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”„ Resumen del Flujo con Checkpoints\n",
    "\n",
    "```\n",
    "PROCESO DE NEUROEVOLUCIÃ“N CON CHECKPOINTS:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. EVOLUCIÃ“N (MÃºltiples Generaciones)\n",
    "   â”‚\n",
    "   â”œâ”€ Para cada individuo:\n",
    "   â”‚  â”œâ”€ Entrenar y evaluar\n",
    "   â”‚  â”œâ”€ Calcular fitness\n",
    "   â”‚  â”‚\n",
    "   â”‚  â””â”€ SI fitness > mejor_global:\n",
    "   â”‚     â”œâ”€ ðŸŒŸ NUEVO MEJOR GLOBAL\n",
    "   â”‚     â”œâ”€ âœ— Eliminar checkpoint anterior\n",
    "   â”‚     â””â”€ âœ“ Guardar nuevo checkpoint\n",
    "   â”‚\n",
    "   â””â”€ Continuar hasta convergencia\n",
    "\n",
    "2. AL FINALIZAR LA EVOLUCIÃ“N\n",
    "   â”‚\n",
    "   â””â”€ Se tiene el checkpoint del MEJOR modelo global\n",
    "\n",
    "3. EVALUACIÃ“N 5-FOLD CROSS-VALIDATION\n",
    "   â”‚\n",
    "   â”œâ”€ âœ“ Cargar checkpoint del mejor modelo\n",
    "   â”‚\n",
    "   â”œâ”€ Para cada fold (1 a 5):\n",
    "   â”‚  â”œâ”€ Crear modelo nuevo\n",
    "   â”‚  â”œâ”€ Inicializar con pesos pre-entrenados (Transfer Learning)\n",
    "   â”‚  â”œâ”€ Fine-tuning con datos del fold\n",
    "   â”‚  â””â”€ Evaluar y guardar mÃ©tricas\n",
    "   â”‚\n",
    "   â””â”€ Calcular promedios y desviaciones estÃ¡ndar\n",
    "\n",
    "4. RESULTADOS FINALES\n",
    "   â””â”€ MÃ©tricas robustas para la tabla de comparaciÃ³n\n",
    "```\n",
    "\n",
    "### âœ¨ Beneficios de este enfoque:\n",
    "\n",
    "- âœ… **Ahorro de espacio**: Solo 1 checkpoint (el mejor)\n",
    "- âœ… **Eficiencia**: Transfer learning en lugar de entrenar desde cero\n",
    "- âœ… **Robustez**: MÃ©tricas con 5-fold CV\n",
    "- âœ… **Trazabilidad**: Se mantiene el historial del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acc991",
   "metadata": {},
   "source": [
    "## ðŸ“ Nota Importante\n",
    "\n",
    "**Este enfoque tiene mucho sentido porque:**\n",
    "\n",
    "1. **Durante la evoluciÃ³n**, cada vez que un modelo supera el mejor fitness global:\n",
    "   - Se guarda automÃ¡ticamente su checkpoint\n",
    "   - Se elimina el checkpoint anterior (ahorro de espacio)\n",
    "   - Se asegura que siempre tenemos el mejor modelo disponible\n",
    "\n",
    "2. **Para la evaluaciÃ³n 5-fold CV**:\n",
    "   - En lugar de entrenar 5 modelos desde cero (aleatorio)\n",
    "   - Se usan los pesos pre-entrenados del mejor modelo como inicio\n",
    "   - Esto es **Transfer Learning**, que tÃ­picamente da mejores resultados\n",
    "   - Cada fold hace fine-tuning con sus propios datos\n",
    "\n",
    "3. **Ventajas prÃ¡cticas**:\n",
    "   - Si el proceso se interrumpe, no se pierde el mejor modelo\n",
    "   - Se puede reanudar la evaluaciÃ³n 5-fold desde el checkpoint\n",
    "   - Las mÃ©tricas son mÃ¡s estables y representativas\n",
    "   - Se optimiza el uso de recursos (disco y tiempo de entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375b04a",
   "metadata": {},
   "source": [
    "## 10. EvaluaciÃ³n Completa de MÃ©tricas (Tabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9088a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando evaluaciÃ³n 5-fold cross-validation de la mejor arquitectura...\n",
      "\n",
      "Usando el checkpoint del mejor modelo encontrado durante la evoluciÃ³n.\n",
      "\n",
      "================================================================================\n",
      "EVALUACIÃ“N 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Arquitectura a evaluar:\n",
      "   Conv1D Layers: 12\n",
      "   FC Layers: 4\n",
      "   Optimizer: rmsprop\n",
      "   Learning Rate: 0.0005\n",
      "   Ã‰pocas por fold: 20\n",
      "\n",
      "Intentando cargar checkpoint del mejor modelo...\n",
      "âœ“ Checkpoint cargado exitosamente: checkpoints/best_model_gen14_id7cf1d714_fitness70.92.pth\n",
      "  Fitness: 70.92%, Gen: 14, ID: 7cf1d714\n",
      "âœ“ Checkpoint cargado exitosamente\n",
      "  Los modelos de cada fold se inicializarÃ¡n con estos pesos pre-entrenados\n",
      "\n",
      "\n",
      "Cargando datos del Fold 1...\n",
      "   Train batches: 136\n",
      "   Test batches: 56\n",
      "\n",
      "======================================================================\n",
      "FOLD 1/5\n",
      "======================================================================\n",
      "   Inicializando desde modelo pre-entrenado...\n",
      "   âœ“ Pesos pre-entrenados cargados exitosamente\n",
      "Entrenando por 20 Ã©pocas...\n",
      "   Ã‰poca 1/20: loss=0.2372\n",
      "   Ã‰poca 5/20: loss=0.2097\n",
      "   Ã‰poca 10/20: loss=0.2066\n",
      "   Ã‰poca 15/20: loss=0.2042\n",
      "   Ã‰poca 20/20: loss=0.2017\n",
      "Evaluando...\n",
      "\n",
      "Resultados Fold 1:\n",
      "   Accuracy:     51.95%\n",
      "   Sensitivity:  71.81%\n",
      "   Specificity:  32.09%\n",
      "   F1-Score:     59.91%\n",
      "   AUC:          55.32%\n",
      "\n",
      "\n",
      "Cargando datos del Fold 2...\n",
      "   Train batches: 132\n",
      "   Test batches: 60\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/5\n",
      "======================================================================\n",
      "   Inicializando desde modelo pre-entrenado...\n",
      "   âœ“ Pesos pre-entrenados cargados exitosamente\n",
      "Entrenando por 20 Ã©pocas...\n",
      "   Ã‰poca 1/20: loss=0.4983\n",
      "   Ã‰poca 5/20: loss=0.2713\n",
      "   Ã‰poca 10/20: loss=0.2430\n",
      "   Ã‰poca 15/20: loss=0.2339\n",
      "   Ã‰poca 20/20: loss=0.2208\n",
      "Evaluando...\n",
      "\n",
      "Resultados Fold 2:\n",
      "   Accuracy:     51.85%\n",
      "   Sensitivity:  29.47%\n",
      "   Specificity:  74.23%\n",
      "   F1-Score:     37.97%\n",
      "   AUC:          54.54%\n",
      "\n",
      "\n",
      "Cargando datos del Fold 3...\n",
      "   Train batches: 134\n",
      "   Test batches: 58\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/5\n",
      "======================================================================\n",
      "   Inicializando desde modelo pre-entrenado...\n",
      "   âœ“ Pesos pre-entrenados cargados exitosamente\n",
      "Entrenando por 20 Ã©pocas...\n",
      "   Ã‰poca 1/20: loss=0.5462\n",
      "   Ã‰poca 5/20: loss=0.2677\n",
      "   Ã‰poca 10/20: loss=0.2431\n",
      "   Ã‰poca 15/20: loss=0.2259\n",
      "   Ã‰poca 20/20: loss=0.2194\n",
      "Evaluando...\n",
      "\n",
      "Resultados Fold 3:\n",
      "   Accuracy:     57.57%\n",
      "   Sensitivity:  54.04%\n",
      "   Specificity:  61.09%\n",
      "   F1-Score:     56.02%\n",
      "   AUC:          57.96%\n",
      "\n",
      "\n",
      "Cargando datos del Fold 4...\n",
      "   Train batches: 136\n",
      "   Test batches: 56\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/5\n",
      "======================================================================\n",
      "   Inicializando desde modelo pre-entrenado...\n",
      "   âœ“ Pesos pre-entrenados cargados exitosamente\n",
      "Entrenando por 20 Ã©pocas...\n",
      "   Ã‰poca 1/20: loss=0.5110\n",
      "   Ã‰poca 5/20: loss=0.2547\n",
      "   Ã‰poca 10/20: loss=0.2221\n",
      "   Ã‰poca 15/20: loss=0.2155\n",
      "   Ã‰poca 20/20: loss=0.2064\n",
      "Evaluando...\n",
      "\n",
      "Resultados Fold 4:\n",
      "   Accuracy:     51.36%\n",
      "   Sensitivity:  48.70%\n",
      "   Specificity:  54.01%\n",
      "   F1-Score:     50.03%\n",
      "   AUC:          54.46%\n",
      "\n",
      "\n",
      "Cargando datos del Fold 5...\n",
      "   Train batches: 138\n",
      "   Test batches: 54\n",
      "\n",
      "======================================================================\n",
      "FOLD 5/5\n",
      "======================================================================\n",
      "   Inicializando desde modelo pre-entrenado...\n",
      "   âœ“ Pesos pre-entrenados cargados exitosamente\n",
      "Entrenando por 20 Ã©pocas...\n",
      "   Ã‰poca 1/20: loss=0.5133\n",
      "   Ã‰poca 5/20: loss=0.2580\n",
      "   Ã‰poca 10/20: loss=0.2313\n",
      "   Ã‰poca 15/20: loss=0.2202\n",
      "   Ã‰poca 20/20: loss=0.2141\n",
      "Evaluando...\n",
      "\n",
      "Resultados Fold 5:\n",
      "   Accuracy:     44.21%\n",
      "   Sensitivity:  39.24%\n",
      "   Specificity:  49.18%\n",
      "   F1-Score:     41.29%\n",
      "   AUC:          44.89%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS AGREGADOS (5-FOLD CROSS-VALIDATION)\n",
      "================================================================================\n",
      "\n",
      "RESULTADOS POR FOLD:\n",
      "Fold   Accuracy     Sensitivity    Specificity    F1-Score     AUC         \n",
      "--------------------------------------------------------------------------------\n",
      "1       51.95%       71.81%         32.09%         59.91%       55.32%\n",
      "2       51.85%       29.47%         74.23%         37.97%       54.54%\n",
      "3       57.57%       54.04%         61.09%         56.02%       57.96%\n",
      "4       51.36%       48.70%         54.01%         50.03%       54.46%\n",
      "5       44.21%       39.24%         49.18%         41.29%       44.89%\n",
      "--------------------------------------------------------------------------------\n",
      "Mean    51.39%       48.65%         54.12%         49.04%       53.43%\n",
      "Std      4.25%       14.30%         13.88%          8.37%        4.46%\n",
      "\n",
      "================================================================================\n",
      "FORMATO PARA TABLA\n",
      "================================================================================\n",
      "\n",
      "MÃ‰TRICAS FINALES (promedio Â± desviaciÃ³n estÃ¡ndar):\n",
      "   Accuracy:     51.39% Â± 4.25%\n",
      "   Sensitivity:  48.65% Â± 14.30%\n",
      "   Specificity:  54.12% Â± 13.88%\n",
      "   F1-Score:     49.04% Â± 8.37%\n",
      "   AUC:          53.43% Â± 4.46%\n",
      "\n",
      "FORMATO PARA TABLA (valores en escala 0-1):\n",
      "   Model: Neuroevolution-12Conv1D+4FC\n",
      "   Accuracy:     0.51 (4%)\n",
      "   Sensitivity:  0.49 (14%)\n",
      "   Specificity:  0.54 (13%)\n",
      "   F1-Score:     0.49 (8%)\n",
      "   AUC:          0.53 (4%)\n",
      "\n",
      "FORMATO LaTeX:\n",
      "   Neuroevolution-12Conv1D+4FC & 0.51 (4\\%) & 0.49 (14\\%) & 0.54 (13\\%) & 0.49 (8\\%) & 0.53 (4\\%) \\\\\n",
      "\n",
      "FORMATO Markdown:\n",
      "   | Neuroevolution-12Conv1D+4FC | 0.51 (4%) | 0.49 (14%) | 0.54 (13%) | 0.49 (8%) | 0.53 (4%) |\n",
      "\n",
      "âœ“ Resultados guardados en: 5fold_cv_results_20251027_171048.json\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def load_fold_data(config, fold_number):\n",
    "    \"\"\"\n",
    "    Carga los datos de un fold especÃ­fico.\n",
    "    \n",
    "    Args:\n",
    "        config: ConfiguraciÃ³n del sistema\n",
    "        fold_number: NÃºmero de fold (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple de (train_loader, test_loader) para ese fold\n",
    "    \"\"\"\n",
    "    fold_files_directory = os.path.join(\n",
    "        config['data_path'], \n",
    "        f\"files_{config['fold_id']}\"\n",
    "    )\n",
    "    \n",
    "    fold_index = fold_number\n",
    "    dataset_id = config['dataset_id']\n",
    "    \n",
    "    # Cargar datos del fold\n",
    "    x_train = np.load(os.path.join(fold_files_directory, f'X_train_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    y_train = np.load(os.path.join(fold_files_directory, f'y_train_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    x_val = np.load(os.path.join(fold_files_directory, f'X_val_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    y_val = np.load(os.path.join(fold_files_directory, f'y_val_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    x_test = np.load(os.path.join(fold_files_directory, f'X_test_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    y_test = np.load(os.path.join(fold_files_directory, f'y_test_{dataset_id}_fold_{fold_index}.npy'))\n",
    "    \n",
    "    # Reshape si es necesario\n",
    "    if len(x_train.shape) == 2:\n",
    "        x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "        x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "        x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "    \n",
    "    # Convertir a tensores\n",
    "    x_train_tensor = torch.FloatTensor(x_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train.astype(np.int64))\n",
    "    x_val_tensor = torch.FloatTensor(x_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val.astype(np.int64))\n",
    "    x_test_tensor = torch.FloatTensor(x_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test.astype(np.int64))\n",
    "    \n",
    "    # Crear datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    x_eval = torch.cat([x_val_tensor, x_test_tensor], dim=0)\n",
    "    y_eval = torch.cat([y_val_tensor, y_test_tensor], dim=0)\n",
    "    test_dataset = torch.utils.data.TensorDataset(x_eval, y_eval)\n",
    "    \n",
    "    # Crear DataLoaders\n",
    "    fold_train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    fold_test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    return fold_train_loader, fold_test_loader\n",
    "\n",
    "\n",
    "def evaluate_single_fold(best_genome, config, fold_train_loader, fold_test_loader, fold_num, num_epochs=20, use_pretrained=False, pretrained_model=None):\n",
    "    \"\"\"\n",
    "    Entrena y evalÃºa el modelo en un solo fold.\n",
    "    \n",
    "    Args:\n",
    "        best_genome: Genoma de la mejor arquitectura\n",
    "        config: ConfiguraciÃ³n del sistema\n",
    "        fold_train_loader: DataLoader de entrenamiento del fold\n",
    "        fold_test_loader: DataLoader de test del fold\n",
    "        fold_num: NÃºmero del fold\n",
    "        num_epochs: Ã‰pocas de entrenamiento\n",
    "        use_pretrained: Si True, usa el modelo pre-entrenado como inicio\n",
    "        pretrained_model: Modelo pre-entrenado opcional\n",
    "    \n",
    "    Returns:\n",
    "        dict: MÃ©tricas del fold\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {fold_num}/5\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Crear modelo nuevo para este fold\n",
    "    model = EvolvableCNN(best_genome, config).to(device)\n",
    "    \n",
    "    # Si hay un modelo pre-entrenado, copiar sus pesos como punto de partida\n",
    "    if use_pretrained and pretrained_model is not None:\n",
    "        print(\"   Inicializando desde modelo pre-entrenado...\")\n",
    "        try:\n",
    "            model.load_state_dict(pretrained_model.state_dict())\n",
    "            print(\"   âœ“ Pesos pre-entrenados cargados exitosamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âœ— Error cargando pesos pre-entrenados: {e}\")\n",
    "            print(\"   Continuando con pesos aleatorios...\")\n",
    "    \n",
    "    # Configurar optimizer y criterion\n",
    "    optimizer_class = OPTIMIZERS[best_genome['optimizer']]\n",
    "    optimizer = optimizer_class(model.parameters(), lr=best_genome['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Entrenamiento\n",
    "    print(f\"Entrenando por {num_epochs} Ã©pocas...\")\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for data, target in fold_train_loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        avg_loss = running_loss / max(1, batch_count)\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"   Ã‰poca {epoch}/{num_epochs}: loss={avg_loss:.4f}\")\n",
    "    \n",
    "    # EvaluaciÃ³n\n",
    "    print(\"Evaluando...\")\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in fold_test_loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Probabilidades para AUC\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            \n",
    "            # Predicciones\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    y_true = np.array(all_targets)\n",
    "    y_pred = np.array(all_predictions)\n",
    "    y_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calcular mÃ©tricas\n",
    "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1, zero_division=0) * 100\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0, zero_division=0) * 100\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0) * 100\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_probs[:, 1]) * 100\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nResultados Fold {fold_num}:\")\n",
    "    print(f\"   Accuracy:     {accuracy:.2f}%\")\n",
    "    print(f\"   Sensitivity:  {sensitivity:.2f}%\")\n",
    "    print(f\"   Specificity:  {specificity:.2f}%\")\n",
    "    print(f\"   F1-Score:     {f1:.2f}%\")\n",
    "    print(f\"   AUC:          {auc:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_num,\n",
    "        'accuracy': accuracy,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'n_samples': len(y_true)\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_5fold_cross_validation(best_genome, config, num_epochs=20, neuroevolution_instance=None):\n",
    "    \"\"\"\n",
    "    EvalÃºa la mejor arquitectura usando 5-fold cross-validation.\n",
    "    Utiliza el checkpoint del mejor modelo si estÃ¡ disponible.\n",
    "    \n",
    "    Args:\n",
    "        best_genome: Genoma de la mejor arquitectura\n",
    "        config: ConfiguraciÃ³n del sistema\n",
    "        num_epochs: Ã‰pocas de entrenamiento por fold\n",
    "        neuroevolution_instance: Instancia de HybridNeuroevolution para cargar checkpoint\n",
    "    \n",
    "    Returns:\n",
    "        dict: Resultados agregados de todos los folds\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EVALUACIÃ“N 5-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nArquitectura a evaluar:\")\n",
    "    print(f\"   Conv1D Layers: {best_genome['num_conv_layers']}\")\n",
    "    print(f\"   FC Layers: {best_genome['num_fc_layers']}\")\n",
    "    print(f\"   Optimizer: {best_genome['optimizer']}\")\n",
    "    print(f\"   Learning Rate: {best_genome['learning_rate']}\")\n",
    "    print(f\"   Ã‰pocas por fold: {num_epochs}\")\n",
    "    \n",
    "    # Intentar cargar el checkpoint del mejor modelo\n",
    "    pretrained_model = None\n",
    "    use_pretrained = False\n",
    "    \n",
    "    if neuroevolution_instance is not None:\n",
    "        print(f\"\\nIntentando cargar checkpoint del mejor modelo...\")\n",
    "        genome_from_checkpoint, pretrained_model = neuroevolution_instance.load_best_checkpoint()\n",
    "        \n",
    "        if pretrained_model is not None:\n",
    "            use_pretrained = True\n",
    "            print(f\"âœ“ Checkpoint cargado exitosamente\")\n",
    "            print(f\"  Los modelos de cada fold se inicializarÃ¡n con estos pesos pre-entrenados\")\n",
    "        else:\n",
    "            print(f\"âœ— No se pudo cargar checkpoint, se entrenarÃ¡n desde cero\")\n",
    "    else:\n",
    "        print(f\"\\nNo se proporcionÃ³ instancia de neuroevolution, entrenando desde cero\")\n",
    "    \n",
    "    # Almacenar resultados de cada fold\n",
    "    fold_results = []\n",
    "    \n",
    "    # Evaluar cada fold\n",
    "    for fold_num in range(1, 6):  # 5 folds\n",
    "        print(f\"\\n\\nCargando datos del Fold {fold_num}...\")\n",
    "        \n",
    "        try:\n",
    "            fold_train_loader, fold_test_loader = load_fold_data(config, fold_num)\n",
    "            print(f\"   Train batches: {len(fold_train_loader)}\")\n",
    "            print(f\"   Test batches: {len(fold_test_loader)}\")\n",
    "            \n",
    "            # Evaluar este fold (usando modelo pre-entrenado si estÃ¡ disponible)\n",
    "            fold_result = evaluate_single_fold(\n",
    "                best_genome, \n",
    "                config, \n",
    "                fold_train_loader, \n",
    "                fold_test_loader, \n",
    "                fold_num, \n",
    "                num_epochs,\n",
    "                use_pretrained=use_pretrained,\n",
    "                pretrained_model=pretrained_model\n",
    "            )\n",
    "            fold_results.append(fold_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ERROR en Fold {fold_num}: {e}\")\n",
    "            print(f\"   Saltando este fold...\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Calcular estadÃ­sticas agregadas\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS AGREGADOS (5-FOLD CROSS-VALIDATION)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not fold_results:\n",
    "        print(\"ERROR: No se pudo evaluar ningÃºn fold\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer mÃ©tricas de todos los folds\n",
    "    accuracies = [r['accuracy'] for r in fold_results]\n",
    "    sensitivities = [r['sensitivity'] for r in fold_results]\n",
    "    specificities = [r['specificity'] for r in fold_results]\n",
    "    f1_scores = [r['f1_score'] for r in fold_results]\n",
    "    aucs = [r['auc'] for r in fold_results]\n",
    "    \n",
    "    # Calcular promedios y desviaciones estÃ¡ndar\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    mean_sensitivity = np.mean(sensitivities)\n",
    "    std_sensitivity = np.std(sensitivities)\n",
    "    \n",
    "    mean_specificity = np.mean(specificities)\n",
    "    std_specificity = np.std(specificities)\n",
    "    \n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    \n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    # Mostrar resultados por fold\n",
    "    print(f\"\\nRESULTADOS POR FOLD:\")\n",
    "    print(f\"{'Fold':<6} {'Accuracy':<12} {'Sensitivity':<14} {'Specificity':<14} {'F1-Score':<12} {'AUC':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    for r in fold_results:\n",
    "        print(f\"{r['fold']:<6} {r['accuracy']:>6.2f}%      {r['sensitivity']:>6.2f}%        {r['specificity']:>6.2f}%        {r['f1_score']:>6.2f}%      {r['auc']:>6.2f}%\")\n",
    "    \n",
    "    # Mostrar promedios\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Mean':<6} {mean_accuracy:>6.2f}%      {mean_sensitivity:>6.2f}%        {mean_specificity:>6.2f}%        {mean_f1:>6.2f}%      {mean_auc:>6.2f}%\")\n",
    "    print(f\"{'Std':<6} {std_accuracy:>6.2f}%      {std_sensitivity:>6.2f}%        {std_specificity:>6.2f}%        {std_f1:>6.2f}%      {std_auc:>6.2f}%\")\n",
    "    \n",
    "    # Resultados finales\n",
    "    results = {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_accuracy': std_accuracy,\n",
    "        'mean_sensitivity': mean_sensitivity,\n",
    "        'std_sensitivity': std_sensitivity,\n",
    "        'mean_specificity': mean_specificity,\n",
    "        'std_specificity': std_specificity,\n",
    "        'mean_f1': mean_f1,\n",
    "        'std_f1': std_f1,\n",
    "        'mean_auc': mean_auc,\n",
    "        'std_auc': std_auc,\n",
    "        'n_folds': len(fold_results),\n",
    "        'architecture': f\"{best_genome['num_conv_layers']}Conv1D+{best_genome['num_fc_layers']}FC\"\n",
    "    }\n",
    "    \n",
    "    # Formato para tabla\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FORMATO PARA TABLA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nMÃ‰TRICAS FINALES (promedio Â± desviaciÃ³n estÃ¡ndar):\")\n",
    "    print(f\"   Accuracy:     {mean_accuracy:.2f}% Â± {std_accuracy:.2f}%\")\n",
    "    print(f\"   Sensitivity:  {mean_sensitivity:.2f}% Â± {std_sensitivity:.2f}%\")\n",
    "    print(f\"   Specificity:  {mean_specificity:.2f}% Â± {std_specificity:.2f}%\")\n",
    "    print(f\"   F1-Score:     {mean_f1:.2f}% Â± {std_f1:.2f}%\")\n",
    "    print(f\"   AUC:          {mean_auc:.2f}% Â± {std_auc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nFORMATO PARA TABLA (valores en escala 0-1):\")\n",
    "    print(f\"   Model: Neuroevolution-{results['architecture']}\")\n",
    "    print(f\"   Accuracy:     {mean_accuracy/100:.2f} ({int(std_accuracy)}%)\")\n",
    "    print(f\"   Sensitivity:  {mean_sensitivity/100:.2f} ({int(std_sensitivity)}%)\")\n",
    "    print(f\"   Specificity:  {mean_specificity/100:.2f} ({int(std_specificity)}%)\")\n",
    "    print(f\"   F1-Score:     {mean_f1/100:.2f} ({int(std_f1)}%)\")\n",
    "    print(f\"   AUC:          {mean_auc/100:.2f} ({int(std_auc)}%)\")\n",
    "    \n",
    "    print(f\"\\nFORMATO LaTeX:\")\n",
    "    latex_row = f\"Neuroevolution-{results['architecture']} & {mean_accuracy/100:.2f} ({int(std_accuracy)}\\\\%) & {mean_sensitivity/100:.2f} ({int(std_sensitivity)}\\\\%) & {mean_specificity/100:.2f} ({int(std_specificity)}\\\\%) & {mean_f1/100:.2f} ({int(std_f1)}\\\\%) & {mean_auc/100:.2f} ({int(std_auc)}\\\\%) \\\\\\\\\"\n",
    "    print(f\"   {latex_row}\")\n",
    "    \n",
    "    print(f\"\\nFORMATO Markdown:\")\n",
    "    markdown_row = f\"| Neuroevolution-{results['architecture']} | {mean_accuracy/100:.2f} ({int(std_accuracy)}%) | {mean_sensitivity/100:.2f} ({int(std_sensitivity)}%) | {mean_specificity/100:.2f} ({int(std_specificity)}%) | {mean_f1/100:.2f} ({int(std_f1)}%) | {mean_auc/100:.2f} ({int(std_auc)}%) |\"\n",
    "    print(f\"   {markdown_row}\")\n",
    "    \n",
    "    # Guardar resultados\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"5fold_cv_results_{timestamp}.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        print(f\"\\nâœ“ Resultados guardados en: {results_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error guardando resultados: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Ejecutar evaluaciÃ³n 5-fold cross-validation\n",
    "print(\"Iniciando evaluaciÃ³n 5-fold cross-validation de la mejor arquitectura...\\n\")\n",
    "print(\"Usando el checkpoint del mejor modelo encontrado durante la evoluciÃ³n.\\n\")\n",
    "cv_results = evaluate_5fold_cross_validation(best_genome, CONFIG, num_epochs=20, neuroevolution_instance=neuroevolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2964f-0098-4c42-bf72-e66c4ca0ed5a",
   "metadata": {},
   "source": [
    "## 10. EvaluaciÃ³n 5-Fold Cross-Validation con Checkpoint\n",
    "\n",
    "Esta secciÃ³n evalÃºa la mejor arquitectura encontrada usando **5-fold cross-validation**.\n",
    "\n",
    "### ðŸŽ¯ Ventajas del enfoque con checkpoints:\n",
    "\n",
    "1. **Eficiencia**: Se guarda el mejor modelo durante la evoluciÃ³n (no se reentrena desde cero)\n",
    "2. **Transfer Learning**: Los pesos pre-entrenados sirven como punto de partida para cada fold\n",
    "3. **GestiÃ³n de espacio**: Solo se mantiene el checkpoint del mejor modelo global\n",
    "4. **Robustez**: MÃ©tricas mÃ¡s confiables con intervalos de confianza\n",
    "\n",
    "### ðŸ“Š Proceso:\n",
    "\n",
    "1. Se carga el checkpoint del mejor modelo encontrado\n",
    "2. Para cada fold:\n",
    "   - Se inicializa un modelo con los pesos pre-entrenados\n",
    "   - Se fine-tunea con los datos de entrenamiento del fold\n",
    "   - Se evalÃºa en los datos de test del fold\n",
    "3. Se calculan mÃ©tricas agregadas (promedio Â± desviaciÃ³n estÃ¡ndar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
